{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Agent Tools with FastMCP\n",
    "\n",
    "> Computational Analysis of Social Complexity\n",
    ">\n",
    "> Fall 2025, Spencer Lyon\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- L.A2.01 (Function calling and tool use)\n",
    "- L.A2.02 (Type-safe agents with PydanticAI)\n",
    "- L.A2.03 (Agent evaluations)\n",
    "- Basic understanding of client-server architecture\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Understand the Model Context Protocol (MCP) and its role in the AI ecosystem\n",
    "- Create MCP servers using FastMCP to expose computational tools\n",
    "- Integrate MCP servers with PydanticAI agents for distributed tool access\n",
    "- Deploy and test MCP servers in multiple environments (local, HTTP, Claude Desktop)\n",
    "- Apply MCP patterns to course domains: network analysis, game theory, and agent-based models\n",
    "\n",
    "**References**\n",
    "\n",
    "- [Model Context Protocol Specification](https://modelcontextprotocol.io/)\n",
    "- [FastMCP Documentation](https://gofastmcp.com/)\n",
    "- [FastMCP GitHub Repository](https://github.com/jlowin/fastmcp)\n",
    "- [Anthropic MCP Announcement](https://www.anthropic.com/news/model-context-protocol)\n",
    "- [PydanticAI Documentation](https://ai.pydantic.dev/)\n",
    "- [NetworkX Documentation](https://networkx.org/)\n",
    "- [Mesa Documentation](https://mesa.readthedocs.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Embedded Tools to Distributed Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: The Week A2 Pattern\n",
    "\n",
    "Last week, we learned how to build AI agents with tools using PydanticAI.\n",
    "\n",
    "The pattern looked like this:\n",
    "\n",
    "```python\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "agent = Agent('anthropic:claude-haiku-4-5')\n",
    "\n",
    "@agent.tool\n",
    "def calculate_degree_centrality(graph_id: str, node: int) -> float:\n",
    "    \"\"\"Calculate degree centrality for a node in a network.\"\"\"\n",
    "    # Implementation here\n",
    "    return centrality_score\n",
    "```\n",
    "\n",
    "This works beautifully. The agent can call our tools, we get type safety, and everything lives in one Python process.\n",
    "\n",
    "But there's a problem.\n",
    "\n",
    "### The Reusability Problem\n",
    "\n",
    "Suppose you've built an amazing network analysis toolkit:\n",
    "- Calculate centrality measures\n",
    "- Find communities\n",
    "- Compute shortest paths\n",
    "- Analyze network structure\n",
    "\n",
    "You spent hours implementing it with proper validation, error handling, and optimization.\n",
    "\n",
    "Now you want to use these tools in:\n",
    "1. Your PydanticAI agent for research\n",
    "2. A ChatGPT plugin for students\n",
    "3. A Claude Desktop integration\n",
    "4. An API for your web app\n",
    "5. A Jupyter notebook assistant\n",
    "\n",
    "**Problem**: You have to reimplement the tools for each platform.\n",
    "\n",
    "- ChatGPT wants OpenAPI spec\n",
    "- Claude wants their tool format\n",
    "- Your API needs REST endpoints\n",
    "- Each has different authentication, deployment, testing\n",
    "\n",
    "You end up maintaining **5 different implementations** of the same tools.\n",
    "\n",
    "This is the **reusability problem**.\n",
    "\n",
    "### The Integration Challenge\n",
    "\n",
    "It gets worse.\n",
    "\n",
    "When you write tools with `@agent.tool`, they're **locked into PydanticAI**. \n",
    "\n",
    "What if:\n",
    "- You want to use a different agent framework?\n",
    "- You want to share tools with colleagues using different tech stacks?\n",
    "- You want tools to work in Claude Desktop without rewriting them?\n",
    "- You want a student to use your tools from their own application?\n",
    "\n",
    "Each framework has its own way of defining tools. There's no common language.\n",
    "\n",
    "This is the **integration challenge**.\n",
    "\n",
    "### Enter: The Model Context Protocol\n",
    "\n",
    "What if there was a universal standard for AI tools?\n",
    "\n",
    "Like how USB-C works with any device, what if there was \"USB-C for AI\"?\n",
    "\n",
    "**That's the Model Context Protocol (MCP)**.\n",
    "\n",
    "The idea is simple:\n",
    "\n",
    "1. **Write your tools once** as an MCP server\n",
    "2. **Use them anywhere** with any MCP-compatible client\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────┐\n",
    "│     Your MCP Server                 │\n",
    "│  (Network Analysis Tools)           │\n",
    "│                                     │\n",
    "│  - calculate_centrality()           │\n",
    "│  - find_communities()               │\n",
    "│  - shortest_path()                  │\n",
    "└──────────────┬──────────────────────┘\n",
    "               │\n",
    "               │  MCP Protocol\n",
    "               │\n",
    "    ┌──────────┴──────────┐\n",
    "    │                     │\n",
    "    ▼                     ▼\n",
    "┌─────────┐          ┌─────────┐\n",
    "│ Claude  │          │ ChatGPT │\n",
    "│ Desktop │          │  Plugin │\n",
    "└─────────┘          └─────────┘\n",
    "    │                     │\n",
    "    ▼                     ▼\n",
    "┌─────────┐          ┌─────────┐\n",
    "│Pydantic │          │  Your   │\n",
    "│   AI    │          │   App   │\n",
    "└─────────┘          └─────────┘\n",
    "```\n",
    "\n",
    "Write once, use everywhere.\n",
    "\n",
    "### The Three MCP Primitives\n",
    "\n",
    "MCP defines three types of capabilities servers can expose:\n",
    "\n",
    "**1. Tools** (Functions)\n",
    "- Actions the AI can perform\n",
    "- Examples: `calculate_centrality()`, `find_nash_equilibrium()`, `run_simulation()`\n",
    "- What we've been working with in Week A2\n",
    "\n",
    "**2. Resources** (Data)\n",
    "- Read-only access to information\n",
    "- Examples: network datasets, simulation results, research papers\n",
    "- Like files or database queries\n",
    "\n",
    "**3. Prompts** (Templates)\n",
    "- Reusable message templates\n",
    "- Examples: \"Analyze this network\", \"Explain this game theory result\"\n",
    "- Workflows that users can invoke\n",
    "\n",
    "Today we'll focus primarily on **Tools**, with a brief look at Resources and Prompts.\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "Think back to our course themes:\n",
    "\n",
    "**Network Science (Weeks 3-5)**:\n",
    "- You built expertise in graph theory\n",
    "- You know how to calculate centrality, find communities, analyze structure\n",
    "- What if **any AI agent** could access your network analysis capabilities?\n",
    "\n",
    "**Game Theory (Weeks 8-9)**:\n",
    "- You can solve games, find Nash equilibria, analyze auctions\n",
    "- What if researchers could ask an AI to \"solve this game\" and it **actually computes** the answer?\n",
    "\n",
    "**Agent-Based Models (Weeks 6-7)**:\n",
    "- You built simulations of complex systems\n",
    "- What if an AI could **run your simulations** and **interpret the results**?\n",
    "\n",
    "MCP makes this possible.\n",
    "\n",
    "Let's build it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastMCP Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is FastMCP?\n",
    "\n",
    "FastMCP is a Python framework for building production-ready MCP servers.\n",
    "\n",
    "It's created by the same team behind Pydantic (which powers OpenAI SDK, Anthropic SDK, FastAPI, and countless production systems).\n",
    "\n",
    "**Philosophy**: The \"Pydantic way\"\n",
    "- Type-safe by default\n",
    "- Automatic validation\n",
    "- Minimal boilerplate\n",
    "- Production-ready patterns\n",
    "\n",
    "**Core Concepts**:\n",
    "\n",
    "1. **Server Creation**: One line to create an MCP server\n",
    "2. **Tool Decoration**: `@mcp.tool` decorator (just like `@agent.tool`!)\n",
    "3. **Automatic Schema Generation**: From type hints and docstrings\n",
    "4. **Multiple Transports**: stdio (local), HTTP (remote), Claude Desktop\n",
    "\n",
    "Let's see it in action.\n",
    "\n",
    "### Installation\n",
    "\n",
    "First, install FastMCP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastmcp pydantic-ai networkx quantecon mesa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your First MCP Server: Calculator\n",
    "\n",
    "Let's start with the simplest possible MCP server - a calculator.\n",
    "\n",
    "This demonstrates the core pattern we'll use throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Calculator MCP server created with 2 tools\n"
     ]
    }
   ],
   "source": [
    "from fastmcp import FastMCP\n",
    "\n",
    "# Create an MCP server\n",
    "mcp = FastMCP(\"Calculator\")\n",
    "\n",
    "# Define a tool\n",
    "@mcp.tool()\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers together.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "print(\"✓ Calculator MCP server created with 2 tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That's it**.\n",
    "\n",
    "We just created an MCP server with two tools.\n",
    "\n",
    "Notice:\n",
    "- No JSON schema writing (FastMCP generates from type hints)\n",
    "- No manual validation (Pydantic handles it)\n",
    "- No complex setup (one line: `FastMCP(\"Calculator\")`)\n",
    "\n",
    "The pattern is identical to what we learned with PydanticAI:\n",
    "- Type hints for parameters\n",
    "- Docstring for description\n",
    "- Decorator to register the tool\n",
    "\n",
    "### Transport Protocols\n",
    "\n",
    "MCP servers can run in different modes:\n",
    "\n",
    "**1. stdio (Standard Input/Output)**\n",
    "- For local communication\n",
    "- Client launches server as subprocess\n",
    "- Communication via stdin/stdout\n",
    "- Use case: Claude Desktop, local testing\n",
    "\n",
    "**2. StreamableHTTP**\n",
    "- For remote communication\n",
    "- Server runs on HTTP\n",
    "- Clients connect over network\n",
    "- Use case: Production deployments, web apps\n",
    "\n",
    "We'll use stdio for local development and HTTP for production patterns.\n",
    "\n",
    "### Running an MCP Server\n",
    "\n",
    "In production, you'd run the server like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting calculator_server.py\n"
     ]
    }
   ],
   "source": [
    "%%file calculator_server.py\n",
    "\n",
    "# calculator_server.py\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Calculator\")\n",
    "\n",
    "@mcp.tool()\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# Run the server\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()  # stdio by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then from command line:\n",
    "```bash\n",
    "python calculator_server.py\n",
    "```\n",
    "\n",
    "For HTTP:\n",
    "```python\n",
    "mcp.run(transport=\"http\", port=8000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Testing an MCP Server\n",
    "\n",
    "We can test our server programmatically using the FastMCP Client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tools: ['add']\n",
      "5 + 3 = CallToolResult(content=[TextContent(type='text', text='8.0', annotations=None, meta=None)], structured_content={'result': 8.0}, data=8.0, is_error=False)\n",
      "Note: Full client testing requires running server as separate process\n",
      "We'll see integration with PydanticAI shortly\n"
     ]
    }
   ],
   "source": [
    "from fastmcp import Client\n",
    "\n",
    "async with Client(\"calculator_server.py\") as client:\n",
    "    tools = await client.list_tools()\n",
    "    print(\"Available tools:\", [t.name for t in tools])\n",
    "\n",
    "    result = await client.call_tool(\"add\", {\"a\": 5, \"b\": 3})\n",
    "    print(\"5 + 3 =\", result)\n",
    "\n",
    "print(\"Note: Full client testing requires running server as separate process\")\n",
    "print(\"We'll see integration with PydanticAI shortly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insight\n",
    "\n",
    "The calculator server we just built is **immediately usable** by:\n",
    "- Claude Desktop (via `fastmcp install claude-desktop calculator_server.py`)\n",
    "- Any PydanticAI agent (via FastMCP Client)\n",
    "- Custom applications (via MCP protocol)\n",
    "\n",
    "Write once, use everywhere.\n",
    "\n",
    "Now let's build something more interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Course-Specific MCP Servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Analysis MCP Server\n",
    "\n",
    "Remember Weeks 3-5? We studied network science:\n",
    "- Graph theory fundamentals\n",
    "- Centrality measures\n",
    "- Community detection\n",
    "- Network structure\n",
    "\n",
    "Let's build an MCP server that makes these capabilities available to any AI agent.\n",
    "\n",
    "We'll use **NetworkX**, the canonical Python library for network analysis.\n",
    "\n",
    "#### State Management: The Challenge\n",
    "\n",
    "Our network analysis server needs to **remember graphs** between tool calls.\n",
    "\n",
    "When an agent says:\n",
    "1. \"Create a network with these edges\"\n",
    "2. \"Calculate centrality for node 5\"\n",
    "\n",
    "The server needs to remember the graph from step 1.\n",
    "\n",
    "**Important**: FastMCP's Context is **request-scoped** - each tool call gets a fresh context.\n",
    "\n",
    "From the FastMCP documentation:\n",
    "> \"State set during one request will not be available in subsequent requests. For persistent data storage across requests, use external storage mechanisms like databases, files, or in-memory caches.\"\n",
    "\n",
    "**Solution**: Use a **global dictionary** outside of Context. This simple cache persists across tool calls:\n",
    "\n",
    "```python\n",
    "cache: Dict[str, Any] = {}  # Global cache, lives for server lifetime\n",
    "```\n",
    "\n",
    "In production, you'd use Redis, a database, or file storage. For our purposes, a dict works perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting network_analysis_server.py\n"
     ]
    }
   ],
   "source": [
    "%%file network_analysis_server.py\n",
    "\n",
    "# network_analysis_server.py\n",
    "from fastmcp import FastMCP\n",
    "import networkx as nx\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "\n",
    "# Global cache for persistent state across tool calls\n",
    "# MCP Context is request-scoped, so we need external storage\n",
    "# A simple dict works perfectly for our purposes\n",
    "cache: Dict[str, Any] = {}\n",
    "\n",
    "\n",
    "# Create network analysis server\n",
    "network_mcp = FastMCP(\"NetworkAnalysis\")\n",
    "\n",
    "\n",
    "@network_mcp.tool()\n",
    "def create_network(\n",
    "    graph_id: str,\n",
    "    edges: List[Tuple[int, int]]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a network from an edge list and store it.\n",
    "\n",
    "    Args:\n",
    "        graph_id: Unique identifier for this graph (e.g., 'social_network', 'graph1')\n",
    "        edges: List of edges as [source, target] pairs. Example: [[1,2], [2,3], [1,3]]\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with graph statistics (num_nodes, num_edges, density)\n",
    "    \"\"\"\n",
    "    # Create NetworkX graph\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    # Store in global cache (persists across tool calls!)\n",
    "    cache[f\"graph:{graph_id}\"] = G\n",
    "\n",
    "    return {\n",
    "        \"graph_id\": graph_id,\n",
    "        \"num_nodes\": G.number_of_nodes(),\n",
    "        \"num_edges\": G.number_of_edges(),\n",
    "        \"density\": round(nx.density(G), 4)\n",
    "    }\n",
    "\n",
    "\n",
    "@network_mcp.tool()\n",
    "def calculate_degree_centrality(\n",
    "    graph_id: str,\n",
    "    node: int\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calculate degree centrality for a node.\n",
    "\n",
    "    Degree centrality measures how many connections a node has.\n",
    "    Higher values indicate more central/connected nodes.\n",
    "\n",
    "    Args:\n",
    "        graph_id: ID of the graph to analyze\n",
    "        node: The node ID to calculate centrality for\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with degree and normalized centrality value\n",
    "    \"\"\"\n",
    "    # Retrieve graph from global cache\n",
    "    G = cache.get(f\"graph:{graph_id}\")\n",
    "    \n",
    "    if G is None:\n",
    "        return {\"error\": f\"Graph '{graph_id}' not found. Create it first.\"}\n",
    "\n",
    "    if node not in G:\n",
    "        return {\"error\": f\"Node {node} not in graph '{graph_id}'\"}\n",
    "\n",
    "    degree = G.degree(node)\n",
    "    max_possible = G.number_of_nodes() - 1\n",
    "    normalized = degree / max_possible if max_possible > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"node\": node,\n",
    "        \"degree\": degree,\n",
    "        \"normalized_centrality\": round(normalized, 4)\n",
    "    }\n",
    "\n",
    "\n",
    "@network_mcp.tool()\n",
    "def calculate_betweenness(\n",
    "    graph_id: str,\n",
    "    node: int\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calculate betweenness centrality for a node.\n",
    "\n",
    "    Betweenness measures how often a node lies on shortest paths between other nodes.\n",
    "    High betweenness nodes are 'bridges' connecting different parts of the network.\n",
    "\n",
    "    Args:\n",
    "        graph_id: ID of the graph to analyze\n",
    "        node: The node ID to calculate betweenness for\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with betweenness centrality value\n",
    "    \"\"\"\n",
    "    G = cache.get(f\"graph:{graph_id}\")\n",
    "    \n",
    "    if G is None:\n",
    "        return {\"error\": f\"Graph '{graph_id}' not found\"}\n",
    "\n",
    "    if node not in G:\n",
    "        return {\"error\": f\"Node {node} not in graph '{graph_id}'\"}\n",
    "\n",
    "    betweenness = nx.betweenness_centrality(G)\n",
    "\n",
    "    return {\n",
    "        \"node\": node,\n",
    "        \"betweenness_centrality\": round(betweenness[node], 4)\n",
    "    }\n",
    "\n",
    "\n",
    "@network_mcp.tool()\n",
    "def find_shortest_path(\n",
    "    graph_id: str,\n",
    "    source: int,\n",
    "    target: int\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Find shortest path between two nodes.\n",
    "\n",
    "    Args:\n",
    "        graph_id: ID of the graph to search\n",
    "        source: Starting node ID\n",
    "        target: Destination node ID\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with path and length, or error if no path exists\n",
    "    \"\"\"\n",
    "    G = cache.get(f\"graph:{graph_id}\")\n",
    "    \n",
    "    if G is None:\n",
    "        return {\"error\": f\"Graph '{graph_id}' not found\"}\n",
    "\n",
    "    try:\n",
    "        path = nx.shortest_path(G, source, target)\n",
    "        return {\n",
    "            \"found\": True,\n",
    "            \"path\": path,\n",
    "            \"length\": len(path) - 1\n",
    "        }\n",
    "    except nx.NetworkXNoPath:\n",
    "        return {\n",
    "            \"found\": False,\n",
    "            \"message\": f\"No path exists between {source} and {target}\"\n",
    "        }\n",
    "    except nx.NodeNotFound:\n",
    "        return {\n",
    "            \"found\": False,\n",
    "            \"message\": f\"One or both nodes not in graph\"\n",
    "        }\n",
    "\n",
    "\n",
    "# Run the server\n",
    "if __name__ == \"__main__\":\n",
    "    network_mcp.run()  # stdio by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We Just Built\n",
    "\n",
    "This MCP server exposes network analysis capabilities from Weeks 3-5.\n",
    "\n",
    "**Key Features**:\n",
    "\n",
    "1. **State Management**\n",
    "   - Global `cache` dict stores graphs between calls\n",
    "   - Agent can create a graph, then analyze it\n",
    "   - Multiple graphs can coexist (different `graph_id`s)\n",
    "   - Pattern: `cache[f\"graph:{graph_id}\"] = G`\n",
    "\n",
    "2. **Type Safety**\n",
    "   - All inputs validated automatically\n",
    "   - Type hints ensure correct data types\n",
    "   - Clear error messages for invalid inputs\n",
    "\n",
    "3. **Domain Expertise Encoded**\n",
    "   - Docstrings explain **when** to use each tool\n",
    "   - Return values are structured and self-documenting\n",
    "   - Error handling guides the agent\n",
    "\n",
    "4. **Natural Language Interface**\n",
    "   - Agent can say \"find the shortest path from 1 to 5\"\n",
    "   - Server translates to `nx.shortest_path(G, 1, 5)`\n",
    "   - Result returned in natural language-friendly format\n",
    "\n",
    "**This is powerful**: Any AI agent can now perform network analysis by calling these tools.\n",
    "\n",
    "No need to understand NetworkX. No need to write code. Just natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Network Analysis Server\n",
    "\n",
    "Since we wrote the server to a file using `%%file`, we can now test it using the FastMCP Client. \n",
    "\n",
    "Let's explore how to interact with our network analysis server programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tools:\n",
      "  - create_network\n",
      "  - calculate_degree_centrality\n",
      "  - calculate_betweenness\n",
      "  - find_shortest_path\n",
      "\n",
      "==================================================\n",
      "\n",
      "Creating a social network...\n",
      "Network created: {'graph_id': 'social_network', 'num_nodes': 9, 'num_edges': 11, 'density': 0.3056}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Calculating degree centrality for node 3 (bridge node)...\n",
      "Node 3 centrality: {'node': 3, 'degree': 4, 'normalized_centrality': 0.5}\n",
      "\n",
      "Calculating degree centrality for node 1 (peripheral node)...\n",
      "Node 1 centrality: {'node': 1, 'degree': 2, 'normalized_centrality': 0.25}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Calculating betweenness centrality for node 3...\n",
      "Node 3 betweenness: {'node': 3, 'betweenness_centrality': 0.75}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Finding shortest path from node 1 to node 9...\n",
      "Path result: {'found': True, 'path': [1, 3, 7, 9], 'length': 3}\n",
      "\n",
      "Finding shortest path from node 2 to node 6...\n",
      "Path result: {'found': True, 'path': [2, 3, 4, 6], 'length': 3}\n"
     ]
    }
   ],
   "source": [
    "from fastmcp import Client\n",
    "\n",
    "async with Client(\"network_analysis_server.py\") as client:\n",
    "    # 1. Discover available tools\n",
    "    tools = await client.list_tools()\n",
    "    print(\"Available tools:\")\n",
    "    for tool in tools:\n",
    "        print(f\"  - {tool.name}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # 2. Create a social network (small-world structure)\n",
    "    print(\"Creating a social network...\")\n",
    "    result = await client.call_tool(\n",
    "        \"create_network\",\n",
    "        {\n",
    "            \"graph_id\": \"social_network\",\n",
    "            \"edges\": [\n",
    "                [1, 2], [1, 3], [2, 3],  # Triangle cluster\n",
    "                [3, 4], [4, 5], [5, 6], [6, 4],  # Another cluster\n",
    "                [3, 7], [7, 8], [8, 9], [9, 7]   # Third cluster\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    print(f\"Network created: {result.data}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # 3. Analyze centrality - who's most important?\n",
    "    print(\"Calculating degree centrality for node 3 (bridge node)...\")\n",
    "    result = await client.call_tool(\n",
    "        \"calculate_degree_centrality\",\n",
    "        {\"graph_id\": \"social_network\", \"node\": 3}\n",
    "    )\n",
    "    print(f\"Node 3 centrality: {result.data}\")\n",
    "    \n",
    "    print(\"\\nCalculating degree centrality for node 1 (peripheral node)...\")\n",
    "    result = await client.call_tool(\n",
    "        \"calculate_degree_centrality\",\n",
    "        {\"graph_id\": \"social_network\", \"node\": 1}\n",
    "    )\n",
    "    print(f\"Node 1 centrality: {result.data}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # 4. Calculate betweenness - who controls information flow?\n",
    "    print(\"Calculating betweenness centrality for node 3...\")\n",
    "    result = await client.call_tool(\n",
    "        \"calculate_betweenness\",\n",
    "        {\"graph_id\": \"social_network\", \"node\": 3}\n",
    "    )\n",
    "    print(f\"Node 3 betweenness: {result.data}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # 5. Find shortest paths\n",
    "    print(\"Finding shortest path from node 1 to node 9...\")\n",
    "    result = await client.call_tool(\n",
    "        \"find_shortest_path\",\n",
    "        {\"graph_id\": \"social_network\", \"source\": 1, \"target\": 9}\n",
    "    )\n",
    "    print(f\"Path result: {result.data}\")\n",
    "    \n",
    "    print(\"\\nFinding shortest path from node 2 to node 6...\")\n",
    "    result = await client.call_tool(\n",
    "        \"find_shortest_path\",\n",
    "        {\"graph_id\": \"social_network\", \"source\": 2, \"target\": 6}\n",
    "    )\n",
    "    print(f\"Path result: {result.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Results\n",
    "\n",
    "Notice what just happened:\n",
    "\n",
    "1. **Tool Discovery**: The client automatically discovered all 4 tools available on the server\n",
    "2. **State Persistence**: We created a network, then analyzed it in subsequent calls - the server remembered the graph\n",
    "3. **Structured Results**: Each tool returned a dictionary with clear, semantic field names\n",
    "4. **Network Insights**: \n",
    "   - Node 3 has the highest degree (4 connections) and acts as a bridge between clusters\n",
    "   - Node 3 also has high betweenness centrality - it controls information flow\n",
    "   - The shortest path from node 1 to node 9 must go through node 3 (the bridge)\n",
    "\n",
    "**This is the power of MCP**: We're performing sophisticated network analysis through a simple client API. The same server could be called from Claude Desktop, a web application, or any other MCP-compatible client.\n",
    "\n",
    "Let's see one more example - handling errors gracefully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to analyze a non-existent graph...\n",
      "Result: {'error': \"Graph 'does_not_exist' not found. Create it first.\"}\n",
      "\n",
      "==================================================\n",
      "\n",
      "Creating a small graph...\n",
      "Attempting to analyze non-existent node 999...\n",
      "Result: {'error': \"Node 999 not in graph 'test_graph'\"}\n",
      "\n",
      "The server provides clear error messages that guide the AI agent\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating error handling\n",
    "async with Client(\"network_analysis_server.py\") as client:\n",
    "    # Try to analyze a non-existent graph\n",
    "    print(\"Attempting to analyze a non-existent graph...\")\n",
    "    result = await client.call_tool(\n",
    "        \"calculate_degree_centrality\",\n",
    "        {\"graph_id\": \"does_not_exist\", \"node\": 1}\n",
    "    )\n",
    "    print(f\"Result: {result.data}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # Create a graph, then try to access a non-existent node\n",
    "    print(\"Creating a small graph...\")\n",
    "    await client.call_tool(\n",
    "        \"create_network\",\n",
    "        {\"graph_id\": \"test_graph\", \"edges\": [[1, 2], [2, 3]]}\n",
    "    )\n",
    "    \n",
    "    print(\"Attempting to analyze non-existent node 999...\")\n",
    "    result = await client.call_tool(\n",
    "        \"calculate_degree_centrality\",\n",
    "        {\"graph_id\": \"test_graph\", \"node\": 999}\n",
    "    )\n",
    "    print(f\"Result: {result.data}\")\n",
    "\n",
    "print(\"\\nThe server provides clear error messages that guide the AI agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Theory MCP Server\n",
    "\n",
    "Let's apply the same pattern to game theory (Weeks 8-9).\n",
    "\n",
    "We'll use `quantecon.game_theory` for equilibrium computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting game_server.py\n"
     ]
    }
   ],
   "source": [
    "%%file game_server.py\n",
    "\n",
    "from fastmcp import FastMCP\n",
    "import quantecon.game_theory as gt\n",
    "import numpy as np\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "game_mcp = FastMCP(\"GameTheory\")\n",
    "\n",
    "# Global cache for games (same pattern as network server)\n",
    "game_cache: Dict[str, Any] = {}\n",
    "\n",
    "@game_mcp.tool()\n",
    "def create_game(\n",
    "    game_id: str,\n",
    "    payoff_matrix_p1: List[List[float]],\n",
    "    payoff_matrix_p2: List[List[float]]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a two-player normal-form game.\n",
    "\n",
    "    Args:\n",
    "        game_id: Unique identifier for this game\n",
    "        payoff_matrix_p1: Payoff matrix for Player 1 (rows = P1 strategies, cols = P2 strategies)\n",
    "        payoff_matrix_p2: Payoff matrix for Player 2 (rows = P1 strategies, cols = P2 strategies)\n",
    "\n",
    "    Returns:\n",
    "        Game statistics and confirmation\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays\n",
    "    p1_payoffs = np.array(payoff_matrix_p1)\n",
    "    p2_payoffs = np.array(payoff_matrix_p2)\n",
    "\n",
    "    # Create game\n",
    "    game = gt.NormalFormGame([p1_payoffs, p2_payoffs])\n",
    "\n",
    "    # Store in global cache\n",
    "    game_cache[game_id] = game\n",
    "\n",
    "    return {\n",
    "        \"game_id\": game_id,\n",
    "        \"num_players\": 2,\n",
    "        \"p1_strategies\": p1_payoffs.shape[0],\n",
    "        \"p2_strategies\": p1_payoffs.shape[1],\n",
    "        \"message\": f\"Game '{game_id}' created successfully\"\n",
    "    }\n",
    "\n",
    "@game_mcp.tool()\n",
    "def find_pure_nash_equilibria(\n",
    "    game_id: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Find all pure strategy Nash equilibria in the game.\n",
    "\n",
    "    A Nash equilibrium is a strategy profile where no player can improve\n",
    "    by unilaterally changing their strategy.\n",
    "\n",
    "    Args:\n",
    "        game_id: ID of the game to analyze\n",
    "\n",
    "    Returns:\n",
    "        List of Nash equilibria (strategy profiles) and their payoffs\n",
    "    \"\"\"\n",
    "    game = game_cache.get(game_id)\n",
    "    \n",
    "    if game is None:\n",
    "        return {\"error\": f\"Game '{game_id}' not found\"}\n",
    "\n",
    "    equilibria = game.pure_nash_brute()\n",
    "\n",
    "    results = []\n",
    "    for eq in equilibria:\n",
    "        # eq is a tuple of strategy indices\n",
    "        payoffs = [game.players[i].payoff_array[eq] for i in range(len(game.players))]\n",
    "        results.append({\n",
    "            \"strategies\": eq,\n",
    "            \"payoffs\": [float(p) for p in payoffs]\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        \"game_id\": game_id,\n",
    "        \"num_equilibria\": len(results),\n",
    "        \"equilibria\": results\n",
    "    }\n",
    "\n",
    "@game_mcp.tool()\n",
    "def check_not_dominated(\n",
    "    game_id: str,\n",
    "    player: int,\n",
    "    strategy: int\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Check if a strategy is not dominated for a player.\n",
    "\n",
    "    A dominated strategy is one that always yields lower payoff than some other strategy.\n",
    "    A not-dominated strategy may be part of a Nash equilibrium.\n",
    "\n",
    "    Args:\n",
    "        game_id: ID of the game\n",
    "        player: Player number (0 or 1)\n",
    "        strategy: Strategy index to check\n",
    "\n",
    "    Returns:\n",
    "        Whether the strategy is dominated and analysis\n",
    "    \"\"\"\n",
    "    game = game_cache.get(game_id)\n",
    "    \n",
    "    if game is None:\n",
    "        return {\"error\": f\"Game '{game_id}' not found\"}\n",
    "\n",
    "    if player not in [0, 1]:\n",
    "        return {\"error\": \"Player must be 0 or 1\"}\n",
    "\n",
    "    is_dominated = game.players[player].is_dominated(strategy)\n",
    "\n",
    "    return {\n",
    "        \"game_id\": game_id,\n",
    "        \"player\": player,\n",
    "        \"strategy\": strategy,\n",
    "        \"is_dominated\": bool(is_dominated),\n",
    "        \"is_not_dominated\": not is_dominated,\n",
    "        \"explanation\": \"This strategy is dominated by another strategy\" if is_dominated else \"This strategy is not dominated and may be part of a Nash equilibrium\"\n",
    "    }\n",
    "\n",
    "print(\"✓ Game Theory MCP server created with 3 tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent-Based Model Controller\n",
    "\n",
    "Finally, let's create an MCP server for running agent-based models (Weeks 6-7).\n",
    "\n",
    "We'll use **Mesa**, the Python framework for ABMs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting abm_server.py\n"
     ]
    }
   ],
   "source": [
    "%%file abm_server.py\n",
    "\n",
    "from fastmcp import FastMCP\n",
    "from mesa import Agent, Model\n",
    "from mesa.time import RandomActivation\n",
    "from mesa.space import SingleGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "from typing import Dict, List, Any\n",
    "import random\n",
    "\n",
    "abm_mcp = FastMCP(\"AgentBasedModels\")\n",
    "\n",
    "# Global cache for ABM models\n",
    "abm_cache: Dict[str, Any] = {}\n",
    "\n",
    "# Define a simple Schelling segregation agent\n",
    "class SchellingAgent(Agent):\n",
    "    def __init__(self, unique_id, model, agent_type):\n",
    "        super().__init__(unique_id, model)\n",
    "        self.type = agent_type\n",
    "\n",
    "    def step(self):\n",
    "        # Find neighbors\n",
    "        neighbors = self.model.grid.get_neighbors(\n",
    "            self.pos, moore=True, include_center=False\n",
    "        )\n",
    "\n",
    "        # Count similar neighbors\n",
    "        similar = sum(1 for n in neighbors if n.type == self.type)\n",
    "        total = len(neighbors)\n",
    "\n",
    "        # Move if unhappy (less than threshold% similar)\n",
    "        if total > 0 and (similar / total) < self.model.homophily:\n",
    "            self.model.grid.move_to_empty(self)\n",
    "\n",
    "class SchellingModel(Model):\n",
    "    def __init__(self, width=20, height=20, density=0.8, minority_pc=0.2, homophily=3):\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.density = density\n",
    "        self.minority_pc = minority_pc\n",
    "        self.homophily = homophily / 8  # Convert to ratio\n",
    "\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.grid = SingleGrid(width, height, torus=True)\n",
    "\n",
    "        # Create agents\n",
    "        n_agents = int(width * height * density)\n",
    "        for i in range(n_agents):\n",
    "            agent_type = 1 if random.random() < minority_pc else 0\n",
    "            agent = SchellingAgent(i, self, agent_type)\n",
    "            self.schedule.add(agent)\n",
    "\n",
    "            # Place randomly\n",
    "            x = random.randrange(width)\n",
    "            y = random.randrange(height)\n",
    "            self.grid.position_agent(agent, (x, y))\n",
    "\n",
    "        # Data collector\n",
    "        self.datacollector = DataCollector(\n",
    "            model_reporters={\n",
    "                \"segregation\": lambda m: self.measure_segregation(m)\n",
    "            }\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def measure_segregation(model):\n",
    "        \"\"\"Calculate segregation metric (0-1, higher = more segregated).\"\"\"\n",
    "        similar_neighbors = 0\n",
    "        total_neighbors = 0\n",
    "\n",
    "        for agent in model.schedule.agents:\n",
    "            neighbors = model.grid.get_neighbors(\n",
    "                agent.pos, moore=True, include_center=False\n",
    "            )\n",
    "            if neighbors:\n",
    "                similar = sum(1 for n in neighbors if n.type == agent.type)\n",
    "                similar_neighbors += similar\n",
    "                total_neighbors += len(neighbors)\n",
    "\n",
    "        return similar_neighbors / total_neighbors if total_neighbors > 0 else 0\n",
    "\n",
    "    def step(self):\n",
    "        self.datacollector.collect(self)\n",
    "        self.schedule.step()\n",
    "\n",
    "@abm_mcp.tool()\n",
    "def create_schelling_model(\n",
    "    model_id: str,\n",
    "    width: int = 20,\n",
    "    height: int = 20,\n",
    "    density: float = 0.8,\n",
    "    minority_percent: float = 0.2,\n",
    "    homophily: int = 3\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a Schelling segregation model.\n",
    "\n",
    "    The Schelling model demonstrates how mild preferences for similar neighbors\n",
    "    can lead to high levels of segregation.\n",
    "\n",
    "    Args:\n",
    "        model_id: Unique identifier for this model\n",
    "        width: Grid width (default 20)\n",
    "        height: Grid height (default 20)\n",
    "        density: Fraction of cells occupied (0-1, default 0.8)\n",
    "        minority_percent: Fraction of agents that are minority type (0-1, default 0.2)\n",
    "        homophily: Number of similar neighbors desired (out of 8, default 3)\n",
    "\n",
    "    Returns:\n",
    "        Model configuration and initial state\n",
    "    \"\"\"\n",
    "    model = SchellingModel(width, height, density, minority_percent, homophily)\n",
    "\n",
    "    # Store in global cache\n",
    "    abm_cache[model_id] = model\n",
    "\n",
    "    return {\n",
    "        \"model_id\": model_id,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"num_agents\": len(model.schedule.agents),\n",
    "        \"initial_segregation\": round(model.measure_segregation(model), 3)\n",
    "    }\n",
    "\n",
    "@abm_mcp.tool()\n",
    "def step_model(\n",
    "    model_id: str,\n",
    "    num_steps: int = 1\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run the model for a specified number of steps.\n",
    "\n",
    "    Args:\n",
    "        model_id: ID of the model to step\n",
    "        num_steps: Number of steps to run (default 1)\n",
    "\n",
    "    Returns:\n",
    "        Segregation metrics after stepping\n",
    "    \"\"\"\n",
    "    model = abm_cache.get(model_id)\n",
    "    \n",
    "    if model is None:\n",
    "        return {\"error\": f\"Model '{model_id}' not found\"}\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        model.step()\n",
    "\n",
    "    df = model.datacollector.get_model_vars_dataframe()\n",
    "\n",
    "    return {\n",
    "        \"model_id\": model_id,\n",
    "        \"steps_completed\": num_steps,\n",
    "        \"total_steps\": len(df),\n",
    "        \"current_segregation\": round(df['segregation'].iloc[-1], 3),\n",
    "        \"initial_segregation\": round(df['segregation'].iloc[0], 3)\n",
    "    }\n",
    "\n",
    "@abm_mcp.tool()\n",
    "def get_segregation_metric(\n",
    "    model_id: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get current segregation level in the model.\n",
    "\n",
    "    Args:\n",
    "        model_id: ID of the model to query\n",
    "\n",
    "    Returns:\n",
    "        Current and historical segregation metrics\n",
    "    \"\"\"\n",
    "    model = abm_cache.get(model_id)\n",
    "    \n",
    "    if model is None:\n",
    "        return {\"error\": f\"Model '{model_id}' not found\"}\n",
    "\n",
    "    current_seg = model.measure_segregation(model)\n",
    "\n",
    "    df = model.datacollector.get_model_vars_dataframe()\n",
    "\n",
    "    return {\n",
    "        \"model_id\": model_id,\n",
    "        \"current_segregation\": round(current_seg, 3),\n",
    "        \"mean_segregation\": round(df['segregation'].mean(), 3),\n",
    "        \"max_segregation\": round(df['segregation'].max(), 3),\n",
    "        \"total_steps\": len(df)\n",
    "    }\n",
    "\n",
    "print(\"✓ ABM MCP server created with 3 tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What We've Accomplished\n",
    "\n",
    "We now have **three MCP servers** that expose capabilities from our course:\n",
    "\n",
    "1. **Network Analysis** (Weeks 3-5)\n",
    "   - Create networks, calculate centrality, find paths\n",
    "   - Any AI can now do network science\n",
    "\n",
    "2. **Game Theory** (Weeks 8-9)\n",
    "   - Create games, find equilibria, check dominance\n",
    "   - Any AI can now solve games\n",
    "\n",
    "3. **Agent-Based Models** (Weeks 6-7)\n",
    "   - Create Schelling model, run simulations, measure emergence\n",
    "   - Any AI can now run computational experiments\n",
    "\n",
    "**Key Patterns**:\n",
    "\n",
    "- **Global Cache for State**: `cache: Dict[str, Any] = {}` stores data between calls\n",
    "- **No Context Dependency**: Tools access global cache, not request-scoped Context\n",
    "- **Type Safety**: All inputs validated automatically\n",
    "- **Clear Errors**: Guide the AI when something goes wrong\n",
    "- **Structured Returns**: Dictionaries with semantic field names\n",
    "- **Documentation**: Docstrings explain **what** and **when**\n",
    "\n",
    "These servers are production-ready and reusable across any MCP-compatible client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCP Resources: Read-Only Data\n",
    "\n",
    "In addition to **Tools** (functions), MCP servers can expose **Resources** (data).\n",
    "\n",
    "Resources are for read-only access to information:\n",
    "- Datasets\n",
    "- Simulation results\n",
    "- Documentation\n",
    "- Configuration files\n",
    "\n",
    "**Example Use Cases**:\n",
    "- Network adjacency matrices\n",
    "- Historical game theory results\n",
    "- ABM simulation outputs\n",
    "- Research paper abstracts\n",
    "\n",
    "Let's add a resource to our network analysis server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Network resources server created\n"
     ]
    }
   ],
   "source": [
    "from fastmcp import FastMCP, Context\n",
    "\n",
    "# Create a new server with resources\n",
    "network_resources_mcp = FastMCP(\"NetworkResources\")\n",
    "\n",
    "@network_resources_mcp.resource(\"network://{graph_id}/adjacency\")\n",
    "def get_adjacency_matrix(\n",
    "    ctx: Context,\n",
    "    graph_id: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Get the adjacency matrix representation of a network.\n",
    "\n",
    "    Resources use URI templates (RFC 6570).\n",
    "    Clients can request: network://my_graph/adjacency\n",
    "    \"\"\"\n",
    "    if not hasattr(ctx, 'graphs') or graph_id not in ctx.graphs:\n",
    "        return f\"Error: Graph '{graph_id}' not found\"\n",
    "\n",
    "    G = ctx.graphs[graph_id]\n",
    "    adj_matrix = nx.adjacency_matrix(G).todense()\n",
    "\n",
    "    return str(adj_matrix)\n",
    "\n",
    "@network_resources_mcp.resource(\"network://{graph_id}/summary\")\n",
    "def get_network_summary(\n",
    "    ctx: Context,\n",
    "    graph_id: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Get a text summary of network properties.\n",
    "    \"\"\"\n",
    "    if not hasattr(ctx, 'graphs') or graph_id not in ctx.graphs:\n",
    "        return f\"Error: Graph '{graph_id}' not found\"\n",
    "\n",
    "    G = ctx.graphs[graph_id]\n",
    "\n",
    "    summary = f\"\"\"\n",
    "Network Summary: {graph_id}\n",
    "==================\n",
    "Nodes: {G.number_of_nodes()}\n",
    "Edges: {G.number_of_edges()}\n",
    "Density: {nx.density(G):.4f}\n",
    "Average Degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\n",
    "Is Connected: {nx.is_connected(G)}\n",
    "\"\"\"\n",
    "    return summary\n",
    "\n",
    "print(\"✓ Network resources server created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration Architecture\n",
    "\n",
    "Now comes the magic: connecting our MCP servers to PydanticAI agents.\n",
    "\n",
    "PydanticAI has **native MCP support** built in. MCP servers are treated as **toolsets** that can be directly registered with agents.\n",
    "\n",
    "The architecture looks like this:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────┐\n",
    "│      PydanticAI Agent               │\n",
    "│   (Your AI Application)             │\n",
    "└──────────────┬──────────────────────┘\n",
    "               │\n",
    "               │  toolsets=[server]\n",
    "               ▼\n",
    "┌─────────────────────────────────────┐\n",
    "│      MCP Server Connection          │\n",
    "│   (MCPServerStdio, FastMCPToolset)  │\n",
    "└──────────────┬──────────────────────┘\n",
    "               │\n",
    "               │  MCP Protocol\n",
    "               ▼\n",
    "┌─────────────────────────────────────┐\n",
    "│      MCP Servers                    │\n",
    "│   - Network Analysis                │\n",
    "│   - Game Theory                     │\n",
    "│   - ABM Controller                  │\n",
    "└─────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "PydanticAI provides multiple ways to connect:\n",
    "1. **MCPServerStdio** - Run server as subprocess (stdio transport)\n",
    "2. **MCPServerStreamableHTTP** - Connect to HTTP server\n",
    "3. **FastMCPToolset** - High-level integration via FastMCP Client\n",
    "\n",
    "### Using MCPServerStdio with PydanticAI\n",
    "\n",
    "The simplest integration - run your MCP server as a subprocess:\n",
    "\n",
    "```python\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.mcp import MCPServerStdio\n",
    "\n",
    "# Create connection to our network analysis server\n",
    "server = MCPServerStdio(\n",
    "    'python', \n",
    "    args=['network_analysis_server.py']\n",
    ")\n",
    "\n",
    "# Create agent with MCP server as toolset\n",
    "agent = Agent('anthropic:claude-sonnet-4-5', toolsets=[server])\n",
    "\n",
    "async def main():\n",
    "    # Agent automatically has access to all MCP tools!\n",
    "    result = await agent.run(\n",
    "        'Create a triangle network with nodes 1,2,3 and edges between all pairs. '\n",
    "        'Then calculate the degree centrality of node 1.'\n",
    "    )\n",
    "    print(result.output)\n",
    "\n",
    "# Run with: asyncio.run(main())\n",
    "```\n",
    "\n",
    "**What's happening here?**\n",
    "1. `MCPServerStdio` launches the server as a subprocess\n",
    "2. The agent discovers all tools from the server automatically\n",
    "3. When the agent needs network analysis, it calls the MCP tools\n",
    "4. Communication happens over stdin/stdout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using FastMCPToolset (Simpler Integration)\n",
    "\n",
    "FastMCP provides an even simpler integration pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Network Analysis Results\n",
      "\n",
      "### **Overall Network Statistics:**\n",
      "- **Number of Nodes:** 4 (connected nodes) + 1 isolated node (Person 5)\n",
      "- **Number of Edges:** 5\n",
      "- **Network Density:** 0.833 (83.3%)\n",
      "  - This is quite high, indicating a very well-connected group. The maximum possible would be 1.0 (complete graph).\n",
      "\n",
      "### **Degree Centrality (How Connected Each Person Is):**\n",
      "\n",
      "| Person | Degree | Normalized Centrality | Interpretation |\n",
      "|--------|--------|----------------------|-----------------|\n",
      "| **1** | 3 | 1.0 | **Hub** - Most connected |\n",
      "| **2** | 2 | 0.667 | Moderately connected |\n",
      "| **3** | 3 | 1.0 | **Hub** - Most connected |\n",
      "| **4** | 2 | 0.667 | Moderately connected |\n",
      "| **5** | 0 | 0.0 | Isolated - No friends |\n",
      "\n",
      "### **Betweenness Centrality (Bridge Roles):**\n",
      "\n",
      "| Person | Betweenness | Interpretation |\n",
      "|--------|------------|-----------------|\n",
      "| **1** | 0.167 | Acts as a bridge for some connections |\n",
      "| **2** | 0.0 | Not a bridge (direct connections available) |\n",
      "| **3** | 0.167 | Acts as a bridge for some connections |\n",
      "| **4** | 0.0 | Not a bridge (direct connections available) |\n",
      "\n",
      "### **Key Insights:**\n",
      "\n",
      "1. **Core Group:** Persons 1, 2, 3, and 4 form a highly connected core group (83.3% density)\n",
      "2. **Hub Nodes:** Persons 1 and 3 are the most influential, each with 3 connections\n",
      "3. **Bridge Nodes:** Persons 1 and 3 serve as bridges connecting the network\n",
      "4. **Outlier:** Person 5 is completely isolated with no connections\n",
      "5. **Network Resilience:** The network is quite robust due to high density; removing any single node wouldn't disconnect the group\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.toolsets.fastmcp import FastMCPToolset\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to MCP server (many options!)\n",
    "# toolset = FastMCPToolset('network_analysis_server.py')\n",
    "\n",
    "# Or directly from a FastMCP server object (no network overhead!)\n",
    "from network_analysis_server import network_mcp\n",
    "toolset = FastMCPToolset(network_mcp)\n",
    "\n",
    "agent = Agent('anthropic:claude-haiku-4-5', toolsets=[toolset])\n",
    "\n",
    "async def main():\n",
    "    prompt = \"\"\"\n",
    "    I have a social network with the following friendships (edges):\n",
    "    - Person 1 is friends with persons 2, 3, and 4\n",
    "    - Person 2 is friends with persons 1 and 3\n",
    "    - Person 3 is friends with persons 1, 2, and 4\n",
    "    - Person 4 is friends with persons 1 and 3\n",
    "    - Person 5 is friends with nobody\n",
    "\n",
    "    Create this network and analyze its structure.\n",
    "\n",
    "    think carefully, proceed step by step.\n",
    "    \"\"\"\n",
    "    result = await agent.run(prompt)\n",
    "    print(result.output)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FastMCPToolset can connect to:**\n",
    "- Python scripts: `FastMCPToolset('my_server.py')`\n",
    "- HTTP URLs: `FastMCPToolset('http://localhost:8000/mcp')`\n",
    "- FastMCP objects: `FastMCPToolset(network_mcp)`\n",
    "- JSON config: `FastMCPToolset({'mcpServers': {...}})`\n",
    "\n",
    "### Direct FastMCP Server Integration\n",
    "\n",
    "If your MCP server is in the same codebase, you can skip the network entirely:\n",
    "\n",
    "```python\n",
    "from fastmcp import FastMCP\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.toolsets.fastmcp import FastMCPToolset\n",
    "\n",
    "# Define server (same as before)\n",
    "network_mcp = FastMCP(\"NetworkAnalysis\")\n",
    "\n",
    "@network_mcp.tool()\n",
    "def create_network(graph_id: str, edges: list) -> dict:\n",
    "    # ... implementation\n",
    "    pass\n",
    "\n",
    "# Create toolset directly from server object\n",
    "toolset = FastMCPToolset(network_mcp)\n",
    "\n",
    "# Agent uses tools without any network overhead\n",
    "agent = Agent('anthropic:claude-sonnet-4-5', toolsets=[toolset])\n",
    "```\n",
    "\n",
    "This is **zero-overhead** - the agent calls the tools directly.\n",
    "\n",
    "### Multi-Server Agents\n",
    "\n",
    "The real power: connecting to **multiple MCP servers**:\n",
    "\n",
    "```python\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.mcp import MCPServerStdio\n",
    "\n",
    "# Connect to multiple servers\n",
    "network_server = MCPServerStdio('python', args=['network_analysis_server.py'])\n",
    "game_server = MCPServerStdio('python', args=['game_theory_server.py'])\n",
    "abm_server = MCPServerStdio('python', args=['abm_server.py'])\n",
    "\n",
    "# Agent has tools from all three domains!\n",
    "agent = Agent(\n",
    "    'anthropic:claude-sonnet-4-5', \n",
    "    toolsets=[network_server, game_server, abm_server]\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    # Agent orchestrates across servers\n",
    "    result = await agent.run(\n",
    "        'Create a network, model it as a coordination game, '\n",
    "        'and run an ABM simulation of agent behavior'\n",
    "    )\n",
    "    print(result.output)\n",
    "```\n",
    "\n",
    "Using tool prefixes to avoid naming conflicts:\n",
    "\n",
    "```python\n",
    "from pydantic_ai.mcp import MCPServerStdio\n",
    "\n",
    "network_server = MCPServerStdio(\n",
    "    'python', \n",
    "    args=['network_server.py'],\n",
    "    tool_prefix='network'  # Tools prefixed with 'network_'\n",
    ")\n",
    "\n",
    "game_server = MCPServerStdio(\n",
    "    'python', \n",
    "    args=['game_server.py'],\n",
    "    tool_prefix='game'  # Tools prefixed with 'game_'\n",
    ")\n",
    "```\n",
    "\n",
    "The agent **orchestrates** across servers:\n",
    "- \"Analyze the social network\" → network server\n",
    "- \"Model this as a game\" → game theory server\n",
    "- \"Run a simulation\" → ABM server\n",
    "\n",
    "**This is powerful**: compose capabilities like Lego blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Example: PydanticAI Agent with MCP Tools\n",
    "\n",
    "Let's see this in action. We'll create a PydanticAI agent that uses our network analysis MCP server:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Development: stdio Transport\n",
    "\n",
    "For development and testing, use stdio transport.\n",
    "\n",
    "**File: `network_server.py`**\n",
    "```python\n",
    "from fastmcp import FastMCP\n",
    "# ... define tools ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()  # stdio by default\n",
    "```\n",
    "\n",
    "**Run:**\n",
    "```bash\n",
    "python network_server.py\n",
    "```\n",
    "\n",
    "Server communicates via stdin/stdout. Perfect for local testing.\n",
    "\n",
    "### Claude Desktop Integration\n",
    "\n",
    "FastMCP has **built-in Claude Desktop support**.\n",
    "\n",
    "Install your server:\n",
    "```bash\n",
    "fastmcp install claude-desktop network_server.py\n",
    "```\n",
    "\n",
    "This:\n",
    "1. Adds server to Claude Desktop config\n",
    "2. Makes tools available in Claude Desktop app\n",
    "3. Users can interact naturally: \"Calculate centrality for node 5\"\n",
    "\n",
    "**This is incredibly powerful**:\n",
    "- Your research tools → available in Claude Desktop\n",
    "- Students can use them without coding\n",
    "- Natural language interface to computational methods\n",
    "\n",
    "### HTTP Deployment (Streamable HTTP)\n",
    "\n",
    "For production, deploy as HTTP server using the **Streamable HTTP** transport:\n",
    "\n",
    "```python\n",
    "# network_server.py\n",
    "from fastmcp import FastMCP\n",
    "# ... define tools ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport='streamable-http', port=8000)\n",
    "```\n",
    "\n",
    "**Run:**\n",
    "```bash\n",
    "python network_server.py\n",
    "```\n",
    "\n",
    "Server runs on `http://localhost:8000/mcp`.\n",
    "\n",
    "**Connect from PydanticAI using MCPServerStreamableHTTP:**\n",
    "```python\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.mcp import MCPServerStreamableHTTP\n",
    "\n",
    "server = MCPServerStreamableHTTP('http://localhost:8000/mcp')\n",
    "agent = Agent('anthropic:claude-sonnet-4-5', toolsets=[server])\n",
    "\n",
    "async def main():\n",
    "    result = await agent.run('Analyze the network')\n",
    "    print(result.output)\n",
    "```\n",
    "\n",
    "**Or using FastMCPToolset:**\n",
    "```python\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.toolsets.fastmcp import FastMCPToolset\n",
    "\n",
    "toolset = FastMCPToolset('http://localhost:8000/mcp')\n",
    "agent = Agent('anthropic:claude-sonnet-4-5', toolsets=[toolset])\n",
    "```\n",
    "\n",
    "**Deploy to production**:\n",
    "- Run on cloud server (AWS, GCP, Azure)\n",
    "- Use Docker for containerization\n",
    "- Add authentication and rate limiting\n",
    "- Scale horizontally as needed\n",
    "\n",
    "### Loading MCP Servers from Configuration\n",
    "\n",
    "You can load multiple servers from a JSON configuration file:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"mcpServers\": {\n",
    "    \"network-analysis\": {\n",
    "      \"command\": \"python\",\n",
    "      \"args\": [\"network_analysis_server.py\"]\n",
    "    },\n",
    "    \"game-theory\": {\n",
    "      \"url\": \"http://localhost:8001/mcp\"\n",
    "    },\n",
    "    \"abm-controller\": {\n",
    "      \"command\": \"python\",\n",
    "      \"args\": [\"abm_server.py\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Load with PydanticAI:\n",
    "```python\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.mcp import load_mcp_servers\n",
    "\n",
    "servers = load_mcp_servers('mcp_config.json')\n",
    "agent = Agent('anthropic:claude-sonnet-4-5', toolsets=servers)\n",
    "```\n",
    "\n",
    "Or with FastMCPToolset:\n",
    "```python\n",
    "from pydantic_ai.toolsets.fastmcp import FastMCPToolset\n",
    "\n",
    "toolset = FastMCPToolset({'mcpServers': {...}})\n",
    "agent = Agent('anthropic:claude-sonnet-4-5', toolsets=[toolset])\n",
    "```\n",
    "\n",
    "**Benefits**:\n",
    "- Configure servers externally without code changes\n",
    "- Support for environment variables (`${VAR:-default}`)\n",
    "- Easy to manage multiple servers\n",
    "\n",
    "### FastMCP Cloud\n",
    "\n",
    "FastMCP offers hosted deployment:\n",
    "\n",
    "1. Push your server to GitHub\n",
    "2. Connect repo to FastMCP Cloud\n",
    "3. Automatic deployment on push\n",
    "4. Get a public URL for your server\n",
    "\n",
    "**Benefits**:\n",
    "- Zero infrastructure management\n",
    "- Automatic scaling\n",
    "- Built-in monitoring\n",
    "- Easy sharing with collaborators\n",
    "\n",
    "Perfect for research projects and teaching.\n",
    "\n",
    "### Testing MCP Servers\n",
    "\n",
    "Use pytest for testing:\n",
    "\n",
    "```python\n",
    "# test_network_server.py\n",
    "import pytest\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.mcp import MCPServerStdio\n",
    "\n",
    "@pytest.mark.asyncio\n",
    "async def test_network_analysis_agent():\n",
    "    server = MCPServerStdio('python', args=['network_analysis_server.py'])\n",
    "    agent = Agent('anthropic:claude-sonnet-4-5', toolsets=[server])\n",
    "    \n",
    "    async with agent:\n",
    "        result = await agent.run('Create a triangle network and count the edges')\n",
    "        # Verify the agent used the tools correctly\n",
    "        assert '3' in result.data  # Triangle has 3 edges\n",
    "\n",
    "@pytest.mark.asyncio\n",
    "async def test_direct_mcp_client():\n",
    "    from fastmcp import Client\n",
    "    \n",
    "    async with Client(\"network_analysis_server.py\") as client:\n",
    "        result = await client.call_tool(\n",
    "            \"create_network\",\n",
    "            {\"graph_id\": \"test\", \"edges\": [[1, 2], [2, 3]]}\n",
    "        )\n",
    "        assert result.data[\"num_nodes\"] == 3\n",
    "        assert result.data[\"num_edges\"] == 2\n",
    "```\n",
    "\n",
    "**Run tests:**\n",
    "```bash\n",
    "pytest test_network_server.py\n",
    "```\n",
    "\n",
    "### Integration with Evaluation Frameworks\n",
    "\n",
    "Remember Week A2.03 (Evaluations)?\n",
    "\n",
    "We can evaluate agents that use MCP servers:\n",
    "\n",
    "```python\n",
    "from pydantic_evals import Case, Dataset, evaluate\n",
    "\n",
    "# Define test cases\n",
    "network_eval_dataset = Dataset(\n",
    "    cases=[\n",
    "        Case(\n",
    "            input=\"Create a triangle network and find the most central node\",\n",
    "            expected_output={\"node\": 1}  # All nodes equally central\n",
    "        ),\n",
    "        Case(\n",
    "            input=\"Create a star network and identify the center\",\n",
    "            expected_output={\"node\": 1}  # Center has highest centrality\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Evaluate agent with MCP tools\n",
    "results = evaluate(\n",
    "    task=network_analysis_agent,\n",
    "    dataset=network_eval_dataset,\n",
    "    evaluators=[...]\n",
    ")\n",
    "```\n",
    "\n",
    "This ensures your MCP servers work correctly with AI agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: FastMCPToolset Integration\n",
    "\n",
    "For an even simpler integration, use `FastMCPToolset`. This is especially powerful when the server is in the same codebase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response: Perfect! I've created the path network and found the shortest path.\n",
      "\n",
      "**Network Statistics:**\n",
      "- **Nodes**: 5\n",
      "- **Edges**: 4\n",
      "- **Density**: 0.4\n",
      "\n",
      "**Shortest Path from 1 to 5:**\n",
      "- **Path**: 1 → 2 → 3 → 4 → 5\n",
      "- **Length**: 4 (number of edges/hops)\n",
      "\n",
      "Since this is a simple linear path network, there's only one way to get from node 1 to node 5, and it requires traversing all 4 edges connecting the nodes in sequence.\n",
      "\n",
      "FastMCPToolset provides the simplest integration path!\n"
     ]
    }
   ],
   "source": [
    "# Alternative: FastMCPToolset for simpler integration\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.toolsets.fastmcp import FastMCPToolset\n",
    "\n",
    "# Option 1: Connect to Python script (runs as subprocess)\n",
    "toolset = FastMCPToolset('network_analysis_server.py')\n",
    "\n",
    "# Option 2: Connect directly to FastMCP server object (zero network overhead!)\n",
    "# This is great when server is in the same codebase\n",
    "# from network_analysis_server import network_mcp  # Would need to import\n",
    "# toolset = FastMCPToolset(network_mcp)\n",
    "\n",
    "agent = Agent(\n",
    "    'anthropic:claude-haiku-4-5',\n",
    "    toolsets=[toolset],\n",
    "    system_prompt=\"You are a helpful network analysis assistant.\"\n",
    ")\n",
    "\n",
    "# FastMCPToolset handles all the connection details\n",
    "async with agent:\n",
    "    result = await agent.run(\n",
    "        'Create a path network (1-2-3-4-5) and find the shortest path from 1 to 5'\n",
    "    )\n",
    "    print(\"Agent Response:\", result.output)\n",
    "\n",
    "print(\"\\nFastMCPToolset provides the simplest integration path!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Network prompts server created\n"
     ]
    }
   ],
   "source": [
    "from fastmcp import FastMCP\n",
    "\n",
    "network_prompts_mcp = FastMCP(\"NetworkPrompts\")\n",
    "\n",
    "@network_prompts_mcp.prompt()\n",
    "def analyze_network_structure(graph_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a comprehensive network analysis prompt.\n",
    "\n",
    "    This creates a structured request for analyzing a network's properties.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "Please analyze the network '{graph_id}' and provide:\n",
    "\n",
    "1. Basic Statistics:\n",
    "   - Number of nodes and edges\n",
    "   - Network density\n",
    "   - Average degree\n",
    "\n",
    "2. Centrality Analysis:\n",
    "   - Identify the top 3 nodes by degree centrality\n",
    "   - Identify the top 3 nodes by betweenness centrality\n",
    "   - Explain what makes these nodes central\n",
    "\n",
    "3. Structural Properties:\n",
    "   - Is the network connected?\n",
    "   - What is the clustering coefficient?\n",
    "   - Are there any obvious communities or clusters?\n",
    "\n",
    "4. Interpretation:\n",
    "   - What does this structure tell us about the system?\n",
    "   - What are the implications for information flow?\n",
    "\"\"\"\n",
    "\n",
    "@network_prompts_mcp.prompt()\n",
    "def explain_centrality_measures() -> str:\n",
    "    \"\"\"\n",
    "    Educational prompt explaining different centrality measures.\n",
    "    \"\"\"\n",
    "    return \"\"\"\n",
    "Please explain the following network centrality measures:\n",
    "\n",
    "1. Degree Centrality\n",
    "   - What does it measure?\n",
    "   - When is it useful?\n",
    "   - Example interpretation\n",
    "\n",
    "2. Betweenness Centrality\n",
    "   - What does it measure?\n",
    "   - How does it differ from degree?\n",
    "   - Example interpretation\n",
    "\n",
    "3. When to use each measure?\n",
    "   - What questions does each answer?\n",
    "   - Real-world applications\n",
    "\"\"\"\n",
    "\n",
    "print(\"✓ Network prompts server created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools vs Resources vs Prompts\n",
    "\n",
    "When should you use each?\n",
    "\n",
    "**Tools** (Functions):\n",
    "- ✓ When the AI needs to **perform an action**\n",
    "- ✓ When computation is required\n",
    "- ✓ When results depend on parameters\n",
    "- Examples: `calculate_centrality()`, `find_nash_equilibrium()`\n",
    "\n",
    "**Resources** (Data):\n",
    "- ✓ When the AI needs to **read information**\n",
    "- ✓ When data is static or slow-changing\n",
    "- ✓ When you want to provide datasets\n",
    "- Examples: adjacency matrices, simulation logs, documentation\n",
    "\n",
    "**Prompts** (Templates):\n",
    "- ✓ When you want to **guide the user**\n",
    "- ✓ When there are common workflows\n",
    "- ✓ When you want to showcase capabilities\n",
    "- Examples: \"Analyze this network\", \"Explain this concept\"\n",
    "\n",
    "**A complete MCP server** might have all three:\n",
    "- **Tools** to perform analysis\n",
    "- **Resources** to access data\n",
    "- **Prompts** to guide usage\n",
    "\n",
    "This makes your server self-documenting and user-friendly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Security Considerations (Preview for A3.02)\n",
    "\n",
    "Next lecture, we'll dive deep into security.\n",
    "\n",
    "For now, key considerations:\n",
    "\n",
    "**Input Validation**:\n",
    "- MCP servers should validate all inputs\n",
    "- Use Pydantic models for type safety\n",
    "- Reject unexpected or malicious data\n",
    "\n",
    "**Rate Limiting**:\n",
    "- Limit tool calls per client\n",
    "- Prevent denial-of-service\n",
    "- Implement backoff strategies\n",
    "\n",
    "**Authentication**:\n",
    "- HTTP servers should require auth tokens\n",
    "- Verify client identity\n",
    "- Track usage per user\n",
    "\n",
    "**Sandboxing**:\n",
    "- Run untrusted code in isolated environments\n",
    "- Limit access to file system and network\n",
    "- Use containers (Docker) for isolation\n",
    "\n",
    "**Least Privilege**:\n",
    "- Only expose necessary capabilities\n",
    "- Separate read and write operations\n",
    "- Require confirmation for destructive actions\n",
    "\n",
    "We'll explore these in depth next time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Conceptual Understanding\n",
    "\n",
    "**Part A**: Explain the difference between:\n",
    "1. Embedded tools (`@agent.tool` in PydanticAI)\n",
    "2. MCP servers with tools (`@mcp.tool` in FastMCP)\n",
    "\n",
    "When would you use each approach?\n",
    "\n",
    "**Part B**: For each scenario, identify whether you should use a Tool, Resource, or Prompt:\n",
    "1. Providing access to a dataset of network structures\n",
    "2. Computing the Nash equilibrium of a game\n",
    "3. Guiding users through a network analysis workflow\n",
    "4. Running a simulation for 1000 steps\n",
    "5. Retrieving historical simulation results\n",
    "\n",
    "**Part C**: Explain how MCP relates to:\n",
    "1. Network effects (from Week 3-4)\n",
    "2. Emergence (from Week 6-7)\n",
    "3. Strategic interaction (from Week 8-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Build a Simple MCP Server\n",
    "\n",
    "Create an MCP server for **statistical analysis** with these tools:\n",
    "\n",
    "1. `calculate_mean(data: List[float]) -> float`\n",
    "2. `calculate_std(data: List[float]) -> float`\n",
    "3. `find_outliers(data: List[float], threshold: float = 2.0) -> List[float]`\n",
    "\n",
    "**Requirements**:\n",
    "- Use FastMCP\n",
    "- Include proper docstrings\n",
    "- Add type hints\n",
    "- Handle edge cases (empty lists, etc.)\n",
    "\n",
    "**Bonus**: Add a resource that returns a summary of all analyses performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from fastmcp import FastMCP, Context\n",
    "from typing import List, Dict\n",
    "\n",
    "stats_mcp = FastMCP(\"Statistics\")\n",
    "\n",
    "# TODO: Implement tools\n",
    "@stats_mcp.tool()\n",
    "def calculate_mean(data: List[float]) -> float:\n",
    "    \"\"\"Calculate the arithmetic mean of a list of numbers.\"\"\"\n",
    "    # TODO: implement\n",
    "    pass\n",
    "\n",
    "# TODO: Add other tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Extend the Network Analysis Server\n",
    "\n",
    "Add these tools to the network analysis MCP server:\n",
    "\n",
    "1. `calculate_clustering_coefficient(graph_id: str) -> float`\n",
    "   - Use `nx.average_clustering(G)`\n",
    "   \n",
    "2. `find_communities(graph_id: str) -> List[List[int]]`\n",
    "   - Use `nx.community.greedy_modularity_communities(G)`\n",
    "   \n",
    "3. `calculate_diameter(graph_id: str) -> int`\n",
    "   - Use `nx.diameter(G)` (handle disconnected graphs!)\n",
    "\n",
    "**Bonus**: Add error handling for disconnected graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "@network_mcp.tool()\n",
    "def calculate_clustering_coefficient(\n",
    "    ctx: Context,\n",
    "    graph_id: str\n",
    ") -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Calculate the average clustering coefficient.\n",
    "\n",
    "    Clustering coefficient measures how much nodes tend to cluster together.\n",
    "    Values close to 1 indicate high clustering (friends of friends are friends).\n",
    "    \"\"\"\n",
    "    # TODO: implement\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Design an MCP Server for Your Domain\n",
    "\n",
    "Choose a domain from the course and design (don't implement yet) an MCP server:\n",
    "\n",
    "**Option A: Blockchain Analysis**\n",
    "- Tools for querying on-chain data\n",
    "- Analyzing transaction patterns\n",
    "- Computing wallet statistics\n",
    "\n",
    "**Option B: Auction Mechanisms**\n",
    "- Tools for different auction types\n",
    "- Computing bidding strategies\n",
    "- Analyzing revenue and efficiency\n",
    "\n",
    "**Option C: Your Research Domain**\n",
    "- What computational tools do you use?\n",
    "- How could an AI agent access them?\n",
    "- What would make them useful to others?\n",
    "\n",
    "**Deliverable**: Write specifications for 5 tools:\n",
    "- Tool name\n",
    "- Parameters (with types)\n",
    "- Return value (with type)\n",
    "- Docstring explaining what it does\n",
    "- When/why you'd use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: MCP vs Embedded Tools Trade-offs\n",
    "\n",
    "Consider a project that needs network analysis capabilities.\n",
    "\n",
    "**Scenario 1**: Single-user research script\n",
    "- Would you use MCP or embedded tools? Why?\n",
    "- What are the trade-offs?\n",
    "\n",
    "**Scenario 2**: Multi-user web application\n",
    "- Would you use MCP or embedded tools? Why?\n",
    "- How would you deploy it?\n",
    "\n",
    "**Scenario 3**: Educational platform for students\n",
    "- Would you use MCP or embedded tools? Why?\n",
    "- How would students interact with it?\n",
    "\n",
    "**Analysis**: For each scenario, discuss:\n",
    "- Complexity\n",
    "- Maintenance\n",
    "- Reusability\n",
    "- Performance\n",
    "- Security"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Official Documentation\n",
    "\n",
    "**Model Context Protocol**:\n",
    "- [MCP Specification](https://modelcontextprotocol.io/) - Official protocol documentation\n",
    "- [Anthropic MCP Announcement](https://www.anthropic.com/news/model-context-protocol) - Vision and motivation\n",
    "- [MCP Server Examples](https://github.com/modelcontextprotocol/servers) - Community-contributed servers\n",
    "\n",
    "**FastMCP**:\n",
    "- [FastMCP Documentation](https://gofastmcp.com/) - Complete guide\n",
    "- [FastMCP GitHub](https://github.com/jlowin/fastmcp) - Source code and examples\n",
    "- [FastMCP Examples](https://github.com/jlowin/fastmcp/tree/main/examples) - Sample servers\n",
    "\n",
    "**PydanticAI**:\n",
    "- [PydanticAI Docs](https://ai.pydantic.dev/) - Complete framework documentation\n",
    "- [Agents Guide](https://ai.pydantic.dev/agents/) - Building agents\n",
    "- [Tools Guide](https://ai.pydantic.dev/tools/) - Tool use patterns\n",
    "\n",
    "### Related Libraries\n",
    "\n",
    "**Network Analysis**:\n",
    "- [NetworkX Documentation](https://networkx.org/documentation/stable/) - Python network analysis\n",
    "- [NetworkX Tutorial](https://networkx.org/documentation/stable/tutorial.html) - Getting started\n",
    "\n",
    "**Game Theory**:\n",
    "- [QuantEcon.game_theory](https://quanteconpy.readthedocs.io/en/latest/game_theory.html) - Game theory tools\n",
    "- [QuantEcon Lectures](https://quantecon.org/lectures/) - Economic modeling\n",
    "\n",
    "**Agent-Based Modeling**:\n",
    "- [Mesa Documentation](https://mesa.readthedocs.io/) - Python ABM framework\n",
    "- [Mesa Examples](https://github.com/projectmesa/mesa-examples) - Sample models\n",
    "\n",
    "### Academic Papers\n",
    "\n",
    "**Tool Use and Function Calling**:\n",
    "- Schick et al. (2023) \"Toolformer: Language Models Can Teach Themselves to Use Tools\" [arXiv:2302.04761](https://arxiv.org/abs/2302.04761)\n",
    "- Qin et al. (2023) \"Tool Learning with Foundation Models\" [arXiv:2304.08354](https://arxiv.org/abs/2304.08354)\n",
    "- Patil et al. (2023) \"Gorilla: Large Language Model Connected with Massive APIs\" [arXiv:2305.15334](https://arxiv.org/abs/2305.15334)\n",
    "\n",
    "**Multi-Agent Systems**:\n",
    "- Wang et al. (2024) \"A Survey on Large Language Model Based Autonomous Agents\" [arXiv:2308.11432](https://arxiv.org/abs/2308.11432)\n",
    "- Xi et al. (2023) \"The Rise and Potential of Large Language Model Based Agents\" [arXiv:2309.07864](https://arxiv.org/abs/2309.07864)\n",
    "\n",
    "### Industry Resources\n",
    "\n",
    "**MCP Implementations**:\n",
    "- [Anthropic Claude Desktop](https://www.anthropic.com/claude/desktop) - Native MCP support\n",
    "- [MCP Server Registry](https://github.com/modelcontextprotocol/servers) - Community servers\n",
    "\n",
    "**Agent Frameworks**:\n",
    "- [LangChain](https://python.langchain.com/) - Alternative agent framework\n",
    "- [AutoGen](https://microsoft.github.io/autogen/) - Multi-agent conversations\n",
    "- [CrewAI](https://www.crewai.com/) - Role-based agents\n",
    "\n",
    "### Video Tutorials\n",
    "\n",
    "**MCP Introductions**:\n",
    "- Search for \"Model Context Protocol tutorial\" on YouTube\n",
    "- Anthropic developer talks on MCP\n",
    "\n",
    "**FastMCP Walkthroughs**:\n",
    "- Creator's introduction videos\n",
    "- Community live coding sessions\n",
    "\n",
    "### Community\n",
    "\n",
    "**Discussion and Support**:\n",
    "- [MCP Discord](https://discord.gg/modelcontextprotocol) - Community discussion\n",
    "- [PydanticAI Discussions](https://github.com/pydantic/pydantic-ai/discussions) - Q&A\n",
    "- [FastMCP Issues](https://github.com/jlowin/fastmcp/issues) - Bug reports and features\n",
    "\n",
    "### Course-Related\n",
    "\n",
    "**Week 3-5 (Networks)**:\n",
    "- Newman, M. (2018) \"Networks\" - Comprehensive network science textbook\n",
    "- Barabási, A.-L. \"Network Science\" - Free online textbook\n",
    "\n",
    "**Week 6-7 (ABMs)**:\n",
    "- Railsback & Grimm (2019) \"Agent-Based and Individual-Based Modeling\"\n",
    "- Wilensky & Rand (2015) \"An Introduction to Agent-Based Modeling\"\n",
    "\n",
    "**Week 8-9 (Game Theory)**:\n",
    "- Osborne & Rubinstein (1994) \"A Course in Game Theory\"\n",
    "- Shoham & Leyton-Brown (2008) \"Multiagent Systems\"\n",
    "\n",
    "### Next Lecture Preview\n",
    "\n",
    "**Security Resources** (for L.A3.02):\n",
    "- [Simon Willison's Blog on Prompt Injection](https://simonwillison.net/2023/Apr/14/worst-that-can-happen/)\n",
    "- [OWASP Top 10 for LLM Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/)\n",
    "- [Claude API reccomendations for security and safeguards](https://support.claude.com/en/articles/9199617-api-safeguards-tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
