{"version":"1","records":[{"hierarchy":{"lvl1":"Welcome"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Welcome"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nWelcome to week 1!\n\nThis week we will get to know eachother and get on the same page with respect to what this class is all about.\n\nWe will also dive right in to the computational infrastructure we will need by installing the Julia programming langauge and learning a bit about how to use it.\n\nEach week lecture notes will be distributed as a collection of Jupyter notebooks. The notebooks will follow a strict naming convention, where each notebook has a name such as L@@.##_XXX.ipynb where @@ is a two digit lecture number and ## is a two digit file number and XXX is one or more words describing the content of the notebook. We will work through the notebooks in the order indicated by the ##. The XXX are to provide easier access when reviewing notes after class.\n\n","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Welcome","lvl2":"About Me"},"type":"lvl2","url":"/#about-me","position":2},{"hierarchy":{"lvl1":"Welcome","lvl2":"About Me"},"content":"Spencer Lyon (\n\nspencer​.lyon@ucf​.edu)\n\nEconomics PhD from NYU (2018)\n\nLove to teach: mostly economics, data science, AI/ML – all have\nprogramming/computational element\n\nMoved to Orlando in July 2018 with wife and 5 (yes!) kids\n\nRun consulting (training/projects) business:   Valorum Data\n\nWorking on a couple startups\n\n","type":"content","url":"/#about-me","position":3},{"hierarchy":{"lvl1":"Welcome","lvl2":"About you"},"type":"lvl2","url":"/#about-you","position":4},{"hierarchy":{"lvl1":"Welcome","lvl2":"About you"},"content":"Background?\n\nProgress in program?\n\nAreas of interest? (meaningful answers here! they matter…)\n\nRumors about the course?\n\n","type":"content","url":"/#about-you","position":5},{"hierarchy":{"lvl1":"Welcome","lvl2":"About the course"},"type":"lvl2","url":"/#about-the-course","position":6},{"hierarchy":{"lvl1":"Welcome","lvl2":"About the course"},"content":"Interdisciplinary by nature\n\n“Living course”: only been taught a handful of times, content is flexible\n\nMore ideas/topics than time!\n\nHas been altered fairly significantly over the past few years (but the heart/soul of the course remains the same)\n\nNo required topics or standard textbook, so we get to pick!\n\nTheoretical concepts\n\nGraphs: less detail than network science course, but more algorithms\n\nGame Theory: strategic interaction/competition\n\nAgent Based Models: simulation of rule based systems\n\nAuction theory: Game theory at scale in bidding markets\n\nBlockchain: cryptographically secure, public, distributed ledger\n\nSocial, information, financial networks\n\nApplications\n\nTwitter\n\nEconomic markets and trade\nnetwork\n\nMore...\n\n","type":"content","url":"/#about-the-course","position":7},{"hierarchy":{"lvl1":"Welcome","lvl2":"Expectations"},"type":"lvl2","url":"/#expectations","position":8},{"hierarchy":{"lvl1":"Welcome","lvl2":"Expectations"},"content":"Take the time in the first 2 weeks to learn Julia\n\nYou’ll be glad you did\n\nContent moves quick and you don’t want syntax/programming to distract you or hold you back\n\nStudy reading assignments before class\n\nComplete assignments on time -- no exceptions\n\nParticipate in in-class discussions\n\nSpend ~3-6 hours outside of class per week\n\nCommunication\n\nPost all content related questions to class discussion forum\n\nRespond to peers’ questions and engage in discussions\n\nPersonal questions should go directly to me via email\n\nI do not use email on Sunday. Other days I will respond within 48 hours.\n\nDeliverables\n\nHomework (~8 – 30%)\n\nExam (2 – 30%)\n\nProjects (2 – 30%)\n\nCitizenship (throughout - 10%)\n\nFirst best: attend class in person, actively participate\n\nAcceptable: attend virtually, but keep video on and be ready to speak up when called on\n\nUnacceptable: attend virtually, but keep video off and/or don’t participate in discussions\n\n","type":"content","url":"/#expectations","position":9},{"hierarchy":{"lvl1":"Welcome","lvl2":"Tools/Resources"},"type":"lvl2","url":"/#tools-resources","position":10},{"hierarchy":{"lvl1":"Welcome","lvl2":"Tools/Resources"},"content":"Core textbooks\n\nNetworks, Crowds, and Markets by David Easley and Jon Kleinberg\n\nEconomics Networks by John Stachurski and Thomas Sargent\n\nWill be supplemented by lecture notes for more computational content\n\nJulia Programming language\n\nLecture notes are accessible via the \n\ncourse website\n\nLecture notes AND assignments in Jupyter notebooks\n\nAll course administration will happen through webcourses (Canvas)\n\nAssignments me <-> you\n\nFeedback on assignments me -> you\n\nDiscussion me + you <-> me + you\n\nOfficial grades will be visible on canvas","type":"content","url":"/#tools-resources","position":11},{"hierarchy":{"lvl1":"Julia Setup"},"type":"lvl1","url":"/l01-02-setup","position":0},{"hierarchy":{"lvl1":"Julia Setup"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nLaptop or personal computer with internet connection\n\nOutcomes\n\nInstall Julia and IJulia locally\n\nInstall VS Code\n\nOpen lecture notes locally\n\nReferences\n\nLecture notes\n\nQuantEcon lectures\n\nSetting up Julia\n\nGit, GitHub, Version Control\n\nJulia tools and editors\n\n","type":"content","url":"/l01-02-setup","position":1},{"hierarchy":{"lvl1":"Julia Setup","lvl2":"Step 1: Install Julia"},"type":"lvl2","url":"/l01-02-setup#step-1-install-julia","position":2},{"hierarchy":{"lvl1":"Julia Setup","lvl2":"Step 1: Install Julia"},"content":"The first step is to install Julia\n\n","type":"content","url":"/l01-02-setup#step-1-install-julia","position":3},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Install Julia","lvl2":"Step 1: Install Julia"},"type":"lvl3","url":"/l01-02-setup#task-install-julia","position":4},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Install Julia","lvl2":"Step 1: Install Julia"},"content":"Windows: windows users can install Julia from the microsoft store OR by running winget install --name Julia --id 9NJNWW8PVKMN -e -s msstore from powershell\n\nMac/Linux: Open terminal and run curl -fsSL https://install.julialang.org | sh (it is safe -- I promise ;))\n\n","type":"content","url":"/l01-02-setup#task-install-julia","position":5},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Launch Julia REPL","lvl2":"Step 1: Install Julia"},"type":"lvl3","url":"/l01-02-setup#task-launch-julia-repl","position":6},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Launch Julia REPL","lvl2":"Step 1: Install Julia"},"content":"Launch the Julia REPL (read-eval-print-loop) by clicking on the Julia icon or running julia from your shell (PowerShell or Terminal)\n\nYou will be greeted with a prompt that looks like this:   _       _ _(_)_     |  Documentation: https://docs.julialang.org\n  (_)     | (_) (_)    |\n   _ _   _| |_  __ _   |  Type \"?\" for help, \"]?\" for Pkg help.\n  | | | | | | |/ _` |  |\n  | | |_| | | | (_| |  |  Version 1.11.6 (2025-07-09)\n _/ |\\__'_|_|_|\\__'_|  |  Official https://julialang.org/ release\n|__/                   |\n\njulia> \n\nYou are now in what is called the Julia REPL (read-eval-print-loop). This is a place where you can type Julia commands and have them executed immediately.\n\nTest it out by typing rand(2, 2) and pressing enter\n\nYou should see something like this (note the numbers will be different for you):julia> rand(2, 2)\n2×2 Matrix{Float64}:\n 0.698944  0.676245\n 0.17375   0.448243\n\nCongratulations! You have successfully installed Julia and are ready to move on to the next step!\n\n","type":"content","url":"/l01-02-setup#task-launch-julia-repl","position":7},{"hierarchy":{"lvl1":"Julia Setup","lvl2":"Step 2: Install IJulia.jl"},"type":"lvl2","url":"/l01-02-setup#step-2-install-ijulia-jl","position":8},{"hierarchy":{"lvl1":"Julia Setup","lvl2":"Step 2: Install IJulia.jl"},"content":"With Julia installed we are now ready to install some Julia packages\n\nThe first package we’ll be using is called IJulia\n\nThis is a package integrates with Jupyter to allow us to run Julia code from notebooks\n\nSame Jupyter you may have used with Python\n\n","type":"content","url":"/l01-02-setup#step-2-install-ijulia-jl","position":9},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Install IJulia","lvl2":"Step 2: Install IJulia.jl"},"type":"lvl3","url":"/l01-02-setup#task-install-ijulia","position":10},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Install IJulia","lvl2":"Step 2: Install IJulia.jl"},"content":"Launch the Julia REPL (by typing julia from the Linux/OSX terminal prompt or using the start menu on Windows)\n\nAt the juila> prompt, type ]\n\nPrompt will switch to (@v1.11) pkg> \n\nOnce there type add IJulia and press enter\n\nIJulia.jl will be downloaded and installed on your machine\n\n","type":"content","url":"/l01-02-setup#task-install-ijulia","position":11},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Start IJulia","lvl2":"Step 2: Install IJulia.jl"},"type":"lvl3","url":"/l01-02-setup#task-start-ijulia","position":12},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Start IJulia","lvl2":"Step 2: Install IJulia.jl"},"content":"At the juila> prompt (press backspace to exit Pkg mode if needed), type using IJulia\n\nThen run the command: IJulia.notebook()\n\nA web browser should pop open with the IJulia.jl interface (should look similar to what I’m using)\n\n","type":"content","url":"/l01-02-setup#task-start-ijulia","position":13},{"hierarchy":{"lvl1":"Julia Setup","lvl2":"Step 3: Install Visual Studio Code"},"type":"lvl2","url":"/l01-02-setup#step-3-install-visual-studio-code","position":14},{"hierarchy":{"lvl1":"Julia Setup","lvl2":"Step 3: Install Visual Studio Code"},"content":"While we can and will use the native Julia REPL and first-party Jupyter software for our lecture notes, it is also helpful to have the ability to edit and run Julia code in a more full-featured editor\n\nFor this we will use Visual Studio Code (VSCode)\n\nVSCode is a free, open-source, cross-platform editor that has a large community of users and developers\n\nIt also has great support for Julia\n\nLearning how to use a general purpose text editor will help you in the long run\n\nYou can use it for Julia, Python, R, C, C++, etc.\n\nYou can use it for writing papers, taking notes, etc.\n\nNote on VS Code alternatives: There are several popular forks/alternatives to VS Code that provide enhanced features, particularly for AI-assisted coding:\n\nCursor: An AI-first code editor built on VS Code with enhanced AI capabilities\n\nWindsurf: Another AI-powered editor with advanced coding assistance features\n\nThese alternatives generally maintain compatibility with VS Code extensions (including the Julia extension), so you can use any of them for this course if you prefer. The instructions below will work for VS Code and most of its forks.\n\n","type":"content","url":"/l01-02-setup#step-3-install-visual-studio-code","position":15},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Download/Install VS Code","lvl2":"Step 3: Install Visual Studio Code"},"type":"lvl3","url":"/l01-02-setup#task-download-install-vs-code","position":16},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Download/Install VS Code","lvl2":"Step 3: Install Visual Studio Code"},"content":"Download and install VSCode from \n\nhere\n\nFollow all system prompts and accept default options\n\nOpen/launch VSCode\n\n","type":"content","url":"/l01-02-setup#task-download-install-vs-code","position":17},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Install Julia extension","lvl2":"Step 3: Install Visual Studio Code"},"type":"lvl3","url":"/l01-02-setup#task-install-julia-extension","position":18},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Install Julia extension","lvl2":"Step 3: Install Visual Studio Code"},"content":"VSCode has a large ecosystem of extensions that add functionality to the editor\n\nWe will install the Julia extension to add Julia support to VSCode\n\nIn VSCode, click on the “Extensions” icon in the left-hand toolbar (looks like a box with four squares in it)\n\nSearch for “Julia” and click the “Install” button on the “Julia” extension (subtitle is “Julia Language Support”)\n\n","type":"content","url":"/l01-02-setup#task-install-julia-extension","position":19},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: run Julia code in VSCode","lvl2":"Step 3: Install Visual Studio Code"},"type":"lvl3","url":"/l01-02-setup#task-run-julia-code-in-vscode","position":20},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: run Julia code in VSCode","lvl2":"Step 3: Install Visual Studio Code"},"content":"We can now run Julia code in VSCode\n\nOpen a new file in VSCode (File -> New File)\n\nType the following code into the file:println(\"Hello world!\")\n\nSave the file as hello.jl in a location you can find later\n\nPress Ctrl + Shift + P (or Cmd + Shift + P on Mac) to open the command palette\n\nType “Julia” and select “Julia: Run file in new process”\n\nYou should see the output of the code show up in a new terminal window within VS Code\n\n","type":"content","url":"/l01-02-setup#task-run-julia-code-in-vscode","position":21},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: run code with shift + Enter","lvl2":"Step 3: Install Visual Studio Code"},"type":"lvl3","url":"/l01-02-setup#task-run-code-with-shift-enter","position":22},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: run code with shift + Enter","lvl2":"Step 3: Install Visual Studio Code"},"content":"Go back to hello.jl and add the coden = 5\nP = rand(n, n)\n\nThen, put your cursor on the line that contains n = and press shift and enter at the same time\n\nThis will start a new Julia REPL within your VS Code session and execute the code for you\n\nIt will also move your cursor down to the P = line. Press shift + enter again to execute that line\n\n","type":"content","url":"/l01-02-setup#task-run-code-with-shift-enter","position":23},{"hierarchy":{"lvl1":"Julia Setup","lvl2":"Open Notebooks Locally"},"type":"lvl2","url":"/l01-02-setup#open-notebooks-locally","position":24},{"hierarchy":{"lvl1":"Julia Setup","lvl2":"Open Notebooks Locally"},"content":"You should view/follow along with lectures on the your computer\n\nBeing able to run code on your machine is critical for success in this course and will allow you to take skills with you after the course\n\n","type":"content","url":"/l01-02-setup#open-notebooks-locally","position":25},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Download notebooks","lvl2":"Open Notebooks Locally"},"type":"lvl3","url":"/l01-02-setup#task-download-notebooks","position":26},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Download notebooks","lvl2":"Open Notebooks Locally"},"content":"Go to the course website and download the notebooks for the first week\n\nMove the downloaded folder from your “Downloads” folder to wherever you’d like to store materials for the semester\n\nFollow the instructions above to start Julia, load IJulia, and open the Jupyter notebook with IJulia\n\nInside your local Jupyter notebook instance (in your web browser), navigate to where you copied the “Handouts” folder and open up this notebook\n\n","type":"content","url":"/l01-02-setup#task-download-notebooks","position":27},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Open notebook in vscode","lvl2":"Open Notebooks Locally"},"type":"lvl3","url":"/l01-02-setup#task-open-notebook-in-vscode","position":28},{"hierarchy":{"lvl1":"Julia Setup","lvl3":"Task: Open notebook in vscode","lvl2":"Open Notebooks Locally"},"content":"You can also run Jupyter notebooks directly in VS Code\n\nOpen VS Code and click on the “File” menu and select “Open Folder”\n\nNavigate to where you copied the notebooks for the first week\n\nClick on the “L01.02_setup.ipynb” file in the left-hand toolbar\n\nYou should see the notebook open in VS Code\n\nYou can run cells by clicking the “Run Cell” button in the top right of each cell, or by pressing Shift + Enter while your cursor is in the cell\n\nA menu will appear, choose the option containing Julia Release\n\nTest this out below\n\n# some random Julia code\nprintln(\"That's all, folks!\")","type":"content","url":"/l01-02-setup#task-open-notebook-in-vscode","position":29},{"hierarchy":{"lvl1":"Julia Foundations"},"type":"lvl1","url":"/l01-03-julia-basics","position":0},{"hierarchy":{"lvl1":"Julia Foundations"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nLaptop or personal computer with internet connection\n\nOutcomes\n\nUnderstand the main benefits and features of Julia\n\nSee how to define variables, functions, and types in Julia\n\nInstall commonly used packages for Graphs, DataFrames, Plotting and more\n\nReferences\n\nPackages and Software Engineering sections of QuantEcon julia lectures\n\nJulia \n\ndocumentation\n\nDocumentation for packages: \n\nGraphs, \n\nDataFrames, \n\nPlots\n\n","type":"content","url":"/l01-03-julia-basics","position":1},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"What is Julia?"},"type":"lvl2","url":"/l01-03-julia-basics#what-is-julia","position":2},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"What is Julia?"},"content":"Julia is a relatively new programming language (first public release in 2012, 1.0 release in 2018)\n\nGeneral purpose, but specializes in numerical computation\n\nLeverages advanced compiler technology to generate very efficient code\n\nIt can be as clear to read and write as Python, and as quick to evaluate as C!\n\n","type":"content","url":"/l01-03-julia-basics#what-is-julia","position":3},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Core Types"},"type":"lvl2","url":"/l01-03-julia-basics#core-types","position":4},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Core Types"},"content":"We’ll start by learning about the core datatypes built in to Julia\n\nAlong the way we’ll pick up some of the key syntax elements\n\nWe will move quickly, so some prior programming experience would be helpful\n\n","type":"content","url":"/l01-03-julia-basics#core-types","position":5},{"hierarchy":{"lvl1":"Julia Foundations","lvl3":"Numbers","lvl2":"Core Types"},"type":"lvl3","url":"/l01-03-julia-basics#numbers","position":6},{"hierarchy":{"lvl1":"Julia Foundations","lvl3":"Numbers","lvl2":"Core Types"},"content":"Let’s start with numbers\n\nTo work with a number, just type it!\n\n42\n\nWe can also do basic arithmetic in the way you would expect\n\n10 * 3\n\n1 + 2\n\nSo far we’ve worked with integers (whole numbers)\n\nJulia can also work with numbers containing a decimal\n\nIn Julia these are called floating point numbers\n\n1.234 ^ 2.2  # use `^` for exponentiation, not `**` like in python\n\n553.34 / 12.9\n\nWe can mix and match integers and floats\n\n25 / 2.5\n\n25 / 2  # dividing integers returns a float (notice the `.`)\n\nnotice we used # to define a comment\n\n","type":"content","url":"/l01-03-julia-basics#numbers","position":7},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Text Data"},"type":"lvl2","url":"/l01-03-julia-basics#text-data","position":8},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Text Data"},"content":"Not all data is numerical\n\nSome is textual\n\nTo represent text in Julia we use a String\n\nTo define a String we use quotation marks (\") as below\n\n\"My name is Spencer\"\n\n\"1\"  # an integer in a string\n\nYou cannot use single quotes for strings as in other languages (like Python or Javascript)\n\nGo ahead... try it by removing the # and excuting the cell below\n\n# 'hello'\n\n\"\"\"\nThis\n\nis\n\nalso\n\na\n\nstring\n\"\"\"\n\n","type":"content","url":"/l01-03-julia-basics#text-data","position":9},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Arrays"},"type":"lvl2","url":"/l01-03-julia-basics#arrays","position":10},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Arrays"},"content":"When doing numerical work, we often need to deal with multiple pieces of data at the same time\n\nIn Julia the default way of doing this is to use an array\n\nArrays are defined with [ and ] as below\n\n[1, 2, 3.14]  # a 3 element array\n\n[1 2 3]  # a 1x3 matrix\n\n[1 2; 3 4]  # a 2x2 matrix\n\n[1 2\n 3 4]  # another way to write a 2x2 matrix\n\n[1 \"hello\"; 2 \"world\"]  # a 2x2 matrix with int and string\n\n","type":"content","url":"/l01-03-julia-basics#arrays","position":11},{"hierarchy":{"lvl1":"Julia Foundations","lvl3":"Accessing array items","lvl2":"Arrays"},"type":"lvl3","url":"/l01-03-julia-basics#accessing-array-items","position":12},{"hierarchy":{"lvl1":"Julia Foundations","lvl3":"Accessing array items","lvl2":"Arrays"},"content":"We can use [N] to access the Nth element\n\nWe can also use [i:j] to access items i through j\n\nFinally we can use [[n1, n2]] to access the n1th and n2th elements\n\n[100, 101, 102, 103][2]\n\n[100, 101, 102, 103][2:4]\n\n[100, 101, 102, 103][[1, 3]]\n\nNote that unlike Python, Julia starts counting at 1\n\nAlso note that end can be used to refer to the last element, end-1 to second to last, and so on\n\n[1, 2, 3, 4][end]\n\n[1, 2, 3, 4][end-2]\n\n","type":"content","url":"/l01-03-julia-basics#accessing-array-items","position":13},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Tuples"},"type":"lvl2","url":"/l01-03-julia-basics#tuples","position":14},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Tuples"},"content":"There is another data type for holding “lists” of data called a tuple\n\nTuples are create using parenthesis instead of square brackets as follows\n\n(1, 2, 3, \"hello\")\n\n(\"hello\", 5)\n\n(\"hello\", 5)[2]\n\nThe main differences between tuples and arrays are\n\nTuples are meant to hold immutable or non-changing data\n\nTuples aren’t usually meant for computation or linear algebra\n\n","type":"content","url":"/l01-03-julia-basics#tuples","position":15},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Dictionary"},"type":"lvl2","url":"/l01-03-julia-basics#dictionary","position":16},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Dictionary"},"content":"Very often in programming we want to be able to associate a key or name to a specific value\n\nOne data type for doing that is a Dict\n\nDicts are created with the somewhat inconvenient syntax Dict(name => value, ...) where the ... means we can repeat the pattern multiple times\n\nThey keys and values can be of any type\n\nDict(\"x\" => 1, 2 => \"y\", [\"w\", \"z\"] => [1, 2, 3])\n\n# use `[name]` to access element with `name`\nDict(\"x\" => 1, 2 => \"y\", [\"w\", \"z\"] => [1, 2, 3])[2]\n\nDict(\"x\" => 1, \"y\" =>2)\n\nDictionaries are often used for passing around groups of parameters\n\nWe’ll see examples later on\n\n","type":"content","url":"/l01-03-julia-basics#dictionary","position":17},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Named Tuples"},"type":"lvl2","url":"/l01-03-julia-basics#named-tuples","position":18},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Named Tuples"},"content":"The final “collection” we’ll talk about is the named tuple\n\nIt is a hybrid between a tuple and a dictionary\n\nTo create them we use the synax (name = value, ...)\n\nThey names or keys need to be just names (not numbers or arrays). The values can be anything\n\n(x = 1, y = 2, z=\"hello\")\n\n(x = 1, y = 2, z=\"hello\").z # use `.name` to access item\n\nNamed tuples are a newer feature of Julia\n\nThey are often used for the same purpsoes as dictionaries because the syntax is much cleaner\n\n","type":"content","url":"/l01-03-julia-basics#named-tuples","position":19},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Variables"},"type":"lvl2","url":"/l01-03-julia-basics#variables","position":20},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Variables"},"content":"Often when programming, we need to refer to the same piece of data more than once\n\nTo do this we use a variable\n\nVariables are defined using an =, as in name = value\n\nx = 1\n\ny = 42\n\nx + y  # 'use' or 'refer to' x and y\n\nm1 = [1 0; 0 1]\n\nm2 = [1 2; 3 4]\n\nm1 * m2  # matrix multiplication\n\nm2 * m2  # again -- but with something besides identity matrix!\n\nd = Dict(\"X\" => 1, \"Y\" => 2)\n\nd[\"X\"]\n\n","type":"content","url":"/l01-03-julia-basics#variables","position":21},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Functions"},"type":"lvl2","url":"/l01-03-julia-basics#functions","position":22},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Functions"},"content":"Most Julia programs do more than basic arithmetic operations on data\n\nTo apply an operation to a piece of data, we call a function\n\nTo call a function we use the function_name(data1, data2)\n\nA very handy function is the typeof function\n\ntypeof(1)\n\ntypeof(2.0)\n\ntypeof([1,2,3])\n\ntypeof([1 2; 3 4.0])\n\nMany standard operations are built in to Julia as functions\n\nsum([1, 2, 3])  # compute sum of array of numbers\n\ninv([1 2; 3 4])  # matrix inverse\n\nsize([1 2; 3 4])  # number of (rows, columns)  in matrix\n\nlength([1, 2, 3])  # number of elements in array\n\nlength([1 2; 3 4])  # returns total number of elements in a Matrix\n\nrand(2, 2, 2)  # a 2x2x2 array of random numbers, sampled from uniform[0,1] dist\n\nJulia has 1000s of functions\n\nWe’ll learn more as we go along...\n\nJust watch for the pattern with parentisis: name(args)\n\n","type":"content","url":"/l01-03-julia-basics#functions","position":23},{"hierarchy":{"lvl1":"Julia Foundations","lvl3":"Defining Functions","lvl2":"Functions"},"type":"lvl3","url":"/l01-03-julia-basics#defining-functions","position":24},{"hierarchy":{"lvl1":"Julia Foundations","lvl3":"Defining Functions","lvl2":"Functions"},"content":"Functions are used to execute a predefined set of operations\n\nDefining our own funcitons allows us to break programs into small, easily written an understood components\n\nWe define functions using the syntaxfunction name(arg1, arg2)\n    # steps\nend\n\nfunction mean(x)\n    total = sum(x)\n    N = length(x)\n    total / N\nend\n\nmean([1, 2, 3])\n\n# mean of 1000 random samples from U[0,1] -- should be ~ 0.5\nmean(rand(1000))\n\nIf a function only contains one line of code, you can also use a shorthand notation:function_name(arg1, arg2) = # step\n\nadd_two(x) = x + 2\n\nadd_two(40)\n\n","type":"content","url":"/l01-03-julia-basics#defining-functions","position":25},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Getting help for functions"},"type":"lvl2","url":"/l01-03-julia-basics#getting-help-for-functions","position":26},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Getting help for functions"},"content":"Given that there are so many functions, sometimes it is hard to remember exactly what a function does\n\nThankfully we can get help from Julia\n\nIf we type ?function_name, Julia will present us with documentation about the function\n\n?map\n\n?extrema\n\n","type":"content","url":"/l01-03-julia-basics#getting-help-for-functions","position":27},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Control Flow"},"type":"lvl2","url":"/l01-03-julia-basics#control-flow","position":28},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Control Flow"},"content":"Julia has the basic elements of control flow:\n\nif-else statements\n\nfor loops\n\nif 1 > 2 # no parenthesis needed\n    println(\"what???\")\nelse     # else is optional\n    return mean([1, 2, 3])\n    print(\"phew\")\nend      # all \"blocks\" terminate with word `end`\n\nfor i in 1:5 # range of numbers 1 to 5\n    println(i, \" \", i^2)\nend\n\nWe will see many more examples as we go forward\n\n","type":"content","url":"/l01-03-julia-basics#control-flow","position":29},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Packages"},"type":"lvl2","url":"/l01-03-julia-basics#packages","position":30},{"hierarchy":{"lvl1":"Julia Foundations","lvl2":"Packages"},"content":"Julia comes ready to go with many powerful functions and data types\n\nHowever, there is a very active community of Julia programmers who are experts in different subfields of science and engineering\n\nThis has led to the development of vibrant and exciting ecosystem of packages or toolboxes for performing specific tasks\n\nWe can access these routines by using Julia packages\n\n","type":"content","url":"/l01-03-julia-basics#packages","position":31},{"hierarchy":{"lvl1":"Julia Foundations","lvl3":"Loading packages","lvl2":"Packages"},"type":"lvl3","url":"/l01-03-julia-basics#loading-packages","position":32},{"hierarchy":{"lvl1":"Julia Foundations","lvl3":"Loading packages","lvl2":"Packages"},"content":"By default Julia ships with a “standard library”\n\nThese are packages that come bundled with Julia itself and are pre-installed\n\nTo load a package and all of its types/functions use the using keyword\n\nFor example, we can load the Dates package and start using it\n\nusing Dates\n\nt1 = Dates.now()\n\nDates.format(t1, \"yyyy-mm-dd\")\n\nt2 = Dates.now()\n\nt2 > t1\n\nt3 = DateTime(1776, 7, 4)\n\n\"America is $(t1 - t3) ($(floor(t1 - t3, Dates.Day))) old\"\n\n","type":"content","url":"/l01-03-julia-basics#loading-packages","position":33},{"hierarchy":{"lvl1":"Julia Foundations","lvl3":"Installing Packages","lvl2":"Packages"},"type":"lvl3","url":"/l01-03-julia-basics#installing-packages","position":34},{"hierarchy":{"lvl1":"Julia Foundations","lvl3":"Installing Packages","lvl2":"Packages"},"content":"In addition to the standard library, we can also use packages created by other Julia users\n\nTo use a 3rd party package, we first need to install it\n\nThere are two ways to do this\n\n1]add PackageName\n\n2using Pkg  # a standard library package\nPkg.add(\"PackageName\")\n\nLet’s try them both\n\n]add Plots\n\nusing Pkg\nPkg.add(\"DataFrames\")\n\nAfter installing packages, we can load and use them just as we did the standard library packages\n\nusing Plots  # Python: from Plots import *\n\nplot([sin, cos], -2pi, 2pi)\n\nusing DataFrames\ndf = DataFrame(c1=1:10, c2=(1:10).^2)\n\n","type":"content","url":"/l01-03-julia-basics#installing-packages","position":35},{"hierarchy":{"lvl1":"Julia Foundations","lvl3":"Package Composability","lvl2":"Packages"},"type":"lvl3","url":"/l01-03-julia-basics#package-composability","position":36},{"hierarchy":{"lvl1":"Julia Foundations","lvl3":"Package Composability","lvl2":"Packages"},"content":"One unique feature sof Julia is that most of the language itself, in addition to packages, are written in Julia\n\nFor other languages like Python or R the “built in” part of the language is often written in another language like C\n\nThis difference has a large impact for Julia users\n\nBuilt in code and user code (including packages) are given the same “treatment”\n\nAnything the language creators can do, so can you\n\nA practical implication of this is that packages can operate on built in types (like we saw in our examples above) as well as types from other packages\n\nLet’s see what this looks like by plotting a DataFrame\n\n# install \"StatsPlots\", which links Plots and DataFrames\nPkg.add(\"StatsPlots\")\n\nusing StatsPlots\n\n@df df scatter(:c1, :c2)\n\nPkg.add(\"RDatasets\") # common datasets from R programming language\nusing RDatasets\nschool = RDatasets.dataset(\"mlmRev\",\"Hsb82\")\n@df school density(:MAch, group = :Sx)\n\n@df school density(:MAch, group = (:Sx, :Sector))","type":"content","url":"/l01-03-julia-basics#package-composability","position":37},{"hierarchy":{"lvl1":"Julia Types and Methods"},"type":"lvl1","url":"/l02-01-julia-types-methods","position":0},{"hierarchy":{"lvl1":"Julia Types and Methods"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nLaptop or personal computer with internet connection\n\nJulia intro lecture\n\nOutcomes\n\nUnderstand key components of Julia’s type system: abstract types, primitive types, composite types, and parametric types\n\nBe able to define our own custom types to hold data\n\nUnderstand the concept of multiple dispatch\n\nBe able to leverage the mulitple dispatch system to define custom behavior for built-in and custom types\n\nReferences\n\nLecture notes\n\nJulia documentation on \n\ntypes and \n\nmethods (these are technical, but comprehensive and well-written)\n\nQuantEcon lectures on \n\ntypes and generic programming\n\n","type":"content","url":"/l02-01-julia-types-methods","position":1},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl2":"Types in Julia"},"type":"lvl2","url":"/l02-01-julia-types-methods#types-in-julia","position":2},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl2":"Types in Julia"},"content":"Julia is both very expressive and runtime efficient\n\nThis is made possible because of the underlying compiler technology\n\nThe main strategy for user interaction with the compiler is by defining custom types and methods that operate on those types\n\nTypes and multiple dispatch go hand in hand and are key to effective Julia\n\n","type":"content","url":"/l02-01-julia-types-methods#types-in-julia","position":3},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"What is a type?","lvl2":"Types in Julia"},"type":"lvl3","url":"/l02-01-julia-types-methods#what-is-a-type","position":4},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"What is a type?","lvl2":"Types in Julia"},"content":"Each piece of data in a program resides in memory (RAM) on the host computer\n\nWe often assign names to data, which we call variables (in x = \"hello\", x is a variable)\n\nAt its most basic level, a variable is composed of\n\nAn arrangment of 0’s and 1’s called bits\n\nAn address to where in memory the data is recorded\n\nA Symbol representing the name we gave the data\n\nA type in Julia represents what kind of object is represented at a certain memory address\n\nJulia uses this type information to enable syntax (e.g. the $ in a string to interpolate or the . access for an objects fields) and ultimiately decide what behaviors are defined to operate on the data\n\n","type":"content","url":"/l02-01-julia-types-methods#what-is-a-type","position":5},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"Organizing types","lvl2":"Types in Julia"},"type":"lvl3","url":"/l02-01-julia-types-methods#organizing-types","position":6},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"Organizing types","lvl2":"Types in Julia"},"content":"In Julia types are organized into a hierarchy\n\nAt the top of the hierarcy is Any -- all objects are instances of Any\n\nAt the bottom of the hierarchy is Union{} -- no objects are instances of Union{}\n\nIn between these endpoints we have a rich family of types\n\nEach type can have at most one parent type (if not specified, default parent is Any)\n\nTypes can actually come in a few different flavors...\n\n","type":"content","url":"/l02-01-julia-types-methods#organizing-types","position":7},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"Types of Types","lvl2":"Types in Julia"},"type":"lvl3","url":"/l02-01-julia-types-methods#types-of-types","position":8},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"Types of Types","lvl2":"Types in Julia"},"content":"Abstract Types: cannot be created directly, but serve as nodes in a type hierarchy. Help us organize types into families and provide shared behavior for all members of the family\n\nPrimitive types: provided to us by Julia and represent a collection of bits (e.g. Float64, Bool, and Int8). We could create them, but we won’t. We won’t say anything else about them here\n\nComposite Types: types that contain additional data called fields. An instance can be treated as a single value. This is what we typically define and use\n\nNOTE: all objects in Julia are instances of either primitive or composite types, and can be related to one another by sharing common abstract type ancestors\n\n","type":"content","url":"/l02-01-julia-types-methods#types-of-types","position":9},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl2":"Abstract Types"},"type":"lvl2","url":"/l02-01-julia-types-methods#abstract-types","position":10},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl2":"Abstract Types"},"content":"Abstract types help organize composite types into families\n\nFor example, the number system in Julia looks like this (really -- look \n\nhere)abstract type Number end\nabstract type Real     <: Number end\nabstract type AbstractFloat <: Real end\nabstract type Integer  <: Real end\nabstract type Signed   <: Integer end\nabstract type Unsigned <: Integer end\n\nNote:\n\nNumber’s parent type is Any\n\nReal is a special kind of Number and can be broken into two subgroups: AbstractFloat and Integer\n\n","type":"content","url":"/l02-01-julia-types-methods#abstract-types","position":11},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"Why Abstract Types?","lvl2":"Abstract Types"},"type":"lvl3","url":"/l02-01-julia-types-methods#why-abstract-types","position":12},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"Why Abstract Types?","lvl2":"Abstract Types"},"content":"We said before we can’t create an instance of abstract types...\n\nSo, why do we have them?\n\nThe primary reason to have abstract types is to introduced shared functionality via methods defined on the abstract type\n\nExample: suppose you needed to define a function isint to determine if an object is an integer\n\nWithout abstract types, you could have a long sequence of checks for if a variable is any integer type:\n\nfunction isint1(x)\n\tfor T in [\n\t\tInt8, UInt8, Int16, UInt16, \n\t\tInt32, UInt32, Int64, UInt64, \n\t\tInt128, UInt128\n\t]\n\t\tif isa(x, T)\n\t\t\treturn true\n\t\tend\n\tend\n\treturn false\nend\n\nisint1(10), isint1(\"Hello\")\n\nWith abstract types we can define two methods:\n\nisint(x) = false\nisint(x::Integer) = true\n\nisint(10), isint(\"Hello\")\n\nThis has many benefits\n\nMuch simpler to write/reason about\n\nMore “fool proof”: what if we forgot one of the “UIntXX” types?\n\nMore “future proof”: what if a new type of integer gets introduced (e.g. UInt256 like is widely used in blockchain data!)\n\nPushes work into the compiler:\n\n@code_lowered isint1(\"hello\")\n\n@code_lowered isint1(UInt128(12341234123423134))\n\n@code_lowered isint(\"hello\") \n\n@code_lowered isint(UInt128(12341234123423134))\n\n","type":"content","url":"/l02-01-julia-types-methods#why-abstract-types","position":13},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl2":"Composite Types"},"type":"lvl2","url":"/l02-01-julia-types-methods#composite-types","position":14},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl2":"Composite Types"},"content":"Abstract types are very useful when used in conjunction with multiple dispatch (defining multiple methods of function with same name, but varying code depending on argument types)\n\nHowever, most often we create types to hold collections of related data together\n\nWe do this using composite types\n\nA composite type can be created as follows:struct Name <: AbstractParentType\n    field1::Field1Type\n\t# more fields\nend\n\nNote that the <: AbstractParentType is optional, as are types on all fields\n\n","type":"content","url":"/l02-01-julia-types-methods#composite-types","position":15},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"Composite Types: Examples","lvl2":"Composite Types"},"type":"lvl3","url":"/l02-01-julia-types-methods#composite-types-examples","position":16},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"Composite Types: Examples","lvl2":"Composite Types"},"content":"\n\nstruct Foo\n   bar\n   baz::Int\n   qux::Float64\nend\n\nfoo = Foo(\"Hello, world.\", 23, 1.5)\n\ntypeof(foo)\n\n# this will not work. Uncomment and try it out\n# Foo((), 23.5, 1)\n\nfieldnames(Foo)\n\nfoo.bar\n\nfoo.baz\n\nfoo.qux\n\n","type":"content","url":"/l02-01-julia-types-methods#composite-types-examples","position":17},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"Composite Types and Dispatch","lvl2":"Composite Types"},"type":"lvl3","url":"/l02-01-julia-types-methods#composite-types-and-dispatch","position":18},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"Composite Types and Dispatch","lvl2":"Composite Types"},"content":"Above we saw an example of defining multiple methods of isint, using an abstract type to route dispatch\n\nWe can also use composite types\n\nisint(x::Foo) = isint(x.bar)\n\nisint(10), isint(1.0), isint(UInt128(234901324987213)), isint(Foo(\"not an int\", 12, 1.0))\n\n@code_lowered isint(Foo(\"not an int\", 12, 1.0))\n\n@code_lowered isint(UInt128(12341234123423134))\n\nisint(foo)\n\nfoo, isint(foo)\n\nisint(Foo(1, 23, 1.5))\n\n","type":"content","url":"/l02-01-julia-types-methods#composite-types-and-dispatch","position":19},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"Exercises","lvl2":"Composite Types"},"type":"lvl3","url":"/l02-01-julia-types-methods#exercises","position":20},{"hierarchy":{"lvl1":"Julia Types and Methods","lvl3":"Exercises","lvl2":"Composite Types"},"content":"Create an abstract type called Person\n\nCreate two composite subtypes of Person called Friend and Foe\n\nEach of these should have fields name and height_inches\n\nFor friend you should also have a field favorite_color\n\nMAKE SURE TO ADD TYPES FOR ALL FIELDS\n\nCreate a third composite subtype of Person called Stranger, but without any fields\n\nSuppose we are trying to decide who to invite to a dinner party. Our rule is that friends should get a definite yes. Enemies a definite no. Strangers a 50%/50% toss up. However, if our spouse says we should invite a person, the answer is always yes\n\nCreate a function should_invite_to_party that implements that logic\n\nHINT: you will need 4 methods. 3 of these have only one argument, the 4th has two\n\nIn the cell at the bottom we have written a test case. You will know you’ve done this correctly when all the tests pass\n\n# Your code here\n\nusing Test\n\nfunction tests()\n\t@testset \"people\" begin\n\t\n\t\t@test fieldnames(Friend) == (:name, :height_inches, :favorite_color)\n\t\t@test fieldnames(Foe) == (:name, :height_inches)\n\t\t@test fieldnames(Stranger) == tuple()\n\n\t\tjim = Friend(\"Jim\", 64, \"blue\")\n\t\tdwight = Foe(\"Dwight\", 61)\n\t\tcreed = Stranger()\n\n\t\t@test jim isa Person\n\t\t@test dwight isa Person\n\t\t@test creed isa Person\n\n\t\t@test should_invite_to_party(jim) \n\t\t@test !should_invite_to_party(dwight)\n\t\t@test should_invite_to_party(dwight, true)\n\t\t\n\t\tcreed_invites = map(i->should_invite_to_party(creed), 1:100)\n\t\t@test any(creed_invites)\n\t\t@test any(map(!, creed_invites))\n\n\t\tcreed_invites_spouse = map(i->should_invite_to_party(creed, true), 1:100)\n\t\t@test all(creed_invites_spouse)\t\n\tend\nend\n\n# uncomment and run this cell when you are ready to test your code\ntests()","type":"content","url":"/l02-01-julia-types-methods#exercises","position":21},{"hierarchy":{"lvl1":"Julia Code Organization"},"type":"lvl1","url":"/l02-02-code-organization","position":0},{"hierarchy":{"lvl1":"Julia Code Organization"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nLaptop or personal computer with internet connection\n\nJulia intro lecture\n\nOutcomes\n\nCreating julia modules\n\nImporting Julia source fode files with the include function\n\nExporting types and functions to create\n\nReferences\n\nLecture notes\n\nJulia documentation on \n\nmodules\n\n","type":"content","url":"/l02-02-code-organization","position":1},{"hierarchy":{"lvl1":"Julia Code Organization","lvl2":"Introduction"},"type":"lvl2","url":"/l02-02-code-organization#introduction","position":2},{"hierarchy":{"lvl1":"Julia Code Organization","lvl2":"Introduction"},"content":"Julia can be succesfully used for exploratory analysis and one-off scripts\n\nAs projects grow, it is often useful to add structure and organization to the code\n\nIn Julia, the main building blocks for code organization and re-use include\n\nTypes/structs\n\nFunctions/methods\n\n.jl source code files\n\nModules\n\nPackages\n\nIn this not we’ll learn how to manage .jl files and Modules\n\nWe’ll pick up with Packages in another lecture\n\n","type":"content","url":"/l02-02-code-organization#introduction","position":3},{"hierarchy":{"lvl1":"Julia Code Organization","lvl2":".jl files"},"type":"lvl2","url":"/l02-02-code-organization#id-jl-files","position":4},{"hierarchy":{"lvl1":"Julia Code Organization","lvl2":".jl files"},"content":"Julia source code typically lives in a plain text file with a .jl extension\n\nWhile the extension is optional and not enforced by the Julia REPL or runtime, it is a strong convention followed by the community and by 3rd party tools like code editors and GitHub\n\nSuppose we have the following code for simulating Markov Chains in Julia\n\n# Markov Chain code\n\nstruct MarkovChain{T}\n    P::Matrix{Float64}\n    initial_state::Vector{Float64}\n    state_values::Vector{T}\n\n    P_dists::Vector{Vector{Float64}}\nend\n\nfunction MarkovChain(P::Matrix{Float64}, initial_state::Vector{Float64}, state_values::Vector{T}) where T\n    P_dists = [cumsum(row) for row in eachrow(P)]\n    return MarkovChain{T}(P, initial_state, state_values, P_dists)\nend\n\nfunction simulate_indices(mc::MarkovChain, n_steps::Int)\n    init_dist = cumsum(mc.initial_state)\n    states = Vector{Int}(undef, n_steps)\n    states[1] = searchsortedfirst(init_dist, rand())\n    for i in 2:n_steps\n        states[i] = searchsortedfirst(mc.P_dists[states[i-1]], rand())\n    end\n    return states\nend\n\nfunction simulate_values(mc::MarkovChain{T}, n_steps::Int)::Vector{T} where T\n    states = simulate_indices(mc, n_steps)\n    return mc.state_values[states]\nend\n\nP1 = [0.5 0.5; 0.5 0.5]\nmc1 = MarkovChain(P1, [1.0, 0.0], [\"A\", \"B\"])\n\ntypeof(mc1)\n\nmc1.P_dists\n\ninds = simulate_indices(mc1, 10)\n\nvals = simulate_values(mc1, 10)\nvals\n\nAs you can see, we can use this code from inside a Jupyter notebook by running the defining cell and then calling the routines\n\nHowever, what if we wanted to reuse the code for another notebook\n\nWe have two options:\n\nCopy/paste it to the new notebook\n\nStore the code in a .jl file and import it from both places\n\nLet’s pick the latter\n\n","type":"content","url":"/l02-02-code-organization#id-jl-files","position":5},{"hierarchy":{"lvl1":"Julia Code Organization","lvl2":"include"},"type":"lvl2","url":"/l02-02-code-organization#include","position":6},{"hierarchy":{"lvl1":"Julia Code Organization","lvl2":"include"},"content":"I have created markov.jl with that code:\n\nprintln(String(read(\"markov.jl\")))\n\nTo make use of this code in julia I can run include(\"markov.jl\")\n\nYou can think of the include function as copy/pasting AND evaluating the code from a file in whatever setting you are in\n\ninclude(\"markov.jl\")\n\nNotice that in the markov.jl file I added two extra functions (rand and stationary_ditributions)\n\nWe can verify that these were defined for us when we ran include by calling them:\n\nrand(mc1, 4)\n\nstationary_distributions(mc1)\n\n","type":"content","url":"/l02-02-code-organization#include","position":7},{"hierarchy":{"lvl1":"Julia Code Organization","lvl2":"Modules"},"type":"lvl2","url":"/l02-02-code-organization#modules","position":8},{"hierarchy":{"lvl1":"Julia Code Organization","lvl2":"Modules"},"content":"Being able to define code in a .jl file and load it in a notebook (or other .jl file!) is already a huge win for organization and reusability\n\nBut we can do better!\n\nOne issue with our approach here is that all types, functions, and methods we define in our included files will become part of our working Julia session.\n\nThis is not always wanted\n\nSuppose instead we really only wanted to make the MarkovChain, rand, and stationary_distributions code part of our session when loading our file\n\nTo do this, we will need to organize our code into a Module\n\nTo create module we use the syntaxmodule NAME\n\n# code here\n\nend\n\nHere we use the module keyword, followed by the name of the module\n\nBetween the module name and end we insert any code we want to include in the module\n\nBy convention, the contents of a module are not indented (this is a rare exception to indenting code that comes before end)\n\nI’ve created a module for our Markov chain code in module.jl:\n\nprintln(String(read(\"module.jl\")))\n\nNotice a few things:\n\nI used the export keyword to list types/functions I want to be added to the caller’s namespace when someone runs using Markov\n\nI used include to add the actual source code in the module\n\nThis is a very common pattern in Julia and is one we will see throughout our course\n\n","type":"content","url":"/l02-02-code-organization#modules","position":9},{"hierarchy":{"lvl1":"Julia Code Organization","lvl3":"Using Modules","lvl2":"Modules"},"type":"lvl3","url":"/l02-02-code-organization#using-modules","position":10},{"hierarchy":{"lvl1":"Julia Code Organization","lvl3":"Using Modules","lvl2":"Modules"},"content":"To use a module we first have to evaluate the code defining it\n\nTo do that we can include(\"module.jl\")\n\nWarning\n\nI restarted my kernel here!!!!\n\ninclude(\"module.jl\")\n\n\nNotice the printout shows that we now have a Main.Markov object\n\nNOTE: Main is the name of the default module the user executed code is evaluated in to\n\nWe can now access Markov.<NAME> where <NAME> is any type or function in the module\n\nP2 = [0.2 0.8; 0.5 0.5]\nmc2 = Markov.MarkovChain(P2, [1.0, 0.0], [10, 20])\n\nMarkov.rand(mc2, 2)\n\nNotice that I had to use Markov. to access members of the module\n\nNow taht the module is defined I can call using Markov to make it possible to use any exported function without the Markov. prefix\n\nusing Main.Markov\nstationary_distributions(mc2)\n\n","type":"content","url":"/l02-02-code-organization#using-modules","position":11},{"hierarchy":{"lvl1":"Julia Code Organization","lvl2":"Exercise"},"type":"lvl2","url":"/l02-02-code-organization#exercise","position":12},{"hierarchy":{"lvl1":"Julia Code Organization","lvl2":"Exercise"},"content":"Now it is your turn\n\nLet’s create a module for working with geometric shapes\n\nCreate two new .jl files\n\nOne called shapes.jl: here define the following:\n\nAn abstract type Shape2D\n\nConcrete types Circle, Rectangle, and Triangle that are subtypes of Shape2D\n\nMethods for area and perimeter for each shape type\n\nA function is_inside(shape, x, y) that checks if a point (x, y) is inside the shape\n\nOne called GeometricShapes.jl: here wrap the code from shapes.jl in a module named GeometricShapes\n\nExport the types: Shape2D, Circle, Rectangle, Triangle\n\nExport the functions: area, perimeter, is_inside\n\ninclude your new module and test it by:\n\nCreating instances of each shape\n\nComputing their areas and perimeters\n\nTesting if various points are inside or outside the shapes","type":"content","url":"/l02-02-code-organization#exercise","position":13},{"hierarchy":{"lvl1":"Julia Package Development"},"type":"lvl1","url":"/l02-03-julia-packages","position":0},{"hierarchy":{"lvl1":"Julia Package Development"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nLaptop or personal computer with internet connection\n\nJulia intro lecture\n\nJulia Modules lecture\n\nOutcomes\n\nInstalling, uninstalling, and updating packages\n\nManaging a Project.toml file and understanding the related Manifest.toml\n\nCreate new Julia packages to organize code snippets\n\nReferences\n\nLecture notes\n\nJulia documentation on \n\npackages\n\nPkg.jl standard library \n\ndocs\n\n","type":"content","url":"/l02-03-julia-packages","position":1},{"hierarchy":{"lvl1":"Julia Package Development","lvl2":"Introduction"},"type":"lvl2","url":"/l02-03-julia-packages#introduction","position":2},{"hierarchy":{"lvl1":"Julia Package Development","lvl2":"Introduction"},"content":"Julia is a very powerful, modern language\n\nIt comes packed with many essential components for creating high performing numerical programs\n\nArrays\n\nParallel processing\n\nMulti threading\n\nCalling C code\n\n... and many more\n\nHowever, Julia also has a thriving 3rd party library ecosystem (\n\nML, \n\nPlotting, \n\nNotebooks, \n\nDifferential Equations, and more)\n\nJulia libraries are known as packages\n\nToday we will learn how to manage and develop packages\n\n","type":"content","url":"/l02-03-julia-packages#introduction","position":3},{"hierarchy":{"lvl1":"Julia Package Development","lvl2":"Package Management"},"type":"lvl2","url":"/l02-03-julia-packages#package-management","position":4},{"hierarchy":{"lvl1":"Julia Package Development","lvl2":"Package Management"},"content":"To start, let’s learn how to manage Julia packages\n\nThere are two primary methods for managing packages:\n\nImporting and calling functions from the Pkg standard library package\n\nUsing the pkg REPL mode from the main Julia REPL\n\nWe will learn both here\n\nFirst, we’ll import the Pkg package\n\nNote\n\nExamples of the pkg REPL mode will be pasted here for you to view\n\nimport Pkg\n\n","type":"content","url":"/l02-03-julia-packages#package-management","position":5},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Installing","lvl2":"Package Management"},"type":"lvl3","url":"/l02-03-julia-packages#installing","position":6},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Installing","lvl2":"Package Management"},"content":"To install a package use Pkg.add(\"PACKAGE_NAME\")\n\nBelow we install the popular CSV package used for handling CSV files in Julia\n\nPkg.add(\"CSV\")\n\nTo use the pkg REPL mode, I first start the repl by running julia in my terminal\n\nThen I press ] to enter Pkg mode\n\nREPL prompt chanegs to (@v1.11) pkg> (where v1.11 represents my Julia system version)\n\nOnce here I run add CSV to get the following output:(@v1.11) pkg> add CSV\n   Resolving package versions...\n    Updating `~/.julia/environments/v1.11/Project.toml`\n  [336ed68f] + CSV v0.10.15\n    Updating `~/.julia/environments/v1.11/Manifest.toml`\n  [336ed68f] + CSV v0.10.15\n  [944b1d66] + CodecZlib v0.7.8\n  [34da2185] + Compat v4.18.0\n  [9a962f9c] + DataAPI v1.16.0\n  [e2d170a0] + DataValueInterfaces v1.0.0\n  [48062228] + FilePathsBase v0.9.24\n  [842dd82b] + InlineStrings v1.4.4\n  [82899510] + IteratorInterfaceExtensions v1.0.0\n  [bac558e1] + OrderedCollections v1.8.1\n  [2dfb63ee] + PooledArrays v1.4.3\n  [91c51154] + SentinelArrays v1.4.8\n  [3783bdb8] + TableTraits v1.0.1\n  [bd369af6] + Tables v1.12.1\n  [3bb67fe8] + TranscodingStreams v0.11.3\n  [ea10d353] + WeakRefStrings v1.4.2\n  [76eceee3] + WorkerUtilities v1.6.1\n  [9fa8497b] + Future v1.11.0\n\n","type":"content","url":"/l02-03-julia-packages#installing","position":7},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Checking Status","lvl2":"Package Management"},"type":"lvl3","url":"/l02-03-julia-packages#checking-status","position":8},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Checking Status","lvl2":"Package Management"},"content":"To check the status of my packages, I can use the Pkg.status function  or status command at the pkg REPL\n\nPkg.status()\n\n(@v1.11) pkg> status\nStatus `~/.julia/environments/v1.11/Project.toml`\n  [336ed68f] CSV v0.10.15\n⌃ [7073ff75] IJulia v1.29.2\nInfo Packages marked with ⌃ have new versions available and may be upgradable.\n\nThe printout here will show one line per explicity installed package (not transitive dependencies)\n\nThe format of each line is _ [ID] NAME VERSION where\n\nID is the beginning of a universially unique identifier (UUID) that identifies the package in the Julia ecosystem\n\nNAME is the name of the package\n\nVERSION is the installed version number\n\n_ is a placeholder for possible version updates. These placeholders will be explained beneath the list of packages\n\n","type":"content","url":"/l02-03-julia-packages#checking-status","position":9},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Updating","lvl2":"Package Management"},"type":"lvl3","url":"/l02-03-julia-packages#updating","position":10},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Updating","lvl2":"Package Management"},"content":"Notice how our printout shows we have version v1.29.2 of IJulia, but that there is an update available\n\nTo update to the latest verison (reccomended for security and features) we use the Pkg.udpate function or up REPL command\n\nIf we run pkg> up, Julia will attempt to get the latest version of all installed packages (same for Pkg.update())\n\nIf instead we do pkg> up IJulia, Julia will only update IJulia (same for Pkg.update(\"IJulia\"))\n\n(@v1.11) pkg> up IJulia\n    Updating registry at `~/.julia/registries/General.toml`\n    Updating `~/.julia/environments/v1.11/Project.toml`\n  [7073ff75] ↑ IJulia v1.29.2 ⇒ v1.30.0\n    Updating `~/.julia/environments/v1.11/Manifest.toml`\n  [7073ff75] ↑ IJulia v1.29.2 ⇒ v1.30.0\n  [b85f4697] - SoftGlobalScope v1.1.0\n\nNow running status does not show that IJulia has a newer available version\n\nPkg.status()\n\n","type":"content","url":"/l02-03-julia-packages#updating","position":11},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Uninstalling","lvl2":"Package Management"},"type":"lvl3","url":"/l02-03-julia-packages#uninstalling","position":12},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Uninstalling","lvl2":"Package Management"},"content":"To uninstall a package we can use the Pkg.rm(\"NAME\") functino or pkg> rm NAME REPL command:|\n\nPkg.rm(\"CSV\")\n\nStatus now shows we no longer have CSV\n\nPkg.status()\n\n","type":"content","url":"/l02-03-julia-packages#uninstalling","position":13},{"hierarchy":{"lvl1":"Julia Package Development","lvl2":"Environments"},"type":"lvl2","url":"/l02-03-julia-packages#environments","position":14},{"hierarchy":{"lvl1":"Julia Package Development","lvl2":"Environments"},"content":"Notice above when managing packages, I always saw the following at the top of the file:   Resolving package versions...\n    Updating `~/.julia/environments/v1.11/Project.toml`\n\nThis was a hint to how Julia keeps its packages organized...\n\nWhenever we are working in Julia, there is always an environment active\n\nBy default, the environment is specific to the user account (~/ is UNIX shorthand for current user’s home directory) and the Julia version number (v1.11)\n\nThis means that all packages we install will be available any time someone starts Julia v1.11 from my user account\n\n","type":"content","url":"/l02-03-julia-packages#environments","position":15},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Environment Management","lvl2":"Environments"},"type":"lvl3","url":"/l02-03-julia-packages#environment-management","position":16},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Environment Management","lvl2":"Environments"},"content":"Having a single, global environment is very convenient for simple tasks and exploration\n\nHowever, for larger software or research projects, it is a best practice to have an environment specific for that project\n\nThe Julia package manager has built in support for managing isolated sets of packages in named environments\n\n","type":"content","url":"/l02-03-julia-packages#environment-management","position":17},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Activate","lvl2":"Environments"},"type":"lvl3","url":"/l02-03-julia-packages#activate","position":18},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Activate","lvl2":"Environments"},"content":"To create an environment, start Julia within the folder for the project (use pwd()) to check your folder\n\nThen run Pkg.activate(\".\") or pkg> activate . to create a new project, or activate an existing project specific to the current folder\n\nWhen you run this command, no files will have been changed, but checking status will show you are in a different environment\n\nPkg.activate(\".\")\n\nPkg.status()\n\n","type":"content","url":"/l02-03-julia-packages#activate","position":19},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Manage Packages","lvl2":"Environments"},"type":"lvl3","url":"/l02-03-julia-packages#manage-packages","position":20},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Manage Packages","lvl2":"Environments"},"content":"Now that we have a new environment activated, we can install packages specific to this project\n\nPkg.add([\"VegaLite\", \"VegaDatasets\"])\n\nPkg.status()\n\nNote two things:\n\nWe can now use the packages\n\nThe Pkg.add command had this line in the printout: Updating ~/Teaching/UCF/CAP-6318/book-myst/week02/Project.toml\n\nWe’ll demonstrate we can use the packages below, then we’ll dig into the Project.toml\n\nusing VegaLite, VegaDatasets\n\ndataset(\"cars\") |>\n@vlplot(\n    :point,\n    x=:Horsepower,\n    y=:Miles_per_Gallon,\n    color=:Origin,\n    width=400,\n    height=400\n)\n\n","type":"content","url":"/l02-03-julia-packages#manage-packages","position":21},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Package.toml","lvl2":"Environments"},"type":"lvl3","url":"/l02-03-julia-packages#package-toml","position":22},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Package.toml","lvl2":"Environments"},"content":"Julia environments are managed and described using in a format called TOML (Tom’s obvious markup language) in a file Project.toml\n\nThis file will be created and updated as needed by Pkg as we run Pkg commands\n\nLet’s see what our new Project.toml looks like:\n\nprintln(String(read(\"Project.toml\")))\n\nThis shows us we have a [deps] section with entries for the three packages we installed\n\nEach package line has the NAME = UUID syntax\n\nThere can be other top level items (not in a section) and other sections\n\nWe’ll discuss these as they come up\n\n","type":"content","url":"/l02-03-julia-packages#package-toml","position":23},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Manifest.toml","lvl2":"Environments"},"type":"lvl3","url":"/l02-03-julia-packages#manifest-toml","position":24},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Manifest.toml","lvl2":"Environments"},"content":"Notice that the Project.toml file does not have any information about the version of our installed packages\n\nThere is a companion file called Manifest.toml that does have this information\n\nLet’s take a look:\n\nprintln(String(read(\"Manifest.toml\")))\n\nThe Manifest.toml file is a very comprehensive overview of ALL details about a Julia environment\n\nThis file is rarely (if ever) touched by humans\n\nIt can be used to reproduce an exact replica of the Julia version, packages, and package versions on any machine\n\n","type":"content","url":"/l02-03-julia-packages#manifest-toml","position":25},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Set up environment on new machine","lvl2":"Environments"},"type":"lvl3","url":"/l02-03-julia-packages#set-up-environment-on-new-machine","position":26},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Set up environment on new machine","lvl2":"Environments"},"content":"If you are given a Project.toml/Manifest.toml combo, you can easily create a duplicate of teh author’s Julia environment\n\nTo do this follow these two steps:\n\nCall Pkg.activate(\".\")  (or pkg> activate) from the directory containing the .toml files\n\nCall Pkg.instantiate() (or pkg> instantiate)\n\nThis will first activate the Project’s environment in your current Julia session and then install all dependencies\n\nusing Pkg\nPkg.activate(\".\")\nPkg.instantiate()\n\n","type":"content","url":"/l02-03-julia-packages#set-up-environment-on-new-machine","position":27},{"hierarchy":{"lvl1":"Julia Package Development","lvl2":"Package Development"},"type":"lvl2","url":"/l02-03-julia-packages#package-development","position":28},{"hierarchy":{"lvl1":"Julia Package Development","lvl2":"Package Development"},"content":"The vast majority of Julia itself -- including the packages in its standard library -- are written in Julia\n\nThis means that to be a package author you really only need to know Julia\n\nSince you know Julia, you can author packages!\n\nThe Pkg module has a \n\ngenerate function to help us develop packages, however Julia authors reccomend using the first party PkgTemplates.jl package to start a new package\n\nSo, we’ll start by installing PkgTemplates\n\nusing Pkg\nPkg.add(\"PkgTemplates\")\n\nusing PkgTemplates\n\n","type":"content","url":"/l02-03-julia-packages#package-development","position":29},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"CAP6318","lvl2":"Package Development"},"type":"lvl3","url":"/l02-03-julia-packages#cap6318","position":30},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"CAP6318","lvl2":"Package Development"},"content":"As we progress throughout the semseter we will build up a toolbox of useful types and functions\n\nLet’s organize these into a helpful package called CAP6318\n\nWe can also use this package as a way to specify dependencies specifically required for the course\n\nTo create our package we will need to follow the \n\nPkgTemplates.jl documentation to (1) establish the template for our project and (2) run the template on our project name\n\nt = Template(;\n    user=\"sglyon\", # TODO: you change this!\n    plugins=[PkgTemplates.Develop(), ]\n)\n\npackage_dir = t(\"CAP6318\")\n\nNotice that the code generated a new project in ~/.julia/dev/CAP6318\n\nLet’s take a look at was created for us\n\nLet’s see what was created for us\n\ncmd =`tree $package_dir`\nprintln(\"About to run: $cmd\")\nrun(cmd);\n\nHere we see a LICENSE, Manifest.toml/Project.toml pair, and a README.md (for usage instructions) in the top folder\n\nThen inside src/ we have a module file CAP6318.jl\n\nInside test/ we have a runtests.jl file\n\nLet’s peek inside the files\n\nprint_pkg_file(parts::String...) = println(String(read(joinpath(package_dir, parts...))))\nprint_pkg_file(\"Project.toml\")\n\nprint_pkg_file(\"src\", \"CAP6318.jl\")\n\nprint_pkg_file(\"test\", \"runtests.jl\")\n\nOk, we have a nicely structured starting point\n\nWe will add to this throughout the course\n\n","type":"content","url":"/l02-03-julia-packages#cap6318","position":31},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Exercise","lvl2":"Package Development"},"type":"lvl3","url":"/l02-03-julia-packages#exercise","position":32},{"hierarchy":{"lvl1":"Julia Package Development","lvl3":"Exercise","lvl2":"Package Development"},"content":"Perform the following tasks\n\nActivate the project by doing activate CAP6318. Because we specified Develop() in our template and this is the package name we do not need to be in the same directory or pass the directory path\n\nInstall CSV, DataFrames, VegaLite, Graphs in the CAP6318 project. We’ll use them later\n\nEnsure that you installed these correctly by using the print_pkg_file function above and looking for the [deps] section\n\nCreate a new function greet() = println(\"Hello from CAP6318\") in your src/CAP6318.jl module file. Note you will have to open this file in your text editor\n\nCall using CAP6318 then run greet() to see your message","type":"content","url":"/l02-03-julia-packages#exercise","position":33},{"hierarchy":{"lvl1":"Graphs"},"type":"lvl1","url":"/l03-01-graphs","position":0},{"hierarchy":{"lvl1":"Graphs"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nJulia setup\n\nJulia basics\n\nJulia types and methods\n\nOutcomes\n\nUnderstand key components of networks/graphs\n\nUse the Graphs.jl package for working with graphs in Julia\n\nImplement the breadth-first search algorithm\n\nReferences\n\nEasley and Kleinberg chapter 2\n\n","type":"content","url":"/l03-01-graphs","position":1},{"hierarchy":{"lvl1":"Graphs","lvl2":"Introduction"},"type":"lvl2","url":"/l03-01-graphs#introduction","position":2},{"hierarchy":{"lvl1":"Graphs","lvl2":"Introduction"},"content":"\n\n","type":"content","url":"/l03-01-graphs#introduction","position":3},{"hierarchy":{"lvl1":"Graphs","lvl3":"Why Study Graphs?","lvl2":"Introduction"},"type":"lvl3","url":"/l03-01-graphs#why-study-graphs","position":4},{"hierarchy":{"lvl1":"Graphs","lvl3":"Why Study Graphs?","lvl2":"Introduction"},"content":"Economic, cultural, political, and social interactions are influenced by structure of relationships\n\nTransmission of viruses\n\nInternational trade, supply chains, marketplaces\n\nSpread of information, diffusion of innovation\n\nPolitical persuasion, localized voting patterns\n\nHuman behaviors influenced by network of friends (sports, clothes, music)\n\nBehaviors can be effected by social networks\n\n“Influencers”\n\nCircles of followers can create echo chambers\n\n","type":"content","url":"/l03-01-graphs#why-study-graphs","position":5},{"hierarchy":{"lvl1":"Graphs","lvl3":"Edges and Nodes","lvl2":"Introduction"},"type":"lvl3","url":"/l03-01-graphs#edges-and-nodes","position":6},{"hierarchy":{"lvl1":"Graphs","lvl3":"Edges and Nodes","lvl2":"Introduction"},"content":"A graph specifies relationships between a collection of items\n\nEach item is called a node\n\nA relationship between nodes is represented by an edge\n\nVisually, graphs might look like this:\n\nHere the nodes are A, B, C, D\n\nThe edges connect nodes A-B, B-C, B-D, C-D\n\n","type":"content","url":"/l03-01-graphs#edges-and-nodes","position":7},{"hierarchy":{"lvl1":"Graphs","lvl3":"Adjacency Matrix","lvl2":"Introduction"},"type":"lvl3","url":"/l03-01-graphs#adjacency-matrix","position":8},{"hierarchy":{"lvl1":"Graphs","lvl3":"Adjacency Matrix","lvl2":"Introduction"},"content":"How might we represent the graph above numerically?\n\nOne very common approach is to use a matrix of 0’s and 1’s called an adjancency matrix\n\nSuppose we have a graph of N nodes\n\nWithout loss of generality, we’ll represent them as integers 1:N\n\nLet A \\in \\{0,1\\}^{N \\times N} be our adjacency matrix\n\nElement A_{ij} will be zero unless there is an edge between nodes i and j (diagonal is left as 0)\n\nIn our above we had\n\nNodes A, B, C, D (or 1, 2, 3, 4 respectively)\n\nEdges connecting nodes 1-2, 2-3, 2-4, 3-4\n\nThe adjacency matrix for this example is\nA = \\begin{bmatrix}\n0 & 1 & 0 & 0 \\\\\n1 & 0 & 1 & 1 \\\\\n0 & 1 & 0 & 1 \\\\\n0 & 1 & 1 & 0\n\\end{bmatrix}\n\n","type":"content","url":"/l03-01-graphs#adjacency-matrix","position":9},{"hierarchy":{"lvl1":"Graphs","lvl2":"Graphs in Julia"},"type":"lvl2","url":"/l03-01-graphs#graphs-in-julia","position":10},{"hierarchy":{"lvl1":"Graphs","lvl2":"Graphs in Julia"},"content":"In Julia there are a few ways we could represent our example graph above\n\nWe could start with the adjacency matrix concept as follows\n\nA = [\n\t0 1 0 0\n\t1 0 1 1\n\t0 1 0 1\n\t0 1 1 0\n]\n\n","type":"content","url":"/l03-01-graphs#graphs-in-julia","position":11},{"hierarchy":{"lvl1":"Graphs","lvl3":"Working with Adjacency Matrices","lvl2":"Graphs in Julia"},"type":"lvl3","url":"/l03-01-graphs#working-with-adjacency-matrices","position":12},{"hierarchy":{"lvl1":"Graphs","lvl3":"Working with Adjacency Matrices","lvl2":"Graphs in Julia"},"content":"An adjacency matrix gives us a lot of information about the structure of the graph\n\nWe could compute all of the following\n\nTotal number of nodes: number of rows or columns of A\n\nTotal number of edges: \\sum_{ij} A_{ij}\n\nNode with most edges: \\text{argmax}_{i} \\sum_{j} A_{i,j}\n\nAverage number of edges per node: \\frac{2}{N} \\cdot \\sum_{i,j>i} A_{i,j}\n\n","type":"content","url":"/l03-01-graphs#working-with-adjacency-matrices","position":13},{"hierarchy":{"lvl1":"Graphs","lvl3":"Exercise: Adjacency Matrix","lvl2":"Graphs in Julia"},"type":"lvl3","url":"/l03-01-graphs#exercise-adjacency-matrix","position":14},{"hierarchy":{"lvl1":"Graphs","lvl3":"Exercise: Adjacency Matrix","lvl2":"Graphs in Julia"},"content":"In the cell below we have defined an adjacency matrix called A_ex1\n\nUsing A_ex1 answer the following questions:\n\nHow many nodes are in the graph?\n\nHow many edges?\n\nNode with most edges (hint, use the dims argument to sum and then the argmax function)\n\nAverage number of edges per node\n\nNumber of connections for node 7: \\sum_j A_{j7}\n\nimport Random\nRandom.seed!(42)\n\nA_ex1 = zeros(Int, 30, 30)\n\nfor i in 1:30\n    for j in (i+1):30\n        if rand() < 0.2\n            A_ex1[i, j] = 1\n            A_ex1[j, i] = 1\n        end\n    end\nend\n\n# Your code here\n\nex1_total_nodes = missing\nex1_total_edges = missing\nex1_node_most_edges = missing\nex1_average_edges_per_node = missing\nex1_connections_node_7 = missing\n\n","type":"content","url":"/l03-01-graphs#exercise-adjacency-matrix","position":15},{"hierarchy":{"lvl1":"Graphs","lvl3":"Graphs.jl","lvl2":"Graphs in Julia"},"type":"lvl3","url":"/l03-01-graphs#graphs-jl","position":16},{"hierarchy":{"lvl1":"Graphs","lvl3":"Graphs.jl","lvl2":"Graphs in Julia"},"content":"There are many smart graph theory experts in the Juila community\n\nThey have built a package called Graphs for working with graphs (as well as ancillary pacakges for extra features)\n\nWe can build a Graphs.Graph object directly from our adjacency matrix\n\nusing Graphs\n\nG1 = Graph(A)\n\ncollect(edges(G1))  # collect turns an `iterator` into an array\n\ncollect(vertices(G1))  # Graphs refers to nodes as `vertices`\n\n","type":"content","url":"/l03-01-graphs#graphs-jl","position":17},{"hierarchy":{"lvl1":"Graphs","lvl4":"Visualizing Graphs","lvl3":"Graphs.jl","lvl2":"Graphs in Julia"},"type":"lvl4","url":"/l03-01-graphs#visualizing-graphs","position":18},{"hierarchy":{"lvl1":"Graphs","lvl4":"Visualizing Graphs","lvl3":"Graphs.jl","lvl2":"Graphs in Julia"},"content":"We can use the GraphPlot package to visualize our graph\n\nNote that the actual placement of the nodes is randomly generated and then tweaked to clearly show all nodes and edges\n\nThe important thing is not the placement of nodes, but rather their relative structure\n\nusing GraphPlot  # load GraphPlot package\n\ngplot(G1)\n\n","type":"content","url":"/l03-01-graphs#visualizing-graphs","position":19},{"hierarchy":{"lvl1":"Graphs","lvl3":"Size considerations","lvl2":"Graphs in Julia"},"type":"lvl3","url":"/l03-01-graphs#size-considerations","position":20},{"hierarchy":{"lvl1":"Graphs","lvl3":"Size considerations","lvl2":"Graphs in Julia"},"content":"Using Array{Int64,2} to store an adjacency matrix turns out to be a rather costly way to store a graph\n\nIn the original example graph we had 4 nodes and 4 edges\n\nTo store this we needed to have a 4x4 matrix of 64 bit integers\n\nThis is only (Int(16 * 64 / 8) == 128) bytes in our exapmle,\n\nBut consider a graph of websites and links between them -- that graph would have millions of nodes and edges...\n\nThere are a few approaches to reducing this storage cost:\n\nOnly store the upper triangle of the matrix\n\nUse Array{Bool,2} instead of Array{Int64,2} to store adjacency matrix ( each element only sizeof(Bool) == 1 bit!)\n\nUse a \n\nSparseMatrix\n\nStore as a Vector{Vector{Int}}\n\n# Vector{Vector{Int}}\nA2 = [[2], [1, 3, 4], [2, 4], [2, 3]]\n\nG1.fadjlist\n\n","type":"content","url":"/l03-01-graphs#size-considerations","position":21},{"hierarchy":{"lvl1":"Graphs","lvl2":"Graph Theory Concepts"},"type":"lvl2","url":"/l03-01-graphs#graph-theory-concepts","position":22},{"hierarchy":{"lvl1":"Graphs","lvl2":"Graph Theory Concepts"},"content":"Let’s explore some concepts often used in analysis of graphs\n\n","type":"content","url":"/l03-01-graphs#graph-theory-concepts","position":23},{"hierarchy":{"lvl1":"Graphs","lvl3":"Paths","lvl2":"Graph Theory Concepts"},"type":"lvl3","url":"/l03-01-graphs#paths","position":24},{"hierarchy":{"lvl1":"Graphs","lvl3":"Paths","lvl2":"Graph Theory Concepts"},"content":"When studying graphs it is often natural to ask about how things travel or flow across the graph\n\nFor example, how information spreads amongst a group of friends, how data travels the internet, how diseases are transmitted from one person to another, and how people navigate a metro subway system\n\nIn each of these cases, the flow of things goes from node to node across edges\n\nA flow from one any node to another node is called a path\n\n","type":"content","url":"/l03-01-graphs#paths","position":25},{"hierarchy":{"lvl1":"Graphs","lvl3":"Degree","lvl2":"Graph Theory Concepts"},"type":"lvl3","url":"/l03-01-graphs#degree","position":26},{"hierarchy":{"lvl1":"Graphs","lvl3":"Degree","lvl2":"Graph Theory Concepts"},"content":"The degree of a node is the number of edges connected to it\n\nIn our example graph G1, node B has degree 3 (connected to A, C, and D)\n\nNode A has degree 1 (only connected to B)\n\nDegree is a fundamental measure of node importance in a network\n\nHigh-degree nodes are often called “hubs”\n\nIn social networks, these might be influential people or “connectors”\n\nWe can compute degree directly from the adjacency matrix\n\nDegree of node i is \\sum_j A_{ij}\n\nGraphs.jl provides the degree function\n\ndegree(G1)\n\ndegree(arpa, node_ints[\"MIT\"])\n\nThe degree distribution of a network tells us a lot about its structure\n\nMany real-world networks have a few high-degree hubs and many low-degree nodes\n\nSocial networks: celebrities with millions of followers\n\nInternet: major websites with many incoming links\n\nTransportation: hub airports like Atlanta or Chicago\n\n","type":"content","url":"/l03-01-graphs#degree","position":27},{"hierarchy":{"lvl1":"Graphs","lvl3":"Arpanet Example","lvl2":"Graph Theory Concepts"},"type":"lvl3","url":"/l03-01-graphs#arpanet-example","position":28},{"hierarchy":{"lvl1":"Graphs","lvl3":"Arpanet Example","lvl2":"Graph Theory Concepts"},"content":"Consider the following Graph of the first iteration of the internet\n\nThere are many possible paths through this network\n\nConsider a path from UCSB to MIT: UCSB-UCLA-RAND-BBN-MIT\n\nAnother possible path from UCSB to MIT is UCSB-SRI-UTAH-MIT\n\n","type":"content","url":"/l03-01-graphs#arpanet-example","position":29},{"hierarchy":{"lvl1":"Graphs","lvl3":"Graphs.jl Arpanet","lvl2":"Graph Theory Concepts"},"type":"lvl3","url":"/l03-01-graphs#graphs-jl-arpanet","position":30},{"hierarchy":{"lvl1":"Graphs","lvl3":"Graphs.jl Arpanet","lvl2":"Graph Theory Concepts"},"content":"Let’s define the Arpanet using Graphs as it will be helpful throughout this lecture\n\nnodes = [\n\t\t\"UCSB\" => [\"SRI\", \"UCLA\"],\n\t\t\"SRI\" => [\"UCSB\", \"UCLA\", \"STAN\", \"UTAH\"],\n\t\t\"UCLA\" => [\"SRI\", \"UCSB\", \"STAN\", \"RAND\"],\n\t\t\"STAN\" => [\"SRI\", \"UCLA\"],\n\t\t\"UTAH\" => [\"SRI\", \"SDC\", \"MIT\"],\n\t\t\"SDC\" => [\"UTAH\", \"RAND\"],\n\t\t\"RAND\" => [\"UCLA\", \"SDC\", \"BBN\"],\n\t\t\"MIT\" => [\"UTAH\", \"BBN\", \"LINC\"],\n\t\t\"BBN\" => [\"MIT\", \"RAND\", \"HARV\"],\n\t\t\"LINC\" => [\"MIT\", \"CASE\"],\n\t\t\"CASE\" => [\"LINC\", \"CARN\"],\n\t\t\"CARN\" => [\"CASE\", \"HARV\"],\n\t\t\"HARV\" => [\"CARN\", \"BBN\"]\n\t]\nnode_ints = Dict(zip(first.(nodes), 1:length(nodes)))\narpa = SimpleGraph(length(nodes))\nfor (node, edges) in nodes\n    for e in edges\n        add_edge!(arpa, node_ints[node], node_ints[e])\n    end\nend\n\n# save graph for loading in future\nsavegraph(\"arpanet.lg\", arpa)\n\narpa\n\ngplot(arpa, nodelabel=first.(nodes))\n\n","type":"content","url":"/l03-01-graphs#graphs-jl-arpanet","position":31},{"hierarchy":{"lvl1":"Graphs","lvl3":"Cycles","lvl2":"Graph Theory Concepts"},"type":"lvl3","url":"/l03-01-graphs#cycles","position":32},{"hierarchy":{"lvl1":"Graphs","lvl3":"Cycles","lvl2":"Graph Theory Concepts"},"content":"An important concept when analyzing graphs is the concept of a cycle\n\nA cycle is a path that starts and ends at the same node\n\nFor the ARPA net, an example cycle is LINC-CASE-CARN-HARV-BBN-MIT-LINC\n\nQuestion... what is the shortest possible cycle in a graph (including all endpoints)?\n\nCycles appear frequently in real-world networks\n\nFriendship networks: if A is friends with B, and B with C, often A and C become friends\n\nTransportation networks: cyclical routes allow for redundancy and flexibility\n\nSupply chains: cyclical dependencies can create both resilience and vulnerabilities\n\n","type":"content","url":"/l03-01-graphs#cycles","position":33},{"hierarchy":{"lvl1":"Graphs","lvl3":"Trees","lvl2":"Graph Theory Concepts"},"type":"lvl3","url":"/l03-01-graphs#trees","position":34},{"hierarchy":{"lvl1":"Graphs","lvl3":"Trees","lvl2":"Graph Theory Concepts"},"content":"A tree is a connected graph with no cycles\n\nTrees have exactly N-1 edges for N nodes (the minimum to stay connected)\n\nAdding any edge to a tree creates a cycle\n\nRemoving any edge from a tree disconnects it\n\nTrees appear frequently in hierarchical structures\n\nOrganizational charts: CEO at root, departments as branches\n\nFamily trees: ancestors and descendants\n\nDecision trees: choices branching from initial state\n\nFile systems: directories and subdirectories\n\nThe breadth-first search we’ll see later naturally creates a tree from any graph\n\n# Example: create a simple tree\ntree = SimpleGraph(5)\nadd_edge!(tree, 1, 2)\nadd_edge!(tree, 1, 3)\nadd_edge!(tree, 2, 4)\nadd_edge!(tree, 2, 5)\ngplot(tree, nodelabel=1:5)\n\nis_tree(tree)  # Graphs.jl can check if a graph is a tree\n\nis_tree(G1)  # Our original graph has a cycle, so it's not a tree\n\n","type":"content","url":"/l03-01-graphs#trees","position":35},{"hierarchy":{"lvl1":"Graphs","lvl3":"Connectedness","lvl2":"Graph Theory Concepts"},"type":"lvl3","url":"/l03-01-graphs#connectedness","position":36},{"hierarchy":{"lvl1":"Graphs","lvl3":"Connectedness","lvl2":"Graph Theory Concepts"},"content":"A graph is connected if there exists a path between every pair of nodes\n\nIn other words, you can travel from any node to any other node by following edges\n\nThe ARPA network was designed to be connected -- ensuring communication between all sites\n\nWe can check if a graph is connected using Graphs.jl\n\nis_connected(arpa)\n\nIt is natural to believe that many real-world networks are connected\n\nTransportation: you can get to any station\n\nInternet: you can visit any website\n\nBut it is entirely possible to have a non-connected graph\n\nSocial networks (nodes: people, edges: friendships) of college students who different countries\n\nSuppliers for a textile company vs a microchip manufacturer\n\n","type":"content","url":"/l03-01-graphs#connectedness","position":37},{"hierarchy":{"lvl1":"Graphs","lvl3":"Distance","lvl2":"Graph Theory Concepts"},"type":"lvl3","url":"/l03-01-graphs#distance","position":38},{"hierarchy":{"lvl1":"Graphs","lvl3":"Distance","lvl2":"Graph Theory Concepts"},"content":"We can extend concept of paths between nodes, to include a notion of distance\n\nThe length of a path is the number of steps it takes from beginning to end\n\nMIT-BBN-RAND-UCLA has length 3 (starting from MIT take three steps before ending at UCLA)\n\nThe distance between two nodes, is the length of the shortest path between those nodes\n\nGraphs can compute distances using the gdistances function\n\nBelow we compute the distance between UCLA and all nodes\n\nDict(zip(first.(nodes), gdistances(arpa, node_ints[\"UCLA\"])))\n\n","type":"content","url":"/l03-01-graphs#distance","position":39},{"hierarchy":{"lvl1":"Graphs","lvl2":"Breadth-First Search"},"type":"lvl2","url":"/l03-01-graphs#breadth-first-search","position":40},{"hierarchy":{"lvl1":"Graphs","lvl2":"Breadth-First Search"},"content":"If asked, how would you go about computing the distance between the HARV node and all other nodes?\n\nOne iterative approach might be:\n\nStart with HARV: note it is distance zero to HARV\n\nMove on to all nodes directly connected to HARV: these are distance 1\n\nThen move to all nodes connected to nodes that are distance 1 from HARV (excluding any you may have already found): declare these to be at distance 2 from HARV\n\nContinue traversing edges until you have visited all nodes\n\nThis algorihtm is called breadth-first search\n\n","type":"content","url":"/l03-01-graphs#breadth-first-search","position":41},{"hierarchy":{"lvl1":"Graphs","lvl3":"Example: Breadth-First Search from MIT","lvl2":"Breadth-First Search"},"type":"lvl3","url":"/l03-01-graphs#example-breadth-first-search-from-mit","position":42},{"hierarchy":{"lvl1":"Graphs","lvl3":"Example: Breadth-First Search from MIT","lvl2":"Breadth-First Search"},"content":"The image below shows how breadth-first search would proceed for the MIT node\n\n","type":"content","url":"/l03-01-graphs#example-breadth-first-search-from-mit","position":43},{"hierarchy":{"lvl1":"Graphs","lvl3":"Exercise (difficult!): BFS","lvl2":"Breadth-First Search"},"type":"lvl3","url":"/l03-01-graphs#exercise-difficult-bfs","position":44},{"hierarchy":{"lvl1":"Graphs","lvl3":"Exercise (difficult!): BFS","lvl2":"Breadth-First Search"},"content":"Now it is time for you to try this out!\n\nOur goal is to use breadth-first search to compute the distance betwen a given node and all other nodes\n\nThe return value you end up with should be an Vector{Vector{Int}}, where element i of this vector contains all node labels at distance i from the starting node\n\nFill in the logic for the breadth_first_distances function below\n\nfunction breadth_first_distances(g, start::Int)\n\tout = Vector{Int}[]\n\t# use push!(out, new_nodes) to add to out\n\tdistance = 0\n\n\t# TODO: your code here...\n\n\t# return out\n\tout\nend\n\n# Test code\n\nfunction test_bfd_methods(val, want)\n    if length(val) == 0\n        error(\"Make sure to `push!` on to `out` in your function\")\n    elseif length(val) != maximum(gdistances(arpa, node_ints[\"HARV\"]))\n        error(\"`out` has incorrect number of elements\")\n    elseif length.(val) != length.(want)\n        error(\"Right number of elements, but not right number in each subvector\")\n    elseif all(map(x12 -> all(sort(x12[1]) .== sort(x12[2])), zip(val, want)))\n        println(\"correct!\")\n    end\nend\n\nfunction run_tests()\n    val = breadth_first_distances(arpa, node_ints[\"HARV\"])\n    want = [[9, 12], [7, 8, 11], [3, 6, 5, 10], [1, 2, 4]]\n    test_bfd_methods(val, want)\nend\n\n# uncomment the code below and run when you are ready to test your code\n# run_tests()\n\n","type":"content","url":"/l03-01-graphs#exercise-difficult-bfs","position":45},{"hierarchy":{"lvl1":"Graphs","lvl3":"BFS with Graphs","lvl2":"Breadth-First Search"},"type":"lvl3","url":"/l03-01-graphs#bfs-with-graphs","position":46},{"hierarchy":{"lvl1":"Graphs","lvl3":"BFS with Graphs","lvl2":"Breadth-First Search"},"content":"The Graphs library contains routines implementing breadth-first search\n\nThe main function is called bfs_tree\n\nbfs_carn = bfs_tree(arpa, node_ints[\"CARN\"])\n\nNotice that the printout says we have a graph with 13 nodes, 12 edges and it is a directed graph\n\nThus far, all graphs we have considered have been undirected\n\nWe have only been concerned about if a connection (edge) exists between nodes\n\nA directed graph extends the notion of connecting nodes with a direction\n\nWe can now say that things flow across edges from one node to another -- always in the same direction\n\nWhy would the breadth-first search routine return a directed graph instead of the undirected type we started with?\n\nLet’s visualize it and see if we can understand why\n\ngplot(bfs_carn, nodelabel=first.(nodes))\n\nNotice that arrows only flow out of CARN\n\nThey also always flow away from CARN\n\nThe use of directed edges allows Graphs to represent the shortest path from CARN to any other node\n\nFor example STAN: CARN -> HARV -> BBN -> RAND -> UCLA -> STAN\n\n","type":"content","url":"/l03-01-graphs#bfs-with-graphs","position":47},{"hierarchy":{"lvl1":"Graphs","lvl3":"Exercise: Explore DiGraph","lvl2":"Breadth-First Search"},"type":"lvl3","url":"/l03-01-graphs#exercise-explore-digraph","position":48},{"hierarchy":{"lvl1":"Graphs","lvl3":"Exercise: Explore DiGraph","lvl2":"Breadth-First Search"},"content":"The bfs_carn object has type $(Markdown.Code(string(typeof(bfs_carn))))\n\nLet’s view the names of its properties (properties)\n\npropertynames(bfs_carn)\n\nbfs_carn.fadjlist\n\nThe fadjlist (forward adjacency list) property is a Vector{Vector{Int64}}\n\nfadjlist has one element per node (call index into outer Vector i for node i)\n\nEach element is itself a vector containing node indices for all nodes j for which there is an edge flowing from i to j\n\nBelow we have set up a new method (see below) for the breadth_first_distances function that takes a DiGraph as an argument\n\nYour task is to implement the the method so that it has the same return value as the previous method from above\n\nfunction breadth_first_distances(g::SimpleDiGraph, start::Int)\n\tout = Vector{Int}[]\n\t# use push!(out, new_nodes) to add to out\n\tdistance = 0\n\n\t# TODO: your code here...\n\n\t# return out\n\tout\nend\n\n# test code\nfunction test_digraph_ex()\n\tval = breadth_first_distances(\n\t\tbfs_tree(arpa, node_ints[\"HARV\"]),\n\t\tnode_ints[\"HARV\"]\n\t)\n\twant = [[9, 12], [7, 8, 11], [3, 6, 5, 10], [1, 2, 4]]\n\ttest_bfd_methods(val, want)\nend\n\n# uncomment the code below when you are ready to test your code!\n# test_digraph_ex()\n\n","type":"content","url":"/l03-01-graphs#exercise-explore-digraph","position":49},{"hierarchy":{"lvl1":"Graphs","lvl2":"Components"},"type":"lvl2","url":"/l03-01-graphs#components","position":50},{"hierarchy":{"lvl1":"Graphs","lvl2":"Components"},"content":"A component of a graph is a self-contained subset of the nodes\n\nMore precisely, a set of nodes is a component if\n\nEvery node in the subset has a path to every other node in the subset\n\nThe subset is not part of a larger set with property (1)\n\nExample:\n\n","type":"content","url":"/l03-01-graphs#components","position":51},{"hierarchy":{"lvl1":"Graphs","lvl3":"Finding Components","lvl2":"Components"},"type":"lvl3","url":"/l03-01-graphs#finding-components","position":52},{"hierarchy":{"lvl1":"Graphs","lvl3":"Finding Components","lvl2":"Components"},"content":"Graphs.jl provides functions to identify and work with components\n\nconnected_components(g) returns a vector of vectors, where each inner vector contains the nodes in one component\n\nLet’s create a graph with multiple components and explore it\n\n# Create a graph with three components\nmulti_component = SimpleGraph(10)\n# Component 1: nodes 1, 2, 3\nadd_edge!(multi_component, 1, 2)\nadd_edge!(multi_component, 2, 3)\nadd_edge!(multi_component, 3, 1)\n# Component 2: nodes 4, 5, 6, 7\nadd_edge!(multi_component, 4, 5)\nadd_edge!(multi_component, 5, 6)\nadd_edge!(multi_component, 6, 7)\nadd_edge!(multi_component, 7, 4)\n# Component 3: nodes 8, 9\nadd_edge!(multi_component, 8, 9)\n# Node 10 is isolated (its own component)\n\ncomponents = connected_components(multi_component)\n\nprintln(\"Number of components: \", length(components))\nfor (i, comp) in enumerate(components)\n    println(\"Component $i has $(length(comp)) nodes: $comp\")\nend\n\ngplot(multi_component, nodelabel=1:10)\n\n","type":"content","url":"/l03-01-graphs#finding-components","position":53},{"hierarchy":{"lvl1":"Graphs","lvl3":"Why Components Matter","lvl2":"Components"},"type":"lvl3","url":"/l03-01-graphs#why-components-matter","position":54},{"hierarchy":{"lvl1":"Graphs","lvl3":"Why Components Matter","lvl2":"Components"},"content":"Components help us understand the structure of social networks\n\nEach component represents a group that can communicate internally but not with other groups\n\nIn social network analysis, components reveal:\n\nInformation silos: Ideas spread within components but not between them\n\nEcho chambers: Opinions reinforce within isolated groups\n\nCommunity detection: Natural groupings in social structures\n\nInfluence boundaries: Limits of where influence can spread\n\n","type":"content","url":"/l03-01-graphs#why-components-matter","position":55},{"hierarchy":{"lvl1":"Graphs","lvl3":"Real-World Implications","lvl2":"Components"},"type":"lvl3","url":"/l03-01-graphs#real-world-implications","position":56},{"hierarchy":{"lvl1":"Graphs","lvl3":"Real-World Implications","lvl2":"Components"},"content":"Disease spread: Each component represents a boundary for transmission\n\nCOVID-19 travel restrictions aimed to keep countries as separate components\n\nContact tracing identifies components to contain outbreaks\n\nMarketing: Products spread through word-of-mouth within components\n\nNeed to seed each component separately for full market penetration\n\nViral marketing campaigns can fail if they don’t bridge components\n\nPolitical polarization: Separate components in social media\n\nDifferent groups may never see opposing viewpoints\n\nBridging nodes between components become crucial for dialogue\n\nInfrastructure resilience: Power grids, internet backbone\n\nMultiple components mean system fragmentation after failures\n\nRedundant connections prevent network from splitting into components\n\n","type":"content","url":"/l03-01-graphs#real-world-implications","position":57},{"hierarchy":{"lvl1":"Graphs","lvl3":"Giant Component","lvl2":"Components"},"type":"lvl3","url":"/l03-01-graphs#giant-component","position":58},{"hierarchy":{"lvl1":"Graphs","lvl3":"Giant Component","lvl2":"Components"},"content":"Many real-world networks have a giant component containing most nodes\n\nPlus several small components or isolated nodes\n\nLet’s check if ARPANET has this structure\n\narpa_components = connected_components(arpa)\nprintln(\"ARPANET has $(length(arpa_components)) component(s)\")\nprintln(\"Component sizes: \", length.(arpa_components))\n\nARPANET is fully connected (one component) by design\n\nThis ensures any site can communicate with any other site\n\nNetwork resilience was a key design goal for the early internet\n\n","type":"content","url":"/l03-01-graphs#giant-component","position":59},{"hierarchy":{"lvl1":"Graphs","lvl2":"Example"},"type":"lvl2","url":"/l03-01-graphs#example","position":60},{"hierarchy":{"lvl1":"Graphs","lvl2":"Example"},"content":"How many components are in this graph?\n\n","type":"content","url":"/l03-01-graphs#example","position":61},{"hierarchy":{"lvl1":"Graphs","lvl2":"Real-World Network Examples"},"type":"lvl2","url":"/l03-01-graphs#real-world-network-examples","position":62},{"hierarchy":{"lvl1":"Graphs","lvl2":"Real-World Network Examples"},"content":"Let’s analyze some actual network datasets to see these concepts in practice\n\nWe’ll look at:\n\nZachary’s Karate Club: A classic social network dataset\n\nFacebook ego networks: Social connections from real Facebook data\n\nEmail networks: Communication patterns in organizations\n\n","type":"content","url":"/l03-01-graphs#real-world-network-examples","position":63},{"hierarchy":{"lvl1":"Graphs","lvl3":"Zachary’s Karate Club","lvl2":"Real-World Network Examples"},"type":"lvl3","url":"/l03-01-graphs#zacharys-karate-club","position":64},{"hierarchy":{"lvl1":"Graphs","lvl3":"Zachary’s Karate Club","lvl2":"Real-World Network Examples"},"content":"Famous dataset from sociology (Zachary, 1977)\n\nDocuments friendships in a karate club that split into two factions\n\n34 members (nodes), 78 friendships (edges)\n\nPerfect for studying community structure and components\n\n# Graphs.jl includes several famous networks as built-in datasets!\nkarate = smallgraph(:karate)\n\n# Analyze the karate club network\nusing Statistics  # for `mean` function\nprintln(\"Karate Club Network:\")\nprintln(\"  Nodes: \", nv(karate))\nprintln(\"  Edges: \", ne(karate))\nprintln(\"  Average degree: \", round(mean(degree(karate)), digits=2))\nprintln(\"  Is connected: \", is_connected(karate))\n\n# Look at degree distribution\ndegrees = degree(karate)\nprintln(\"\\nDegree distribution:\")\nprintln(\"  Min degree: \", minimum(degrees))\nprintln(\"  Max degree: \", maximum(degrees))\nprintln(\"  Node with most connections: \", argmax(degrees))\n\n# Visualize the karate club network\ngplot(karate, nodelabel=1:nv(karate), nodesize=0.1)\n\n","type":"content","url":"/l03-01-graphs#zacharys-karate-club","position":65},{"hierarchy":{"lvl1":"Graphs","lvl3":"Exercise: Analyzing the Petersen Graph","lvl2":"Real-World Network Examples"},"type":"lvl3","url":"/l03-01-graphs#exercise-analyzing-the-petersen-graph","position":66},{"hierarchy":{"lvl1":"Graphs","lvl3":"Exercise: Analyzing the Petersen Graph","lvl2":"Real-World Network Examples"},"content":"The Petersen graph is a famous graph in graph theory\n\nIt appears in many theoretical results and counterexamples\n\nYour task: analyze this network’s structure\n\n# Load the Petersen graph\npetersen = smallgraph(:petersen)\n\n# TODO: Calculate the following properties\nnum_nodes = missing           # Total number of nodes\nnum_edges = missing           # Total number of edges\navg_degree = missing          # Average degree (should be the same for all nodes!)\nis_it_connected = missing     # Is the graph connected?\nis_it_tree = missing          # Is it a tree?\nnum_components = missing      # How many components?\n\n# Print your results\nprintln(\"Petersen Graph Analysis:\")\nprintln(\"  Number of nodes: \", num_nodes)\nprintln(\"  Number of edges: \", num_edges)\nprintln(\"  Average degree: \", avg_degree)\nprintln(\"  Is connected: \", is_it_connected)\nprintln(\"  Is it a tree: \", is_it_tree)\nprintln(\"  Number of components: \", num_components)\n\n","type":"content","url":"/l03-01-graphs#exercise-analyzing-the-petersen-graph","position":67},{"hierarchy":{"lvl1":"Graphs","lvl3":"Other Built-in Networks","lvl2":"Real-World Network Examples"},"type":"lvl3","url":"/l03-01-graphs#other-built-in-networks","position":68},{"hierarchy":{"lvl1":"Graphs","lvl3":"Other Built-in Networks","lvl2":"Real-World Network Examples"},"content":"Graphs.jl includes many classic networks for teaching and research\n\nSome interesting examples you can explore:\n\n# Examples of other built-in graphs\ngraphs_to_explore = [\n    :house,        # The \"house\" graph (5 nodes)\n    :bull,         # The bull graph\n    :cubical,      # 3-dimensional cube\n    :diamond,      # Diamond graph\n    :dodecahedral, # Dodecahedron graph (20 nodes)\n    :heawood,      # Heawood graph (14 nodes)\n    :moebiuskantor,# Möbius-Kantor graph\n    :octahedral,   # Octahedron graph\n    :pappus,       # Pappus graph\n    :tutte,        # Tutte graph (46 nodes)\n]\n\n# Try loading and analyzing one!\n# Example: g = smallgraph(:house)","type":"content","url":"/l03-01-graphs#other-built-in-networks","position":69},{"hierarchy":{"lvl1":"Strong and Weak Ties"},"type":"lvl1","url":"/l03-02-strong-weak-ties","position":0},{"hierarchy":{"lvl1":"Strong and Weak Ties"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nIntroduction to Graphs\n\nOutcomes\n\nRecognize open and closed triangles in a graph\n\nUnderstand concept of triadic closure\n\nBe able to identify global and local bridges in a network: visually and programatically\n\nUnderstand the “strength of weak ties”\n\nBe familiar with betweenness centrality and its use in graph partitioning\n\nReferences\n\nEasley and Kleinberg chapter 3\n\n","type":"content","url":"/l03-02-strong-weak-ties","position":1},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl2":"Granovetter’s question"},"type":"lvl2","url":"/l03-02-strong-weak-ties#granovetters-question","position":2},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl2":"Granovetter’s question"},"content":"In the late 1960s a PhD student Mark Granovetter wanted to understand how people get a new job\n\nHe interviewed many people who recently changed firms and asked how they got their job\n\nUnsurprisingly, people said they got referrals or learned about the job from personal contacts\n\nSurprisingly, most people said the contacts were made via their “acquaintances” and not “friends”\n\nWhy?\n\n","type":"content","url":"/l03-02-strong-weak-ties#granovetters-question","position":3},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Graphs for Information Flow","lvl2":"Granovetter’s question"},"type":"lvl3","url":"/l03-02-strong-weak-ties#graphs-for-information-flow","position":4},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Graphs for Information Flow","lvl2":"Granovetter’s question"},"content":"To answer Granovetter’s question, we’ll turn to graphs\n\nAs we’ll see, this is one of many possible examples of how we can use a graph to study the flow of information\n\nWhat other examples are there?\n\nFrom what sources do you get your information?\n\nDo you get different types of information from different types of source? Why?\n\nOne interesting point to make in this regard is that by studying information flow via graphs we are taking something inherently interpersonal or emotional (friendships and sharing information) and analyzing it from a structural perspective (as a graph)\n\nKeep these themes in mind as we study the theoretical/technical tools\n\nWe’ll return back to Granovetter’s question after building up some tools\n\n","type":"content","url":"/l03-02-strong-weak-ties#graphs-for-information-flow","position":5},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl2":"Triangles"},"type":"lvl2","url":"/l03-02-strong-weak-ties#triangles","position":6},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl2":"Triangles"},"content":"When studying graphs, the smallest possible structure involving more than two nodes is a triangle\n\nTriangles are made up of three nodes and either two or three edges that connect them\n\nA triangle with only two edges is said to be open\n\nA triangle with three edges is closed\n\nIn the example below, there are 3 triangles, all of which are open\n\nusing Graphs, GraphPlot\n\ng1 = star_graph(4)\nadd_vertex!(g1)\ngplot(g1, nodelabel='A':'E', layout=shell_layout)\n\n","type":"content","url":"/l03-02-strong-weak-ties#triangles","position":7},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Social Triangles","lvl2":"Triangles"},"type":"lvl3","url":"/l03-02-strong-weak-ties#social-triangles","position":8},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Social Triangles","lvl2":"Triangles"},"content":"Suppose our graph is of students arriving for first year of college\n\nEach node is a student\n\nAn edge represents a friendship or connection between students\n\nStory...\n\nA went to and out of school state, but happened to know B, C, and D from various summer camps or family-friend relationships\n\nNone of B, C and D know one another\n\nQuestion: Given only this information, is it more likely that B and E become friends, or B and C? Why?\n\n","type":"content","url":"/l03-02-strong-weak-ties#social-triangles","position":9},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Closing triangles","lvl2":"Triangles"},"type":"lvl3","url":"/l03-02-strong-weak-ties#closing-triangles","position":10},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Closing triangles","lvl2":"Triangles"},"content":"In our example graph the only edges are between A and another node\n\nConsider a triangle formed by nodes A, B, C\n\nTo close this triangle, there would need to be an edge between B-C as follows\n\ng2 = copy(g1)\nadd_edge!(g2, 2, 3)\ngplot(g2, nodelabel='A':'E', layout=shell_layout)\n\n","type":"content","url":"/l03-02-strong-weak-ties#closing-triangles","position":11},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Triadic Closure","lvl2":"Triangles"},"type":"lvl3","url":"/l03-02-strong-weak-ties#triadic-closure","position":12},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Triadic Closure","lvl2":"Triangles"},"content":"There is overwhelming empirical evidence to support the intuition that when there are edges A-B and A-C, it is likely that an edge B-C will form\n\nThis is known as triadic closure (closing the final edge of a triangle)\n\nFor this reason, when analyzing social network data it is very common to see triangles\n\n","type":"content","url":"/l03-02-strong-weak-ties#triadic-closure","position":13},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Triangles with Graphs.jl","lvl2":"Triangles"},"type":"lvl3","url":"/l03-02-strong-weak-ties#triangles-with-graphs-jl","position":14},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Triangles with Graphs.jl","lvl2":"Triangles"},"content":"There is good support in Graphs.jl for helping us count triangles in a graph\n\nThe two key functions are triangles(g) and local_clustering(g)\n\ntriangles(g) will return an array of integers, where values correspond to how many closed triangles there are in the graph\n\n@show triangles(g1)\n@show triangles(g2);\n\nThe local_clustering(g) function will return a tuple of two things:\n\nThe number of closed triangles for each node (same as triangles(g))\n\nThe number of possible triangles for each node in g\n\n@show local_clustering(g1)\n@show local_clustering(g2);\n\n","type":"content","url":"/l03-02-strong-weak-ties#triangles-with-graphs-jl","position":15},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Clustering Coefficients","lvl2":"Triangles"},"type":"lvl3","url":"/l03-02-strong-weak-ties#clustering-coefficients","position":16},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Clustering Coefficients","lvl2":"Triangles"},"content":"It is helpful to have a single number summary of how “closed” a graphs triangles are\n\nThe clustering coefficient tells us the fraction of triangles that are closed\n\n“The clustering coefficient of a node A is defined as the probability that two randomly selected friends of A are friends with each other. In other words, it is the fraction of pairs of A’s friends that are connected to each other by edges” (E&K pg. 49)\n\nThere is a local flavor, where we consider all triangles for a specific node\n\nThere is also a global flavor where we consider all triangles for the entire graph\n\nGraphs.jl has functions local_clustering_coefficient and global_clustering_coefficient to compute these quantities respectively\n\nlocal_clustering_coefficient(g2)\n\nglobal_clustering_coefficient(g2)\n\nQuestion: In each of the graphs below, how many open triangles are there? How many closed?\n\n#graph 1\ngplot(g2, nodelabel='A':'E', layout=shell_layout)\n\n#graph 2\ngplot(path_graph(5), nodelabel='A':'E', layout=shell_layout)\n\n# graph 3\ngplot(dorogovtsev_mendes(7), nodelabel=1:7)\n\n# graph 4\ngplot(smallgraph(:bull), nodelabel=1:5)\n\n","type":"content","url":"/l03-02-strong-weak-ties#clustering-coefficients","position":17},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl2":"Bridges"},"type":"lvl2","url":"/l03-02-strong-weak-ties#bridges","position":18},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl2":"Bridges"},"content":"Consider the graph below\n\ng3 = barbell_graph(4, 4)\ngplot(g3, nodelabel='A':'H', layout=spring_layout)\n\nNow consider D\n\nNotice that connection between D and any of A B C is somehow different from connection to E\n\nD-E is known as a bridge\n\nA bridge is an edge that, if removed, would cause the nodes involved to be in different components of the graph\n\ng4 = copy(g3)\nrem_edge!(g4, 4, 5)\ngplot(g4, nodelabel='A':'H', layout=spring_layout)\n\n","type":"content","url":"/l03-02-strong-weak-ties#bridges","position":19},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Frequency of bridges","lvl2":"Bridges"},"type":"lvl3","url":"/l03-02-strong-weak-ties#frequency-of-bridges","position":20},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Frequency of bridges","lvl2":"Bridges"},"content":"Given our discussion on triadic closure, bridges are likely to be rare in real social networks\n\nIt is very likely that an edge will form between E and one of A``B``C\n\nEven if that isn’t the case, consider the possibility that the graph we have been looking at is actually a smaller subset of a larger graph:\n\nusing Downloads\nif !isfile(\"local_bridge.lg\")\n    Downloads.download(\"https://ucf-cap-6318-resources.s3.amazonaws.com/data/local_bridge.lg\", \"local_bridge.lg\")\nend\ng5 = loadgraph(\"local_bridge.lg\")\ngplot(g5, nodelabel='A':'M', layout=spring_layout)\n\nLocal Bridges\n\nIn the graph above even if D-E were broken, there would only be one component in our graph\n\nIn other words there is another path from D to E (here D-I-K-M-E)\n\nBecause true bridges are so rare, a looser definition of bridge was created called a local bridge\n\nAn edge is a local bridge if A and B have no neighbors in common\n\n","type":"content","url":"/l03-02-strong-weak-ties#frequency-of-bridges","position":21},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Detecting Local Bridges","lvl2":"Bridges"},"type":"lvl3","url":"/l03-02-strong-weak-ties#detecting-local-bridges","position":22},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Detecting Local Bridges","lvl2":"Bridges"},"content":"So far we have dealt with example graphs that we can visually inspect\n\nMost real world graphs are far too large for this\n\nTo analyze larger graphs we need computational tools\n\nLet’s build up some code that will allow us to find local bridges\n\nExercise\n\nPopulate the num_shared_neighbors function below\n\n\"\"\"\n    num_shared_neighbors(g, n1, n2)\n\nGiven a graph `g` and node indexes `n1` and `n2`, compute\nhow many neighbors `n1` and `n2` have in common\n\"\"\"\nfunction num_shared_neighbors(g, n1, n2)\n    # HINT: `neighbors(g, n1)` will give you an array of neighbors\n    #        of `n1`\n\n\nend\n\n\n\n# test code here\nusing Test\n\nfunction test_num_shared_neighbors()\n    @testset \"num_shared_neighbors\" begin\n        vals = [\n            num_shared_neighbors(g5, 6, 7),\n            num_shared_neighbors(g5, 4, 5)\n        ]\n        @test !isnothing(vals[1])\n        @test vals[1] isa Integer\n        @test vals == [2, 0]\n    end\nend\n\n# uncomment and run the code below when you are ready to test your code\n# test_num_shared_neighbors()\n\nExercise\n\nNow that we have a function for computing the number of shared neighbors, we can use it to build a routine for finding a local bridge\n\nWe’ll do that now\n\nYour task is to fill in the missing logic for the local_bridges(g) function below\n\n\"\"\"\n    local_bridges(g)\n\nGiven a graph `g`, find all local bridges in the graph\n\"\"\"\nfunction local_bridges(g)\n    out = []\n    for n1 in 1:nv(g)\n\n        # TODO determine what to loop over for n2\n\n        # TODO: call num_shared_neighbors(g, n1, n2)\n\n        # TODO: if n1 and n2 have no shared neighbors, **AND** (n1 < n2)\n        #       call push!(out, (n1, n2))\n    end\n    return out\nend\n\nfunction test_local_bridges()\n    @testset \"local_bridges\" begin\n        vals = [\n            local_bridges(g5),\n            local_bridges(g4)\n        ]\n        @test vals[1] isa Array\n        @test length(vals[1]) == 1\n        @test length(vals[2]) == 0\n        @test vals[1][1] == (4, 5)\n    end\nend\n\n# uncomment and run the code below when you are ready to test your code\n# test_local_bridges()\n\n","type":"content","url":"/l03-02-strong-weak-ties#detecting-local-bridges","position":23},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Example: Twitter connections","lvl2":"Bridges"},"type":"lvl3","url":"/l03-02-strong-weak-ties#example-twitter-connections","position":24},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Example: Twitter connections","lvl2":"Bridges"},"content":"Let’s now consider an example using real social network data\n\nBelow we’ll load up a graph called tw that is a graph of connections between twitter users\n\nEach node is a different twitter account\n\nThere is an edge between nodes if either one of the accounts follows the other\n\nusing Downloads\nif !isfile(\"twitter.lg\")\n    Downloads.download(\"https://ucf-cap-6318-resources.s3.amazonaws.com/data/twitter.lg\", \"twitter.lg\")\nend\ntw = loadgraph(\"twitter.lg\")\n\nNotice that there are 81,306 nodes and 1,342,310 edges\n\nThis network is far too big to analyze visually\n\nLet’s use a few of our empirical metrics to study the properties of this graph\n\nglobal_clustering_coefficient(tw)\n\ntw_bridges = bridges(tw)\n\nratio_bridges = length(tw_bridges) / ne(tw)\n\nNotice how only 0.372% of edges are bridges (true bridges, not local bridges)!\n\n","type":"content","url":"/l03-02-strong-weak-ties#example-twitter-connections","position":25},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl2":"Edge Strength"},"type":"lvl2","url":"/l03-02-strong-weak-ties#edge-strength","position":26},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl2":"Edge Strength"},"content":"We have so far considered only whether or not two nodes are connected\n\nWe have not discussed the strength of these connections\n\nWe will now extend our analysis to the notion of an edge representing a strong or a weak tie\n\nIn our friendship example, the strong ties would represent friends and the weak ties would represent acquaintances\n\n","type":"content","url":"/l03-02-strong-weak-ties#edge-strength","position":27},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Strong and Weak ties","lvl2":"Edge Strength"},"type":"lvl3","url":"/l03-02-strong-weak-ties#strong-and-weak-ties","position":28},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Strong and Weak ties","lvl2":"Edge Strength"},"content":"In the figure below, we have a representation of a graph similar to our g5 where all edges have been annotated with a S or a W\n\nA S edge represents a strong edge, or friendship\n\nA W edge represents a weak edge or, or acquaintance\n\n","type":"content","url":"/l03-02-strong-weak-ties#strong-and-weak-ties","position":29},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Triadic Closure: Strong Vs Weak","lvl2":"Edge Strength"},"type":"lvl3","url":"/l03-02-strong-weak-ties#triadic-closure-strong-vs-weak","position":30},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Triadic Closure: Strong Vs Weak","lvl2":"Edge Strength"},"content":"Let’s extend the intuition behind triadic closure to our strong/weak setting\n\nOur argument was that because we have edges A-B and A-C, it is likely that an edge B-C will form\n\nNow we’ll state that if A-B and A-C are both strong ties, then it is more likely that B-C will form than if either A-B or A-C were weak\n\nMore formally... we have  the Strong Triadic Closure Property\n\nWe say that a node A violates the Strong Triadic Closure Property if it has strong ties to two other nodes B and C, and there is no edge at all (either a strong or weak tie) between B and C. We say that a node A satisfies the Strong Triadic Closure Property if it does not violate it.\n\n","type":"content","url":"/l03-02-strong-weak-ties#triadic-closure-strong-vs-weak","position":31},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Local Bridges and Weak Ties","lvl2":"Edge Strength"},"type":"lvl3","url":"/l03-02-strong-weak-ties#local-bridges-and-weak-ties","position":32},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Local Bridges and Weak Ties","lvl2":"Edge Strength"},"content":"Given this definition of the Strong Triadic Closure Property, we can make the following claim (see section 3.2 of E&K for proof, intuition in figure below):\n\nClaim: If a node A in a network satisfies the Strong Triadic Closure Property and is involved in at least two strong ties, then any local bridge it is involved in must be a weak tie.\n\n","type":"content","url":"/l03-02-strong-weak-ties#local-bridges-and-weak-ties","position":33},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Back to Granovetter","lvl2":"Edge Strength"},"type":"lvl3","url":"/l03-02-strong-weak-ties#back-to-granovetter","position":34},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Back to Granovetter","lvl2":"Edge Strength"},"content":"Recall our original question: why do people report finding jobs through acquaintances (weak ties) more often than close friends (strong ties)?\n\nThe Strong Triadic Closure Property gives the answer...\n\nSuppose A lost its job\n\nBy asking for a referral from any of C, D, or E; A is likely to get a similar set of information as they are strongly connected to one other and likely have access to the same set of information\n\nInstead by talking to the weak tie B, A is likely to get new information from people in B’s social circle (including H and the three unlabeled nodes)\n\ntl;dr: local bridges are weak ties, so it is weak ties that get you access to “new” parts of the network\n\n","type":"content","url":"/l03-02-strong-weak-ties#back-to-granovetter","position":35},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl2":"Graph Partitioning"},"type":"lvl2","url":"/l03-02-strong-weak-ties#graph-partitioning","position":36},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl2":"Graph Partitioning"},"content":"Social networks often consist of tightly knit regions and weak ties that connect them\n\nOne algorithmic problem that has been studied and applied in many settings is that of graph partitioning\n\nTo partition a graph is to break it down into the tightly-knit components\n\nWhen a graph is partitioned, it is broken down into components called regions\n\ng6 = let\n    edges = Edge.([\n        (1,2), (1,3), (2,3), (3,7), (7,6), (6,4), (6,5), (4,5), (7,8),\n        (8,9), (9,10), (10,11), (9,11), (8,12), (12,13), (13,14), (12,14)\n    ])\n    Graph(edges)\nend\n\ngplot(g6, nodelabel=1:14, layout=spring_layout)\n\n","type":"content","url":"/l03-02-strong-weak-ties#graph-partitioning","position":37},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Two Approaches","lvl2":"Graph Partitioning"},"type":"lvl3","url":"/l03-02-strong-weak-ties#two-approaches","position":38},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Two Approaches","lvl2":"Graph Partitioning"},"content":"There are two classes of algorithms that can be used to partition a graph:\n\nDivisive: partition a graph by removing local bridges (“spanning links”)  and breaking down the network into large chunks\n\nAgglomerative: start with a single node and construct regions “bottom-up” by iteratively finding nodes highly connected to existing nodes in the region\n\nWe’ll focus on divisive methods here\n\n","type":"content","url":"/l03-02-strong-weak-ties#two-approaches","position":39},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Betweenness Centrality","lvl2":"Graph Partitioning"},"type":"lvl3","url":"/l03-02-strong-weak-ties#betweenness-centrality","position":40},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Betweenness Centrality","lvl2":"Graph Partitioning"},"content":"In order to build a divisive partitioning algorithm, we’ll first define a key metric for analyzing how “central” a node is in a network\n\nWe’ll provide a brief introduction here, and refer you to section 3.6 of E&K for more detail\n\nLet V represent set of all nodes and s, t, v \\in V\n\nLet \\sigma_{st} represent the number of shortest paths between s and t\n\nLet \\sigma_{st}(v) represent the number of shortest paths between s and t that pass through v.\n\nThen, the betweenness centrality  for node v (C_{B}(v)) is defined as:\nC_{B}(v) = \\sum_{s \\ne v \\ne t \\in V} \\frac{\\sigma_{st}(v)}{\\sigma_{st}}\n\nConceptually, C_B(v) captures how much information “flows” across node v on average\n\n","type":"content","url":"/l03-02-strong-weak-ties#betweenness-centrality","position":41},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Computing C_B(v)","lvl2":"Graph Partitioning"},"type":"lvl3","url":"/l03-02-strong-weak-ties#computing-c-b-v","position":42},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Computing C_B(v)","lvl2":"Graph Partitioning"},"content":"There are various algorithms we could use to compute C_B(v)\n\nFor now we will let Graphs.jl handle it for us ;)\n\nbetweenness_centrality(g6)\n\nNote that 7 and 8 are a local bridge\n\nAlso note that they carry the highest value of C_B...🤔\n\n","type":"content","url":"/l03-02-strong-weak-ties#computing-c-b-v","position":43},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Algorithm: Girvan-Newman","lvl2":"Graph Partitioning"},"type":"lvl3","url":"/l03-02-strong-weak-ties#algorithm-girvan-newman","position":44},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl3":"Algorithm: Girvan-Newman","lvl2":"Graph Partitioning"},"content":"We will not present the algorithm in detail, but will describe the overall steps\n\nRefer to Section 3.6 of E&K for details\n\nThe Girvan-Newman algorithm for graph partitioning:\n\nInputs: node\n\nOutputs: list of edges to delete at each step\n\nAlgorithm:\n\nFind nodes with highest betweenness centrality -- remove them from the network (and add edges connecting them to the network to the list of deleted edges for first step)\n\nRe-compute betweenness centrality for all subgraphs that resulted from deletion in step 1. Remove all nodes with highest betweenness centrality and record list of deleted edges\n\nContinue until all edges have been removed\n\n","type":"content","url":"/l03-02-strong-weak-ties#algorithm-girvan-newman","position":45},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl2":"Summary: Key ideas"},"type":"lvl2","url":"/l03-02-strong-weak-ties#summary-key-ideas","position":46},{"hierarchy":{"lvl1":"Strong and Weak Ties","lvl2":"Summary: Key ideas"},"content":"Triangles are key network structures\n\nClosed triangles are common in social networks due to triadic closure\n\nSocial networks are often composed of tightly knit regions bound together with weak ties\n\nWeak ties often form local bridges and are therefore valuable for referrals and information flow\n\nBetweenness centrality captures idea of how essential a node is in connecting regions of a graph (how much information flows across a node)","type":"content","url":"/l03-02-strong-weak-ties#summary-key-ideas","position":47},{"hierarchy":{"lvl1":"Homophily"},"type":"lvl1","url":"/l04-01-homophily","position":0},{"hierarchy":{"lvl1":"Homophily"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nIntroduction to Graphs\n\nStrong and Weak Ties\n\nOutcomes\n\nUnderstand the concept of homophily\n\nPractice working through “by hand” examples of diagnosing homophily\n\nBe prepared to computationally diagnose homophily in a large network\n\nReferences\n\nEasley and Kleinberg chapter 4 (especially section 4.1)\n\nDatasets\n\nFlorentine family relationships: \n\nhttps://​www​.cs171​.org​/2018​/assets​/instructions​/lab8​/Lab8​.html\n\n","type":"content","url":"/l04-01-homophily","position":1},{"hierarchy":{"lvl1":"Homophily","lvl2":"Introduction"},"type":"lvl2","url":"/l04-01-homophily#introduction","position":2},{"hierarchy":{"lvl1":"Homophily","lvl2":"Introduction"},"content":"\n\n","type":"content","url":"/l04-01-homophily#introduction","position":3},{"hierarchy":{"lvl1":"Homophily","lvl3":"Main Idea","lvl2":"Introduction"},"type":"lvl3","url":"/l04-01-homophily#main-idea","position":4},{"hierarchy":{"lvl1":"Homophily","lvl3":"Main Idea","lvl2":"Introduction"},"content":"Consider your friends. Do they tend to\n\nEnjoy the same movies, music, hobbies as you?\n\nHold similar religious or political beliefs?\n\nCome from similar schools, workplaces, or socio-economic settings?\n\nWhat about a random sample of people in the world?\n\nIf you are like me, your answers likely indicate that you have more in common with your friends than you would expect to have with a random sample of people\n\nThis concept -- that we are similar to our friends -- is called homophily\n\n","type":"content","url":"/l04-01-homophily#main-idea","position":5},{"hierarchy":{"lvl1":"Homophily","lvl3":"Homophily in Graphs","lvl2":"Introduction"},"type":"lvl3","url":"/l04-01-homophily#homophily-in-graphs","position":6},{"hierarchy":{"lvl1":"Homophily","lvl3":"Homophily in Graphs","lvl2":"Introduction"},"content":"In the context of graphs or networks, homophily means that nodes that are connected are more similar than nodes at a further distance in the graph\n\nBut what do we mean by more similar?\n\nIdea: We might have common friends.\n\nThis is an intrinsic force that led to node formation (e.g. triadic closure)\n\nAlternative: We may share characteristics or properties that are not represented in the graph -- external forces.\n\nExamples: same race, gender, school, employer, sports team, etc.\n\nThese external forces are what homophily captures\n\n","type":"content","url":"/l04-01-homophily#homophily-in-graphs","position":7},{"hierarchy":{"lvl1":"Homophily","lvl3":"Context","lvl2":"Introduction"},"type":"lvl3","url":"/l04-01-homophily#context","position":8},{"hierarchy":{"lvl1":"Homophily","lvl3":"Context","lvl2":"Introduction"},"content":"To identify if homophily is active in a network, we must have access to context on top of list of nodes and edges\n\nOne way to represent this context would be with a DataFrame in addition to a graph:\n\nOne row per node\n\nOne column indicating the node identifier (or just use row number)\n\nOne column for additional characteristic\n\nusing DataFrames, Graphs, GraphPlot\n\n\n\ndf1 = DataFrame(\n    family=[\n        \"Acciaiuoli\", \"Albizzi\", \"Barbadori\", \"Bischeri\", \"Castellani\",\n        \"Ginori\", \"Guadagni\", \"Lamberteschi\", \"Medici\", \"Pazzi\",\n        \"Peruzzi\", \"Ridolfi\", \"Salviati\", \"Strozzi\", \"Tornabuoni\"\n    ],\n    wealth=[10, 36, 55, 44, 20, 32, 8, 42, 103, 48, 49,  27, 10, 146, 48],\n    priorates=[53, 65, missing, 12, 22, missing, 21, 0, 53, missing, 42, 38, 35, 74, missing],\n)\n\nIt will be easier to do our homohpily calculations with binary data,\n\nwe’ll create new columns, high_wealth and high_power if the wealth and priorates columns, respectively, are above the column medians\n\nusing Statistics\ndf1[!, :high_wealth] = df1.wealth .> median(df1.wealth)\ndf1[!, :high_power] = df1.priorates .> median(df1.priorates[.!(ismissing.(df1.priorates))])\ndf1[ismissing.(df1.priorates), :high_power] .= false\ndf1\n\n\nmarriages = [\n    0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n    0 0 0 0 0 1 1 0 1 0 0 0 0 0 0\n    0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n    0 0 0 0 0 0 1 0 0 0 1 0 0 1 0\n    0 0 1 0 0 0 0 0 0 0 1 0 0 1 0\n    0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n    0 1 0 1 0 0 0 1 0 0 0 0 0 0 1\n    0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n    1 1 1 0 0 0 0 0 0 0 0 1 1 0 1\n    0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n    0 0 0 1 1 0 0 0 0 0 0 0 0 1 0\n    0 0 0 0 0 0 0 0 1 0 0 0 0 1 1\n    0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n    0 0 0 1 1 0 0 0 0 0 1 1 0 0 0\n    0 0 0 0 0 0 1 0 1 0 0 1 0 0 0\n]\ng1 = Graph(marriages)\n\ngplot(g1, nodelabel=df1.family)\n\n","type":"content","url":"/l04-01-homophily#context","position":9},{"hierarchy":{"lvl1":"Homophily","lvl2":"Measuring Homophily"},"type":"lvl2","url":"/l04-01-homophily#measuring-homophily","position":10},{"hierarchy":{"lvl1":"Homophily","lvl2":"Measuring Homophily"},"content":"Our discussion on homophily so far has been conceptual... let’s make it precise\n\nWe’ll frame the discussion in terms of a null hypothesis\n\nConcept should be familiar from statistics, but not exactly the same we we won’t make distributional assumptions\n\n","type":"content","url":"/l04-01-homophily#measuring-homophily","position":11},{"hierarchy":{"lvl1":"Homophily","lvl3":"Random Homophily","lvl2":"Measuring Homophily"},"type":"lvl3","url":"/l04-01-homophily#random-homophily","position":12},{"hierarchy":{"lvl1":"Homophily","lvl3":"Random Homophily","lvl2":"Measuring Homophily"},"content":"Our analytical approach begins with a thought experiment (counter factual) that all edges are randomly formed\n\nIn this case, we should not expect the context around our graph to help us predict its structure\n\nSuppose we consider a characteristic X\n\nWe have N nodes and N_x of them exhibit feature X and N - N_x of them to not\n\nWe’ll work with probabilities: p_x = \\frac{N_x}{N}\n\nThe probability that an arbitrary edge is between two nodes that both share X is equal to p_x^2\n\nProbability of edge between two non X nodes: (1-p_x)^2\n\nProbabillity of edge bewtween one X and one non X:\n\\begin{aligned}\\text{prob}(\\text{edge (X <=> not X)}) &= p_x (1-p_x) + (1-p_x) p_x \\\\ &= 2 p_x (1-p_x)\\end{aligned}\n\nThis will be our “random edge formation” benchmark\n\n","type":"content","url":"/l04-01-homophily#random-homophily","position":13},{"hierarchy":{"lvl1":"Homophily","lvl3":"Counting Frequencies","lvl2":"Measuring Homophily"},"type":"lvl3","url":"/l04-01-homophily#counting-frequencies","position":14},{"hierarchy":{"lvl1":"Homophily","lvl3":"Counting Frequencies","lvl2":"Measuring Homophily"},"content":"Now an empirical value...\n\nLet there be e edges\n\nLet...\n\nvariable\n\nmeaning\n\ne_{xx}\n\n# edges between 2 X\n\ne_{yy}\n\n# edges between 2 not X\n\ne_{xy}\n\n# edges between 1 X  and 1 not X\n\nThen e = e_{xx} + e_{yy} + e_{xy}\n\nWe’ll use these 4 numbers to count frequencies of edges between X types and non-X types\n\n","type":"content","url":"/l04-01-homophily#counting-frequencies","position":15},{"hierarchy":{"lvl1":"Homophily","lvl3":"Testing for Homophily","lvl2":"Measuring Homophily"},"type":"lvl3","url":"/l04-01-homophily#testing-for-homophily","position":16},{"hierarchy":{"lvl1":"Homophily","lvl3":"Testing for Homophily","lvl2":"Measuring Homophily"},"content":"We are now ready to test for homophily\n\nWe’ll consider the assumption (null hypothesis) that there is no homophily in characteristic X\n\n\\Longrightarrow observed proportion of cross-characteristic edges is (approximately) the same as characteristic frequencies in the full population\n\nTo test this assumption, we compare\n\n2 p_x(1-p_x): the likelihood of a cross-characteristic edge forming, under the assumption of purely random edge formation\n\n\\frac{e_{xy}}{e}: the proportion of cross-characteristic edges that exist in the network\n\nWhen comparing these statistics, we could get one of three outcomes:\n\nCondition\n\nresult\n\n\\frac{e_{xy}}{e} >> 2 p_x(1-p_x)\n\ninverse homophily\n\n\\frac{e_{xy}}{e} \\approx 2 p_x(1-p_x)\n\nno homophily\n\n\\frac{e_{xy}}{e} << 2 p_x(1-p_x)\n\nhomophily\n\nIntuition: If observed cross characteristic edge formation is significantly less than what we’d expected under random edge formation, we reject the hypothesis that homophily is not present, and conclude that characteristic X is meaningful for edge formation\n\n","type":"content","url":"/l04-01-homophily#testing-for-homophily","position":17},{"hierarchy":{"lvl1":"Homophily","lvl3":"Example: high school relationships","lvl2":"Measuring Homophily"},"type":"lvl3","url":"/l04-01-homophily#example-high-school-relationships","position":18},{"hierarchy":{"lvl1":"Homophily","lvl3":"Example: high school relationships","lvl2":"Measuring Homophily"},"content":"Recall the graph of romantic relationships between high school students\n\nQuestion: does this graph exhibit homophily in gender? Why?\n\n","type":"content","url":"/l04-01-homophily#example-high-school-relationships","position":19},{"hierarchy":{"lvl1":"Homophily","lvl2":"Example: Florentines"},"type":"lvl2","url":"/l04-01-homophily#example-florentines","position":20},{"hierarchy":{"lvl1":"Homophily","lvl2":"Example: Florentines"},"content":"Let’s work through an example of numerically dianosing homophily using the Florentine data\n\nI’ll repeat the data below\n\ndf1\n\nnode_color = map(x -> x ? \"blue\" : \"red\", df1.high_wealth)\ngplot(g1, nodelabel=df1.family, nodefillc=node_color)\n\n","type":"content","url":"/l04-01-homophily#example-florentines","position":21},{"hierarchy":{"lvl1":"Homophily","lvl3":"Step 1: Counting frequencies","lvl2":"Example: Florentines"},"type":"lvl3","url":"/l04-01-homophily#step-1-counting-frequencies","position":22},{"hierarchy":{"lvl1":"Homophily","lvl3":"Step 1: Counting frequencies","lvl2":"Example: Florentines"},"content":"First we need to count frequencies for all our characteristics\n\nWe’ll do that here\n\nusing DataStructures\n\nfunction count_frequencies(vals)\n    counts = DataStructures.counter(vals)\n    total = length(vals)\n    Dict(c => v / total for (c, v) in pairs(counts))\nend\n\ncount_frequencies(df1.high_wealth)\n\nDict(\n    n => count_frequencies(df1[!, n])\n    for n in names(df1)[4:end]\n)\n\n","type":"content","url":"/l04-01-homophily#step-1-counting-frequencies","position":23},{"hierarchy":{"lvl1":"Homophily","lvl3":"Step 2: Counting Edges","lvl2":"Example: Florentines"},"type":"lvl3","url":"/l04-01-homophily#step-2-counting-edges","position":24},{"hierarchy":{"lvl1":"Homophily","lvl3":"Step 2: Counting Edges","lvl2":"Example: Florentines"},"content":"Next we need to count the number of edges of each type\n\nThis step is a bit tricker as it will require that we access both data from the Graph and the DataFrame\n\nTo not spoil the fun, we’ll leave this code as an exercise on the homework\n\nFor now we’ll look at things “by hand”\n\nLet’s consider high_wealth and test if marriages where influenced by mutual wealth\n\nData: We have 7 high wealth families in the dataset\n\nCounting edge types for high_wealth vs non high_wealth:\n\nhigh-high edges: 6\n\nlow-low edges: 3\n\nCross edges (high to low): 11\n\nTotal: 11 + 6 + 3 = 20 edges ✓\n\nThe ratio of cross edges is 11/20 = 0.55\n\nThe ratio of nodes that are high is 7/15 = 0.46 (p_x)\n\ngplot(g1, nodelabel=df1.family)\n\nE = ne(g1)\nExy = 11  # cross edges\nn_high = 7\nN = nv(g1)\npx = n_high / N\n\n# test\n2 * px * (1-px), Exy/E\n\nHere we have that the actual proportion of cross edges (0.55) is slightly higher than what we’d expect under random formation (0.5)\n\nThis suggests a very mild instance of inverse homophily (opposites attract), though the difference is quite small\n\nThis does make some sense, as anecdotally we have heard tales of parents desiring their daughters to marry into a wealthy family\n\n","type":"content","url":"/l04-01-homophily#step-2-counting-edges","position":25},{"hierarchy":{"lvl1":"Homophily","lvl3":"Exercise","lvl2":"Example: Florentines"},"type":"lvl3","url":"/l04-01-homophily#exercise","position":26},{"hierarchy":{"lvl1":"Homophily","lvl3":"Exercise","lvl2":"Example: Florentines"},"content":"Repeat the counting exercise, but for the high_power characteristic\n\nWhat do you find? Do you see homophily in this characteristic?","type":"content","url":"/l04-01-homophily#exercise","position":27},{"hierarchy":{"lvl1":"Weighted Graphs"},"type":"lvl1","url":"/l04-02-weighted-graphs","position":0},{"hierarchy":{"lvl1":"Weighted Graphs"},"content":"Prerequisites\n\nIntroduction to Graphs\n\nStrong and Weak Ties\n\nOutcomes\n\nKnow what a weighted graph is and how to construct them using SimpleWeightedGraphs.jl\n\nImplement the shortest path algorithm for traversing a weighted graph\n\nReferences\n\nEasley and Kleinberg chapter 5 (especially section 5.1-5-3)\n\n# import Pkg; Pkg.add(\"SimpleWeightedGraphs\")\n\nusing Graphs, GraphPlot, SimpleWeightedGraphs\n\n","type":"content","url":"/l04-02-weighted-graphs","position":1},{"hierarchy":{"lvl1":"Weighted Graphs","lvl2":"Introduction"},"type":"lvl2","url":"/l04-02-weighted-graphs#introduction","position":2},{"hierarchy":{"lvl1":"Weighted Graphs","lvl2":"Introduction"},"content":"So far we have considered a few types of graphs\n\nUndirected graph: nodes A and B are connected by an edge\n\nDirected graph: connection from node A to node B\n\nStrong/weak graphs: each edge is labeled as strong or weak\n\nToday we extend our understanding of networks to talk about weighted graphs\n\nEach edge is assigned a float denoting the strength of tie\n\nTies can be positive (friends) or negative (enemies)\n\nCan also very in strength (+2.0 better friends than +0.2)\n\n","type":"content","url":"/l04-02-weighted-graphs#introduction","position":3},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"Weighted Adjacency Matrix","lvl2":"Introduction"},"type":"lvl3","url":"/l04-02-weighted-graphs#weighted-adjacency-matrix","position":4},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"Weighted Adjacency Matrix","lvl2":"Introduction"},"content":"In a simple (unweighted) graph, we used a matrix of 0’s and 1’s as an adjacency matrix\n\nA 1 in row i column j marked an edge between i and j (or from i->j for directed)\n\nA 0 marked lack of an edge\n\nG1 = complete_graph(4)\nlocs_x = [1, 2, 3, 2.0]\nlocs_y = [1.0, 0.7, 1, 0]\nlabels1 = collect('A':'Z')[1:nv(G1)]\ngplot(G1, locs_x, locs_y, nodelabel=labels1)\n\nA1 = adjacency_matrix(G1)\n\nWe can extend idea of adjacency matrix to include weighted edges\n\nSuppose nodes A, B, C are friends -- but A-C are best friends\n\nAlso suppose that all of A, B, C consider D an enemy\n\nTo represent this we might say weight of edges is:\n\nA-B and B-C: 1.0\n\nA-C: 2.0\n\nA-D, B-D, C-D: -1.0\n\nHere’s the adjacency matrix\n\nA2 = [0 1 2 -1; 1 0 1 -1; 2 1 0 -1; -1 -1 -1.0 0]\n\nAnd here is how we might visualize this graph (notice the labeled edges)\n\nG2 = SimpleWeightedGraph(A2)\ngplot(\n    G2, locs_x, locs_y,\n    nodelabel=labels1, edgelabel=weight.(edges(G2)),\n)\n\n","type":"content","url":"/l04-02-weighted-graphs#weighted-adjacency-matrix","position":5},{"hierarchy":{"lvl1":"Weighted Graphs","lvl2":"Shortest Paths"},"type":"lvl2","url":"/l04-02-weighted-graphs#shortest-paths","position":6},{"hierarchy":{"lvl1":"Weighted Graphs","lvl2":"Shortest Paths"},"content":"We talked previously about shortest paths for a Graph\n\nThis was defined as the minimum number of edges needed to move from node n1 to node n2\n\nWhen we have a weighted graph things get more interesting...\n\nLet w_{ab} represent the weight connecting nodes A and B\n\nDefine the shortest path between n1 and n2 as the path that minimizes \\sum w_{ab} for all edges A->B along a path\n\n","type":"content","url":"/l04-02-weighted-graphs#shortest-paths","position":7},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"Example","lvl2":"Shortest Paths"},"type":"lvl3","url":"/l04-02-weighted-graphs#example","position":8},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"Example","lvl2":"Shortest Paths"},"content":"Consider the following directed graph\n\nA3 = [\n    0 1 5 3 0 0 0\n    0 0 0 9 6 0 0\n    0 0 0 0 0 2 0\n    0 0 0 0 0 4 8\n    0 0 0 0 0 0 4\n    0 0 0 0 0 0 1\n    0 0 0 0 0 0 0\n]\nG3 = SimpleWeightedDiGraph(A3)\n\n#plotting details\nlocs_x_3 = [3, 5, 1, 3, 4, 2, 3.0]\nlocs_y_3 = [1, 2, 2, 3, 4, 4, 5.0]\nlabels3 = collect('A':'Z')[1:size(A3, 1)]\ngplot(G3, locs_x_3, locs_y_3, nodelabel=labels3, edgelabel=weight.(edges(G3)))\n\nWe wish to travel from node A to node G at minimum cost\n\nThe shortest path (ignoring weights)  is A-D-G\n\nTaking into account weights we have 3 + 8 = 11\n\nThere are two other paths that lead to lower cost (total of 8)\n\nA-C-F-G has cost 5 + 2 + 1 = 8\n\nA-D-F-G has cost 3 + 4 + 1 = 8\n\nFor this small graph, we could find these paths by hand\n\nFor a larger one, we will need an algorithm...\n\n","type":"content","url":"/l04-02-weighted-graphs#example","position":9},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"Shortest path algorithm","lvl2":"Shortest Paths"},"type":"lvl3","url":"/l04-02-weighted-graphs#shortest-path-algorithm","position":10},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"Shortest path algorithm","lvl2":"Shortest Paths"},"content":"Let J(v) be the minimum cost-to-go from node v to node G\n\nSuppose that we know J(v) for each node v, as shown below for our example graph\n\nNote J(G) = 0\n\n\n\nWith J(v) in hand, the following algorithm will find the cost-minimizing path from A to G:\n\nStart with v = A\n\nFrom current node v move to any node that solves \\min_{n \\in F_v} w_{vn} + J(n), where F_v is the set of nodes that can be reached from v.\n\nUpdate notation to set v = n\n\nRepeat steps 2-3 (making note of which we visit) until v = G\n\n","type":"content","url":"/l04-02-weighted-graphs#shortest-path-algorithm","position":11},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"Exercise: Traversing Cost-Minimizing Path","lvl2":"Shortest Paths"},"type":"lvl3","url":"/l04-02-weighted-graphs#exercise-traversing-cost-minimizing-path","position":12},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"Exercise: Traversing Cost-Minimizing Path","lvl2":"Shortest Paths"},"content":"Let’s implement the algorithm above\n\nBelow I have started a function called traverse_graph\n\nYour task is to complete it until you get that the minimum cost path has a cost of 8 and length(4)\n\nJ3 = [8, 10, 3, 5, 4, 1, 0]\n\nfunction traverse_graph(\n        G::SimpleWeightedDiGraph, \n        J::AbstractArray, \n        start_node::Int, end_node::Int\n    )\n    path = Int[start_node]\n    cost = 0.0\n    W = weights(G)\n\n    # TODO: step1, initialize v\n    v = 1  # CHANGE ME\n    num = 0\n    while v != end_node && num < nv(G)  # prevent infinite loop\n        num +=1\n        F_v = neighbors(G, v)\n\n        # TODO: step 2, compute costs for all n in F_v\n        costs = [0 for n in F_v]  # CHANGE ME\n\n        n = F_v[argmin(costs)]\n\n        # TODO: how should we update cost?\n        cost += 0   # CHANGE ME\n\n        push!(path, n)\n\n        # TODO: step 3 -- update v\n        v = v  # CHANGE ME\n    end\n    path, cost\nend\n\ntraverse_graph(G3, J3, 1, 7)\n\n","type":"content","url":"/l04-02-weighted-graphs#exercise-traversing-cost-minimizing-path","position":13},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"But what about J(v)","lvl2":"Shortest Paths"},"type":"lvl3","url":"/l04-02-weighted-graphs#but-what-about-j-v","position":14},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"But what about J(v)","lvl2":"Shortest Paths"},"content":"The shortest path algorithm we presented above sounds simple, but assumed we know J(v)\n\nHow can we find it?\n\nIf you stare at the following equation long enough, you’ll be convinced that J satisfies\nJ(v) = \\min_{n \\in F_v} w_{vn} + J(n)\n\nThis is known as the Bellman equation\n\nIt is a restriction that J must satisfy\n\nWe’ll use this restriction to compute J\n\n","type":"content","url":"/l04-02-weighted-graphs#but-what-about-j-v","position":15},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"Computing J: Guess and Iterate","lvl2":"Shortest Paths"},"type":"lvl3","url":"/l04-02-weighted-graphs#computing-j-guess-and-iterate","position":16},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"Computing J: Guess and Iterate","lvl2":"Shortest Paths"},"content":"We’ll present the standard algorithm for computing J(v)\n\nThis is an iterative method\n\nLet i represent the iteration we are on and J_i(v) be the guess for J(v) on iteration i\n\nAlgorithm\n\nSet i=0, and J_i(v) = 0 \\forall v\n\nSet J_{i+1}(v) = \\min_{n \\in F_v} w_{vn} + J_i(n) \\forall n\n\nCheck if J_{i+1} and J_i are equal for all v -- if not set i = i+1 and see repeat steps 2-3\n\nThis algorithm converges to J (we won’t prove it here...)\n\n","type":"content","url":"/l04-02-weighted-graphs#computing-j-guess-and-iterate","position":17},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"Implementation","lvl2":"Shortest Paths"},"type":"lvl3","url":"/l04-02-weighted-graphs#implementation","position":18},{"hierarchy":{"lvl1":"Weighted Graphs","lvl3":"Implementation","lvl2":"Shortest Paths"},"content":"Let’s now implement the algorithm!\n\nWe’ll walk you through our implementation\n\ncost(W, J, n, v) = W[v, n] + J[n]\n\nfunction compute_J(G::SimpleWeightedDiGraph, dest_node::Int)\n    N = nv(G)\n    # step 1. start with zeros\n    i = 0\n    Ji = zeros(N)\n\n    next_J = zeros(N)\n\n    W = weights(G)\n\n    done = false\n    while !done\n        i += 1\n        for v in 1:N\n            if v == dest_node\n                next_J[v] = 0\n                continue\n            end\n            F_v = neighbors(G, v)\n            costs = [cost(W, Ji, n, v) for n in F_v]\n            next_J[v] = minimum(costs)\n        end\n        done = all(next_J .≈ Ji)\n        copy!(Ji, next_J)\n    end\n    Ji\nend\n\ncompute_J(G3, 7)\n\n","type":"content","url":"/l04-02-weighted-graphs#implementation","position":19},{"hierarchy":{"lvl1":"Weighted Graphs","lvl2":"Exercise: Shortest Path"},"type":"lvl2","url":"/l04-02-weighted-graphs#exercise-shortest-path","position":20},{"hierarchy":{"lvl1":"Weighted Graphs","lvl2":"Exercise: Shortest Path"},"content":"Let’s now combine the two functions to compute a shortest path (and associated cost) for a graph\n\nYour task is to fill in the function below and get the test to pass\n\n\"\"\"\nGiven a weighted graph `G`, enumerate a shortest path between `start_node` and `end_node`\n\"\"\"\nfunction shortest_path(G::SimpleWeightedDiGraph, start_node::Int, end_node::Int)\n    # your code here\nend\n\n","type":"content","url":"/l04-02-weighted-graphs#exercise-shortest-path","position":21},{"hierarchy":{"lvl1":"Weighted Graphs","lvl2":"Summary"},"type":"lvl2","url":"/l04-02-weighted-graphs#summary","position":22},{"hierarchy":{"lvl1":"Weighted Graphs","lvl2":"Summary"},"content":"Weighted graphs allow us to analyze the cost of travsersing paths\n\nApplied in situations like traffic flows (on physical roads/bridges), resource planning, supply chain, international trade (weights as tarrifs), and more\n\nProgramming skills...\n\nWe built up an algorithm shortest_path using two smaller routines: traverse_graph, compute_J\n\nFor each of the 3 functions we were able to write tests to verify code correctness\n\nGood habit to break a hard problem into smaller sub-problems that can be implemented/tested separately\n\nThen compose overall routine using functions for sub-problems\n\nNot all practitioners do this... we’ve seen some scary notebooks and scripts... don’t do that... you know better","type":"content","url":"/l04-02-weighted-graphs#summary","position":23},{"hierarchy":{"lvl1":"Structural Balance"},"type":"lvl1","url":"/l04-03-structural-balance","position":0},{"hierarchy":{"lvl1":"Structural Balance"},"content":"Prerequisites\n\nIntroduction to Graphs\n\nStrong and Weak Ties\n\nWeighted Graphs\n\nOutcomes\n\nUnderstand the structural balance property for sets of three nodes\n\nUnderstand the structural balance theorem for a graph\n\nRecognize structural balance in a weighted graph\n\nReferences\n\nEasley and Kleinberg chapter 5 (especially section 5.1-5-3)\n\n","type":"content","url":"/l04-03-structural-balance","position":1},{"hierarchy":{"lvl1":"Structural Balance","lvl2":"Introduction"},"type":"lvl2","url":"/l04-03-structural-balance#introduction","position":2},{"hierarchy":{"lvl1":"Structural Balance","lvl2":"Introduction"},"content":"We now shift our discussion to the notion of whether or not a network is balanced\n\nFor this discussion we will use weighted graphs, where weights are one of\n\n1: if nodes are friends (also called +)\n\n0: if they don’t know eachother\n\n-1: if nodes are enemies (also called -)\n\nWe won’t consider strength of ties right now\n\nWe will also limit discussion to complete graphs (cliques) where all nodes are connected to all other nodes\n\n","type":"content","url":"/l04-03-structural-balance#introduction","position":3},{"hierarchy":{"lvl1":"Structural Balance","lvl2":"Balance in Triangles"},"type":"lvl2","url":"/l04-03-structural-balance#balance-in-triangles","position":4},{"hierarchy":{"lvl1":"Structural Balance","lvl2":"Balance in Triangles"},"content":"To start thinking about balance, consider the possible configurations of + and - edges in a triangle\n\nThere are 4 options as shown below\n\n\n\nIn (a) all people are friends -- this is happy and balanced\n\nIn (c) A-B are friends with a common enemy C -- nobody has reason to change alliances => balanced\n\nIn (b) A is friends with B and C, but they are enemies -- B and C may try to flip A against other => not balanced\n\nIn (d) all are enemies -- two parties have incentive to team up against common enemy => not balanced\n\n","type":"content","url":"/l04-03-structural-balance#balance-in-triangles","position":5},{"hierarchy":{"lvl1":"Structural Balance","lvl2":"Balance In Graphs"},"type":"lvl2","url":"/l04-03-structural-balance#balance-in-graphs","position":6},{"hierarchy":{"lvl1":"Structural Balance","lvl2":"Balance In Graphs"},"content":"This definition of balance in triangles can be extended to graphs\n\nA complete graph G satisfies the Structural Balance Property if for every set of three nodes, exactly one or three of the edges is labeled +\n\n","type":"content","url":"/l04-03-structural-balance#balance-in-graphs","position":7},{"hierarchy":{"lvl1":"Structural Balance","lvl3":"Implications: Balance Theorem","lvl2":"Balance In Graphs"},"type":"lvl3","url":"/l04-03-structural-balance#implications-balance-theorem","position":8},{"hierarchy":{"lvl1":"Structural Balance","lvl3":"Implications: Balance Theorem","lvl2":"Balance In Graphs"},"content":"One implication of the Structural Balance Property is the Balance Theorem\n\nIf a labeled complete graph is balanced, then either all pairs of nodes are friends, or else the nodes can be divided into two groups, X and Y , such that every pair of nodes in X like each other, every pair of nodes in Y like each other, and everyone in X is the enemy of everyone in Y .\n\nNotice the strength of the statement: either all + or two mutually exclusive groups of friends that are all enemies with other group\n\n","type":"content","url":"/l04-03-structural-balance#implications-balance-theorem","position":9},{"hierarchy":{"lvl1":"Structural Balance","lvl3":"Proving Balance Theorem","lvl2":"Balance In Graphs"},"type":"lvl3","url":"/l04-03-structural-balance#proving-balance-theorem","position":10},{"hierarchy":{"lvl1":"Structural Balance","lvl3":"Proving Balance Theorem","lvl2":"Balance In Graphs"},"content":"We will provide some intuition for how to prove the Balance Theorem, which will help us understand why it is true\n\nConsider a complete Graph G\n\nTwo alternative cases:\n\nEveryone is friends: satisfies theorem by definition\n\nThere are some + and some - edges: need to prove\n\nFor case 2, we must be able to split G into X and Y where the following hold\n\nEvery node in X is friends with every other node in X\n\nEvery node in Y is friends with every other node in Y\n\nEvery node in X is enemies with every node in Y\n\n","type":"content","url":"/l04-03-structural-balance#proving-balance-theorem","position":11},{"hierarchy":{"lvl1":"Structural Balance","lvl3":"Proof by construction","lvl2":"Balance In Graphs"},"type":"lvl3","url":"/l04-03-structural-balance#proof-by-construction","position":12},{"hierarchy":{"lvl1":"Structural Balance","lvl3":"Proof by construction","lvl2":"Balance In Graphs"},"content":"Start with complete, balanced graph G (our only assumption!)\n\nWe will prove the balance theorem by constructing sets X and Y and verifying that the members of these sets satisfy the 3 properties outlined above\n\nTo start, pick any node A \\in G\n\nDivide all other nodes that are friends with A into X and enemies into Y\n\nBecause G is complete, this is all nodes\n\n","type":"content","url":"/l04-03-structural-balance#proof-by-construction","position":13},{"hierarchy":{"lvl1":"Structural Balance","lvl4":"Condition 1: \\forall B, C \\in X \\quad B \\rightarrow C = +","lvl3":"Proof by construction","lvl2":"Balance In Graphs"},"type":"lvl4","url":"/l04-03-structural-balance#condition-1-forall-b-c-in-x-quad-b-rightarrow-c","position":14},{"hierarchy":{"lvl1":"Structural Balance","lvl4":"Condition 1: \\forall B, C \\in X \\quad B \\rightarrow C = +","lvl3":"Proof by construction","lvl2":"Balance In Graphs"},"content":"Let B, C \\in X\n\nWe know A \\rightarrow B = + and A \\rightarrow C = +\n\nBecause graph is balanced, this triangle must have 1 or 3 +\n\nThere are already 2, so it must be that B \\rightarrow C = +\n\nB, C were arbitrary, so this part is proven\n\n","type":"content","url":"/l04-03-structural-balance#condition-1-forall-b-c-in-x-quad-b-rightarrow-c","position":15},{"hierarchy":{"lvl1":"Structural Balance","lvl4":"Condition 2: \\forall D, E \\in Y \\quad D \\rightarrow E = +","lvl3":"Proof by construction","lvl2":"Balance In Graphs"},"type":"lvl4","url":"/l04-03-structural-balance#condition-2-forall-d-e-in-y-quad-d-rightarrow-e","position":16},{"hierarchy":{"lvl1":"Structural Balance","lvl4":"Condition 2: \\forall D, E \\in Y \\quad D \\rightarrow E = +","lvl3":"Proof by construction","lvl2":"Balance In Graphs"},"content":"Let D, E \\in Y\n\nWe know A \\rightarrow D = - and A \\rightarrow E = -\n\nBecause graph is balanced, this triangle must have 1 or 3 +\n\nThere no + and only one option left, so it must be that D \\rightarrow E = +\n\nD, E were arbitrary, so this part is proven\n\n","type":"content","url":"/l04-03-structural-balance#condition-2-forall-d-e-in-y-quad-d-rightarrow-e","position":17},{"hierarchy":{"lvl1":"Structural Balance","lvl4":"Condition 3: \\forall B \\in X and E \\in Y \\quad B \\rightarrow E = -","lvl3":"Proof by construction","lvl2":"Balance In Graphs"},"type":"lvl4","url":"/l04-03-structural-balance#condition-3-forall-b-in-x-and-e-in-y-quad-b-rightarrow-e","position":18},{"hierarchy":{"lvl1":"Structural Balance","lvl4":"Condition 3: \\forall B \\in X and E \\in Y \\quad B \\rightarrow E = -","lvl3":"Proof by construction","lvl2":"Balance In Graphs"},"content":"Let B \\in X and D \\in Y\n\nWe know A \\rightarrow D = - and A \\rightarrow B = +\n\nBecause graph is balanced, this triangle must have 1 or 3 +\n\nThere is one + (A \\rightarrow B) and only one option left, so it must be that B \\rightarrow D = -\n\nB, D were arbitrary, so this part is proven\n\n","type":"content","url":"/l04-03-structural-balance#condition-3-forall-b-in-x-and-e-in-y-quad-b-rightarrow-e","position":19},{"hierarchy":{"lvl1":"Structural Balance","lvl3":"Summary","lvl2":"Balance In Graphs"},"type":"lvl3","url":"/l04-03-structural-balance#summary","position":20},{"hierarchy":{"lvl1":"Structural Balance","lvl3":"Summary","lvl2":"Balance In Graphs"},"content":"We’ve just proven that for any complete, balanced graph G; we can partition G into sets X and Y that satisfy the group structure of all friends or two groups of friends\n\nThis has interesting implications for fields like social interactions, international relations, and online behavior\n\n","type":"content","url":"/l04-03-structural-balance#summary","position":21},{"hierarchy":{"lvl1":"Structural Balance","lvl2":"Application: International Relations"},"type":"lvl2","url":"/l04-03-structural-balance#application-international-relations","position":22},{"hierarchy":{"lvl1":"Structural Balance","lvl2":"Application: International Relations"},"content":"Consider the evolution of alliances in Europe between 1872 and 1907 as represented in the graphs below\n\n","type":"content","url":"/l04-03-structural-balance#application-international-relations","position":23},{"hierarchy":{"lvl1":"Production Networks"},"type":"lvl1","url":"/l05-01-production-networks","position":0},{"hierarchy":{"lvl1":"Production Networks"},"content":"Prerequisites\n\nIntroduction to Graphs\n\nWeighted Graphs\n\nOutcomes\n\nRecall the key concepts of spectral theory from Linear Algebra\n\nDesribe the key proprties of the Leintief family of production models\n\nExplain the difference between “in”-based centrality and “out”-based centrality\n\nAnalyze the impact of sector specific shocks on other sectors of the US economy\n\nReferences\n\nQuantEcon Networks chapters 1-2  (especially section 1.2)\n\n","type":"content","url":"/l05-01-production-networks","position":1},{"hierarchy":{"lvl1":"Production Networks","lvl2":"Linear Algebra"},"type":"lvl2","url":"/l05-01-production-networks#linear-algebra","position":2},{"hierarchy":{"lvl1":"Production Networks","lvl2":"Linear Algebra"},"content":"Linear algebra is the backbone of modern computational algorithms\n\nGraphics\n\nStatistics\n\nData analysis\n\nOptimization\n\nMachine Learning\n\nWorkhorse for accelerated computing\n\nGPUs work on matrices to efficiently parallellize common computations\n\nSpecialty hardware like the TPU (tensor processing unit) take this even further\n\n","type":"content","url":"/l05-01-production-networks#linear-algebra","position":3},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Building Blocks","lvl2":"Linear Algebra"},"type":"lvl3","url":"/l05-01-production-networks#building-blocks","position":4},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Building Blocks","lvl2":"Linear Algebra"},"content":"Vectors: arrays of numbers representing points in multi-dimensional space\n\nMatrices\n\nRectangular arrays that transform vectors\n\nAlso used to represent certain datasets/relationships: e.g. adjacency matrix in Graph Theory\n\nTensors: higher dimensional collections of numbers that allow high-dimensional\n\nVectors are 1d tensors, matrices 2d tensors, etc.\n\nImplemented in numpy as np.array and Julia as the build in array\n\n","type":"content","url":"/l05-01-production-networks#building-blocks","position":5},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Some Key Theories","lvl2":"Linear Algebra"},"type":"lvl3","url":"/l05-01-production-networks#some-key-theories","position":6},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Some Key Theories","lvl2":"Linear Algebra"},"content":"Linear systems of equations\n\nInner product spaces (length, distance, and angles)\n\nEigenvalues and eigen vectors (spectral theory)\n\n","type":"content","url":"/l05-01-production-networks#some-key-theories","position":7},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Spectral Theory","lvl2":"Linear Algebra"},"type":"lvl3","url":"/l05-01-production-networks#spectral-theory","position":8},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Spectral Theory","lvl2":"Linear Algebra"},"content":"Let’s dig into eigenvalues and eigenvectors\n\nLet A \\in \\mathbb{R}^{n \\times n}\n\nA scalar \\lambda \\in \\mathbb{C} is an eigenvalue of A if there exists a nonzero vector e \\in \\mathbb{C}^n such that A e = \\lambda e\n\nA vector e satisfying this equality is called an eigenvector corresponding to the eigenvalue \\lambda\n\nA vector \\epsilon sastifying A ' \\epsilon = \\lambda \\epsilon is a left-eigenvector of A\n\nusing LinearAlgebra\n\nA = [\n    0 -1\n    1 0\n]\neigvals(A)\n\n","type":"content","url":"/l05-01-production-networks#spectral-theory","position":9},{"hierarchy":{"lvl1":"Production Networks","lvl4":"Definitions","lvl3":"Spectral Theory","lvl2":"Linear Algebra"},"type":"lvl4","url":"/l05-01-production-networks#definitions","position":10},{"hierarchy":{"lvl1":"Production Networks","lvl4":"Definitions","lvl3":"Spectral Theory","lvl2":"Linear Algebra"},"content":"The set of all eigenvalues of A is called the spectrum of A and is written \\sigma(A)\n\nThe spectral radius of A is written r(A) \\equiv \\max \\{ | \\lambda | : \\lambda \\in \\sigma(A) \\}\n\nThe spectral radius important when considering the convergence of a dynamic system driven by A\n\nIf x_{t+1} = A x_t and r(A)< 1 then the sequence \\{x\\}_t is finite and will converge\n\nSome facts (not proven here)\n\nA will have at most n distinct eigenvalues\n\nEigenvectors are only unique to a scalar multiple: if (\\lambda, e) is an eigenpair, then so is (\\lambda, \\alpha e) for any \\alpha \\in \\mathbb{R}, \\alpha \\ne 0\n\nSometimes a matrix will have a repeated eigenvalue (the same value works with multiple distinct eigenvectors)\n\nThe algebraic multiplicity of an eigenvalue is the number of times it is repeated with distinct eigenvectors\n\nAn eigenvalue with an algebraic multiplicity of one is called simple\n\n","type":"content","url":"/l05-01-production-networks#definitions","position":11},{"hierarchy":{"lvl1":"Production Networks","lvl4":"Diagonalization","lvl3":"Spectral Theory","lvl2":"Linear Algebra"},"type":"lvl4","url":"/l05-01-production-networks#diagonalization","position":12},{"hierarchy":{"lvl1":"Production Networks","lvl4":"Diagonalization","lvl3":"Spectral Theory","lvl2":"Linear Algebra"},"content":"A matrix A \\in \\mathbb{R}^{n \\times n} is diagonalizable if A = PDP^{-1}\n\nD = \\text{diag}(\\lambda_1, \\dots, \\lambda_n), P is some invertible matrix\n\nThe decomposition is called the eigen decomposition or spectral decomposition of A\n\nThe asymptotic properties of m \\mapsto A^m are determined by \\sigma(A)\n\nCan be seen when A is diagonalizable\n\nIf A = P \\text{diag}(\\lambda) P^{-1} \\Longrightarrow A^m = P \\text{diag}(\\lambda_i^m) P^{-1}\n\n","type":"content","url":"/l05-01-production-networks#diagonalization","position":13},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Example: Worker Dynamics","lvl2":"Linear Algebra"},"type":"lvl3","url":"/l05-01-production-networks#example-worker-dynamics","position":14},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Example: Worker Dynamics","lvl2":"Linear Algebra"},"content":"Consider a continuum of workers (large number, not counted discretely)\n\nWorkers can be in one of two states: (1) employed and (2) unemployed\n\nEach month workers are hired at a rate \\alpha and fired at a rate \\beta\n\nWe express these dynamics as a weighted directed graph with adjacency matrix:P_w = \\begin{bmatrix}1-\\alpha & \\alpha \\\\ \\beta & 1-\\beta \\end{bmatrix} \\; \\alpha, \\beta \\in [0, 1]\n\nRow 1 gives the probabilities of employment and unemployement for an employed worker\n\nRow 2 gives the probabilities of employment and unemployement for an unemployed worker\n\n","type":"content","url":"/l05-01-production-networks#example-worker-dynamics","position":15},{"hierarchy":{"lvl1":"Production Networks","lvl4":"Transitions","lvl3":"Example: Worker Dynamics","lvl2":"Linear Algebra"},"type":"lvl4","url":"/l05-01-production-networks#transitions","position":16},{"hierarchy":{"lvl1":"Production Networks","lvl4":"Transitions","lvl3":"Example: Worker Dynamics","lvl2":"Linear Algebra"},"content":"Suppose we have a vector x \\in \\Delta(2) (2 element simplex) representing current fraction of workers that are employed and unemployed\n\nQuestion... What matrix operation between P_w and x will give the fraction of workers that start next month as employed and unemployed?\n\nalpha = 0.3\nbeta = 0.1\n\nP = [1-alpha alpha; beta 1-beta]\n\nx = [0.9, 0.1]\n\n# TODO: simulate for many periods\n\n# TODO: compare to largest left eigenvector\n\n","type":"content","url":"/l05-01-production-networks#transitions","position":17},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Neumann Series Lemma","lvl2":"Linear Algebra"},"type":"lvl3","url":"/l05-01-production-networks#neumann-series-lemma","position":18},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Neumann Series Lemma","lvl2":"Linear Algebra"},"content":"We need one more linear alegbra result...\n\nIf A \\in \\mathbb{R}^{n \\times n} and r(A) < 1, then I-A is non-singular and (I-A)^{-1} = \\sum_{m=0}^{\\infty} A^m\n\nThis is known as the Neumann series lemma\n\n","type":"content","url":"/l05-01-production-networks#neumann-series-lemma","position":19},{"hierarchy":{"lvl1":"Production Networks","lvl2":"Production Networks"},"type":"lvl2","url":"/l05-01-production-networks#production-networks","position":20},{"hierarchy":{"lvl1":"Production Networks","lvl2":"Production Networks"},"content":"We will now study a family of economic models that allow us to analyze the economy as a collection of sectors\n\nThese models were proposed by nobel prize winner Wassily Leontief in 1941 and are still commonly used today\n\nThe key idea behind a Leontief model is the input-output table\n\n","type":"content","url":"/l05-01-production-networks#production-networks","position":21},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Input-output tables","lvl2":"Production Networks"},"type":"lvl3","url":"/l05-01-production-networks#input-output-tables","position":22},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Input-output tables","lvl2":"Production Networks"},"content":"Firms (companies) are categorized into n distinct sectors\n\nFirms use materials produced by other sectors as part of their production process\n\nThe relationship of flows of value are organized into an input/output table\n\n\n\nsector 1\n\nsector 2\n\nsector 3\n\nsector 1\n\na_{11}\n\na_{12}\n\na_{13}\n\nsector 2\n\na_{21}\n\na_{22}\n\na_{23}\n\nsector 3\n\na_{31}\n\na_{32}\n\na_{33}\n\na_{ij} is called an input-output coefficient and is equal to:a_{ij} = \\frac{\\text{value of sector j inputs purchased from sector i}}{\\text{total sales of sector j}}\n\nIf a_{ij} is large, sector i is an important supplier of intermediate goods to sector j\n\nThe sum of column j is the value of all inputs to sector j\n\nRow i shows how intensively each sector uses good i as an intermediate good\n\nThe input output table can be directly used as the adjacency matrix for a weighted directed graph\n\n","type":"content","url":"/l05-01-production-networks#input-output-tables","position":23},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Input-output data","lvl2":"Production Networks"},"type":"lvl3","url":"/l05-01-production-networks#input-output-data","position":24},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Input-output data","lvl2":"Production Networks"},"content":"In the United States, the Bureau of Economic Analysis is responsible for compiling input-output tables for sectors\n\nWe’ll be studying the \n\nInput-Output Accounts Data\n\nThe main set of tables we’ll be using are called the Make-Use tables\n\nThe Make table shows the value of final goods produced by each sector\n\nNote this is predominately a diagonal matrix as each sector primarily produces and sells final goods within their sector\n\nSometimes a firm will have secondary outputs as part of their production process\n\n“Which industries produce which commodities?”\n\nThe Use tables show the intermediate and final use of commodities across sectors\n\n“Who uses or consumes the commodities produced?”\n\nusing CSV, DataFrames, Graphs, SimpleWeightedGraphs, GraphPlot, ColorSchemes, Colors, Downloads, PlotlyBase\n\nusing Downloads\n\nfunction read_remote_csv(url)\n    bn = basename(url)\n    if !isfile(bn)\n        Downloads.download(url, bn)\n    end\n    CSV.read(bn, DataFrame)\nend\n\nmake_15 = read_remote_csv(\"https://compsosci-resources.s3.amazonaws.com/graph-theory-lectures/data/QE-networks/make_15.csv\");\nuse_15 = read_remote_csv(\"https://compsosci-resources.s3.amazonaws.com/graph-theory-lectures/data/QE-networks/use_15.csv\");\ncodes = read_remote_csv(\"https://compsosci-resources.s3.amazonaws.com/graph-theory-lectures/data/QE-networks/codes.csv\");\n\n","type":"content","url":"/l05-01-production-networks#input-output-data","position":25},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Example: US 15 sector data","lvl2":"Production Networks"},"type":"lvl3","url":"/l05-01-production-networks#example-us-15-sector-data","position":26},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Example: US 15 sector data","lvl2":"Production Networks"},"content":"\n\nColor of nodes is according to their hub-based eigenvector centrality (see below)\n\nSize of nodes is according to their total outputs (make table)\n\nThickness of edges is according to amount of goods\n\nRepresent a_{ij} and point from sector creating the intermediate good (sector i) to sector  using intermediate good (sector j)\n\n\n\n","type":"content","url":"/l05-01-production-networks#example-us-15-sector-data","position":27},{"hierarchy":{"lvl1":"Production Networks","lvl4":"Eigenvector Centrality","lvl3":"Example: US 15 sector data","lvl2":"Production Networks"},"type":"lvl4","url":"/l05-01-production-networks#eigenvector-centrality","position":28},{"hierarchy":{"lvl1":"Production Networks","lvl4":"Eigenvector Centrality","lvl3":"Example: US 15 sector data","lvl2":"Production Networks"},"content":"The node size above shows the hub-based eigenvector centrality\n\nThis is equal to the dominant eigenvector of the adjacency matrix (eigenvector associated with largest eigenvalue)\n\nThis measure of centrality measures the influence of a node in a network\n\nWhen computing this statistic for a node N, the value will be higher if it is connected to other “influential” nodes\n\nhttps://​youtu​.be​/LYyZqlyDEL4​?si​=​x2kYhe3phZxQtQvV​&​t​=​202\n\n","type":"content","url":"/l05-01-production-networks#eigenvector-centrality","position":29},{"hierarchy":{"lvl1":"Production Networks","lvl4":"Example","lvl3":"Example: US 15 sector data","lvl2":"Production Networks"},"type":"lvl4","url":"/l05-01-production-networks#example","position":30},{"hierarchy":{"lvl1":"Production Networks","lvl4":"Example","lvl3":"Example: US 15 sector data","lvl2":"Production Networks"},"content":"Let’s compute the eigenvector centrality for the data in the image above\n\nI have some code to import the make/use files into a helpful struct\n\nWe’ll see what all the fields are as we progress through the lecture\n\nto_int(x) = parse(Int, x)\nto_int(x::Integer) = Int(x)\n\nstruct SectorData\n    Z::Matrix{Int}\n    X::Vector{Int}\n    A::Matrix{Float64}\n    F::Matrix{Float64}\n    Z_df::DataFrame\n    names::Vector{String}\n    codes::Vector{String}\n    N::Int\n    G::SimpleWeightedDiGraph{Int64, Float64}\nend\n\nconst CODES = let\n    df = read_remote_csv(\"codes.csv\")\n    Dict(zip(df.name, df.code))\nend\n\nfunction load_sector(N)\n    # read csv\n    df = CSV.read(\"use_$(N).csv\", DataFrame)\n\n    # replace `---` with `0`\n    df .= ifelse.(df .== \"---\", \"0\", df)\n\n    # conver to int\n    df[!, 2:end] .= to_int.(df[!, 2:end])\n\n    # first column is industry name, next columns are sector values\n    # first N rows are values\n    Z = Array(df[1:N, 2:(N+1)])\n    names = df[1:N, 1]\n    codes = [CODES[n] for n in names]\n\n    # total industry outputs come from teh `make_N.csv` file\n    X = CSV.read(\"make_$(N).csv\", DataFrame)[1:N, \"Total Industry Output\"]\n\n    # value of sector j's inputs purchased from i / sales of `j`\n    # or ...\n    A = Z ./ X'\n\n    F = Z ./ X\n\n    # make copy of A where small values are set to zero to make plotting clearer\n    A_copy = copy(A)\n    A_copy[A .<= 0.01] .= 0;\n    G = SimpleWeightedDiGraph(A_copy)\n\n    SectorData(Z, X, A, F, df, names, codes, N, G)\nend\n\ndata15 = load_sector(15);\n\nlambda15 = eigenvector_centrality(data15.G)\n\nPlot(bar(x=data15.codes, y=lambda15))\n\n","type":"content","url":"/l05-01-production-networks#example","position":31},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Accounting","lvl2":"Production Networks"},"type":"lvl3","url":"/l05-01-production-networks#accounting","position":32},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Accounting","lvl2":"Production Networks"},"content":"Let...\n\nd_i be the final consumer demand for good i\n\nx_i be total sales of sector i\n\nz_{ij} be inter-industry sales from sector i to sector j\n\nFor accounts to add up we must have x_i = \\sum_{j=1}^n z_{ij} + d_i\n\nNotice that \\frac{z_{ij}}{x_j} = a_{ij} = \\text{dollar value of inputs from $i$ per dollar output from $j$}\n\nThis means x_i = \\sum_{j=1} a_{ij} x_j + d_i\n\nWhich can be written x = Ax + d\n\n","type":"content","url":"/l05-01-production-networks#accounting","position":33},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Equilibrium","lvl2":"Production Networks"},"type":"lvl3","url":"/l05-01-production-networks#equilibrium","position":34},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Equilibrium","lvl2":"Production Networks"},"content":"An equilibrium in a Leonteif model with input-output coefficient matrix A and a vector d \\in \\mathbb{R}^n of final consumer demands for each sector is a vector x for sector-specific output such that x = Ax + d is satisfied\n\nNote that d and A are treated as given\n\nTo find this vector requires that we trace the impact of final demand on the intermediate linkages through A\n\nExample:\n\nExample\n\nSuppose d_3 \\uparrow\n\nWill cause 3 to consume more from its suppliers (2 and 4)\n\nWhich will cause 2 to demand more from 1\n\nWhich will cause 1 to demand more from 2 and 4\n\n... and so on\n\nComputing an equilibrium is not entirely straight forward...\n\n","type":"content","url":"/l05-01-production-networks#equilibrium","position":35},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Computing an Equilibrium","lvl2":"Production Networks"},"type":"lvl3","url":"/l05-01-production-networks#computing-an-equilibrium","position":36},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Computing an Equilibrium","lvl2":"Production Networks"},"content":"Define v_j \\equiv x_j - \\sum_{i=1}^n z_{ij} as the value added by sector j\n\nAssumption: The input-output adjacency matrix A satisfies \\eta_j \\equiv \\sum_{i=1}^n a_{ij} < 1 \\; \\forall j \\in [n]\n\nThis holds whenever v_j > 0 \\forall j\n\nWhen this assumption holds, for each d \\ge 0 there is a unique, nonnegative output solution given by x^* = Ld \\qquad \\text{where } L \\equiv (I-A)^{-1}\n\nThe matrix L is called the Leontief inverse associated with the coefficient matrix A\n\nL15 = inv(I - data15.A)\n\n# propose a demand vector where each element is between [100, 600]\nd = rand(15).* 500 .+ 100\n\nL15 * d\n\nQuestion\n\nWe don’t have a field for d in our SectorData struct.\n\nHow could we compute/derive d given the fields we do have?\n\nfieldnames(SectorData)\n\n","type":"content","url":"/l05-01-production-networks#computing-an-equilibrium","position":37},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Demand Shocks","lvl2":"Production Networks"},"type":"lvl3","url":"/l05-01-production-networks#demand-shocks","position":38},{"hierarchy":{"lvl1":"Production Networks","lvl3":"Demand Shocks","lvl2":"Production Networks"},"content":"A common form of economic analysis is to consider the impact of external “shocks”\n\nOften, these are modeled as a one time change in the value of a variable\n\nLet’s consider a demand shock of size \\Delta d such that demand moves from d_0 to d_1 = \\Delta d + d_0\n\nThe equilibrium vector shifts from x_0 = L d_0 to x_1 = L d_1\n\nDefine \\Delta x = L (d_1 - d_0) = L \\delta d\n\n","type":"content","url":"/l05-01-production-networks#demand-shocks","position":39},{"hierarchy":{"lvl1":"Production Networks","lvl3":"NSL","lvl2":"Production Networks"},"type":"lvl3","url":"/l05-01-production-networks#nsl","position":40},{"hierarchy":{"lvl1":"Production Networks","lvl3":"NSL","lvl2":"Production Networks"},"content":"We will further assume that r(A)<1 so that we can write the expression for \\Delta x as an infinite sum using the Neumann Series Lemma: \\Delta x = \\Delta d + A (\\Delta d) + A^2 (\\Delta d) + \\cdots\n\n\\Delta d is the initial response in each sector,\n\nA (\\Delta d) is the response generated by the first round of backward linkages,\n\nA^2 (\\Delta d) is the response generated by the second round, and so on.\n\nThe total response is the sum of the responses at each round\n\nThe typical element l_{ij} of L = \\sum_{m=0}^{\\infty} A^m shows total impact on sector i of a unit change in the demand for good j\n\nL15\n\nPlot(heatmap(z=L15))","type":"content","url":"/l05-01-production-networks#nsl","position":41},{"hierarchy":{"lvl1":"Agent Based Models"},"type":"lvl1","url":"/l06-01-abm-concepts","position":0},{"hierarchy":{"lvl1":"Agent Based Models"},"content":"Computational Analysis of Social Complexity\n\nPrerequisites\n\nNone 😏\n\nOutcomes\n\nUnderstand what a model is\n\nKnow the difference between what we call equation based models and agent based models\n\nUnderstand the key building blocks of agent based models\n\nLearn the key components of the Schelling segregation model\n\nReferences\n\nCioffi-Revilla Chapter 10\n\nhttps://​journal​.sohostrategy​.com​/what​-does​-an​-agent​-based​-model​-look​-like​-dc1fbc17f2f5\n\nhttps://​journal​.sohostrategy​.com​/what​-is​-abm​-abms​-f52ff2f1f712\n\nhttps://​towardsdatascience​.com​/agent​-based​-modeling​-will​-unleash​-a​-new​-paradigm​-of​-machine​-learning​-ff6d3b1ac940​?source​=​search​_post​-​-​-​-​-​-​-​--3\n\n","type":"content","url":"/l06-01-abm-concepts","position":1},{"hierarchy":{"lvl1":"Agent Based Models","lvl2":"Why Models?"},"type":"lvl2","url":"/l06-01-abm-concepts#why-models","position":2},{"hierarchy":{"lvl1":"Agent Based Models","lvl2":"Why Models?"},"content":"Many topics of interest for social scientists are either unethical or unreasonable to study in a laboratory\n\nImpact on communities of upsurge in illicit drug usage (can’t give people drugs to see impact)\n\nFlow of traffic given a new infrastructure updates (too costly to experiment with)\n\nImpact of new tariffs in international trading relationships (too costly to coordinate legislation and implement)\n\nFor this reason, we as social scientists turn to models to study our problems\n\nA model is a probability distribution over outcomes\n\nI’ll repeat for emphasis: a model is a probability distribution over outcomes\n\nExample: A model of housing prices doesn’t predict your house will sell for exactly $350,000\n\nInstead, it might say there’s a 60% chance it sells between 340,000-360,000, 30% chance between 320,000-340,000, etc.\n\nThe model describes the likelihood of different outcomes, not a single deterministic answer\n\n","type":"content","url":"/l06-01-abm-concepts#why-models","position":3},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"Types of Models","lvl2":"Why Models?"},"type":"lvl3","url":"/l06-01-abm-concepts#types-of-models","position":4},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"Types of Models","lvl2":"Why Models?"},"content":"A model is a mathematical object: equations, rules, distributional assumptions.\n\nAt its heart, a model is a simplification of some real-world system or phenomenon\n\nMuch complexity is abstracted away (or not included directly in model)\n\nKey aspects relevant for study are modeled explicitly (e.g. trading response to tariffs)\n\nFor our purposes, we will think of models as belonging to one of two families\n\nEquation based models\n\nAgent based models\n\nThis is a simplification and not a perfect classification (because equation based models have agents and agent based models have equations), but we will be able to draw useful distinctions with this classification.\n\n","type":"content","url":"/l06-01-abm-concepts#types-of-models","position":5},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"Equation Based Models","lvl2":"Why Models?"},"type":"lvl3","url":"/l06-01-abm-concepts#equation-based-models","position":6},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"Equation Based Models","lvl2":"Why Models?"},"content":"An equation based model describes the decision making setting for each agent using mathematical equations\n\nTypically, these are posed as (constrained) optimization problems\n\nA set of equations is also developed that describe interaction between agents\n\nThese equations can feature random variables and will require specification of model parameters\n\nMost models I study and develop in my economics research are equation based\n\nPros:\n\nAllow precise specification of assumptions, incentives, and outcomes\n\nHave wide toolbox of numerical optimization, and statistical fitting to “solve” model\n\nCons:\n\nOptimization and calibration of parameters can be very difficult\n\nOften subject to the “curse of dimensionality”, which limits size and complexity of model\n\n","type":"content","url":"/l06-01-abm-concepts#equation-based-models","position":7},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"Agent Based Models (ABMs)","lvl2":"Why Models?"},"type":"lvl3","url":"/l06-01-abm-concepts#agent-based-models-abms","position":8},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"Agent Based Models (ABMs)","lvl2":"Why Models?"},"content":"An agent based model describes rules for how individual agents respond to their environment\n\nThere are usually many agents, each with a set of properties\n\nOne common property is the type of the agent: usually drawn from a small/finite set (buyer-seller, parent-child-teacher, sheep-wolf)\n\nAll agents of the same type have the same set of additional properties\n\nEach agent has a state at each time step t\n\nThe rules are equations that specify how the state of an agent is updated between periods t and t+1\n\nRules are common for all agents of a type, but vary based on that agent’s state and property values\n\nRules will often have random variables as well as parameters\n\nRules often include notion of “neighboring” agents\n\nPros:\n\nFocus on how an individual should respond in a given state without requiring optimization\n\nBecause rules are typically mathematically simple, can have many many agents\n\nCons:\n\nOften lacks notion of equilibrium (could be a feature)\n\nNot very “reusable” -- to study specific topic you usually have to create whole new model\n\nSometimes \n\ntoo many parameters: need for careful calibration\n\n","type":"content","url":"/l06-01-abm-concepts#agent-based-models-abms","position":9},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"Example: Farmer’s Market Pricing","lvl2":"Why Models?"},"type":"lvl3","url":"/l06-01-abm-concepts#example-farmers-market-pricing","position":10},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"Example: Farmer’s Market Pricing","lvl2":"Why Models?"},"content":"Consider modeling prices at a local farmer’s market for tomatoes:\n\nEquation-based approach:\n\nDefine supply and demand curves\n\nSolve for equilibrium price where supply equals demand\n\nResult: Market clears at $3.50/lb with 500 lbs sold\n\nBest for: Understanding average market price, total quantity sold, analyzing policy impacts (e.g., effect of a $0.50/lb subsidy)\n\nAgent-based approach:\n\nIndividual vendors: each has costs, quality, inventory, and pricing strategy\n\nIndividual buyers: each has budget, quality preferences, and willingness to pay\n\nRules: Buyers visit stalls, compare prices/quality, purchase or move on\n\nVendors adjust prices based on remaining inventory and time of day\n\nEmergent patterns: Price dispersion, quality segments, end-of-day discounts\n\nBest for: Understanding why some vendors charge more, how relationships form, impact of vendor reputation\n\nThe equation model tells us the average outcome; the ABM shows us the rich variety of individual transactions that create that average.\n\n","type":"content","url":"/l06-01-abm-concepts#example-farmers-market-pricing","position":11},{"hierarchy":{"lvl1":"Agent Based Models","lvl2":"ABMs"},"type":"lvl2","url":"/l06-01-abm-concepts#abms","position":12},{"hierarchy":{"lvl1":"Agent Based Models","lvl2":"ABMs"},"content":"For the next few lectures we’ll focus on agent base models\n\nWe’ll start by outlining the main components of an ABM\n\nThen we’ll talk about how we could represent them in Julia using the Agents.jl library\n\nThis will require a step up in our Julia skills, so we’ll spend some time covering these concepts in greater detail\n\nFinally we’ll see a few examples of ABMs in practice\n\nNOTE: Most of the study of the Julia skills and ABM examples are not in this notebook\n\n","type":"content","url":"/l06-01-abm-concepts#abms","position":13},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"ABM components","lvl2":"ABMs"},"type":"lvl3","url":"/l06-01-abm-concepts#abm-components","position":14},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"ABM components","lvl2":"ABMs"},"content":"ABMs are made up of 3 distinct components:\n\nAgents\n\nEnvironment\n\nRules\n\n","type":"content","url":"/l06-01-abm-concepts#abm-components","position":15},{"hierarchy":{"lvl1":"Agent Based Models","lvl4":"Agents","lvl3":"ABM components","lvl2":"ABMs"},"type":"lvl4","url":"/l06-01-abm-concepts#agents","position":16},{"hierarchy":{"lvl1":"Agent Based Models","lvl4":"Agents","lvl3":"ABM components","lvl2":"ABMs"},"content":"Have state at discrete time steps t (state is value of properties, some properties might be fixed)\n\nAlways aware of its own state\n\nAutonomous: can make a decisions independent of other agents\n\nReactive: can respond to changes in environment or state of other agents\n\nProactive: can behave in a way to achieve a goal\n\nCommunicate: can make some attributes visible to other agents\n\n","type":"content","url":"/l06-01-abm-concepts#agents","position":17},{"hierarchy":{"lvl1":"Agent Based Models","lvl4":"Environments","lvl3":"ABM components","lvl2":"ABMs"},"type":"lvl4","url":"/l06-01-abm-concepts#environments","position":18},{"hierarchy":{"lvl1":"Agent Based Models","lvl4":"Environments","lvl3":"ABM components","lvl2":"ABMs"},"content":"One of two types\n\nNatural Environments: biophysical landscapes and settings\n\nArtifical environments: classrooms, economic markets, parks, transportation streets, buildings, etc.\n\nAgents reside within an environment\n\nProperties of environment can be fixed (size, dimensions) or varying (weather, congestion, unused capacity)\n\nAgents can observe and potentially respond to properties of the environment\n\n","type":"content","url":"/l06-01-abm-concepts#environments","position":19},{"hierarchy":{"lvl1":"Agent Based Models","lvl4":"Rules","lvl3":"ABM components","lvl2":"ABMs"},"type":"lvl4","url":"/l06-01-abm-concepts#rules","position":20},{"hierarchy":{"lvl1":"Agent Based Models","lvl4":"Rules","lvl3":"ABM components","lvl2":"ABMs"},"content":"Rules are the key feature that makes ABMs dynamic\n\nTypes of rules:\n\nInter-agent: how agents communicate and respond to one another (e.g. information spread)\n\nAgent-environment rules: How an agent responds to an environment (e.g. avoid park if raining), or how an agent’s decisions and behaviors impact environment (e.g. more cars => more pollution)\n\nIntra-environmental rules: cause and effect mechanisms within the environment (e.g. more rain => more vegetation)\n\n","type":"content","url":"/l06-01-abm-concepts#rules","position":21},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"Why ABMs for Social Science?","lvl2":"ABMs"},"type":"lvl3","url":"/l06-01-abm-concepts#why-abms-for-social-science","position":22},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"Why ABMs for Social Science?","lvl2":"ABMs"},"content":"ABMs are particularly powerful for social science because:\n\nNo equilibrium required: Social systems rarely reach stable equilibria\n\nFashion trends, social media virality, political movements constantly evolve\n\nHeterogeneity matters: Individual differences drive social outcomes\n\nNot everyone responds the same way to incentives or information\n\nLocal interactions dominate: Who you know matters more than population averages\n\nJob opportunities through networks, not random matching\n\nDisease spread through actual contact patterns\n\nPath dependence: History and timing matter\n\nEarly adopters can shift entire market dynamics\n\nSmall initial differences can lead to dramatically different outcomes\n\nEmergence: Simple individual rules create complex social patterns\n\nSegregation can emerge without strong individual preferences (as we’ll see with Schelling)\n\n","type":"content","url":"/l06-01-abm-concepts#why-abms-for-social-science","position":23},{"hierarchy":{"lvl1":"Agent Based Models","lvl2":"ABMs in Julia"},"type":"lvl2","url":"/l06-01-abm-concepts#abms-in-julia","position":24},{"hierarchy":{"lvl1":"Agent Based Models","lvl2":"ABMs in Julia"},"content":"We need a way to represent these three components in Julia\n\nAgents: represent as a Julia struct\n\nStruct fields record agent properties\n\nOur custom agent type can have methods that ascribe behavior to agents\n\nEnvironments: either explicitly as Julia struct or implicitly in the update rules\n\nRules: julia functions\n\nKey function is step! which will allow our agents to make decisions and have the environment and agent properties update in response\n\n","type":"content","url":"/l06-01-abm-concepts#abms-in-julia","position":25},{"hierarchy":{"lvl1":"Agent Based Models","lvl2":"Schelling Segregation Model"},"type":"lvl2","url":"/l06-01-abm-concepts#schelling-segregation-model","position":26},{"hierarchy":{"lvl1":"Agent Based Models","lvl2":"Schelling Segregation Model"},"content":"We will work on learning how to represent our agents, rules, and environment in Julia\n\nTo make that discussion more concrete, it will be helpful to have a model to implement\n\nThe “hello world” of ABMs may just be the Schelling segregation model\n\nReferences include \n\nQuantEcon and \n\nAgents.jl tutorial\n\n","type":"content","url":"/l06-01-abm-concepts#schelling-segregation-model","position":27},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"Schelling’s Work","lvl2":"Schelling Segregation Model"},"type":"lvl3","url":"/l06-01-abm-concepts#schellings-work","position":28},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"Schelling’s Work","lvl2":"Schelling Segregation Model"},"content":"Thomas Schelling won a nobel price in economics for his study of racial segregation\n\nAt the heart of his study, was a model proposed in 1969 for how racial segregation can occur in urban areas\n\nOne theme of this work (and ABMs in general) is that local interactions (like decisions of individual agents) can lead to surprising aggregate results\n\n","type":"content","url":"/l06-01-abm-concepts#schellings-work","position":29},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"The Model","lvl2":"Schelling Segregation Model"},"type":"lvl3","url":"/l06-01-abm-concepts#the-model","position":30},{"hierarchy":{"lvl1":"Agent Based Models","lvl3":"The Model","lvl2":"Schelling Segregation Model"},"content":"Environment: 25x25 grid of single family dwellings\n\nAgents with properties:\n\nlocation (x,y) coordinate for current home\n\ntype: orange or blue. Fixed over time. 250 of each\n\nhappiness: 0 if less than N of neighbors are of same type, 1 otherwise\n\nRules:\n\nAgents choose to move to unoccupied grid point if unhappy\n\nNote neighbors for a particular cell are the the 8 other cells surrounding the cell of interest. Corner or edge cells have less than 8 neighbors","type":"content","url":"/l06-01-abm-concepts#the-model","position":31},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl"},"type":"lvl1","url":"/l06-02-schelling-agents","position":0},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl"},"content":"Computational Analysis of Social Complexity\n\nPrerequisites\n\nJulia Basics (from week 2)\n\nJulia Types (from week 2)\n\nABM intro\n\nOutcomes\n\nLearn to use the Julia REPL for running interactive ABM visualizations\n\nImplement the Schelling segregation model using Agents.jl\n\nReferences\n\nAgents.jl tutorial\n\nQuantEcon lecture\n\n","type":"content","url":"/l06-02-schelling-agents","position":1},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl2":"Review Schelling Model"},"type":"lvl2","url":"/l06-02-schelling-agents#review-schelling-model","position":2},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl2":"Review Schelling Model"},"content":"Recall the components of the Schelling segregation model\n\nEnvironment: 25x25 grid of single family dwellings\n\nAgents with properties:\n\nlocation (x,y) coordinate for current home\n\ntype: orange or blue. Fixed over time. 250 of each\n\nhappiness: 0 if less than N of neighbors are of same type, 1 otherwise\n\nRules:\n\nAgents choose to move to unoccupied grid point if unhappy\n\nNote neighbors for a particular cell are the the 8 other cells surrounding the cell of interest. Corner or edge cells have less than 8 neighbors\n\n","type":"content","url":"/l06-02-schelling-agents#review-schelling-model","position":3},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl2":"Agents.jl"},"type":"lvl2","url":"/l06-02-schelling-agents#agents-jl","position":4},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl2":"Agents.jl"},"content":"We are now ready to get started implementing the Schelling segregation model in Julia\n\nWe’ll use the Agents.jl library, which is a very powerful ABM toolkit\n\nHere are some points of comparison between Agents.jl and other ABM software (from the Agents.jl website):\n\n","type":"content","url":"/l06-02-schelling-agents#agents-jl","position":5},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl2":"Schelling in Agents.jl"},"type":"lvl2","url":"/l06-02-schelling-agents#schelling-in-agents-jl","position":6},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl2":"Schelling in Agents.jl"},"content":"Let’s now implement the Schelling Segregation model in Agents.jl\n\nThe first thing we’ll need to do is define our Agent\n\nThe recommended way to do this is to create a new Julia struct using the @agent macro provided by Agents.jl\n\nThe macro will ensure a few things:\n\nThe struct contains id and pos fields to keep track of the agent and its position\n\nThe struct is mutable so the position can be updated\n\nThe struct is a subtype of AbstractAgent so it can be used by other functions in Agents.jl\n\n# load up packages we need for this example... might take a few minutes\n# import Pkg\n# Pkg.activate(\".\")\n# Pkg.instantiate()\n\nusing Agents\n\n@agent struct SchellingAgent(GridAgent{2})\n    is_happy::Bool      # whether the agent is happy in its position. (true = happy)\n    group::Int          # The group of the agent, determines mood as it interacts with neighbors 0: blue, 1: orange\nend\n\nWe can see the complete structure of the ShellingAgent type using the dump function\n\ndump(SchellingAgent)\n\n","type":"content","url":"/l06-02-schelling-agents#schelling-in-agents-jl","position":7},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Schelling Environment","lvl2":"Schelling in Agents.jl"},"type":"lvl3","url":"/l06-02-schelling-agents#schelling-environment","position":8},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Schelling Environment","lvl2":"Schelling in Agents.jl"},"content":"Our Schelling environment will be one the built-in Agents.jl spaces\n\nWe’ll use GridSpace\n\nenvironment = GridSpaceSingle((25, 25); periodic = false)\n\n","type":"content","url":"/l06-02-schelling-agents#schelling-environment","position":9},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Rules","lvl2":"Schelling in Agents.jl"},"type":"lvl3","url":"/l06-02-schelling-agents#rules","position":10},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Rules","lvl2":"Schelling in Agents.jl"},"content":"The last part of our ABM that we need to specify is the rules for how agents respond to the environment and state\n\nOur rule is that agents will choose to move to an empty grid space if they have less than wanted_neighbors neighbors of the same group\n\nAgents.jl requires us to implement these rules in a method agent_step!(agent::SchellingAgent, model)\n\nWe’ll make use of a couple helper functions provided by Agents.jl:\n\nmove_agent_single!: move a single agent to an empty place in the environment. This modifies the pos field of the agent\n\nnearby_agents: return an array of all neighbors of a particular agent. This queries the pos field of all agents\n\nfunction agent_step!(agent::SchellingAgent, model)\n\twant = model.wanted_neighbors\n\thave = 0\n\tfor n in nearby_agents(agent, model)\n\t\tif n.group == agent.group\n\t\t\thave += 1\n\t\tend\n\tend\n\tagent.is_happy = have >= want\n\tif !agent.is_happy\n\t\tmove_agent_single!(agent, model)\n\tend\n\treturn\nend\n\n","type":"content","url":"/l06-02-schelling-agents#rules","position":11},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Combining Agents, Environment, and Rules","lvl2":"Schelling in Agents.jl"},"type":"lvl3","url":"/l06-02-schelling-agents#combining-agents-environment-and-rules","position":12},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Combining Agents, Environment, and Rules","lvl2":"Schelling in Agents.jl"},"content":"We now need to create an instance of the AgentBasedModel (or ABM for short) type\n\nTo construct our instance we need to specify our agent type, our environment, our rules (via agent_step! function), and any additional properties\n\nThese additional properties belong to the model, and can be thought of as parameters that should be calibrated\n\nIn our previous exposition we would have attached these to the environment\n\nproperties = Dict(:wanted_neighbors => 4)\nschelling = AgentBasedModel(SchellingAgent, environment; properties=properties, agent_step! = agent_step!)\n\n","type":"content","url":"/l06-02-schelling-agents#combining-agents-environment-and-rules","position":13},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Add Agents","lvl2":"Schelling in Agents.jl"},"type":"lvl3","url":"/l06-02-schelling-agents#add-agents","position":14},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Add Agents","lvl2":"Schelling in Agents.jl"},"content":"Now we have fully specified the behavior of our ABM, but we have a problem...\n\nWe don’t have any agents!!\n\nTo add agents, we’ll use the add_agent_single!(::SchellingAgent, model) function, which is provided by Agents.jl and knows how to place non-overlapping agents in our environment\n\nThis will set the pos field for our agents\n\nSo that we can run many experiments, we’ll actually create a helper function that will create a new model from scratch and add agents to it\n\nfunction init_schelling(;num_agents_per_group=250)\n\tenvironment = GridSpaceSingle((25, 25), periodic=false)\n\tproperties = Dict(:wanted_neighbors => 4)\n\tmodel = ABM(SchellingAgent, environment; properties=properties, agent_step! = agent_step!)\n\t\n\tid = 0\n\tfor group in 1:2, i in 1:num_agents_per_group\n\t\tagent = SchellingAgent(id+=1, (1, 1), false, group)\n\t\tadd_agent_single!(agent, model)\n\tend\n\tmodel\nend\n\nmodel = init_schelling()\n\n","type":"content","url":"/l06-02-schelling-agents#add-agents","position":15},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Running the Model","lvl2":"Schelling in Agents.jl"},"type":"lvl3","url":"/l06-02-schelling-agents#running-the-model","position":16},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Running the Model","lvl2":"Schelling in Agents.jl"},"content":"To run our model, we need to step forward in time\n\nWe do this using the step! function provided by Agents.jl\n\nThis function will iterate over all the agents in the model and call agent_step! for each of them\n\n# advance one step\nstep!(model)\n\n# advance three steps\nstep!(model, 3)\n\nWe can also use the run function\n\nThis function requires a model, agent_step! function, number of steps and array of agent property names to record\n\nThe output is a DataFrame with all the data\n\nmodel = init_schelling()\nadata = [:pos, :is_happy, :group]  # short for agent data\ndata, _ = run!(model, 10; adata)\ndata\n\n","type":"content","url":"/l06-02-schelling-agents#running-the-model","position":17},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Visualizing the Agents","lvl2":"Schelling in Agents.jl"},"type":"lvl3","url":"/l06-02-schelling-agents#visualizing-the-agents","position":18},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Visualizing the Agents","lvl2":"Schelling in Agents.jl"},"content":"One of the more instructive (and fun!) parts of agent based modeling is visualizing the data\n\nTo do this visualization we will use the abmplot function\n\nusing CairoMakie\n\nagent_color(a) = a.group == 1 ? :blue : :orange\nagent_marker(a) = a.group == 1 ? :circle : :rect\nfigure, _ = abmplot(model; agent_color, agent_marker, agent_size = 10)\nfigure # returning the figure displays it\n\n","type":"content","url":"/l06-02-schelling-agents#visualizing-the-agents","position":19},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Animating the Agents","lvl2":"Schelling in Agents.jl"},"type":"lvl3","url":"/l06-02-schelling-agents#animating-the-agents","position":20},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Animating the Agents","lvl2":"Schelling in Agents.jl"},"content":"We can also create a video that animates our agents moving throughout the system\n\nWe do this using the abmvideo function as follows\n\nmodel = init_schelling();\nabmvideo(\n    \"schelling.mp4\", model;\n    agent_color, agent_marker, agent_size = 10,\n    framerate = 4, frames = 20,\n    title = \"Schelling's segregation model\"\n)\n\n","type":"content","url":"/l06-02-schelling-agents#animating-the-agents","position":21},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Interactive Application","lvl2":"Schelling in Agents.jl"},"type":"lvl3","url":"/l06-02-schelling-agents#interactive-application","position":22},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Interactive Application","lvl2":"Schelling in Agents.jl"},"content":"Agents.jl also makes it very easy to create an interactive application for our model!\n\nWe can do this using the abmexploration function\n\nThis expects a single positional argument:\n\nmodel\n\nWe also have some keyword arguments\n\nparams: Dict mapping model parameters to range of values to test\n\nagent_color, agent_marker, agent_size: control marker color color, symbol, and size as before\n\nadata: Array of (agent_property, summary_func) tuples that specify which data to plot in separate charts\n\nalabels: What label to put on the plots for adata\n\nmodel = init_schelling()\nadata = [(:is_happy, sum)]\nalabels = [\"n_happy\"]\nparameter_range = Dict(:wanted_neighbors => 0:8)\nfigure, abmobs = abmexploration(\n    model;\n    adata, alabels,\n    agent_color, agent_marker, agent_size = 10,\n    params=parameter_range,\n)\nfigure\n\n","type":"content","url":"/l06-02-schelling-agents#interactive-application","position":23},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl2":"Running Julia Code in the REPL"},"type":"lvl2","url":"/l06-02-schelling-agents#running-julia-code-in-the-repl","position":24},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl2":"Running Julia Code in the REPL"},"content":"In order to use the interactive app we need to run the code from the Julia REPL (not inside VS Code or Jupyter)\n\nThe REPL (Read-Eval-Print-Loop) is the default way to run Julia interactively\n\nLet’s learn about the REPL before we run our interactive visualization","type":"content","url":"/l06-02-schelling-agents#running-julia-code-in-the-repl","position":25},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"The Julia REPL","lvl2":"Running Julia Code in the REPL"},"type":"lvl3","url":"/l06-02-schelling-agents#the-julia-repl","position":26},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"The Julia REPL","lvl2":"Running Julia Code in the REPL"},"content":"The REPL is typically started either by typing julia in a terminal or by clicking on the Julia icon in your Applications list\n\nOnce started, you will see a prompt julia> where you can enter Julia code\n\nIf you enter code and press Enter, the REPL will evaluate the code and print the result","type":"content","url":"/l06-02-schelling-agents#the-julia-repl","position":27},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"REPL Modes","lvl2":"Running Julia Code in the REPL"},"type":"lvl3","url":"/l06-02-schelling-agents#repl-modes","position":28},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"REPL Modes","lvl2":"Running Julia Code in the REPL"},"content":"The REPL has several modes you can switch between:\n\nDefault mode julia>: Run Julia code and see output (default)\n\nShell mode shell>: Interact with underlying shell/terminal (activate with ;)\n\nHelp mode help?>: Get help on Julia functions (activate with ?)\n\nPackage mode pkg>: Manage Julia packages (activate with ])\n\nTo return to default mode from any other mode, press backspace at an empty prompt\n\nExamples of what each mode prompt looks like:\n\nDefault: julia>\n\nShell: shell>\n\nHelp: help?>\n\nPackage: (@v1.9) pkg>","type":"content","url":"/l06-02-schelling-agents#repl-modes","position":29},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Running our Interactive Schelling Model","lvl2":"Running Julia Code in the REPL"},"type":"lvl3","url":"/l06-02-schelling-agents#running-our-interactive-schelling-model","position":30},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Running our Interactive Schelling Model","lvl2":"Running Julia Code in the REPL"},"content":"Now let’s run our interactive model from the REPL:\n\nOpen a terminal and type julia to start the REPL\n\nNavigate to this notebook’s directory if needed (using ; for shell mode)\n\nCopy and run the code from the cells above to set up the model\n\nRun the interactive visualization code\n\nYou’ll be able to adjust parameters with sliders and see the model update in real-time!\n\n","type":"content","url":"/l06-02-schelling-agents#running-our-interactive-schelling-model","position":31},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl2":"Real-World Implications"},"type":"lvl2","url":"/l06-02-schelling-agents#real-world-implications","position":32},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl2":"Real-World Implications"},"content":"Schelling’s model was groundbreaking for urban planning and social policy\n\nKey insight: segregation doesn’t require intense prejudice - even mild preferences for similar neighbors create strong patterns\n\nApplications beyond racial segregation:\n\nIncome clustering in neighborhoods\n\nSocial media echo chambers and political polarization\n\nClustering in high school cafeterias\n\nAcademic discipline segregation in universities\n\nModel limitations: Reality includes housing costs, school quality, employment access, historical policies\n\nPolicy implication: Simply reducing prejudice may not eliminate segregation - structural interventions may be needed\n\n","type":"content","url":"/l06-02-schelling-agents#real-world-implications","position":33},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl2":"Exercises"},"type":"lvl2","url":"/l06-02-schelling-agents#exercises","position":34},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl2":"Exercises"},"content":"","type":"content","url":"/l06-02-schelling-agents#exercises","position":35},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Exercise 1: Parameter Sensitivity Analysis","lvl2":"Exercises"},"type":"lvl3","url":"/l06-02-schelling-agents#exercise-1-parameter-sensitivity-analysis","position":36},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Exercise 1: Parameter Sensitivity Analysis","lvl2":"Exercises"},"content":"Using the interactive app or by modifying the code, explore how different wanted_neighbors values affect segregation:\n\nRun the model with wanted_neighbors = 1 (agents want just 1 similar neighbor)\n\nObserve the final pattern. Is there segregation?\n\nRun with wanted_neighbors = 3 (moderate preference)\n\nHow does the pattern differ? How many steps to stability?\n\nRun with wanted_neighbors = 6 (strong preference)\n\nWhat happens? Do all agents become happy?\n\nDocument your findings:\n\nAt what threshold does segregation become noticeable?\n\nWhat happens when the threshold is too high?\n\nHow does empty space (less than 500 agents total) affect the patterns?\n\n","type":"content","url":"/l06-02-schelling-agents#exercise-1-parameter-sensitivity-analysis","position":37},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Exercise 2: Model Extensions","lvl2":"Exercises"},"type":"lvl3","url":"/l06-02-schelling-agents#exercise-2-model-extensions","position":38},{"hierarchy":{"lvl1":"Schelling Model with Agents.jl","lvl3":"Exercise 2: Model Extensions","lvl2":"Exercises"},"content":"Modify the Schelling model to explore these variations:\n\nThree groups instead of two:\n\nAdd a third group (e.g., green agents)\n\nWhat patterns emerge with three groups?\n\nHint: Modify the init_schelling function to have for group in 1:3\n\nAsymmetric populations:\n\nTry 400 agents of group 1 and 100 agents of group 2\n\nDoes the minority group cluster more tightly?\n\nWhat happens to the majority group’s distribution?\n\nDifferent happiness thresholds per group:\n\nModify so group 1 wants 3 similar neighbors, group 2 wants 5\n\nWhich group ends up more segregated?\n\nWhat does this suggest about tolerance and outcomes?\n\nDistance-based happiness (Advanced):\n\nInstead of just counting similar neighbors, weight them by distance\n\nImmediate neighbors count as 1.0, diagonal neighbors as 0.7\n\nHow does this change the segregation patterns?\n\nChoose at least one modification to implement and document your observations.","type":"content","url":"/l06-02-schelling-agents#exercise-2-model-extensions","position":39},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice"},"type":"lvl1","url":"/l07-01-abm-money","position":0},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice"},"content":"Computational Analysis of Social Complexity\n\nPrerequisites\n\nABM\n\nShelling segregation model\n\nOutcomes\n\nRecall key components of ABM\n\nReview additional example of ABM in Julia\n\nReferences\n\nhttps://​proceedings​.scipy​.org​/articles​/Majora​-7b98e3ed​-009​.pdf\n\nhttps://​juliadynamics​.github​.io​/Agents​.jl​/stable/\n\nhttps://​juliadynamics​.github​.io​/AgentsExampleZoo​.jl​/dev​/examples​/wealth​_distribution/\n\n","type":"content","url":"/l07-01-abm-money","position":1},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl2":"Agent Based Models"},"type":"lvl2","url":"/l07-01-abm-money#agent-based-models","position":2},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl2":"Agent Based Models"},"content":"Agent based models are...\n\nAn approximation to some complex system (a model)\n\nUsed in various fields including biology, epidemiology, economics, etc.\n\nComposed of three key elements: (1) Agents (2) Environment (3) Rules\n\n","type":"content","url":"/l07-01-abm-money#agent-based-models","position":3},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl2":"Schelling Segregation Model"},"type":"lvl2","url":"/l07-01-abm-money#schelling-segregation-model","position":4},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl2":"Schelling Segregation Model"},"content":"Recall the Schelling segregation model...\n\nAgents: individuals/families seeking a home in a neighborhood. Have a type and hapiness. Agents are happy if least N of their neighbors are same type\n\nEnvironment: grid of “lots” or homes where agents can live\n\nRules: All unhappy agents move to a new random home in the environment\n\n","type":"content","url":"/l07-01-abm-money#schelling-segregation-model","position":5},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl3":"Schelling Takeaways","lvl2":"Schelling Segregation Model"},"type":"lvl3","url":"/l07-01-abm-money#schelling-takeaways","position":6},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl3":"Schelling Takeaways","lvl2":"Schelling Segregation Model"},"content":"Very simplistic view of agents (people) and decision making criterion (rules)\n\nAgents only considered immediate neighbors when deciding to move (locality)\n\nSimplistic, local behavior led to stark aggregate results: segregation of neighborhoods into agent types\n\nAgents.jl implementation very straightforward: struct to represent agent, struct (Agents.jl defined) to represent environment, function to represent rules for single agent\n\n","type":"content","url":"/l07-01-abm-money#schelling-takeaways","position":7},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl2":"Plan today"},"type":"lvl2","url":"/l07-01-abm-money#plan-today","position":8},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl2":"Plan today"},"content":"See example of second model\n\nBreak into groups and study example models from the \n\nAgents.jl model zoo\n\nPresent model your group studied\n\n","type":"content","url":"/l07-01-abm-money#plan-today","position":9},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl2":"Money Model"},"type":"lvl2","url":"/l07-01-abm-money#money-model","position":10},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl2":"Money Model"},"content":"Agents:\n\nN Agents\n\nAll start with 1.0 wealth\n\nEnvironment: none -- they just exist ;)\n\nRules:\n\nIf agent has at least 1.0 wealth, gives 1.0 wealth to another agent\n\nIf agent has 0 wealth, does nothing\n\n","type":"content","url":"/l07-01-abm-money#money-model","position":11},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl3":"Agents","lvl2":"Money Model"},"type":"lvl3","url":"/l07-01-abm-money#agents","position":12},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl3":"Agents","lvl2":"Money Model"},"content":"\n\n# import Pkg\n# Pkg.activate(\".\")\n# Pkg.instantiate()\n\nusing Agents, Random, DataFrames\n\n@agent struct MoneyAgent(NoSpaceAgent)\n    wealth::Int\nend\n\n","type":"content","url":"/l07-01-abm-money#agents","position":13},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl3":"Rules","lvl2":"Money Model"},"type":"lvl3","url":"/l07-01-abm-money#rules","position":14},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl3":"Rules","lvl2":"Money Model"},"content":"\n\nfunction agent_step!(agent, model)\n    if agent.wealth == 0\n        return\n    end\n    recipient = random_agent(model)\n    agent.wealth -= 1\n    recipient.wealth += 1\nend\n\n","type":"content","url":"/l07-01-abm-money#rules","position":15},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl3":"Model","lvl2":"Money Model"},"type":"lvl3","url":"/l07-01-abm-money#model","position":16},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl3":"Model","lvl2":"Money Model"},"content":"\n\nfunction money_model(; N = 100)\n    m = ABM(MoneyAgent; agent_step!)\n    for _ in 1:N\n        add_agent!(m, 1)\n    end\n    return m\nend\n\nmoney_model()\n\n","type":"content","url":"/l07-01-abm-money#model","position":17},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl3":"Simulation","lvl2":"Money Model"},"type":"lvl3","url":"/l07-01-abm-money#simulation","position":18},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl3":"Simulation","lvl2":"Money Model"},"content":"\n\nm = money_model(N=2000)\nadata = [:wealth]\ndf, _ = run!(m, 10; adata)\n\nusing CairoMakie\n\nhist(\n    filter(x -> x.time == 10, df).wealth;\n    bins = collect(0:9),\n    color = cgrad(:viridis)[28:28:256],\n)\n\nWhat do we see? With 2000 agents starting with equal wealth (1 unit each), after just 10 steps most agents have 0 or 1 units of wealth while very few have accumulated 5+ units\n\nThis concentration of wealth in the hands of a few emerges naturally from random exchanges!\n\nAbove we see the famous “power law” pattern\n\nThis is a common result in many areas of economics: that activity or wealth is concentrated in the very few (the 1%)\n\nReferences: \n\nGabaix (2016), \n\nhttps://​www​.sciencedirect​.com​/science​/article​/abs​/pii​/S0378437197002173, \n\nhttps://​www​.theguardian​.com​/commentisfree​/2011​/nov​/11​/occupy​-movement​-wealth​-power​-law​-distribution\n\n","type":"content","url":"/l07-01-abm-money#simulation","position":19},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl3":"Exercise: Effect of Population Size","lvl2":"Money Model"},"type":"lvl3","url":"/l07-01-abm-money#exercise-effect-of-population-size","position":20},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl3":"Exercise: Effect of Population Size","lvl2":"Money Model"},"content":"Try running the simulation with different population sizes to see how the wealth distribution changes:\n\nRun with N=100, N=500, and N=5000\n\nCompare the histograms - does the power law pattern persist?\n\nHow many steps does it take for the pattern to emerge with different N?\n\n","type":"content","url":"/l07-01-abm-money#exercise-effect-of-population-size","position":21},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl2":"Money Model with space"},"type":"lvl2","url":"/l07-01-abm-money#money-model-with-space","position":22},{"hierarchy":{"lvl1":"Agent Based Models Review/Practice","lvl2":"Money Model with space"},"content":"Let’s expand our environment to a 2d-grid and only allow sharing wealth amongst neighbors\n\nChanges relative to previous setup:\n\nAgents now have a position\n\nEnvironment is 2d GridSpace\n\nAgents randomly pick a neighbor to give money to\n\n@agent struct WealthInSpace(GridAgent{2})\n    wealth::Int\nend\n\nfunction agent_step!(agent::WealthInSpace, model)\n    if agent.wealth == 0\n        return\n    end\n\n    recipient = rand(collect(nearby_agents(agent, model)))\n    agent.wealth -= 1\n    recipient.wealth += 1\nend\n\nfunction money_model_2d(; dims = (25, 25))\n    # periodic = true means agents at edges can interact with agents on opposite edge\n    # This creates a torus topology - think of it like Pac-Man where going off one side\n    # brings you to the other side\n    space = GridSpace(dims, periodic = true)\n    model = ABM(WealthInSpace, space; scheduler = Schedulers.Randomly(), agent_step! = agent_step!)\n\n    fill_space!(model, 1)\n    return model\nend\n\nm2d = money_model_2d()\nadata2d = [:wealth, :pos]\ndf2d, _ = run!(m2d, 10; adata=adata2d)\n\nhist(\n    filter(x -> x.time == 10, df2d).wealth;\n    bins = collect(0:9),\n    color = cgrad(:viridis)[28:28:256],\n)\n\nStill a power law... very pervasive!\n\nfunction make_heatmap(model, df, T=maximum(df.step))\n    df_T = filter(x -> x.time == T, df)\n\n    x = combine(groupby(df_T, :pos), :wealth => sum)\n    arr = zeros(Int, size(getfield(model, :space)))\n\n    for r in eachrow(x)\n        arr[r.pos...] += r.wealth_sum\n    end\n\n    figure = Figure(; size = (600, 450))\n    hmap_l = figure[1, 1] = Axis(figure, title=\"T= $T\")\n    hmap = heatmap!(hmap_l, arr; colormap = cgrad(:default))\n    cbar = figure[1, 2] = Colorbar(figure, hmap; width = 30)\n    return figure\nend\n\nfor t in 0:10\n    display(make_heatmap(m2d, df2d, t))\nend","type":"content","url":"/l07-01-abm-money#money-model-with-space","position":23},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model"},"type":"lvl1","url":"/l07-02-abm-paper-virality","position":0},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model"},"content":"Computational Analysis of Social Complexity\n\nPrerequisites\n\nABM concepts\n\nBasic network analysis\n\nData manipulation with DataFrames\n\nOutcomes\n\nBuild an ABM using real-world data\n\nModel citation dynamics in academic networks\n\nAnalyze emergence of “viral” papers and sleeping beauties\n\nReferences\n\nArXiv Dataset: \n\nhttps://​www​.kaggle​.com​/datasets​/Cornell​-University​/arxiv\n\nCitation Network Tools: \n\nhttps://​github​.com​/mattbierbaum​/arxiv​-public​-datasets\n\n","type":"content","url":"/l07-02-abm-paper-virality","position":1},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Overview"},"type":"lvl2","url":"/l07-02-abm-paper-virality#overview","position":2},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Overview"},"content":"Academic papers spread through citation networks\n\nSome papers go “viral” quickly, others are “sleeping beauties” that gain citations years later\n\nWe’ll model how papers gain citations based on:\n\nAuthor prestige\n\nTopic trends\n\nNetwork position\n\nQuality/novelty\n\n","type":"content","url":"/l07-02-abm-paper-virality#overview","position":3},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Part 1: Data Collection & Exploration"},"type":"lvl2","url":"/l07-02-abm-paper-virality#part-1-data-collection-exploration","position":4},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Part 1: Data Collection & Exploration"},"content":"\n\n","type":"content","url":"/l07-02-abm-paper-virality#part-1-data-collection-exploration","position":5},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Setup and Dependencies","lvl2":"Part 1: Data Collection & Exploration"},"type":"lvl3","url":"/l07-02-abm-paper-virality#setup-and-dependencies","position":6},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Setup and Dependencies","lvl2":"Part 1: Data Collection & Exploration"},"content":"\n\nusing Pkg\nPkg.add([\"JSON3\", \"Downloads\", \"CSV\", \"DataFrames\", \"Graphs\", \"Agents\", \"Random\", \"Statistics\", \"CairoMakie\", \"ProgressMeter\", \"StatsBase\"])\n\nusing JSON3\nusing Downloads\nusing CSV\nusing DataFrames\nusing Graphs\nusing Agents\nusing Random\nusing Statistics\nusing CairoMakie\nusing Dates\nusing StatsBase\n\n","type":"content","url":"/l07-02-abm-paper-virality#setup-and-dependencies","position":7},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Download Sample ArXiv Data","lvl2":"Part 1: Data Collection & Exploration"},"type":"lvl3","url":"/l07-02-abm-paper-virality#download-sample-arxiv-data","position":8},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Download Sample ArXiv Data","lvl2":"Part 1: Data Collection & Exploration"},"content":"For this example, we’ll work with a subset of ArXiv papers. In practice, you would download the full dataset from Kaggle.\n\n# For demonstration, we'll create synthetic data that mimics ArXiv structure\n# In practice, download from: https://www.kaggle.com/datasets/Cornell-University/arxiv\n\nfunction create_sample_arxiv_data(n_papers=1000, n_authors=300)\n    Random.seed!(42)\n\n    # Create authors with varying prestige\n    authors = DataFrame(\n        author_id = 1:n_authors,\n        name = [\"Author_$i\" for i in 1:n_authors],\n        h_index = rand(1:50, n_authors),\n        institution_rank = rand(1:100, n_authors)\n    )\n\n    # Create papers\n    papers = DataFrame()\n    papers.paper_id = 1:n_papers\n    papers.title = [\"Paper_$i\" for i in 1:n_papers]\n    papers.year = rand(2010:2023, n_papers)\n    papers.month = rand(1:12, n_papers)\n    papers.category = rand([\"cs.AI\", \"cs.LG\", \"stat.ML\", \"physics\", \"math\"], n_papers)\n    papers.abstract_length = rand(100:500, n_papers)\n    papers.n_authors = rand(1:5, n_papers)\n    papers.lead_author_id = rand(1:n_authors, n_papers)\n    papers.quality_score = rand(n_papers)  # Hidden variable representing paper quality\n\n    # Create citation network (papers cite older papers)\n    citations = DataFrame(citing_paper=Int[], cited_paper=Int[], citation_year=Int[])\n\n    for i in 1:n_papers\n        paper_year = papers.year[i]\n        # Papers can only cite older papers\n        older_papers = findall(papers.year .< paper_year)\n        if length(older_papers) > 0\n            n_citations = min(rand(0:20), length(older_papers))\n            if n_citations > 0\n                cited = sample(older_papers, n_citations, replace=false)\n                for c in cited\n                    push!(citations, (i, c, paper_year + rand(0:2)))\n                end\n            end\n        end\n    end\n\n    return papers, authors, citations\nend\n\npapers_df, authors_df, citations_df = create_sample_arxiv_data()\nprintln(\"Generated $(nrow(papers_df)) papers, $(nrow(authors_df)) authors, $(nrow(citations_df)) citations\")\n\n","type":"content","url":"/l07-02-abm-paper-virality#download-sample-arxiv-data","position":9},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Explore the Data","lvl2":"Part 1: Data Collection & Exploration"},"type":"lvl3","url":"/l07-02-abm-paper-virality#explore-the-data","position":10},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Explore the Data","lvl2":"Part 1: Data Collection & Exploration"},"content":"\n\n# Show sample of papers\nfirst(papers_df, 5)\n\n# Citation statistics\ncitation_counts = combine(groupby(citations_df, :cited_paper), nrow => :n_citations)\ndescribe(citation_counts.n_citations)\n\n# Visualize citation distribution (classic power law)\nfig = Figure()\nax = Axis(fig[1, 1], xlabel=\"Number of Citations\", ylabel=\"Count\", title=\"Citation Distribution\")\nhist!(ax, citation_counts.n_citations, bins=20)\nfig\n\n","type":"content","url":"/l07-02-abm-paper-virality#explore-the-data","position":11},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Analyze Network Structure","lvl2":"Part 1: Data Collection & Exploration"},"type":"lvl3","url":"/l07-02-abm-paper-virality#analyze-network-structure","position":12},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Analyze Network Structure","lvl2":"Part 1: Data Collection & Exploration"},"content":"\n\n# Build citation graph\nfunction build_citation_graph(papers_df, citations_df)\n    n_papers = nrow(papers_df)\n    g = SimpleDiGraph(n_papers)\n\n    for row in eachrow(citations_df)\n        add_edge!(g, row.citing_paper, row.cited_paper)\n    end\n\n    return g\nend\n\ncitation_graph = build_citation_graph(papers_df, citations_df)\nprintln(\"Graph has $(nv(citation_graph)) nodes and $(ne(citation_graph)) edges\")\nprintln(\"Average degree: $(round(mean(degree(citation_graph)), digits=2))\")\n\n","type":"content","url":"/l07-02-abm-paper-virality#analyze-network-structure","position":13},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Part 2: Agent-Based Model Design"},"type":"lvl2","url":"/l07-02-abm-paper-virality#part-2-agent-based-model-design","position":14},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Part 2: Agent-Based Model Design"},"content":"","type":"content","url":"/l07-02-abm-paper-virality#part-2-agent-based-model-design","position":15},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Model Components","lvl2":"Part 2: Agent-Based Model Design"},"type":"lvl3","url":"/l07-02-abm-paper-virality#model-components","position":16},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Model Components","lvl2":"Part 2: Agent-Based Model Design"},"content":"Agents: Research papers\n\nProperties: quality, author prestige, field, age, citation count\n\nBehavior: Papers get “read” by researchers who may cite them\n\nEnvironment: Academic field with trending topics\n\nTopic hotness varies over time\n\nConferences/journals provide visibility boosts\n\nRules:\n\nEach time step, new papers are “published”\n\nResearchers “read” papers based on:\n\nRecent publications (recency bias)\n\nHigh citation count (preferential attachment)\n\nAuthor prestige\n\nTopic match with current trends\n\nRead papers get cited with probability based on quality\n\n","type":"content","url":"/l07-02-abm-paper-virality#model-components","position":17},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Define Agent Structure","lvl2":"Part 2: Agent-Based Model Design"},"type":"lvl3","url":"/l07-02-abm-paper-virality#define-agent-structure","position":18},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Define Agent Structure","lvl2":"Part 2: Agent-Based Model Design"},"content":"\n\n@agent struct Paper(NoSpaceAgent)\n    # Fixed properties\n    quality::Float64\n    author_prestige::Float64\n    field::String\n    publication_time::Int\n\n    # Dynamic properties\n    citations::Int\n    reads::Int  # Times the paper has been read\n    age::Int\nend\n\n","type":"content","url":"/l07-02-abm-paper-virality#define-agent-structure","position":19},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Define Model Properties","lvl2":"Part 2: Agent-Based Model Design"},"type":"lvl3","url":"/l07-02-abm-paper-virality#define-model-properties","position":20},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Define Model Properties","lvl2":"Part 2: Agent-Based Model Design"},"content":"\n\nmutable struct ModelProperties\n    current_time::Int\n    field_trends::Dict{String, Float64}  # How \"hot\" each field is\n    n_researchers::Int  # Number of researchers reading papers each time step\n    papers_per_researcher::Int  # Papers read per researcher per time step\n    citation_prob_base::Float64  # Base probability of citing a read paper\n    new_papers_per_step::Int  # New papers published each time step\nend\n\n","type":"content","url":"/l07-02-abm-paper-virality#define-model-properties","position":21},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Model Rules","lvl2":"Part 2: Agent-Based Model Design"},"type":"lvl3","url":"/l07-02-abm-paper-virality#model-rules","position":22},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Model Rules","lvl2":"Part 2: Agent-Based Model Design"},"content":"\n\nfunction model_step!(model)\n    props = model.properties\n    props.current_time += 1\n\n    # Update field trends (random walk)\n    for field in keys(props.field_trends)\n        props.field_trends[field] = clamp(props.field_trends[field] + randn() * 0.1, 0.1, 2.0)\n    end\n\n    # Age all papers\n    for paper in allagents(model)\n        paper.age += 1\n    end\n\n    # Researchers read and cite papers\n    all_papers = collect(allagents(model))\n    if length(all_papers) > 0\n        for _ in 1:props.n_researchers\n            # Select papers to read (biased selection)\n            papers_to_read = select_papers_to_read(all_papers, props.papers_per_researcher, props)\n\n            for paper in papers_to_read\n                paper.reads += 1\n\n                # Decide whether to cite (based on quality and other factors)\n                cite_prob = calculate_citation_probability(paper, props)\n                if rand() < cite_prob\n                    paper.citations += 1\n                end\n            end\n        end\n    end\n\n    # Publish new papers\n    for _ in 1:props.new_papers_per_step\n        field = sample(collect(keys(props.field_trends)))\n        add_agent!(\n            model,\n            rand(),  # quality\n            rand(),  # author_prestige\n            field,\n            props.current_time,\n            0,  # citations\n            0,  # reads\n            0   # age\n        )\n    end\nend\n\nfunction select_papers_to_read(papers, n, props)\n    if length(papers) <= n\n        return papers\n    end\n\n    # Calculate selection weights\n    weights = Float64[]\n    for paper in papers\n        # Recency bias\n        recency_weight = exp(-paper.age / 365.0)  # Decay over a year\n\n        # Preferential attachment (rich get richer)\n        citation_weight = log(2 + paper.citations)\n\n        # Field trendiness\n        trend_weight = get(props.field_trends, paper.field, 1.0)\n\n        # Author prestige\n        prestige_weight = paper.author_prestige\n\n        push!(weights, recency_weight * citation_weight * trend_weight * prestige_weight)\n    end\n\n    # Weighted sampling without replacement\n    selected_indices = sample(1:length(papers), Weights(weights), n, replace=false)\n    return papers[selected_indices]\nend\n\nfunction calculate_citation_probability(paper, props)\n    # Base probability modified by paper quality and field trend\n    base_prob = props.citation_prob_base\n    quality_modifier = paper.quality\n    trend_modifier = get(props.field_trends, paper.field, 1.0)\n\n    return clamp(base_prob * quality_modifier * trend_modifier, 0.0, 1.0)\nend\n\n","type":"content","url":"/l07-02-abm-paper-virality#model-rules","position":23},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Initialize Model with Real Data","lvl2":"Part 2: Agent-Based Model Design"},"type":"lvl3","url":"/l07-02-abm-paper-virality#initialize-model-with-real-data","position":24},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Initialize Model with Real Data","lvl2":"Part 2: Agent-Based Model Design"},"content":"\n\nfunction initialize_model_from_data(papers_df, authors_df;\n                                   n_researchers=100,\n                                   papers_per_researcher=5)\n    # Create model properties\n    fields = unique(papers_df.category)\n    field_trends = Dict(f => 1.0 for f in fields)\n\n    props = ModelProperties(\n        0,  # current_time\n        field_trends,\n        n_researchers,\n        papers_per_researcher,\n        0.1,  # citation_prob_base\n        10   # new_papers_per_step\n    )\n\n    # Create model - properties need to be wrapped in Dict\n    model = ABM(Paper; properties=Dict(:properties => props), model_step!)\n\n    # Add initial papers from data\n    for row in eachrow(papers_df[1:min(100, nrow(papers_df)), :])  # Start with first 100 papers\n        author = authors_df[row.lead_author_id, :]\n        prestige = author.h_index / 50.0  # Normalize to [0, 1]\n\n        add_agent!(\n            model,\n            row.quality_score,\n            prestige,\n            row.category,\n            0,  # publication_time\n            0,  # citations\n            0,  # reads\n            0   # age\n        )\n    end\n\n    return model\nend\n\nmodel = initialize_model_from_data(papers_df, authors_df)\nprintln(\"Model initialized with $(nagents(model)) papers\")\n\n","type":"content","url":"/l07-02-abm-paper-virality#initialize-model-with-real-data","position":25},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Part 3: Simulation & Analysis"},"type":"lvl2","url":"/l07-02-abm-paper-virality#part-3-simulation-analysis","position":26},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Part 3: Simulation & Analysis"},"content":"\n\n","type":"content","url":"/l07-02-abm-paper-virality#part-3-simulation-analysis","position":27},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Run Simulation","lvl2":"Part 3: Simulation & Analysis"},"type":"lvl3","url":"/l07-02-abm-paper-virality#run-simulation","position":28},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Run Simulation","lvl2":"Part 3: Simulation & Analysis"},"content":"\n\n# Data to collect\nadata = [:citations, :reads, :age, :quality, :field]\n\n# Run simulation\nn_steps = 365  # Simulate one year\nadf, _ = run!(model, n_steps; adata)\n\nprintln(\"Simulation complete. Final model has $(nagents(model)) papers\")\n\n","type":"content","url":"/l07-02-abm-paper-virality#run-simulation","position":29},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Analyze Citation Dynamics","lvl2":"Part 3: Simulation & Analysis"},"type":"lvl3","url":"/l07-02-abm-paper-virality#analyze-citation-dynamics","position":30},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Analyze Citation Dynamics","lvl2":"Part 3: Simulation & Analysis"},"content":"\n\n# Get final state\nfinal_data = filter(row -> row.time == n_steps, adf)\n\n# Citation distribution\nfig = Figure(resolution=(800, 300))\n\n# Histogram of citations\nax1 = Axis(fig[1, 1], xlabel=\"Citations\", ylabel=\"Count\", title=\"Final Citation Distribution\")\nhist!(ax1, final_data.citations, bins=20)\n\n# Quality vs Citations scatter\nax2 = Axis(fig[1, 2], xlabel=\"Quality\", ylabel=\"Citations\", title=\"Quality vs Citations\")\nscatter!(ax2, final_data.quality, final_data.citations, markersize=5, alpha=0.5)\n\nfig\n\n# Track citation growth over time\nfunction analyze_citation_patterns(adf)\n    # Group by paper ID first, then process each group\n    velocities = Dict{Int, Vector{Float64}}()\n\n    # Use groupby to efficiently iterate through papers\n    for group in groupby(adf, :id)\n        paper_id = first(group.id)\n\n        # Sort by time and get citations\n        sorted_times = sort(group, :time)\n        citations_over_time = sorted_times.citations\n\n        if length(citations_over_time) > 1\n            velocity = diff(citations_over_time)\n            velocities[paper_id] = velocity\n        end\n    end\n\n    return velocities\nend\n\nvelocities = analyze_citation_patterns(adf)\n\n# Find viral papers (high early velocity)\nviral_papers = []\nsleeping_beauties = []\n\nfor (paper_id, vel) in velocities\n    if length(vel) >= 10\n        early_velocity = mean(vel[1:min(10, length(vel))])\n        late_velocity = mean(vel[max(1, end-10):end])\n\n        if early_velocity > 0.5  # Threshold for \"viral\"\n            push!(viral_papers, paper_id)\n        elseif early_velocity < 0.1 && late_velocity > 0.3  # Sleeping beauty pattern\n            push!(sleeping_beauties, paper_id)\n        end\n    end\nend\n\nprintln(\"Found $(length(viral_papers)) viral papers\")\nprintln(\"Found $(length(sleeping_beauties)) sleeping beauties\")\n\n","type":"content","url":"/l07-02-abm-paper-virality#analyze-citation-dynamics","position":31},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Visualize Citation Trajectories","lvl2":"Part 3: Simulation & Analysis"},"type":"lvl3","url":"/l07-02-abm-paper-virality#visualize-citation-trajectories","position":32},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl3":"Visualize Citation Trajectories","lvl2":"Part 3: Simulation & Analysis"},"content":"\n\n# Plot citation trajectories for different paper types\nfig = Figure(resolution=(800, 400))\nax = Axis(fig[1, 1], xlabel=\"Time\", ylabel=\"Cumulative Citations\",\n          title=\"Citation Trajectories\")\n\n# Plot a sample of papers\nsample_papers = vcat(\n    length(viral_papers) > 0 ? viral_papers[1:min(3, length(viral_papers))] : [],\n    length(sleeping_beauties) > 0 ? sleeping_beauties[1:min(3, length(sleeping_beauties))] : [],\n    rand(setdiff(unique(adf.id), vcat(viral_papers, sleeping_beauties)), min(3, nagents(model)))\n)\n\ncolors = [:red, :red, :red, :blue, :blue, :blue, :gray, :gray, :gray]\nlabels = [\"Viral\", \"\", \"\", \"Sleeping Beauty\", \"\", \"\", \"Normal\", \"\", \"\"]\n\nfor (i, paper_id) in enumerate(sample_papers)\n    paper_data = filter(row -> row.id == paper_id, adf)\n    sort!(paper_data, :time)\n\n    if nrow(paper_data) > 0\n        lines!(ax, paper_data.time, paper_data.citations,\n               color=colors[min(i, length(colors))],\n               label=labels[min(i, length(labels))],\n               linewidth=2)\n    end\nend\n\naxislegend(ax, unique=true, position=:lt)\nfig\n\n","type":"content","url":"/l07-02-abm-paper-virality#visualize-citation-trajectories","position":33},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Part 4: Parameter Calibration from Real Data"},"type":"lvl2","url":"/l07-02-abm-paper-virality#part-4-parameter-calibration-from-real-data","position":34},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Part 4: Parameter Calibration from Real Data"},"content":"\n\n# Calibrate model parameters from real citation data\nfunction calibrate_model(citations_df, papers_df)\n    # Calculate empirical citation rate\n    citation_counts = combine(groupby(citations_df, :cited_paper), nrow => :n_citations)\n    mean_citations = mean(citation_counts.n_citations)\n\n    # Calculate field popularity from data\n    field_papers = combine(groupby(papers_df, :category), nrow => :count)\n    total_papers = sum(field_papers.count)\n    field_popularity = Dict(row.category => row.count / total_papers\n                          for row in eachrow(field_papers))\n\n    # Calculate author prestige distribution\n    author_prestiges = Float64[]\n    for paper in eachrow(papers_df)\n        if paper.lead_author_id <= nrow(authors_df)\n            push!(author_prestiges, authors_df[paper.lead_author_id, :h_index] / 50.0)\n        end\n    end\n    mean_prestige = mean(author_prestiges)\n\n    println(\"Calibration Results:\")\n    println(\"  Mean citations per paper: $(round(mean_citations, digits=2))\")\n    println(\"  Mean author prestige: $(round(mean_prestige, digits=3))\")\n    println(\"  Field distribution:\")\n    for (field, pop) in field_popularity\n        println(\"    $field: $(round(pop * 100, digits=1))%\")\n    end\n\n    return Dict(\n        \"mean_citations\" => mean_citations,\n        \"field_trends\" => field_popularity,\n        \"mean_prestige\" => mean_prestige\n    )\nend\n\ncalibration = calibrate_model(citations_df, papers_df)\n\n","type":"content","url":"/l07-02-abm-paper-virality#part-4-parameter-calibration-from-real-data","position":35},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Exercises"},"type":"lvl2","url":"/l07-02-abm-paper-virality#exercises","position":36},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Exercises"},"content":"Network Effects: Modify the model to include co-authorship networks. Papers by frequently collaborating authors should have higher visibility.\n\nConference Boost: Add “conference” events where papers in certain fields get temporary visibility boosts.\n\nReal Data: Download the full ArXiv dataset from Kaggle and run the model with real papers. Compare simulated citation patterns to actual ones.\n\nIntervention Analysis: What happens if we:\n\nIncrease open access (higher base read probability)?\n\nAdd social media promotion (viral boost for some papers)?\n\nImplement better recommendation systems (quality-based selection)?\n\n","type":"content","url":"/l07-02-abm-paper-virality#exercises","position":37},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Summary"},"type":"lvl2","url":"/l07-02-abm-paper-virality#summary","position":38},{"hierarchy":{"lvl1":"Academic Paper Virality: An Agent-Based Model","lvl2":"Summary"},"content":"Built an ABM of academic paper citations using real data structure\n\nObserved emergence of power law citation distributions\n\nIdentified viral papers and sleeping beauties\n\nModel can help understand:\n\nHow quality vs. marketing affects impact\n\nRole of author prestige and networks\n\nEffects of field trends on citation patterns","type":"content","url":"/l07-02-abm-paper-virality#summary","position":39},{"hierarchy":{"lvl1":"Game Theory 1"},"type":"lvl1","url":"/l08-01-game-theory-intro","position":0},{"hierarchy":{"lvl1":"Game Theory 1"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nJulia basics\n\nOutcomes\n\nUnderstand the basic structure of a Game\n\nBe able to identify any Nash Equilibria in pure strategies for a normal form game\n\nUnderstand how normal form and extensive form games are related\n\nReferences\n\nEasley and Kleinberg chapter 6\n\n","type":"content","url":"/l08-01-game-theory-intro","position":1},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"Introduction"},"type":"lvl2","url":"/l08-01-game-theory-intro#introduction","position":2},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"Introduction"},"content":"Computational social science analyzes the connectedness of natural, social, and technological systems\n\nGraph theory (networks) has helped us understand how the structure of relationships influence outcomes\n\nWe now turn to how behaviors, incentives, and strategies influence choices (and thus outcomes)\n\nThe study of how entities make strategic choices in settings where outcomes depend on individual choices and the choices of others is called game theory\n\nGame theory is a very rich topic at the intersection of mathematics and economics\n\nWe will study key concepts, but will not cover them in detail or exhaustively\n\n","type":"content","url":"/l08-01-game-theory-intro#introduction","position":3},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"What is a Game?"},"type":"lvl2","url":"/l08-01-game-theory-intro#what-is-a-game","position":4},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"What is a Game?"},"content":"A game is a description of a strategic environment composed of three elements:\n\nA finite set of N players\n\nFor each player i, a set of feasible actions S_i\n\nDefine \\Sigma = \\times_i S_i as action space  and \\sigma as typical element\n\nFor each player i, a payoff function p_i:\\Sigma \\rightarrow \\mathbb{R}\n\nTo help with notation we’ll focus on two player games (N=2)\n\nWe’ll also start by considering that each player has a discrete set of actions (WLOG call them 1 \\dots M_i for player i)\n\nBasic concepts and definitions can be naturally extended to cases where N>2\n\n","type":"content","url":"/l08-01-game-theory-intro#what-is-a-game","position":5},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"Example: Prisoner’s Dilemma"},"type":"lvl2","url":"/l08-01-game-theory-intro#example-prisoners-dilemma","position":6},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"Example: Prisoner’s Dilemma"},"content":"A very famous example of a game is called the prisoner’s dilemma\n\nStory: two robbery suspects brought in for questioning\n\nInvestigator immediately separates them and gives both the same deal\n\nIf you confess and your partner doesn’t, you go free and he gets 10 years. If you both confess you each get 4 years, and if neither confesses you each get 1 year.\n\nThe payoffs for this game can be summarized as follows:\n\n\nEach table entry has two items\n\nIn terms of our definition of a game we have...\n\nN = 2 players\n\nStrategys: S_i = \\{\\text{not confess}, \\text{ confess} \\} for both players\n\nPayoffs p_i as specified in the table\n\n","type":"content","url":"/l08-01-game-theory-intro#example-prisoners-dilemma","position":7},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Payoffs as matrices","lvl2":"Example: Prisoner’s Dilemma"},"type":"lvl3","url":"/l08-01-game-theory-intro#payoffs-as-matrices","position":8},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Payoffs as matrices","lvl2":"Example: Prisoner’s Dilemma"},"content":"A common representation of payoffs for a single player is a matrix called the payoff matrix P_i \\in \\mathbb{R}^{M_1 \\times M_2}\n\nThe row i, column j element gives the payoff when player i chooses the ith action in S_1 and player j chooses the jth action in S_2\n\nFor the Prisoner’s Dilemma game above, we have\n\npd_p1 = [-1 -10; 0 -4]\npd_p2 = [-1 0 ;-10 -4]\n\n","type":"content","url":"/l08-01-game-theory-intro#payoffs-as-matrices","position":9},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Best Responses","lvl2":"Example: Prisoner’s Dilemma"},"type":"lvl3","url":"/l08-01-game-theory-intro#best-responses","position":10},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Best Responses","lvl2":"Example: Prisoner’s Dilemma"},"content":"What would happen in the Prisoner’s dilemma game?\n\nYou may think that these partners in crime would like to stick together and get a total of 1 year each by not confessing\n\nHowever, that doesn’t happen\n\nThe investigator knows game theory and rigged the game against them...\n\n","type":"content","url":"/l08-01-game-theory-intro#best-responses","position":11},{"hierarchy":{"lvl1":"Game Theory 1","lvl4":"What should Suspect 1 Do?","lvl3":"Best Responses","lvl2":"Example: Prisoner’s Dilemma"},"type":"lvl4","url":"/l08-01-game-theory-intro#what-should-suspect-1-do","position":12},{"hierarchy":{"lvl1":"Game Theory 1","lvl4":"What should Suspect 1 Do?","lvl3":"Best Responses","lvl2":"Example: Prisoner’s Dilemma"},"content":"Let’s consider suspect 1\n\npd_p1\n\nSuppose suspect 1 believes suspect 2 will not confess\n\nSuspect 1 now faces the first column of pd_p1 and sees he’s better of confessing and getting 0 years instead of -1\n\nWhat if suspect 1 believes suspect 2 will confess?\n\n1 now faces second column and prefers -4 to a -10, so he still chooses to confess\n\nIn either case, suspect 1’s best response is to confess\n\nBecause confess is always a best response, we call it a dominating strategy (in this strictly dominating because it is always strictly better than not confess)\n\n","type":"content","url":"/l08-01-game-theory-intro#what-should-suspect-1-do","position":13},{"hierarchy":{"lvl1":"Game Theory 1","lvl4":"How about Suspect 2?","lvl3":"Best Responses","lvl2":"Example: Prisoner’s Dilemma"},"type":"lvl4","url":"/l08-01-game-theory-intro#how-about-suspect-2","position":14},{"hierarchy":{"lvl1":"Game Theory 1","lvl4":"How about Suspect 2?","lvl3":"Best Responses","lvl2":"Example: Prisoner’s Dilemma"},"content":"If we look closely at suspect 2’s payoffs we see his game is symmetric to suspect 1’s:\n\npd_p2\n\nNo matter what suspect 1 chooses, suspect 2’s best response is to confess\n\nThe rational outcome is that both players confess and spend 4 years together in prison\n\n","type":"content","url":"/l08-01-game-theory-intro#how-about-suspect-2","position":15},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"Nash Equilibrium"},"type":"lvl2","url":"/l08-01-game-theory-intro#nash-equilibrium","position":16},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"Nash Equilibrium"},"content":"How did this happen? How is it a rational outcome i.e. an equilibrium?\n\nA famous concept in game theory is called Nash equilibrium (after famous economist John Nash)\n\nDefinition: A strategy \\sigma is a Nash equilibrium if \\sigma_i is a best response to \\sigma_{-i} (everyone else’s actions)\n\nIntuition: A strategy is an Nash equilibrium if after taking into account every one else’s strategies, each player does not want to change their own\n\n","type":"content","url":"/l08-01-game-theory-intro#nash-equilibrium","position":17},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Computing Nash Equilibria","lvl2":"Nash Equilibrium"},"type":"lvl3","url":"/l08-01-game-theory-intro#computing-nash-equilibria","position":18},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Computing Nash Equilibria","lvl2":"Nash Equilibrium"},"content":"There are various algorithms that we can use for computing Nash equilibria\n\nFow now we will utilize the implementation of these algorithms in the GameTheory.jl package\n\nLet’s load it up and create a version of our prisoner’s dilemma game:\n\n# import Pkg; Pkg.add(\"GameTheory\")\n\nusing GameTheory\n\np1 = Player(pd_p1)\n\nGameTheory.jl requires that payoff matrices are always specified from the perspective of the current player\n\nThis means that we need to “reorient” suspect 2’s payoffs such that his actions are noted on the rows\n\nBecuase this is a symmetric game, suspect 2’s payoffs from suspect 2’s perspective looks exactly the same as suspect 1’s payoffs from suspect 1’s perspective\n\nWe can construct our NormalFormGame with two copies of the p1 player above\n\npd_g = NormalFormGame([p1, p1])\n\nWe can now ask GameTheory.jl to compute the nash Equilibria for us\n\nWe’ll use the pure_nash function to do this (we’ll talk about what “pure” means soon)\n\npd_eq = pure_nash(pd_g)\n\nAs we said before, the only equilibrium outcome to this game is that they both confess\n\nWe can see the payoffs each player gets in equilibrium by “indexing” into the game using the strategy array\n\nThe two expressions below are equivalent in this case\n\npd_g[pd_eq[1]...]\n\n# ↑ Equivalent to ↓\npd_g[2, 2]\n\n","type":"content","url":"/l08-01-game-theory-intro#computing-nash-equilibria","position":19},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"Non symmetric games"},"type":"lvl2","url":"/l08-01-game-theory-intro#non-symmetric-games","position":20},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"Non symmetric games"},"content":"Not all games are symmetric like the prisoner’s dilemma\n\nConsider the following game\n\nTwo players (firms) and two strategies each (sell low price or upscale goods)\n\n60% of total spending comes from people who prefer low prices\n\nFirm 1 more popular, so when they compete in same segment, firm 1 gets 80% of market\n\nBelow you find the payoff matrix in units of “% of total possible profit”\n\n\n","type":"content","url":"/l08-01-game-theory-intro#non-symmetric-games","position":21},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Strategies","lvl2":"Non symmetric games"},"type":"lvl3","url":"/l08-01-game-theory-intro#strategies","position":22},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Strategies","lvl2":"Non symmetric games"},"content":"Firm 1 has a dominant strategy: low-priced. They will always play this strategy\n\nFirm 2 is less clear:\n\nIf firm 1 were to choose the upscale market, they would be better off choosing low-priced\n\nhowever, when firm 1 chooses low-priced, firm 2 best response is upscale\n\nHow to find equilbirum?\n\n","type":"content","url":"/l08-01-game-theory-intro#strategies","position":23},{"hierarchy":{"lvl1":"Game Theory 1","lvl4":"Iterated Deletion of Dominated Strategies","lvl3":"Strategies","lvl2":"Non symmetric games"},"type":"lvl4","url":"/l08-01-game-theory-intro#iterated-deletion-of-dominated-strategies","position":24},{"hierarchy":{"lvl1":"Game Theory 1","lvl4":"Iterated Deletion of Dominated Strategies","lvl3":"Strategies","lvl2":"Non symmetric games"},"content":"An algorithm that can help find the solution to this game is called iterated deletion of dominated strategies\n\nThe algorithm proceeds as follows:\n\nSet iteration n = 0\n\nLet S_i^n be set of remaining actions for player i on iteration n. Start S_i^0 = S_i\n\nOn iteration n, for each player i remove from S_i^n any strategies that are dominated by other strategies in S_i^n (taking into account S_{-i}^n). Call surviving strategies S_i^{n+1}\n\nRepeat for all players i\n\nRepeat until one of two conditions is met:\n\nEach player has only one remaining strategy: |S_i^{n+1}| = 1 \\forall i -- this is NE\n\nOne or more players has an empty strategy set\n\n","type":"content","url":"/l08-01-game-theory-intro#iterated-deletion-of-dominated-strategies","position":25},{"hierarchy":{"lvl1":"Game Theory 1","lvl4":"Application to Marketing Game","lvl3":"Strategies","lvl2":"Non symmetric games"},"type":"lvl4","url":"/l08-01-game-theory-intro#application-to-marketing-game","position":26},{"hierarchy":{"lvl1":"Game Theory 1","lvl4":"Application to Marketing Game","lvl3":"Strategies","lvl2":"Non symmetric games"},"content":"Applying this algorithm we start with S_1^0 = \\{1, 2\\} \\; S_2^0 = \\{1, 2\\}\n\nWe see form firm 1 it is optimal to play strategy 1 for any choice of firm 2, which causes us to delete 2. Now we have S_1^1 = \\{1 \\} \\; S_2^1 = \\{1, 2\\}\n\nNow firm 2 takes into account that 1 will play 1 -- only best response is to play 2 and we get S_1^2 = \\{1 \\} \\; S_2^2 = \\{2\\}\n\nWe are done!\n\nThe unique Nash Equilibrium is for firm 1 to take the low-price segment and firm 2 to take the upscale segment\n\n","type":"content","url":"/l08-01-game-theory-intro#application-to-marketing-game","position":27},{"hierarchy":{"lvl1":"Game Theory 1","lvl4":"Exercise","lvl3":"Strategies","lvl2":"Non symmetric games"},"type":"lvl4","url":"/l08-01-game-theory-intro#exercise","position":28},{"hierarchy":{"lvl1":"Game Theory 1","lvl4":"Exercise","lvl3":"Strategies","lvl2":"Non symmetric games"},"content":"Construct the Marketing Game using GameTheory.jl\n\nVerify that the only pure strategy nash equilibrium is [1, 2]\n\nHINT: don’t forget to write player 2’s payoffs from player 2’s perspective!\n\np1_market = Player([0.0 0; 0 0])\np2_market = Player([0.0 0; 0 0])\ng_market = NormalFormGame([p1_market, p2_market])\n\n","type":"content","url":"/l08-01-game-theory-intro#exercise","position":29},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"Matching Pennies"},"type":"lvl2","url":"/l08-01-game-theory-intro#matching-pennies","position":30},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"Matching Pennies"},"content":"Consider the payoff matrices for another famous game called Matching Pennies\n\npennies_p1 = [-1 1; 1 -1]\npennies_p2 = [1 -1; -1 1]\n\npennies_p1, pennies_p2\n\nQuestion: how many players are there?\n\nHow many strategies does player 1 have? Player 2?\n\n","type":"content","url":"/l08-01-game-theory-intro#matching-pennies","position":31},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"More Questions","lvl2":"Matching Pennies"},"type":"lvl3","url":"/l08-01-game-theory-intro#more-questions","position":32},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"More Questions","lvl2":"Matching Pennies"},"content":"Does player 1 have a dominating strategy?\n\nHow about player 2?\n\nWhat is player 1’s best response when 2 chooses T? What about when 2 chooses H?\n\n","type":"content","url":"/l08-01-game-theory-intro#more-questions","position":33},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Pure Strategies","lvl2":"Matching Pennies"},"type":"lvl3","url":"/l08-01-game-theory-intro#pure-strategies","position":34},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Pure Strategies","lvl2":"Matching Pennies"},"content":"Choosing a strategy outright is called playing a pure strategy\n\nNeither player will always choose H or T no matter what the other player does\n\nWe can say that there is no Nash Equilibrium in pure strategies\n\nHowever, for all games we will consider (and most games in general) there is always a Nash equilibrium...\n\n","type":"content","url":"/l08-01-game-theory-intro#pure-strategies","position":35},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Mixed Strategies","lvl2":"Matching Pennies"},"type":"lvl3","url":"/l08-01-game-theory-intro#mixed-strategies","position":36},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Mixed Strategies","lvl2":"Matching Pennies"},"content":"Sometimes players will not be able to play pure strategies in eqiulibrium\n\nIn these cases they will need to randomize their behavior\n\nA mixed strategy is a probability distribution over strategies\n\nFor example, in the matching pennies game, a mixed strategy is to play H with probabilty 0.5 and T with probability 0.5\n\nIt turns out that both players playing this mixed strategy is the unique Nash Equilibrium of the matching pennies game\n\nIntuition: Why does 50-50 randomization work? In equilibrium, each player makes their opponent indifferent between their choices. If player 1 plays H or T with 50% probability each, then player 2’s expected payoff is the same whether they choose H or T (both give expected payoff of 0). This mutual indifference is what sustains the equilibrium - neither player has an incentive to deviate from their randomization.\n\n","type":"content","url":"/l08-01-game-theory-intro#mixed-strategies","position":37},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"Mixed Strategies with GameTheory.jl"},"type":"lvl2","url":"/l08-01-game-theory-intro#mixed-strategies-with-gametheory-jl","position":38},{"hierarchy":{"lvl1":"Game Theory 1","lvl2":"Mixed Strategies with GameTheory.jl"},"content":"GameTheory.jl can compute mixed strategy nash equilibria for us\n\nTo do that we’ll use the support_enumeration method (support enumeration is the name of an algorithm for computing all NE of a game, in pure or mixed strategies)\n\n","type":"content","url":"/l08-01-game-theory-intro#mixed-strategies-with-gametheory-jl","position":39},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Bimatrix","lvl2":"Mixed Strategies with GameTheory.jl"},"type":"lvl3","url":"/l08-01-game-theory-intro#bimatrix","position":40},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Bimatrix","lvl2":"Mixed Strategies with GameTheory.jl"},"content":"Before we have GameTheory compute our mixed strategy NE, we’ll show one other way to create a NormalFormGame -- with a payoff bimatrix\n\nFor an N player game with N_i strategies for each player, a bimatrix is an N_1 \\times N_2 \\times \\cdots \\times N_N \\times N array of payoffs\n\nFor our game, we need a 2x2x2 array\n\nlast 2 represents 2 players\n\nfirst two 2’s represent 2 actions per player\n\npennies_bimatrix = zeros(2, 2, 2)\npennies_bimatrix[1, 1, :] = [-1, 1]\npennies_bimatrix[1, 2, :]  = [1, -1]\npennies_bimatrix[2, 1, :] = [1, -1]\npennies_bimatrix[2, 2, :] = [-1, 1]\npennies_g = NormalFormGame(pennies_bimatrix)\n\nNotice how when using a bimatrix we can directly read the cells of the normal form game\n\nThe (H,H) cell is in position [1,1] and has payoffs [-1, 1]\n\nThe (T, H) cell is in position [2, 1] and has payoffs [1, -1]\n\netc.\n\nThis can make it easier to specify payoffs because we don’t have to worry about “player N payoffs from player N’s perspective”\n\nsupport_enumeration(pennies_g)\n\n","type":"content","url":"/l08-01-game-theory-intro#bimatrix","position":41},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Exercise","lvl2":"Mixed Strategies with GameTheory.jl"},"type":"lvl3","url":"/l08-01-game-theory-intro#exercise-1","position":42},{"hierarchy":{"lvl1":"Game Theory 1","lvl3":"Exercise","lvl2":"Mixed Strategies with GameTheory.jl"},"content":"Try support_enumeration with the other two games we’ve worked with\n\nWhat does it give you with the prisoner’s dilemma?\n\nWhat does it give you with the marketing game?\n\n# TODO: your code AND explanation here","type":"content","url":"/l08-01-game-theory-intro#exercise-1","position":43},{"hierarchy":{"lvl1":"Network Traffic with Game Theory"},"type":"lvl1","url":"/l08-02-network-traffic","position":0},{"hierarchy":{"lvl1":"Network Traffic with Game Theory"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nNetworks\n\nGame Theory\n\nOutcomes\n\nRepresent network traffic weighted DiGraph\n\nAnalyze equilibrium network outcomes using the concept of Nash Equilibirum\n\nUnderstand Braes’ paradox\n\nLearn about the concept of social welfare and a social planners\n\nReferences\n\nEasley and Kleinberg chapter 8\n\n","type":"content","url":"/l08-02-network-traffic","position":1},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl2":"Congestion"},"type":"lvl2","url":"/l08-02-network-traffic#congestion","position":2},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl2":"Congestion"},"content":"We regularly use physical networks of all kinds\n\nPower grids\n\nThe internet\n\nStreets\n\nRailroads\n\nWhat happens when the networks get congested?\n\nTypically -- flow across the network slows down\n\nToday we’ll study how game theoretic ideas are helpful when analyzing how a network with finite capacity or increasing costs\n\n","type":"content","url":"/l08-02-network-traffic#congestion","position":3},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl2":"A Traffic Network"},"type":"lvl2","url":"/l08-02-network-traffic#a-traffic-network","position":4},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl2":"A Traffic Network"},"content":"We’ll start by considering a traffic network\n\nThe figure caption has extra detail -- so be sure to read it!\n\n\nWe’ll write up some helper Julia functions that will let us create and visualize the traffic network for arbitrary values of x\n\nusing Graphs, SimpleWeightedGraphs, GraphPlot\n\nfunction traffic_graph1(x)\n    A = [\n        0 0 x/100 45;\n        0 0 0 0;\n        0 45 0 0;\n        0 x/100 0 0\n        ]\n    SimpleWeightedDiGraph(A)\nend\n\nfunction plot_traffic_graph(g::SimpleWeightedDiGraph)\n    locs_x = [1.0, 3, 2, 2]\n    locs_y = [1.0, 1, 0, 2]\n    labels = collect('A':'Z')[1:nv(g)]\n    gplot(g, locs_x, locs_y, nodelabel=labels, edgelabel=weight.(edges(g)))\nend\n\nplot_traffic_graph(traffic_graph1(10))\n\nTry changing the argument to traffic_graph1 to see how the network changes\n\n","type":"content","url":"/l08-02-network-traffic#a-traffic-network","position":5},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"The Game","lvl2":"A Traffic Network"},"type":"lvl3","url":"/l08-02-network-traffic#the-game","position":6},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"The Game","lvl2":"A Traffic Network"},"content":"Now suppose, as indicated in the figure caption, that we have 4,000 drivers that need to commute from A to B in the morning\n\nIf all take the upper route (A-C-B) we get a total time of 40 + 45 = 85 minutes\n\nIf all take the lower route (A-D-B) we get a total time of 40 + 45 = 85 minutes\n\nIf, however, they evenly divide we get a total time of 20 + 45 = 65 minutes\n\n","type":"content","url":"/l08-02-network-traffic#the-game","position":7},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Equilibrium","lvl2":"A Traffic Network"},"type":"lvl3","url":"/l08-02-network-traffic#equilibrium","position":8},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Equilibrium","lvl2":"A Traffic Network"},"content":"Recall that for a set of strategies (here driving paths) to be a Nash Equilibrium, each player’s strategy must be a best response to the strategy of all other players\n\nWe’ll argue that the only NE of this commuting game is that 2,000 drivers take (A-C-B) and 2,000 take (A-D-B) and everyone takes 65 minutes to commute\n\n","type":"content","url":"/l08-02-network-traffic#equilibrium","position":9},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Exercise","lvl2":"A Traffic Network"},"type":"lvl3","url":"/l08-02-network-traffic#exercise","position":10},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Exercise","lvl2":"A Traffic Network"},"content":"Show that this strategy (2,000 drivers take (A-C-B) and 2,000 take (A-D-B)) is indeed a Nash equilibrium\n\nTo do this recognize that the game is symmetric for all drivers\n\nThen, argue that if 3,999 drivers are following that strategy, the best response for the last driver is also to follow the strategy\n\n","type":"content","url":"/l08-02-network-traffic#exercise","position":11},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Numerical Verification","lvl2":"A Traffic Network"},"type":"lvl3","url":"/l08-02-network-traffic#numerical-verification","position":12},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Numerical Verification","lvl2":"A Traffic Network"},"content":"Let’s verify why the 50-50 split is indeed an equilibrium:\n\nCurrent equilibrium: 2,000 drivers on each path, everyone takes 65 minutes\n\nIf you’re driver #2,001 considering which path to take:\n\nIf you join the upper path (A-C-B):\n\nEdge A-C now has 2,001 drivers: 2,001/100 = 20.01 minutes\n\nEdge C-B still takes 45 minutes\n\nTotal time: 20.01 + 45 = 65.01 minutes\n\nIf you join the lower path (A-D-B):\n\nEdge A-D now has 2,001 drivers: 2,001/100 = 20.01 minutes\n\nEdge D-B still takes 45 minutes\n\nTotal time: 20.01 + 45 = 65.01 minutes\n\nResult: Both paths give the same travel time! No driver has an incentive to switch paths. This confirms our Nash equilibrium.\n\nYour work HERE!\n\n","type":"content","url":"/l08-02-network-traffic#numerical-verification","position":13},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Discussion","lvl2":"A Traffic Network"},"type":"lvl3","url":"/l08-02-network-traffic#discussion","position":14},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Discussion","lvl2":"A Traffic Network"},"content":"Note a powerful outcome here -- without any coordination by a central authority, drivers  will automatically balance perfectly in equilibrium\n\nThe only assumptions we made were:\n\nDrivers want to minimize driving time\n\nDrivers are allowed to respond to the decisions of others\n\nThe first assumption is very plausable -- nobody wants to sit in more traffic than necessary\n\nThe second highlights a key facet of our modern society...\n\nInformation availability (here decisions of other drivers) can (and does!) lead to optimal outcomes without the need for further regulation or policing\n\nfunction traffic_graph2(x)\nG = traffic_graph1(x)\n# Add an edge with minimal weight (1e-16 instead of 0) because\n# GraphPlot doesn’t display edges with weight 0\nadd_edge!(G, 3, 4, 1e-16)\nG\nend\n\nfunction traffic_graph2(x)\n    G = traffic_graph1(x)\n    # need to add an edge with minimal weight so it shows up in plot\n    add_edge!(G, 3, 4, 1e-16)\n    G\nend\n\nplot_traffic_graph(traffic_graph2(10))\n\n","type":"content","url":"/l08-02-network-traffic#discussion","position":15},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Exercise","lvl2":"A Traffic Network"},"type":"lvl3","url":"/l08-02-network-traffic#exercise-1","position":16},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Exercise","lvl2":"A Traffic Network"},"content":"Is a 50/50 split of traffic still a Nash equilibrium in this case?\n\nWhy or why not?\n\nIs all 4,000 drivers doing (A-C-D-B) a Nash equilibrium?\n\nWhy or why not?\n\n","type":"content","url":"/l08-02-network-traffic#exercise-1","position":17},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Braess’ Paradox","lvl2":"A Traffic Network"},"type":"lvl3","url":"/l08-02-network-traffic#braess-paradox","position":18},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Braess’ Paradox","lvl2":"A Traffic Network"},"content":"In the previous exercise, we saw a rather startling result...\n\nDoing a network “upgrade” -- adding a wormhole connecting C and D -- resulted in a worse equilibrium outcome for everyone!\n\nThe equilibrium driving time is now 80 minutes for all drivers instead of 65 minutes (which was the case before the wormhole)\n\nThis is known as Braess’ paradox\n\n","type":"content","url":"/l08-02-network-traffic#braess-paradox","position":19},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Real-World Examples","lvl2":"A Traffic Network"},"type":"lvl3","url":"/l08-02-network-traffic#real-world-examples","position":20},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Real-World Examples","lvl2":"A Traffic Network"},"content":"Braess’ paradox is not just theoretical - it has been observed in real traffic networks:\n\nNew York City (1990): When 42nd Street was closed for Earth Day, traffic flow actually improved rather than worsened. The city later made some closures permanent.\n\nStuttgart, Germany (1969): After investing in a new road to ease congestion, traffic conditions worsened. The road was eventually removed, restoring better traffic flow.\n\nSeoul, South Korea (2003): The demolition of the Cheonggyecheon highway led to improved traffic conditions, contrary to predictions of chaos.\n\nThese cases demonstrate that sometimes removing network capacity can lead to better equilibrium outcomes - a counterintuitive result that game theory helps us understand!\n\n","type":"content","url":"/l08-02-network-traffic#real-world-examples","position":21},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Follow ups","lvl2":"A Traffic Network"},"type":"lvl3","url":"/l08-02-network-traffic#follow-ups","position":22},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Follow ups","lvl2":"A Traffic Network"},"content":"Braess’ paradox was the starting point for a large body of research on using game theory to analyze network traffic\n\nSome questions that have been asked are:\n\nHow much larger can equilibrium travel time increase after a network upgrade?\n\nHow can network upgrade be designed to be resilient to Braess’ paradox?\n\n","type":"content","url":"/l08-02-network-traffic#follow-ups","position":23},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl2":"Social Welfare"},"type":"lvl2","url":"/l08-02-network-traffic#social-welfare","position":24},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl2":"Social Welfare"},"content":"Many economic models are composed of individual actors who make autonomous decisions and have autonomous payoffs\n\nWe’ve been studying some of these settings using tools from game theory, focusing on the individual perspective\n\nOur notion of equilibrium is dependent on no individual wanting to change strategy in response to other strategies\n\nAnother form of analysis works at the macro level -- we analyze the total payoff for all agents (i.e. sum of payoffs)\n\nWe call this aggregate payoff social welfare\n\n","type":"content","url":"/l08-02-network-traffic#social-welfare","position":25},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"The Social Planner","lvl2":"Social Welfare"},"type":"lvl3","url":"/l08-02-network-traffic#the-social-planner","position":26},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"The Social Planner","lvl2":"Social Welfare"},"content":"In an economic model, someone who seeks to maximize social welfare is called a social planner\n\nA social planner is given the authority to make decisions for all agents\n\nIn our traffic model, a social planner would choose to ignore the wormhole and have 1/2 the drivers take A-C-B and the other half take A-D-B\n\nIn this case everyone would be better off with a cost of 65 minutes instead of the equilibrium 80 minutes\n\n","type":"content","url":"/l08-02-network-traffic#the-social-planner","position":27},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Cost of Freedom","lvl2":"Social Welfare"},"type":"lvl3","url":"/l08-02-network-traffic#cost-of-freedom","position":28},{"hierarchy":{"lvl1":"Network Traffic with Game Theory","lvl3":"Cost of Freedom","lvl2":"Social Welfare"},"content":"Question: in a generic traffic model, how much worse can the equilibrium outcome be than the social optimum?\n\nIn our example,\n\nOptimal social welfare is 4000 * 65 = 260,000 total minutes\n\nEquilibrium social welfare is 4000 * 80 = 320,000 total minutes\n\nA change of 60,000 total minutes\n\nPrice of Anarchy: This ratio of equilibrium cost to optimal cost is formally called the Price of Anarchy\n\nPrice of Anarchy = Worst Nash Equilibrium Cost / Social Optimum Cost\n\nIn our example: PoA = 320,000 / 260,000 = 1.23 (the equilibrium is 23% worse than optimal)\n\nTo answer this question for a general traffic model, we need to be able to compute the equilibrium for a generic traffic model\n\nWe may study this next week, or perhaps even on your homework 😉","type":"content","url":"/l08-02-network-traffic#cost-of-freedom","position":29},{"hierarchy":{"lvl1":"More Game Theory"},"type":"lvl1","url":"/l09-01-mixed-strategies","position":0},{"hierarchy":{"lvl1":"More Game Theory"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nIntro to Game Theory\n\nOutcomes\n\nKnow how to solve for a Nash Equilibrium in mixed strategies\n\nUnderstand the concepts of a repeated game and be able to reason about equilibria in such games\n\nUnderstand how normal form and extensive form games are related\n\nReferences\n\nEasley and Kleinberg chapter 6\n\n","type":"content","url":"/l09-01-mixed-strategies","position":1},{"hierarchy":{"lvl1":"More Game Theory","lvl2":"Review: Matching Pennies"},"type":"lvl2","url":"/l09-01-mixed-strategies#review-matching-pennies","position":2},{"hierarchy":{"lvl1":"More Game Theory","lvl2":"Review: Matching Pennies"},"content":"Recall the matching pennies game we studied last week\n\n","type":"content","url":"/l09-01-mixed-strategies#review-matching-pennies","position":3},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Properties","lvl2":"Review: Matching Pennies"},"type":"lvl3","url":"/l09-01-mixed-strategies#properties","position":4},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Properties","lvl2":"Review: Matching Pennies"},"content":"Matching pennies is an example of a wider class of games\n\nSome of its properties are that it is\n\nZero-sum: sum of payoffs from all players is always 0. One player loses, the other wins\n\nNo Nash Equilibrium in Pure Strategies\n\nb/c no NE in PS, beneficial to introduce randomness into actions\n\nZero sum games are very common\n\nExample: D-Day in WW2. US could have landed in France on Normandy or Calais. Germany could have put bulk of defenses at one of these places. Outcome largely depended on US ability to \n\ntrick Germany into putting defenses at Calais\n\n","type":"content","url":"/l09-01-mixed-strategies#properties","position":5},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Mixed Strategies","lvl2":"Review: Matching Pennies"},"type":"lvl3","url":"/l09-01-mixed-strategies#mixed-strategies","position":6},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Mixed Strategies","lvl2":"Review: Matching Pennies"},"content":"A pure strategy is a selection of a single action from set of possible strategies \\sigma_i  \\in S_i\n\nA mixed strategy is a probability distribution over the set of possible strategies \\sigma_i \\in \\triangle(S_i) \\subseteq [0,1]^{M_i}\n\nPure strategy is a special case of a mixed strategy -- a degenerate distribution\n\n","type":"content","url":"/l09-01-mixed-strategies#mixed-strategies","position":7},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Expected Payoffs","lvl2":"Review: Matching Pennies"},"type":"lvl3","url":"/l09-01-mixed-strategies#expected-payoffs","position":8},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Expected Payoffs","lvl2":"Review: Matching Pennies"},"content":"When dealing with pure strategies we could determine payoffs by reading off an appropriate value from the payoff matrix\n\nWith mixed strategies we have to deal with expected payoffs\n\n","type":"content","url":"/l09-01-mixed-strategies#expected-payoffs","position":9},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"P1  Payoffs in Matching Pennies","lvl2":"Review: Matching Pennies"},"type":"lvl3","url":"/l09-01-mixed-strategies#p1-payoffs-in-matching-pennies","position":10},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"P1  Payoffs in Matching Pennies","lvl2":"Review: Matching Pennies"},"content":"Suppose you are player 1 in matching pennies\n\nSuppose further that P2 is following a strategy to play H with probability q and T with probability (1-q)\n\nThe expected payoffs from each of P1’s pure strategies are:\n\nPlays H: p_1(H | q): -1 \\cdot q + 1 \\cdot (1-q) = 1 - 2q\n\nPlays T: p_1(T | q): 1 \\cdot 1 - 1 \\cdot (1-q) = 2q - 1\n\n","type":"content","url":"/l09-01-mixed-strategies#p1-payoffs-in-matching-pennies","position":11},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Indifference","lvl2":"Review: Matching Pennies"},"type":"lvl3","url":"/l09-01-mixed-strategies#indifference","position":12},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Indifference","lvl2":"Review: Matching Pennies"},"content":"Argument: it cannot be optimal for P2 to follow the (q, 1-q) strategy unless it makes P1 indifferent about playing H or T\n\nWhy? Suppose p_1(H | q) > p_1(T | q). Then P1 will always pick H, which would in turn make P2 want to change behavior to always play H\n\nSimilar logic applies if p_1(T | q) > p_1(H | q)\n\nSo, it must be that p_1(T | q) = p_1(H | q)\n\nThis means 1 - 2q = 2q - 1 \\Longrightarrow q = \\frac{1}{2}\n\n","type":"content","url":"/l09-01-mixed-strategies#indifference","position":13},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Comment","lvl2":"Review: Matching Pennies"},"type":"lvl3","url":"/l09-01-mixed-strategies#comment","position":14},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Comment","lvl2":"Review: Matching Pennies"},"content":"Notice that we used P1’s expected payoffs to determine the mixed strategy for P2\n\nThere are two major themes here\n\nTo derive optimal behavior for one player, you must consider impact of that player’s decisions on the rewards to other players\n\nP2’s ability to commit to following the (q, 1-q) both allowed P1 to reason about payoffs AND made P1 indifferent about his/her own choice. Commitment is a major theme in advanced game theory, and one we’ll revisit later in the course when we talk about blockchains and smart contracts\n\n","type":"content","url":"/l09-01-mixed-strategies#comment","position":15},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"P1’s action","lvl2":"Review: Matching Pennies"},"type":"lvl3","url":"/l09-01-mixed-strategies#p1s-action","position":16},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"P1’s action","lvl2":"Review: Matching Pennies"},"content":"We now know (based on P1s expected payoffs) that P2 will do 50/50 split between H and T\n\nNow consider game from P2’s perspective, taking as given that P1 will be playing H with probability p and T with probability 1-p\n\nExercise: use P2’s expected payoffs under the (p, 1-p) strategy for P1 to determine the value of p. What is that value? does it surprise you? Why or Why not?\n\n","type":"content","url":"/l09-01-mixed-strategies#p1s-action","position":17},{"hierarchy":{"lvl1":"More Game Theory","lvl2":"Asymmetry: NFL play choice"},"type":"lvl2","url":"/l09-01-mixed-strategies#asymmetry-nfl-play-choice","position":18},{"hierarchy":{"lvl1":"More Game Theory","lvl2":"Asymmetry: NFL play choice"},"content":"Matching pennies is a particularly simple example of a zero-sum game with no equilibira in pure strategies\n\nThe symmetry in the payoff matrix led to a “boring” outcome\n\nLet’s consider another example that doesn’t have this symmetry\n\nConsider an American football game\n\nEach play\n\nthe offense can choose to call a run or pass play\n\nThe defense can choose to focus play call on defending run or defending pass\n\nThe payoff for offensive team is how many yards they gain\n\nPayoff for defense is always negative and equal to “-” yards gained by offense\n\nPayoffs based on play calls are given below\n\n","type":"content","url":"/l09-01-mixed-strategies#asymmetry-nfl-play-choice","position":19},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Exercise","lvl2":"Asymmetry: NFL play choice"},"type":"lvl3","url":"/l09-01-mixed-strategies#exercise","position":20},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Exercise","lvl2":"Asymmetry: NFL play choice"},"content":"Given what we’ve learned about mixed strategies, determine the equilibrium probability that the defense chooses to defend the pass (call this q) and the equilibrium probability that the offense chooses a pass play (call this p)\n\n","type":"content","url":"/l09-01-mixed-strategies#exercise","position":21},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Comments","lvl2":"Asymmetry: NFL play choice"},"type":"lvl3","url":"/l09-01-mixed-strategies#comments","position":22},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Comments","lvl2":"Asymmetry: NFL play choice"},"content":"In the run/pass example we see that the higher payoff option for the offense is to pass, but that they choose it less than the lower payoff run option\n\nWhy?\n\nThe main idea is that the threat of a successful pass play causes the defense to choose to defend the pass more than 50% of the time.\n\nThe offense takes that strategy as given, and realizes they are better off running more than 1/2 the time\n\nAny deviation by the offense to pass more often than the p you computed would cause the defense to always defend the pass\n\nThis would result in a strictly worse expected payoff for the offense\n\n","type":"content","url":"/l09-01-mixed-strategies#comments","position":23},{"hierarchy":{"lvl1":"More Game Theory","lvl2":"Dynamic Games"},"type":"lvl2","url":"/l09-01-mixed-strategies#dynamic-games","position":24},{"hierarchy":{"lvl1":"More Game Theory","lvl2":"Dynamic Games"},"content":"So far the games we’ve studied have all been static\n\nBy this we mean each participant makes exactly one choice at exactly the same time\n\nGame theory is far more rich than this!\n\nWe now introduce the concept of a dynamic game\n\nOur treatement will focus on non-simultaneous decisions\n\nStudy of repeated games is beyond our scope for now\n\n","type":"content","url":"/l09-01-mixed-strategies#dynamic-games","position":25},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Example: Firm Advertising","lvl2":"Dynamic Games"},"type":"lvl3","url":"/l09-01-mixed-strategies#example-firm-advertising","position":26},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Example: Firm Advertising","lvl2":"Dynamic Games"},"content":"Consider a game with two firms (1 and 2) and two new markets (A and B)\n\nMarket A has a total of 12 profit to be gained and market B has total of 6 profit\n\nBoth firms have to choose which market to advertise to\n\nFirm 1 gets to choose first\n\nBecause of the earlier choice, firm 1 has “first mover advantage”\n\nIf firms choose same market, firm 1 gets 2/3 of potential profit and firm 2 gets 1/3\n\nIf they advertise to separate markets, each firm gets all potential profit in their chosen market\n\n","type":"content","url":"/l09-01-mixed-strategies#example-firm-advertising","position":27},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Extensive form","lvl2":"Dynamic Games"},"type":"lvl3","url":"/l09-01-mixed-strategies#extensive-form","position":28},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Extensive form","lvl2":"Dynamic Games"},"content":"We can represent the game we just described as a tree (or directed graph, if you prefer)\n\nEach node represents a decision point and each branch represents a particular action being chosen\n\nThe game tree for the advertising game is given below\n\n","type":"content","url":"/l09-01-mixed-strategies#extensive-form","position":29},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Equilibrium via Game Tree","lvl2":"Dynamic Games"},"type":"lvl3","url":"/l09-01-mixed-strategies#equilibrium-via-game-tree","position":30},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Equilibrium via Game Tree","lvl2":"Dynamic Games"},"content":"We can use the extensive form representation of a dynamic game to determine the equilibrium outcome\n\nThe approach for doing this is to start at the bottom of the tree and work our way up\n\nIn this example we first start with Player 2 and determine what decision should be made at each decision node:\n\nIf on branch from P1 choosing A, P2 should choose B because p_2(B|A) > p_2(A|A) (6 > 4)\n\nIf on branch from P1 choosing B, P2 should choose A because p_2(A|B) > p_2(B|B) (12 > 2)\n\nNow that we know what P2 will do at each node, we go up the tree to P1s decision\n\nP1 knows P2 will choose the opposite of P1’s choice\n\nSo P1 realizes that p_1(A) > p_1(B) (12 > 6), so P1 chooses A\n\nThe equilibrium of this game is (A, B)\n\n","type":"content","url":"/l09-01-mixed-strategies#equilibrium-via-game-tree","position":31},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Example: Market Entry","lvl2":"Dynamic Games"},"type":"lvl3","url":"/l09-01-mixed-strategies#example-market-entry","position":32},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Example: Market Entry","lvl2":"Dynamic Games"},"content":"Let’s consider a similar game\n\nPlayer 2 is now an incumbent (already existing firm) and player 1 is a startup deciding to enter the market or stay out\n\nIf P1 chooses to stay out (S), the game ends and P2 is happy\n\nIf P1 chooses to enter (E), P2 can choose to retaliate or cooperate\n\nPayoffs are given in game tree below\n\n","type":"content","url":"/l09-01-mixed-strategies#example-market-entry","position":33},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Exercise","lvl2":"Dynamic Games"},"type":"lvl3","url":"/l09-01-mixed-strategies#exercise-1","position":34},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Exercise","lvl2":"Dynamic Games"},"content":"Apply the logic outlined above when studying the advertising game to determine the equilibrium outcome of the Market Entry Game\n\nWhat does Player 1 choose to do?\n\nDoes player 2 have to make a choice? If so, what is it?\n\n","type":"content","url":"/l09-01-mixed-strategies#exercise-1","position":35},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Comparison to Normal Form","lvl2":"Dynamic Games"},"type":"lvl3","url":"/l09-01-mixed-strategies#comparison-to-normal-form","position":36},{"hierarchy":{"lvl1":"More Game Theory","lvl3":"Comparison to Normal Form","lvl2":"Dynamic Games"},"content":"Consider the market entry game in normal form\n\nNotice that in this normal form game there are two NE in pure strategies:\n\n(S, R): An equilibrium that didn’t come up in the dynamic game, because P1 got to move first and chose to enter\n\n(E, C): the equilibrim we’ve already seen\n\nKey idea: taking into account timing may change equilibrium outcomes\n\nIf P2 had the ability to commit to retaliate, then perhaps P1 would choose to stay out\n\nAgain commitment is a key concept in Game theory\n\nBook talks about “if P2 could commit to having a computer play its strategies”\n\nThis is not just a hypothetical if -- smart contracts make it possible and enforce it!","type":"content","url":"/l09-01-mixed-strategies#comparison-to-normal-form","position":37},{"hierarchy":{"lvl1":"Auctions"},"type":"lvl1","url":"/l09-03-auctions","position":0},{"hierarchy":{"lvl1":"Auctions"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nGame Theory\n\nOutcomes\n\nKnow the 4 main types of auctions\n\nUnderstand concept of individual valuation of an item or an outcome\n\nUnderstand why truth-telling in auctions is optimal\n\nReferences\n\nEasley and Kleinberg chapter 9\n\n","type":"content","url":"/l09-03-auctions","position":1},{"hierarchy":{"lvl1":"Auctions","lvl2":"Intro"},"type":"lvl2","url":"/l09-03-auctions#intro","position":2},{"hierarchy":{"lvl1":"Auctions","lvl2":"Intro"},"content":"An auction is a special type of economic market between a seller and many buyers\n\nThe seller has an item or outcome that -- presumably -- the buyers want\n\nRules are established for how buyers indicate their willingness to pay\n\n","type":"content","url":"/l09-03-auctions#intro","position":3},{"hierarchy":{"lvl1":"Auctions","lvl3":"Why/When auctions?","lvl2":"Intro"},"type":"lvl3","url":"/l09-03-auctions#why-when-auctions","position":4},{"hierarchy":{"lvl1":"Auctions","lvl3":"Why/When auctions?","lvl2":"Intro"},"content":"When would auctions be applicable?\n\nIn a typical buyer-seller scenario usually the value of the good for one party is known\n\nThe seller knows costs of creating the good and posts a reasonable price\n\nThe buyer knows how much they are willing to pay and will purchase if affordable\n\nAn auction is to be used when the valuation of the good is either private information (I, a buyer, don’t want seller to know how badly I want the good) or is unknown\n\n","type":"content","url":"/l09-03-auctions#why-when-auctions","position":5},{"hierarchy":{"lvl1":"Auctions","lvl2":"Types of Auctions"},"type":"lvl2","url":"/l09-03-auctions#types-of-auctions","position":6},{"hierarchy":{"lvl1":"Auctions","lvl2":"Types of Auctions"},"content":"First price, ascending (English): what we see on TV. Auctioneer calls out higher and higher prices, bidders indicate willinness to pay, terminates when nobody outbids current highest bid\n\nDescending-bid (Dutch): Price starts high and falls, bidders are quiet until somebody says they’ll buy at current price, auction ends and bidder pays that price\n\nFirst price, sealed-bid: everyone writes down their bid secretly and submits at the same time, highest bidder wins and pays price they wrote\n\nSecond price, sealed-bid (Vickrey): everyone writes down their bid secretly and submits at the same time, highest bidder wins and pays price of second highest bidder\n\n","type":"content","url":"/l09-03-auctions#types-of-auctions","position":7},{"hierarchy":{"lvl1":"Auctions","lvl3":"Equivalence","lvl2":"Types of Auctions"},"type":"lvl3","url":"/l09-03-auctions#equivalence","position":8},{"hierarchy":{"lvl1":"Auctions","lvl3":"Equivalence","lvl2":"Types of Auctions"},"content":"Because auctions are useful in settings with unknown valuations, we often think about how the rules of an auction lead to revealing information\n\nIt turns out that of the 4 types of auctions we just described, only two information patterns emerge:\n\nDescending bid and first-price sealed auction: In this case nobody learns anything about buyers willingness to pay until we see the highest bidder’s price and auction ends. We only ever learn the highest bidder’s bid\n\nAscending and second-price sealed: We see which buyers are willing to purchase at low prices, auction ends when one person has outbid the rest, if auction increments slowly this will be at the maximum price for second place bidder. In either case we learn second highest bidder’s price, which is paid by the highest bidder (we don’t get to see the highest bidder’s valuation)\n\nFor this reason, we’ll study the two forms of sealed-bid auctions\n\n","type":"content","url":"/l09-03-auctions#equivalence","position":9},{"hierarchy":{"lvl1":"Auctions","lvl2":"Second price, sealed bid auction"},"type":"lvl2","url":"/l09-03-auctions#second-price-sealed-bid-auction","position":10},{"hierarchy":{"lvl1":"Auctions","lvl2":"Second price, sealed bid auction"},"content":"Let’s set up the second price, sealed-bid auction as a game\n\nSuppose there are N bidders (each is a player)\n\nBidder i’s strategy is to bid an amount b_i, which is a function of that bidder’s true valuation v_i\n\nPayoffs to player i with valuation v_i and bid b_i are:\n\n0: if b_i is not highest bid\n\nequal to v_i - b_k: if b_i is highest bid and second highest bid is b_k\n\nTies go to bidder with lower index: i wins over k if b_i = b_k and i < k\n\n","type":"content","url":"/l09-03-auctions#second-price-sealed-bid-auction","position":11},{"hierarchy":{"lvl1":"Auctions","lvl3":"Truth telling","lvl2":"Second price, sealed bid auction"},"type":"lvl3","url":"/l09-03-auctions#truth-telling","position":12},{"hierarchy":{"lvl1":"Auctions","lvl3":"Truth telling","lvl2":"Second price, sealed bid auction"},"content":"Claim: in a sealed-bid second price auction, it is a dominant strategy for each bidder to choose b_i = v_i\n\nTo prove this we need to consider possible outcomes if b_i <v_i or if b_i > v_i\n\nCall b_i' the bid above valuation (b_i' > v_i) and b_i'' the bid below valuation (b_i'' < v_i). Also let b_k represent the second highest bid\n\nSuppose bidder i chooses to bid b_i'' < v_i\n\nCase v_i, b_i'' < b_k: lose auction with payoff 0\n\nCase v_i, b_i'' > b_k: win auction with payoff v_i - b_k\n\nCase v_i > b_k and b_i'' < b_k: b_k'' loses auction gets. Bidding b_i = v_i would have won for payoff v_i - b_k \\ge 0. So, bidding too low can’t help, but can hurt\n\nSuppose bidder i chooses to bid b_i' > v_i\n\nCase v_i, b_i' < b_k: payoff 0\n\nCase v_i, b_i' > b_k: payoff v_i - b_k\n\nCase v_i < b_k and b_i' > b_k: b_i' now wins auction and gets payoff v_i - b_k \\le 0. Truthful bid would lose and get payoff 0. Bidding high can’t help, but can hurt\n\nSo, in sealed-bid second price auction it is always optimal to bid true value\n\n","type":"content","url":"/l09-03-auctions#truth-telling","position":13},{"hierarchy":{"lvl1":"Auctions","lvl2":"First price, sealed bid auction"},"type":"lvl2","url":"/l09-03-auctions#first-price-sealed-bid-auction","position":14},{"hierarchy":{"lvl1":"Auctions","lvl2":"First price, sealed bid auction"},"content":"Same notation players, valuations, and bids\n\nPayoffs are now:\n\n0 if b_i not highest\n\nequal to v_i - b_i if b_i is highest\n\nNote that bidding true value is not optimal -- you would always get 0 payoff\n\nWhat is optimal then?\n\nOptimal behavior is to “shade” bid a bit lower than true value\n\nHow much lower depends on interaction between not bidding too close to true value (b/c that diminishes your payoffs) and not bidding too low (b/c you risk losing an otherwise profitable win).\n\nActually solving for this tradeoff is complex!\n\n","type":"content","url":"/l09-03-auctions#first-price-sealed-bid-auction","position":15},{"hierarchy":{"lvl1":"Auctions","lvl3":"Considerations","lvl2":"First price, sealed bid auction"},"type":"lvl3","url":"/l09-03-auctions#considerations","position":16},{"hierarchy":{"lvl1":"Auctions","lvl3":"Considerations","lvl2":"First price, sealed bid auction"},"content":"What factors might influence how much you shade your bid?\n\nNumber of other bidders: with many bidders, shading becomes more risky (more people that might outbid you) so you tend to bid higher\n\nDistribution of bidder values: understanding how the valuations of other bidders are distributed might allow you to shade more\n\n","type":"content","url":"/l09-03-auctions#considerations","position":17},{"hierarchy":{"lvl1":"Auctions","lvl3":"Outcomes","lvl2":"First price, sealed bid auction"},"type":"lvl3","url":"/l09-03-auctions#outcomes","position":18},{"hierarchy":{"lvl1":"Auctions","lvl3":"Outcomes","lvl2":"First price, sealed bid auction"},"content":"For now, we will not discuss how to compute optimal bids in first-price auctions\n\nInstead we will talk about some outcomes:\n\nThe Revelation Principle: in order to derive optimal bids, we use a framework that considers small deviations to v_i instead of b_i. We assert that the expected payoff for using a a strategy derived from a value v_i is at least as high as the expected payoff for a strategy derived from any other value v\n\nRevenue equivalence: the expected payoff to the seller is exactly the same for both first and second price auctions, when bidders follow equilibrium strategies\n\n","type":"content","url":"/l09-03-auctions#outcomes","position":19},{"hierarchy":{"lvl1":"Auctions","lvl2":"Twists"},"type":"lvl2","url":"/l09-03-auctions#twists","position":20},{"hierarchy":{"lvl1":"Auctions","lvl2":"Twists"},"content":"There are some twists to the auction setup we’ve described\n\nOne is the notion of an “all-pay auction”\n\nIn an all-pay auction only the highest bidder wins, but all bidders must pay their bid\n\nTurns out, this style of auction also satisfies the revenue equivalence principle (under equilibrium bidding, expected seller revenue is same as in sealed first and sealed second price bid)\n\nAuction markets on blockchain\n\nImplementing auctions via smart contracts has interesting implications:\n\nTransfer of ownership can be settled immediately and trustlessly\n\nParticipating in an auction is permissionless (anyone can be a seller or buyer)\n\nConditions for resales can be set (i.e. original seller gets x% of all subsequent sales)  -- now we have a repeated, dynamic game!\n\nOwnership rights can be verified and open up new possibilities for digital assets\n\nThis scratches the surface of some economic implications of a class of assets called NFTs or non-fungible tokens","type":"content","url":"/l09-03-auctions#twists","position":21},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications"},"type":"lvl1","url":"/l09-04-game-theory-lab","position":0},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nMixed Strategies (L09.01)\n\nAuctions (L09.03)\n\nOutcomes\n\nApply mixed strategy Nash equilibrium to cybersecurity scenarios\n\nUnderstand auction mechanisms in digital advertising\n\nAnalyze bidding strategies in cloud computing spot markets\n\nPractice computing equilibria with real-world data science examples\n\n","type":"content","url":"/l09-04-game-theory-lab","position":1},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl2":"Cybersecurity: Defender vs Attacker Game"},"type":"lvl2","url":"/l09-04-game-theory-lab#cybersecurity-defender-vs-attacker-game","position":2},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl2":"Cybersecurity: Defender vs Attacker Game"},"content":"\n\n","type":"content","url":"/l09-04-game-theory-lab#cybersecurity-defender-vs-attacker-game","position":3},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Scenario","lvl2":"Cybersecurity: Defender vs Attacker Game"},"type":"lvl3","url":"/l09-04-game-theory-lab#scenario","position":4},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Scenario","lvl2":"Cybersecurity: Defender vs Attacker Game"},"content":"You are the head of security for a data analytics company. Your infrastructure has two critical components:\n\nDatabase: Contains customer data and analytics results\n\nAPI: Processes real-time data requests\n\nDue to resource constraints, you can only deploy intensive monitoring and intrusion detection on ONE system at a time.\n\nMeanwhile, a threat actor is targeting your company and must choose which system to attack.\n\nPayoffs (from Defender’s perspective, in terms of avoided damages, measured in $10,000s):\n\nIf Defender monitors the system being attacked: +8 (attack detected and blocked)\n\nIf Defender monitors the wrong system: -10 (successful breach)\n\nIf Attacker succeeds in breaching Database: Defender loses 10, Attacker gains 10\n\nIf Attacker succeeds in breaching API: Defender loses 10, Attacker gains 10\n\nIf Attacker is blocked: Defender gains 8 (reputation boost), Attacker loses 8 (wasted resources)\n\n","type":"content","url":"/l09-04-game-theory-lab#scenario","position":5},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Payoff Matrix","lvl2":"Cybersecurity: Defender vs Attacker Game"},"type":"lvl3","url":"/l09-04-game-theory-lab#payoff-matrix","position":6},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Payoff Matrix","lvl2":"Cybersecurity: Defender vs Attacker Game"},"content":"\n\nAttacker: Database\n\nAttacker: API\n\nDefender: Database\n\n(8, -8)\n\n(-10, 10)\n\nDefender: API\n\n(-10, 10)\n\n(8, -8)\n\nNote: Payoffs are (Defender, Attacker)\n\n","type":"content","url":"/l09-04-game-theory-lab#payoff-matrix","position":7},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 1.1: Pure Strategy Analysis","lvl2":"Cybersecurity: Defender vs Attacker Game"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-1-1-pure-strategy-analysis","position":8},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 1.1: Pure Strategy Analysis","lvl2":"Cybersecurity: Defender vs Attacker Game"},"content":"Does this game have a Nash Equilibrium in pure strategies? Why or why not?\n\nWhat type of game is this (zero-sum, positive-sum, negative-sum)?\n\nWhy might randomization (mixed strategies) be beneficial for both players?\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-1-1-pure-strategy-analysis","position":9},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 1.2: Computing Mixed Strategy Equilibrium","lvl2":"Cybersecurity: Defender vs Attacker Game"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-1-2-computing-mixed-strategy-equilibrium","position":10},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 1.2: Computing Mixed Strategy Equilibrium","lvl2":"Cybersecurity: Defender vs Attacker Game"},"content":"Let:\n\np = probability Defender monitors Database\n\nq = probability Attacker targets Database\n\nPart A: Write out the Attacker’s expected payoff for each pure strategy as a function of p:\n\nExpected payoff from targeting Database: E_A(\\text{Database} | p) = ?\n\nExpected payoff from targeting API: E_A(\\text{API} | p) = ?\n\nPart B: Use the indifference condition to solve for p^* (the equilibrium probability)\n\nPart C: By symmetry (or by computing Defender’s expected payoffs), what is q^*?\n\nPart D: What is the expected payoff for each player at equilibrium?\n\n# Use this cell to compute the equilibrium probabilities\n\n\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-1-2-computing-mixed-strategy-equilibrium","position":11},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 1.3: Interpretation","lvl2":"Cybersecurity: Defender vs Attacker Game"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-1-3-interpretation","position":12},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 1.3: Interpretation","lvl2":"Cybersecurity: Defender vs Attacker Game"},"content":"What does the equilibrium strategy tell you about security practices?\n\nIf the Defender could credibly commit to always monitoring the Database (e.g., via automated systems), would that change the outcome?\n\nHow does this relate to the concept of “security through obscurity” vs “security through randomization”?\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-1-3-interpretation","position":13},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl2":"Digital Advertising Auctions"},"type":"lvl2","url":"/l09-04-game-theory-lab#digital-advertising-auctions","position":14},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl2":"Digital Advertising Auctions"},"content":"\n\n","type":"content","url":"/l09-04-game-theory-lab#digital-advertising-auctions","position":15},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Background: How Google Ads Works","lvl2":"Digital Advertising Auctions"},"type":"lvl3","url":"/l09-04-game-theory-lab#background-how-google-ads-works","position":16},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Background: How Google Ads Works","lvl2":"Digital Advertising Auctions"},"content":"When you search on Google, advertisers compete in real-time auctions for ad placement. For many years, Google used a Vickrey (second-price) auction mechanism:\n\nEach advertiser submits a maximum bid (how much they’re willing to pay per click)\n\nThe highest bidder wins the top ad slot\n\nThe winner pays the second-highest bid (plus $0.01)\n\nWhy this design?\n\nIncentivizes truthful bidding (bidding your true value)\n\nSimplifies strategy for advertisers\n\nReduces gaming and complexity\n\nNote: Modern Google Ads uses a modified version called “Generalized Second Price” with quality scores, but the core principle remains.\n\n","type":"content","url":"/l09-04-game-theory-lab#background-how-google-ads-works","position":17},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Scenario: Three Advertisers","lvl2":"Digital Advertising Auctions"},"type":"lvl3","url":"/l09-04-game-theory-lab#scenario-three-advertisers","position":18},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Scenario: Three Advertisers","lvl2":"Digital Advertising Auctions"},"content":"Three data analytics companies are bidding for the keyword “business intelligence software”:\n\nCompany A: Estimates that each click is worth $15 to them (based on conversion rate × customer lifetime value)\n\nCompany B: Estimates each click is worth $12\n\nCompany C: Estimates each click is worth $8\n\n","type":"content","url":"/l09-04-game-theory-lab#scenario-three-advertisers","position":19},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 2.1: Second-Price Auction with Truthful Bidding","lvl2":"Digital Advertising Auctions"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-2-1-second-price-auction-with-truthful-bidding","position":20},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 2.1: Second-Price Auction with Truthful Bidding","lvl2":"Digital Advertising Auctions"},"content":"Assume all companies bid their true valuation.\n\nQuestions:\n\nWho wins the auction?\n\nHow much does the winner pay per click?\n\nWhat is the winner’s profit per click?\n\nWhat is the seller’s (Google’s) revenue per click?\n\n# Calculate outcomes for truthful bidding\nvaluations = Dict(\"A\" => 15, \"B\" => 12, \"C\" => 8)\nbids_truthful = Dict(\"A\" => 15, \"B\" => 12, \"C\" => 8)  # truthful bidding\n\n# TODO: compute winner, price paid, profit\n\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-2-1-second-price-auction-with-truthful-bidding","position":21},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 2.2: What if Company A Tries to “Game” the System?","lvl2":"Digital Advertising Auctions"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-2-2-what-if-company-a-tries-to-game-the-system","position":22},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 2.2: What if Company A Tries to “Game” the System?","lvl2":"Digital Advertising Auctions"},"content":"Suppose Company A knows (or guesses) that Company B will bid $12.\n\nCompany A considers bidding lower to reduce what they pay.\n\nScenario 1: Company A bids 13 instead of 15\n\nWho wins?\n\nHow much do they pay?\n\nWhat is Company A’s profit per click?\n\nScenario 2: Company A bids 11 instead of 15\n\nWho wins?\n\nHow much do they pay?\n\nWhat is Company A’s profit per click?\n\nConclusion: Can Company A improve their outcome by bidding untruthfully?\n\n# Scenario 1: A bids 13\nbids_scenario1 = Dict(\"A\" => 13, \"B\" => 12, \"C\" => 8)\n\n# TODO: compute outcome\n\n# Scenario 2: A bids 11\nbids_scenario2 = Dict(\"A\" => 11, \"B\" => 12, \"C\" => 8)\n\n# TODO: compute outcome\n\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-2-2-what-if-company-a-tries-to-game-the-system","position":23},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 2.3: First-Price Auction Comparison","lvl2":"Digital Advertising Auctions"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-2-3-first-price-auction-comparison","position":24},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 2.3: First-Price Auction Comparison","lvl2":"Digital Advertising Auctions"},"content":"Now suppose Google switched to a first-price sealed-bid auction (winner pays their own bid).\n\nQuestions:\n\nIf all companies bid their true valuations (15, 12, 8), what would be each company’s profit?\n\nWhy would Company A want to “shade” their bid downward?\n\nIf you were Company A, what would you bid? (Hint: you want to bid just above $12 to win, but how do you know what B will bid?)\n\nWhich auction format do you think is easier for advertisers to participate in? Why?\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-2-3-first-price-auction-comparison","position":25},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 2.4: Extension - Multiple Ad Slots","lvl2":"Digital Advertising Auctions"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-2-4-extension-multiple-ad-slots","position":26},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 2.4: Extension - Multiple Ad Slots","lvl2":"Digital Advertising Auctions"},"content":"In reality, Google shows multiple ads (positions 1, 2, 3). The top position gets more clicks.\n\nSuppose:\n\nPosition 1: 100 clicks per day\n\nPosition 2: 60 clicks per day\n\nPosition 3: 30 clicks per day\n\nWith valuations: A=15, B=12, C=$8\n\nIn a Generalized Second-Price (GSP) auction:\n\nPosition 1 pays the bid of Position 2\n\nPosition 2 pays the bid of Position 3\n\nPosition 3 pays $0 (or a minimum bid)\n\nQuestions:\n\nIf everyone bids truthfully, what is the daily cost for each advertiser?\n\nWhat is the daily profit for each advertiser?\n\nWhat is Google’s total daily revenue?\n\n# Multi-slot auction analysis\nclicks_per_position = [100, 60, 30]\nvaluations = Dict(\"A\" => 15, \"B\" => 12, \"C\" => 8)\n\n# TODO: compute costs, profits, and revenue\n\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-2-4-extension-multiple-ad-slots","position":27},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"type":"lvl2","url":"/l09-04-game-theory-lab#aws-spot-instances-cloud-computing-auctions","position":28},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"content":"\n\n","type":"content","url":"/l09-04-game-theory-lab#aws-spot-instances-cloud-computing-auctions","position":29},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Background","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"type":"lvl3","url":"/l09-04-game-theory-lab#background","position":30},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Background","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"content":"AWS sells unused computing capacity through Spot Instances at discounted prices (up to 90% off on-demand pricing).\n\nHow it works:\n\nYou specify the maximum price you’re willing to pay per hour\n\nIf the spot price ≤ your bid, you get the instance\n\nYou pay the current spot price (not your bid) - similar to second-price auction!\n\nIf spot price rises above your bid, your instance is terminated (with 2-minute warning)\n\nUse cases:\n\nTraining ML models (can tolerate interruptions)\n\nBatch data processing\n\nRendering and simulations\n\nWeb crawling and data collection\n\n","type":"content","url":"/l09-04-game-theory-lab#background","position":31},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Scenario: Training a Machine Learning Model","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"type":"lvl3","url":"/l09-04-game-theory-lab#scenario-training-a-machine-learning-model","position":32},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Scenario: Training a Machine Learning Model","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"content":"You’re a data scientist at a startup. You need to train a deep learning model and have three options:\n\nOn-Demand Instance: $3.06/hour for a p3.2xlarge (1 GPU), guaranteed availability\n\nSpot Instance: Same machine, but price fluctuates between 0.50 and 2.50 per hour\n\nNo GPU: Use your laptop, takes 10x longer, costs you time\n\nYour training job will take:\n\n10 hours on GPU\n\nCan checkpoint and resume if interrupted\n\nEach interruption costs ~20 minutes of wasted computation + time to restart\n\nYour valuation: You value completing the job at $40 total value\n\nIf it costs you less than $40, you profit\n\nIf it costs more than $40, you should use your laptop instead\n\n","type":"content","url":"/l09-04-game-theory-lab#scenario-training-a-machine-learning-model","position":33},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 3.1: Bidding Strategy Basics","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-3-1-bidding-strategy-basics","position":34},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 3.1: Bidding Strategy Basics","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"content":"Questions:\n\nWhat is your maximum value per hour? (Hint: $40 total value / 10 hours)\n\nIf the current spot price is $1.20/hour, should you use spot instances?\n\nWhat should you bid in the spot instance auction? Your true value per hour, or something different?\n\nWhy is bidding your true value optimal in this second-price auction format?\n\n# Calculate maximum value per hour\ntotal_value = 40\nhours_needed = 10\n\nmax_value_per_hour = total_value / hours_needed\nprintln(\"Maximum value per hour: \\$$(round(max_value_per_hour, digits=2))\")\n\n# Compare to on-demand pricing\non_demand_price = 3.06\nprintln(\"On-demand price: \\$$(round(on_demand_price, digits=2))/hour\")\nprintln(\"Total on-demand cost: \\$$(round(on_demand_price * hours_needed, digits=2))\")\n\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-3-1-bidding-strategy-basics","position":35},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 3.2: Analyzing Spot Price History","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-3-2-analyzing-spot-price-history","position":36},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 3.2: Analyzing Spot Price History","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"content":"Suppose you have historical spot price data for the past 24 hours:\n\nHour\n\nSpot Price\n\n0\n\n$0.92\n\n1\n\n$0.88\n\n2\n\n$0.85\n\n3\n\n$0.90\n\n4\n\n$0.95\n\n5\n\n$1.10\n\n6\n\n$1.45\n\n7\n\n$1.80\n\n8\n\n$2.20\n\n9\n\n$2.10\n\n10\n\n$1.95\n\n11\n\n$1.75\n\n12\n\n$1.60\n\n13\n\n$1.55\n\n14\n\n$1.50\n\n15\n\n$1.45\n\n16\n\n$1.40\n\n17\n\n$1.50\n\n18\n\n$1.65\n\n19\n\n$1.55\n\n20\n\n$1.40\n\n21\n\n$1.20\n\n22\n\n$1.05\n\n23\n\n$0.95\n\nusing Plots\n\n# Spot price data\nhours = 0:23\nspot_prices = [0.92, 0.88, 0.85, 0.90, 0.95, 1.10, 1.45, 1.80,\n               2.20, 2.10, 1.95, 1.75, 1.60, 1.55, 1.50, 1.45,\n               1.40, 1.50, 1.65, 1.55, 1.40, 1.20, 1.05, 0.95]\n\n# TODO: Plot the spot price over time\n# Add a horizontal line at your maximum value per hour\n# Calculate: what percentage of time is spot price below your max?\n\n\nQuestions:\n\nWhat percentage of the time is the spot price below your maximum value per hour ($4.00)?\n\nWhat is the average spot price when it’s below $4.00?\n\nIf you bid $4.00 and could run during any of these hours, what would be your expected cost?\n\nBased on the pattern, what time of day seems best for running spot instances?\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-3-2-analyzing-spot-price-history","position":37},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 3.3: Risk vs Reward","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-3-3-risk-vs-reward","position":38},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 3.3: Risk vs Reward","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"content":"Now consider interruption risk. Historical data shows:\n\nIf you bid $2.00/hour: 30% chance of interruption during your 10-hour job\n\nIf you bid $3.00/hour: 5% chance of interruption\n\nIf you bid $4.00/hour: 1% chance of interruption\n\nEach interruption:\n\nWastes 20 minutes of computation (cost = current spot price × 0.33 hours)\n\nRequires time to restart and resume (assume this is negligible due to checkpointing)\n\nCalculate expected costs:\n\n# Expected cost calculation\nfunction expected_cost(bid_price, avg_spot_price, interruption_prob; hours=10)\n    \"\"\"\n    Calculate expected cost including interruption costs\n\n    Parameters:\n    -----------\n    bid_price : Float64\n        Your maximum bid\n    avg_spot_price : Float64\n        Expected spot price given your bid\n    interruption_prob : Float64\n        Probability of interruption during job\n    hours : Float64\n        Hours needed to complete job\n    \"\"\"\n    # TODO: Calculate base cost (hours × avg spot price)\n    # TODO: Calculate expected interruption cost\n    # TODO: Return total expected cost\n    return 0.0  # placeholder\nend\n\n# Scenario 1: Bid $2.00\n# Scenario 2: Bid $3.00\n# Scenario 3: Bid $4.00\n# Scenario 4: On-demand at $3.06\n\n# TODO: Compare expected costs\n\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-3-3-risk-vs-reward","position":39},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 3.4: Strategic Implications","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-3-4-strategic-implications","position":40},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 3.4: Strategic Implications","lvl2":"AWS Spot Instances: Cloud Computing Auctions"},"content":"Discussion Questions:\n\nTruth-telling: Why is bidding your true value ($4.00/hour) the optimal strategy in AWS spot instances?\n\nPrice Discovery: How does the spot price auction help AWS discover the true market value of computing resources?\n\nMarket Efficiency: How does this auction mechanism help AWS:\n\nMaximize revenue from unused capacity?\n\nAllocate resources to users who value them most?\n\nProvide price signals about demand patterns?\n\nComparison to First-Price: How would your bidding strategy change if AWS used a first-price auction (you pay your bid)?\n\nReal-world Complexity: In practice, AWS spot prices are determined by supply/demand, not just auctions. How does this affect:\n\nPredictability of costs?\n\nStrategic behavior by users?\n\nFairness of resource allocation?\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-3-4-strategic-implications","position":41},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl2":"Synthesis: Comparing the Three Applications"},"type":"lvl2","url":"/l09-04-game-theory-lab#synthesis-comparing-the-three-applications","position":42},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl2":"Synthesis: Comparing the Three Applications"},"content":"\n\n","type":"content","url":"/l09-04-game-theory-lab#synthesis-comparing-the-three-applications","position":43},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 4.1: Common Themes","lvl2":"Synthesis: Comparing the Three Applications"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-4-1-common-themes","position":44},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 4.1: Common Themes","lvl2":"Synthesis: Comparing the Three Applications"},"content":"Reflect on the three scenarios you’ve analyzed:\n\nCybersecurity Game:\n\nZero-sum game\n\nMixed strategy equilibrium\n\nRandomization as a strategic tool\n\nDigital Advertising:\n\nSecond-price auction\n\nTruth-telling as dominant strategy\n\nMultiple bidders with different valuations\n\nAWS Spot Instances:\n\nDynamic pricing auction\n\nRisk/reward tradeoffs\n\nResource allocation mechanism\n\nQuestions:\n\nIn which scenarios is “truth-telling” (revealing your true value) optimal? Why?\n\nIn which scenarios is randomization important? Why?\n\nHow do auction mechanisms help solve information asymmetry problems?\n\nWhat role does “commitment” play in each scenario?\n\nHow might smart contracts or blockchain change any of these scenarios?\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-4-1-common-themes","position":45},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 4.2: Design Your Own Auction","lvl2":"Synthesis: Comparing the Three Applications"},"type":"lvl3","url":"/l09-04-game-theory-lab#exercise-4-2-design-your-own-auction","position":46},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl3":"Exercise 4.2: Design Your Own Auction","lvl2":"Synthesis: Comparing the Three Applications"},"content":"Choose one of the following scenarios and design an auction mechanism:\n\nOption 1: Data Marketplace\n\nMultiple data providers want to sell datasets\n\nMultiple companies want to buy data for ML training\n\nData has different quality levels\n\nDesign: What auction type? How do you handle quality? How do you price?\n\nOption 2: Freelance Data Science Platform\n\nCompanies post projects with unknown complexity\n\nFreelancers bid on projects with their rates\n\nQuality of work varies by freelancer\n\nDesign: Sealed bid? Reverse auction? How to handle quality signals?\n\nOption 3: ML Model Marketplace\n\nData scientists train models and want to sell predictions\n\nCompanies want to buy access to best models\n\nModel quality is uncertain until deployed\n\nDesign: How to auction model access? How to price queries?\n\nFor your chosen scenario:\n\nDefine the players and their valuations\n\nChoose an auction type (first-price, second-price, etc.)\n\nExplain why this auction type is appropriate\n\nDescribe the equilibrium bidding strategy\n\nDiscuss potential issues or limitations\n\n","type":"content","url":"/l09-04-game-theory-lab#exercise-4-2-design-your-own-auction","position":47},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl2":"Conclusion"},"type":"lvl2","url":"/l09-04-game-theory-lab#conclusion","position":48},{"hierarchy":{"lvl1":"Game Theory Lab: Data Science Applications","lvl2":"Conclusion"},"content":"In this lab, you’ve applied game theory concepts to real-world data science scenarios:\n\nMixed strategies help solve security problems where randomization is crucial\n\nSecond-price auctions simplify strategic decisions in advertising and cloud computing\n\nEquilibrium analysis helps predict behavior in competitive environments\n\nAuction design affects market efficiency and resource allocation\n\nThese concepts are fundamental to understanding:\n\nHow tech platforms operate (Google, AWS, Meta)\n\nHow to design data marketplaces and APIs\n\nHow to think strategically about security and competition\n\nHow incentives shape behavior in complex systems\n\nAs you continue in data science, you’ll encounter these game-theoretic situations frequently in:\n\nPricing and monetization strategies\n\nPlatform design and marketplace mechanisms\n\nSecurity and adversarial ML\n\nResource allocation in cloud/distributed systems\n\nAlgorithmic decision-making with strategic agents","type":"content","url":"/l09-04-game-theory-lab#conclusion","position":49},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents"},"type":"lvl1","url":"/l-a1-01-from-rule-based-to-learning-agents","position":0},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nAgent-Based Models (Weeks 6-7)\n\nBasic Julia programming\n\nSchelling segregation model\n\nOutcomes\n\nDistinguish between rule-based agents (traditional ABMs) and learning agents\n\nUnderstand how LLMs function as general-purpose reasoning engines\n\nImplement basic LLM API calls in Julia\n\nCompare emergent behaviors of AI agents vs programmed agents\n\nReferences\n\nAttention Is All You Need - The transformer paper\n\nLanguage Models are Few-Shot Learners - GPT-3 paper\n\nAnthropic Claude Documentation\n\nOpenAI API Documentation\n\nAI Agents Survey Paper\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents","position":1},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"A Tale of Two Agents"},"type":"lvl2","url":"/l-a1-01-from-rule-based-to-learning-agents#a-tale-of-two-agents","position":2},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"A Tale of Two Agents"},"content":"We’ve spent two weeks studying agent-based models\n\nRemember the Schelling segregation model?\n\nAgents with simple rules: “move if less than N neighbors are like me”\n\nEnvironment: 25x25 grid\n\nResult: stark segregation patterns emerge from mild preferences\n\nThose were rule-based agents - they follow explicit, programmed instructions\n\nNow let me show you something different.\n\nSuppose I asked you to write an agent that could:\n\nAnalyze a news article and summarize it\n\nAnswer questions about complex topics it’s never seen before\n\nGenerate creative stories in the style of different authors\n\nWrite code to solve novel problems\n\nEngage in strategic reasoning about social situations\n\nHow would you program those rules?\n\nYou probably can’t - at least not easily. The rule set would be impossibly complex.\n\nThis is where learning agents come in.\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#a-tale-of-two-agents","position":3},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"The Fundamental Shift","lvl2":"A Tale of Two Agents"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#the-fundamental-shift","position":4},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"The Fundamental Shift","lvl2":"A Tale of Two Agents"},"content":"Over the past few years, we’ve witnessed a fundamental shift in how we build intelligent systems:\n\nRule-Based Approach (Traditional ABMs):\n\nDeveloper writes explicit rules\n\nAgent follows those rules deterministically (or with simple randomness)\n\nBehavior is predictable from the code\n\nExample: if unhappy then move to random location\n\nLearning Approach (Modern AI):\n\nDeveloper provides training data and objectives\n\nSystem learns patterns and relationships\n\nBehavior emerges from learned representations\n\nExample: “Here are 10 trillion words from the internet - learn to predict what comes next”\n\nThe second approach has given us Large Language Models (LLMs) - and they’re remarkably capable.\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#the-fundamental-shift","position":5},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Connecting to What We Know"},"type":"lvl2","url":"/l-a1-01-from-rule-based-to-learning-agents#connecting-to-what-we-know","position":6},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Connecting to What We Know"},"content":"Before we dive into AI agents, let’s think about what made our ABMs interesting:\n\nIn the Schelling Model:\n\nSimple agent logic (check neighbors, decide to move)\n\nLocal information only (can’t see whole grid)\n\nEmergent behavior (segregation without a segregationist)\n\nAggregate outcomes differ from individual intentions\n\nIn the Money Model:\n\nEven simpler logic (give $1 to random agent)\n\nNo intelligence at all, just random exchanges\n\nPower law wealth distribution emerges\n\nInequality arises from equality plus randomness\n\nThese models taught us that complexity can emerge from simplicity.\n\nNow consider this: what if we could build agents that aren’t simple?\n\nWhat if individual agents could:\n\nReason about their situation\n\nLearn from experience\n\nCommunicate in natural language\n\nAdapt their strategies\n\nForm and revise beliefs\n\nWhat kinds of collective behaviors might emerge then?\n\nThis is the frontier we’re exploring in this module: Agentic AI Systems.\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#connecting-to-what-we-know","position":7},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Understanding Large Language Models"},"type":"lvl2","url":"/l-a1-01-from-rule-based-to-learning-agents#understanding-large-language-models","position":8},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Understanding Large Language Models"},"content":"\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#understanding-large-language-models","position":9},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"What is an LLM?","lvl2":"Understanding Large Language Models"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#what-is-an-llm","position":10},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"What is an LLM?","lvl2":"Understanding Large Language Models"},"content":"A Large Language Model is a neural network trained to predict the next word (or “token”) in a sequence.\n\nThat’s it. Really.\n\nBut this simple objective, when applied at massive scale, produces something remarkable: a general-purpose reasoning engine.\n\nThe Training Process:\n\nCollect enormous amounts of text (books, websites, code, papers, conversations)\n\nFor each sequence, hide the next word and ask the model to predict it\n\nAdjust the model’s parameters (billions of them) to improve predictions\n\nRepeat trillions of times\n\nWhat the Model Learns:\n\nGrammar and syntax (obvious)\n\nFacts about the world (it saw them in training data)\n\nReasoning patterns (it saw examples of reasoning)\n\nCausal relationships (they’re implicit in language)\n\nSocial norms and conventions (they’re encoded in how people write)\n\nTask structures (it saw many examples of questions and answers)","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#what-is-an-llm","position":11},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"From Next-Word Prediction to Intelligence","lvl2":"Understanding Large Language Models"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#from-next-word-prediction-to-intelligence","position":12},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"From Next-Word Prediction to Intelligence","lvl2":"Understanding Large Language Models"},"content":"You might think: “How does predicting the next word lead to intelligence?”\n\nConsider this sequence:\n\n“The doctor told the patient that she would need to come back next week. The patient thanked...”\n\nTo predict the next word, the model needs to:\n\nTrack that “she” refers to “the patient”\n\nUnderstand doctor-patient relationships\n\nKnow social conventions about gratitude\n\nPredict “her” (the doctor) is the likely continuation\n\nOr this one:\n\n“If all mammals have hearts, and whales are mammals, then whales...”\n\nTo complete this, the model must:\n\nRecognize a logical argument structure\n\nApply deductive reasoning\n\nPredict “have hearts” or similar\n\nThe key insight: To predict text well, you need to model the world.\n\nText is the trace of human thought, and to predict it accurately, you need to simulate the thinking that produced it.\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#from-next-word-prediction-to-intelligence","position":13},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Transformer Architecture (High-Level Intuition)","lvl2":"Understanding Large Language Models"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#transformer-architecture-high-level-intuition","position":14},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Transformer Architecture (High-Level Intuition)","lvl2":"Understanding Large Language Models"},"content":"We won’t dive deep into the math, but here’s the essential idea:\n\nThe Challenge: When predicting the next word, which previous words matter?\n\nIn “The doctor told the patient that she would need to come back”, the word “doctor” is relevant for predicting what comes after “the patient thanked”.\n\nThe Solution: Attention Mechanism\n\nThe transformer architecture uses “attention” to let each word look at all previous words and decide which ones are relevant:\"The patient thanked\" <-- looks back at entire sequence\n                       <-- pays attention to \"doctor\" (high weight)\n                       <-- pays less attention to \"told\" (medium weight)\n                       <-- ignores \"the\" (low weight)\n\nThis attention mechanism is:\n\nLearned, not programmed (the model figures out what to attend to)\n\nParallel (can process all words simultaneously)\n\nMulti-headed (multiple attention patterns can operate in parallel)\n\nStackable (many layers of attention build complex representations)\n\nNetwork Analogy:\n\nIf you squint, attention looks like a weighted graph where:\n\nNodes are words/tokens\n\nEdges are attention weights\n\nInformation flows along high-weight edges\n\nThe model learns to construct this graph dynamically based on the input!","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#transformer-architecture-high-level-intuition","position":15},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Scale is All You Need (Almost)","lvl2":"Understanding Large Language Models"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#scale-is-all-you-need-almost","position":16},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Scale is All You Need (Almost)","lvl2":"Understanding Large Language Models"},"content":"A remarkable empirical finding: model capabilities scale predictably with:\n\nModel size (number of parameters)\n\nData size (amount of training text)\n\nCompute (training time × hardware)\n\nScaling Laws show that doubling compute roughly gives consistent improvements.\n\nModern LLMs (as of 2025):\n\nGPT-5: ~2+ trillion parameters (estimated)\n\nClaude Sonnet 4.5: ~500 billion parameters (estimated)\n\nClaude Haiku 4.5: ~100 billion parameters (estimated)\n\nLlama 3: 70 billion parameters (open source)\n\nFor comparison:\n\nHuman brain: ~86 billion neurons, ~100 trillion synapses\n\nEach parameter is roughly analogous to a synaptic weight\n\nWe’re now at or exceeding biological-scale systems in parameter count.\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#scale-is-all-you-need-almost","position":17},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Prompting as Programming"},"type":"lvl2","url":"/l-a1-01-from-rule-based-to-learning-agents#prompting-as-programming","position":18},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Prompting as Programming"},"content":"\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#prompting-as-programming","position":19},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"A New Interface for Computation","lvl2":"Prompting as Programming"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#a-new-interface-for-computation","position":20},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"A New Interface for Computation","lvl2":"Prompting as Programming"},"content":"With traditional programming:\n\nYou write explicit instructions in a formal language (Julia, Python, etc.)\n\nThe computer executes them precisely\n\nYou get exactly what you specified (bugs included)\n\nWith LLMs:\n\nYou write instructions in natural language\n\nThe model interprets your intent\n\nYou get (hopefully) what you meant\n\nThis is prompting - the art and science of instructing LLMs.","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#a-new-interface-for-computation","position":21},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Anatomy of a Prompt","lvl2":"Prompting as Programming"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#anatomy-of-a-prompt","position":22},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Anatomy of a Prompt","lvl2":"Prompting as Programming"},"content":"A good prompt typically includes:\n\nRole/Context: Who should the model be?\n\n“You are an expert economist...”\n\n“You are a helpful teaching assistant...”\n\nTask: What should it do?\n\n“Analyze the following dataset...”\n\n“Summarize this paper in 3 bullet points...”\n\nConstraints: How should it do it?\n\n“Use only information from the provided text”\n\n“Respond in JSON format”\n\n“Keep your answer under 100 words”\n\nExamples (optional): Show, don’t just tell\n\nFew-shot learning: provide input-output examples\n\nThe model learns the pattern and applies it\n\nOutput Format: Structure the response\n\n“Provide your answer as a numbered list”\n\n“Format your response as: Analysis: ... Conclusion: ...”","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#anatomy-of-a-prompt","position":23},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"In-Context Learning","lvl2":"Prompting as Programming"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#in-context-learning","position":24},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"In-Context Learning","lvl2":"Prompting as Programming"},"content":"One of the most striking capabilities of LLMs is in-context learning:\n\nYou can teach the model a new task just by showing it examples in the prompt - no retraining needed!\n\nExample:Translate English to Pig Latin:\n\nEnglish: hello\nPig Latin: ellohay\n\nEnglish: world  \nPig Latin: orldway\n\nEnglish: agent\nPig Latin:\n\nThe model will likely output: agentyay or agentay\n\nIt learned the pattern from just two examples!\n\nThis is impossible with traditional rule-based agents.\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#in-context-learning","position":25},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Hands-On: Your First AI Agent"},"type":"lvl2","url":"/l-a1-01-from-rule-based-to-learning-agents#hands-on-your-first-ai-agent","position":26},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Hands-On: Your First AI Agent"},"content":"\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#hands-on-your-first-ai-agent","position":27},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Setting Up API Access","lvl2":"Hands-On: Your First AI Agent"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#setting-up-api-access","position":28},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Setting Up API Access","lvl2":"Hands-On: Your First AI Agent"},"content":"To use LLMs, we need to call their APIs. The two major providers are:\n\nAnthropic - We’ll use their Claude models:\n\nClaude Haiku 4.5 (default) - Fast, cost-effective, great for real-time tasks\n\nClaude Sonnet 4.5 - Most intelligent, best for complex reasoning and coding\n\nClaude Opus 4 - Premium model with extended context (200K tokens)\n\nOpenAI - We’ll demonstrate their GPT models using the Responses API:\n\nGPT-5 - Flagship model with advanced reasoning\n\nGPT-5-mini - Cost-effective, 5x cheaper than GPT-5\n\no3 and o3-mini - Specialized reasoning models\n\nNote: We use OpenAI’s modern Responses API (/v1/responses) which provides a cleaner interface with separate instructions and input parameters. This is recommended for new projects. See the \n\nResponses API Quickstart for more details.\n\nBoth require API keys. Send me a message on webcourses and I’ll venmo you $10 to get started\n\nOpenAI: \n\nhttps://​platform​.openai​.com​/signup\n\nAnthropic: \n\nhttps://​console​.anthropic​.com/\n\nImportant: Never commit API keys to git! Use environment variables.\n\nWe’ll use the HTTP.jl package to make API calls (it’s already in our Project.toml).\n\n# Load packages\nusing HTTP\nusing JSON3\nusing DataFrames\nusing DotEnv  # For loading .env files\n\n# Load environment variables from .env file\n# This will read the .env file in your project directory\nDotEnv.load!()\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#setting-up-api-access","position":29},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Getting API Keys","lvl2":"Hands-On: Your First AI Agent"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#getting-api-keys","position":30},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Getting API Keys","lvl2":"Hands-On: Your First AI Agent"},"content":"Cross-Platform Approach: Using .env Files\n\nThe best practice is to store your API keys in a .env file that you never commit to git.\n\nCreate a .env file in your project root (same directory as your notebook):# .env file\nANTHROPIC_API_KEY=your-anthropic-key-here\nOPENAI_API_KEY=your-openai-key-here\n\nAdd .env to your .gitignore to keep keys secure:# Add this line to .gitignore\n.env\n\nInstall DotEnv.jl to load environment variables from the .env file:using Pkg\nPkg.add(\"DotEnv\")\n\nThis approach works on Windows, macOS, and Linux without needing to set system environment variables!\n\nAlternative: System Environment Variables (if you prefer)\n\nYou can also set environment variables at the system level:\n\nmacOS/Linux: Add to ~/.bashrc or ~/.zshrc:export ANTHROPIC_API_KEY=\"your-key-here\"\nexport OPENAI_API_KEY=\"your-key-here\"\n\nWindows (PowerShell):$env:ANTHROPIC_API_KEY=\"your-key-here\"\n$env:OPENAI_API_KEY=\"your-key-here\"\n\nWindows (Command Prompt):set ANTHROPIC_API_KEY=your-key-here\nset OPENAI_API_KEY=your-key-here\n\nFor this lecture, we’ll use the .env file approach since it’s cross-platform and project-specific.\n\n# Get API key from environment variables\n# After running DotEnv.config() above, your .env file is loaded into ENV\n\n# Check if the key exists and provide a helpful message if not\nif haskey(ENV, \"ANTHROPIC_API_KEY\")\n    ANTHROPIC_API_KEY = ENV[\"ANTHROPIC_API_KEY\"]\n    println(\"✓ Anthropic API key loaded successfully\")\nelse\n    @warn \"No ANTHROPIC_API_KEY found! Please create a .env file with your key.\"\n    ANTHROPIC_API_KEY = \"your-key-here\"  # Fallback for demo purposes\nend\n\n# Similarly for OpenAI (optional)\nif haskey(ENV, \"OPENAI_API_KEY\")\n    OPENAI_API_KEY = ENV[\"OPENAI_API_KEY\"]\n    println(\"✓ OpenAI API key loaded successfully\")\nelse\n    println(\"ℹ No OPENAI_API_KEY found (optional)\")\nend\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#getting-api-keys","position":31},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Making Our First API Call","lvl2":"Hands-On: Your First AI Agent"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#making-our-first-api-call","position":32},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Making Our First API Call","lvl2":"Hands-On: Your First AI Agent"},"content":"Let’s create a simple function to call Claude’s API:\n\nCheck the official documentation for the exact current model names:\n\nAnthropic: \n\nhttps://​docs​.anthropic​.com​/en​/docs​/models​-overview\n\nOpenAI: \n\nhttps://​platform​.openai​.com​/docs​/models\n\n\"\"\"\n    call_claude(prompt; model=\"claude-haiku-4-5\", max_tokens=1024)\n\nCall the Anthropic Claude API with a prompt.\n\n# Arguments\n- `prompt`: The text prompt to send to Claude\n- `model`: Which Claude model to use. Options:\n  - \"claude-haiku-4-5\" (default) - Fast and cost-effective\n  - \"claude-sonnet-4-5\" - Most intelligent, best for complex tasks\n  - \"claude-opus-4\" - Premium model with 200K context window\n- `max_tokens`: Maximum length of response (default: 1024)\n\n# Returns\n- String containing Claude's response\n\n# Note\nCheck https://docs.anthropic.com/en/docs/models-overview for exact model identifiers\nas they may include version dates (e.g., \"claude-haiku-4-5-20250101\")\n\"\"\"\nfunction call_claude(prompt; model=\"claude-haiku-4-5\", max_tokens=1024)\n    url = \"https://api.anthropic.com/v1/messages\"\n\n    headers = [\n        \"x-api-key\" => ANTHROPIC_API_KEY,\n        \"anthropic-version\" => \"2023-06-01\",\n        \"content-type\" => \"application/json\"\n    ]\n\n    body = JSON3.write(Dict(\n        \"model\" => model,\n        \"max_tokens\" => max_tokens,\n        \"messages\" => [\n            Dict(\"role\" => \"user\", \"content\" => prompt)\n        ]\n    ))\n\n    response = HTTP.post(url, headers, body)\n    result = JSON3.read(String(response.body))\n\n    return result.content[1].text\nend\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#making-our-first-api-call","position":33},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Testing Our AI Agent","lvl2":"Hands-On: Your First AI Agent"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#testing-our-ai-agent","position":34},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Testing Our AI Agent","lvl2":"Hands-On: Your First AI Agent"},"content":"Let’s start simple and ask Claude to explain something:\n\n# Simple test\nresponse = call_claude(\"\"\"\nExplain the Schelling segregation model in exactly 3 sentences.\nMake it accessible to someone who hasn't studied it before.\n\nRespond with markdown.\n\"\"\")\n\nprintln(response)\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#testing-our-ai-agent","position":35},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Comparing Rule-Based and AI Agents","lvl2":"Hands-On: Your First AI Agent"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#comparing-rule-based-and-ai-agents","position":36},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Comparing Rule-Based and AI Agents","lvl2":"Hands-On: Your First AI Agent"},"content":"Now let’s do something interesting - ask Claude to role-play as both types of agents:\n\nprompt = \"\"\"\nYou are analyzing the difference between rule-based and learning agents.\n\nScenario: An agent needs to decide whether to move to a new location in a neighborhood.\n\nRespond in two parts:\n\n1. RULE-BASED AGENT: Show how a simple rule-based agent (like in Schelling model)\n   would make this decision. Use pseudocode.\n\n2. LEARNING AGENT: Describe how an AI agent with language capabilities might reason\n   about the same decision, considering multiple factors and uncertainty.\n\nKeep your entire response under 200 words.\n\"\"\"\n\ncomparison = call_claude(prompt, max_tokens=500)\nprintln(comparison)\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#comparing-rule-based-and-ai-agents","position":37},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Structured Output: Using AI Agents for Data Analysis","lvl2":"Hands-On: Your First AI Agent"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#structured-output-using-ai-agents-for-data-analysis","position":38},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Structured Output: Using AI Agents for Data Analysis","lvl2":"Hands-On: Your First AI Agent"},"content":"One powerful pattern: use LLMs to generate structured data that we can analyze computationally.\n\nLet’s ask Claude to generate synthetic agent data:\n\nprompt = \"\"\"\nGenerate data for 5 agents in a social network simulation.\n\nFor each agent, provide:\n- id (integer 1-5)\n- personality (one word: cooperative, competitive, or neutral)\n- risk_tolerance (float 0.0 to 1.0)\n- initial_wealth (integer 50-150)\n\nFormat as JSON array of objects. IMPORTANT Respond ONLY with valid JSON, no other text or formatting including \"```json\".`\n\"\"\"\n\njson_response = call_claude(prompt, max_tokens=500)\nprintln(json_response)\n\n# Parse the JSON response\nagents_data = JSON3.read(json_response)\n\n# Convert to DataFrame for analysis\ndf_agents = DataFrame(agents_data)\ndf_agents\n\nNow we have structured data generated by an AI that we can analyze with traditional methods!\n\nThis pattern - LLM generation + computational analysis - is extremely powerful.\n\nWe can combine the flexibility of natural language with the rigor of computation.\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#structured-output-using-ai-agents-for-data-analysis","position":39},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Alternative: Using OpenAI’s Responses API","lvl2":"Hands-On: Your First AI Agent"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#alternative-using-openais-responses-api","position":40},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Alternative: Using OpenAI’s Responses API","lvl2":"Hands-On: Your First AI Agent"},"content":"For completeness, here’s how to call OpenAI’s GPT models using their modern Responses API.\n\nNote: OpenAI introduced the Responses API (/v1/responses) as the recommended interface for new projects. It provides a cleaner structure than the older Chat Completions API, with separate instructions for system-level guidance and input for user queries.\n\n\"\"\"\n    call_gpt(input; instructions=\"\", model=\"gpt-5-mini\", reasoning_effort=\"low\")\n\nCall the OpenAI Responses API with a user input and optional instructions.\n\n# Arguments\n- `input`: The user input/query to send to the model\n- `instructions`: Optional system-level instructions for the model's behavior\n- `model`: Which OpenAI model to use. Options:\n  - \"gpt-5-mini\" (default) - Cost-effective, 5x cheaper than GPT-5\n  - \"gpt-5\" - Flagship model with advanced reasoning\n  - \"o3-mini\" - Specialized reasoning model (cost-effective)\n  - \"o3\" - Advanced reasoning model\n- `reasoning_effort`: Reasoning effort level for faster responses. Options:\n  - \"low\" (default) - Faster responses\n  - \"medium\" - Balanced\n  - \"high\" - Maximum reasoning quality\n\n# Returns\n- String containing the model's response (using the convenience `output_text` field)\n\n# Notes\n- Uses the Responses API endpoint: /v1/responses\n- The response has an `output` array, but we use the convenience `output_text` property\n- The `output` array can contain multiple items (not just text), so always check structure\n- For system instructions, use the `instructions` parameter (replaces the \"system\" role)\n- Check https://platform.openai.com/docs/models for the latest model names\n- API documentation: https://platform.openai.com/docs/api-reference/responses\n\n# Example\n```julia\n# Simple query\nresponse = call_gpt(\"What is emergence?\")\n\n# With instructions\nresponse = call_gpt(\n    \"Explain the Schelling model\",\n    instructions=\"You are an expert in agent-based modeling\"\n)\n\n# Different model and reasoning effort\nresponse = call_gpt(\n    \"Solve this complex problem: ...\",\n    model=\"gpt-5\",\n    reasoning_effort=\"high\"\n)\n```\n\"\"\"\nfunction call_gpt(input::String; instructions::String=\"\", model::String=\"gpt-5-nano\", reasoning_effort::String=\"low\")\n    url = \"https://api.openai.com/v1/responses\"\n\n    # OPENAI_API_KEY should be loaded from ENV via DotEnv\n    headers = [\n        \"Authorization\" => \"Bearer $(ENV[\"OPENAI_API_KEY\"])\",\n        \"Content-Type\" => \"application/json\"\n    ]\n\n    # Build request body with Responses API format\n    request_body = Dict(\n        \"model\" => model,\n        \"input\" => input,\n        \"reasoning\" => Dict(\"effort\" => reasoning_effort)\n    )\n\n    # Add instructions if provided\n    if !isempty(instructions)\n        request_body[\"instructions\"] = instructions\n    end\n\n    body = JSON3.write(request_body)\n\n    response = HTTP.post(url, headers, body)\n    result = JSON3.read(String(response.body))\n\n    # NOTE: result.output is an array that can have multiple items. We are assuming a simple case here...\n    return result.output[end].content[1].text\nend\n\n# Usage examples:\n# response = call_gpt(\"Explain transformers in one sentence\")  # Uses gpt-5-mini by default\n# response = call_gpt(\"Complex reasoning task\", model=\"gpt-5\", reasoning_effort=\"high\")  # Use full GPT-5 for harder tasks\n# response = call_gpt(\"Math problem\", model=\"o3-mini\")  # Use reasoning model\nprintln(call_gpt(\"What is game theory?\", instructions=\"You are a helpful economics professor\")) # With system instructions\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#alternative-using-openais-responses-api","position":41},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Emergent Capabilities of AI Agents"},"type":"lvl2","url":"/l-a1-01-from-rule-based-to-learning-agents#emergent-capabilities-of-ai-agents","position":42},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Emergent Capabilities of AI Agents"},"content":"\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#emergent-capabilities-of-ai-agents","position":43},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"From Scale to Surprise","lvl2":"Emergent Capabilities of AI Agents"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#from-scale-to-surprise","position":44},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"From Scale to Surprise","lvl2":"Emergent Capabilities of AI Agents"},"content":"Remember how emergence worked in our ABMs?\n\nSimple local rules\n\nComplex global patterns\n\nOutcomes not explicitly programmed\n\nLLMs exhibit a similar phenomenon, but at the model level:\n\nTraining Objective: Predict the next word\n\nEmergent Capabilities (things we didn’t explicitly train for):\n\nMulti-step reasoning\n\nCode generation and debugging\n\nTranslation between languages\n\nMathematical problem solving\n\nTheory of mind (reasoning about others’ beliefs)\n\nTool use\n\nPlanning and strategy\n\nThese capabilities often appear suddenly at certain scale thresholds - we call them emergent abilities.","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#from-scale-to-surprise","position":45},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Chain-of-Thought Reasoning","lvl2":"Emergent Capabilities of AI Agents"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#chain-of-thought-reasoning","position":46},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Chain-of-Thought Reasoning","lvl2":"Emergent Capabilities of AI Agents"},"content":"One of the most important emergent capabilities is chain-of-thought (CoT) reasoning.\n\nIf you ask an LLM to “think step by step”, it performs dramatically better on complex tasks.\n\nLet’s demonstrate:\n\n# Without chain-of-thought\nsimple_prompt = \"\"\"\nIn a network, node A is connected to B, B to C, C to D, and D to A.\nIs there a path from A to C that doesn't go through B?\nAnswer with just YES or NO.\n\"\"\"\n\nprintln(\"Without CoT:\")\nprintln(call_claude(simple_prompt, max_tokens=50))\n\n# With chain-of-thought\ncot_prompt = \"\"\"\nIn a network, node A is connected to B, B to C, C to D, and D to A.\nIs there a path from A to C that doesn't go through B?\n\nLet's think step by step:\n1. List all direct connections\n2. Find all possible paths from A to C\n3. Identify which paths avoid B\n4. Give your final answer\n\"\"\"\n\nprintln(\"With CoT:\")\nprintln(call_claude(cot_prompt, max_tokens=300))\n\nThe second version should be more reliable because we asked the model to show its reasoning.\n\nWhy does this work?\n\nThe model generates reasoning steps as text, and each step becomes part of the context for the next step.\n\nIt’s essentially using its own output as a working memory!\n\nThis is analogous to how humans often solve problems by writing things down.","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#chain-of-thought-reasoning","position":47},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Tool Use: Extending Agent Capabilities","lvl2":"Emergent Capabilities of AI Agents"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#tool-use-extending-agent-capabilities","position":48},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Tool Use: Extending Agent Capabilities","lvl2":"Emergent Capabilities of AI Agents"},"content":"Modern LLMs can learn to use external tools:\n\nCalculators (for precise math)\n\nSearch engines (for current information)\n\nCode interpreters (for computation)\n\nDatabase queries (for data access)\n\nAPIs (for external services)\n\nThis is called function calling or tool use.\n\nThe pattern:\n\nTell the model what tools are available (in the prompt)\n\nModel decides which tool to use\n\nModel outputs a structured request (e.g., JSON)\n\nYour code executes the tool\n\nReturn results to the model\n\nModel incorporates results and continues\n\nHere’s a simple example:\n\n# Define a \"tool\" the agent can use\nfunction get_network_density(n_nodes, n_edges)\n    max_edges = n_nodes * (n_nodes - 1) / 2\n    return n_edges / max_edges\nend\n\n# Ask the agent to use it\ntool_prompt = \"\"\"\nYou have access to a function: get_network_density(n_nodes, n_edges)\nthat calculates the density of an undirected network.\n\nA researcher has a social network with 50 people and 245 connections.\nThey want to know if this network is dense (density > 0.3) or sparse.\n\nFirst, tell me what function call you would make (in Julia syntax).\nThen, I'll tell you the result, and you can interpret it.\n\"\"\"\n\nresponse = call_claude(tool_prompt, max_tokens=200)\nprintln(response)\n\nThe model should have identified the correct function call. Let’s execute it:\n\n# Execute the tool\ndensity = get_network_density(50, 245)\nprintln(\"Network density: \", round(density, digits=3))\n\n# Return result to agent\nfollowup_prompt = \"\"\"\nThe function returned: $(round(density, digits=3))\n\nNow interpret this result: is the network dense or sparse?\nExplain in one sentence.\n\"\"\"\n\ninterpretation = call_claude(followup_prompt, max_tokens=100)\nprintln(\"\\nAgent's interpretation:\")\nprintln(interpretation)\n\nThis simple pattern - prompt → tool identification → execution → interpretation - is the foundation of agentic AI.\n\nWe’ll explore this much more deeply in later lectures.\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#tool-use-extending-agent-capabilities","position":49},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Limitations and Considerations"},"type":"lvl2","url":"/l-a1-01-from-rule-based-to-learning-agents#limitations-and-considerations","position":50},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Limitations and Considerations"},"content":"\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#limitations-and-considerations","position":51},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"What LLMs Can’t Do (Well)","lvl2":"Limitations and Considerations"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#what-llms-cant-do-well","position":52},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"What LLMs Can’t Do (Well)","lvl2":"Limitations and Considerations"},"content":"Despite their impressive capabilities, LLMs have important limitations:\n\n1. Precise Arithmetic\n\nThey approximate calculations, don’t compute them\n\nSolution: Use tools (code execution, calculators)\n\n2. Current Information\n\nTraining data has a cutoff date\n\nThey don’t know recent events\n\nSolution: Retrieval Augmented Generation (RAG) - next lecture!\n\n3. Consistency Across Calls\n\nSame prompt can give different answers (they’re stochastic)\n\nSolution: Use temperature=0 for determinism, or run multiple times and aggregate\n\n4. Following Complex Constraints\n\nMay violate constraints you specify in prompts\n\nSolution: Validate outputs programmatically\n\n5. Long-Term Memory\n\nContext window is finite (though growing - now 200K+ tokens)\n\nCan’t remember everything from earlier in long conversations\n\nSolution: External memory systems\n\n6. True Understanding\n\nPhilosophical debate: do they “understand” or just pattern-match?\n\nPractically: they can fail in surprising ways\n\nSolution: Don’t anthropomorphize, verify critical outputs","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#what-llms-cant-do-well","position":53},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Comparing Agent Paradigms","lvl2":"Limitations and Considerations"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#comparing-agent-paradigms","position":54},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Comparing Agent Paradigms","lvl2":"Limitations and Considerations"},"content":"Let’s synthesize what we’ve learned:\n\nAspect\n\nRule-Based Agents\n\nLearning Agents (LLMs)\n\nHow they work\n\nExecute programmed rules\n\nGenerate text predictions\n\nBehavior source\n\nExplicit code\n\nLearned patterns\n\nFlexibility\n\nFixed to programmed scenarios\n\nAdapt to novel situations\n\nPredictability\n\nFully deterministic\n\nStochastic, sometimes surprising\n\nSpeed\n\nVery fast (microseconds)\n\nSlower (seconds)\n\nCost\n\nMinimal (CPU only)\n\nExpensive (GPU inference)\n\nAccuracy\n\nPerfect (within rules)\n\nApproximate, needs validation\n\nDevelopment\n\nCode each behavior\n\nPrompt desired behavior\n\nDebugging\n\nRead the code\n\nPrompt engineering trial-and-error\n\nBest for\n\nWell-defined, repetitive tasks\n\nOpen-ended, language-heavy tasks\n\nThe key insight: These aren’t competing approaches - they’re complementary!\n\nThe most powerful systems combine both:\n\nLLMs for reasoning, planning, and natural language\n\nTraditional code for precise computation, data storage, and execution\n\nThis hybrid approach is what we’ll explore in the rest of this module.\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#comparing-agent-paradigms","position":55},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Connecting to Complex Systems"},"type":"lvl2","url":"/l-a1-01-from-rule-based-to-learning-agents#connecting-to-complex-systems","position":56},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Connecting to Complex Systems"},"content":"\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#connecting-to-complex-systems","position":57},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Emergence at Multiple Scales","lvl2":"Connecting to Complex Systems"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#emergence-at-multiple-scales","position":58},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Emergence at Multiple Scales","lvl2":"Connecting to Complex Systems"},"content":"Throughout this course, we’ve studied emergence:\n\nNetworks:\n\nLocal: Individual connections\n\nGlobal: Small-world structure, clustering\n\nGame Theory:\n\nLocal: Individual strategy choices\n\nGlobal: Nash equilibria, social welfare\n\nABMs:\n\nLocal: Simple agent rules\n\nGlobal: Segregation, wealth inequality\n\nLLMs Add a New Dimension:\n\nTraining: Next-word prediction objective\n\nEmergent: Reasoning, tool use, theory of mind\n\nBut here’s what’s really interesting for our course:\n\nWhat happens when we build multi-agent systems with AI agents?\n\nIf simple agents (Schelling model) produce complex outcomes...\n\nWhat do complex agents produce?","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#emergence-at-multiple-scales","position":59},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Preview: Agentic AI Systems","lvl2":"Connecting to Complex Systems"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#preview-agentic-ai-systems","position":60},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Preview: Agentic AI Systems","lvl2":"Connecting to Complex Systems"},"content":"In the coming lectures, we’ll explore:\n\nLecture A1.02: RAG and Knowledge Augmentation\n\nHow to give agents access to external knowledge\n\nBuilding agents that can retrieve and reason over documents\n\nConnection to information networks\n\nLecture A1.03: Multi-Agent Conversations\n\nAI agents communicating with each other\n\nEmergent coordination and conflict\n\nConnection to game theory and strategic interaction","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#preview-agentic-ai-systems","position":61},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Why This Matters","lvl2":"Connecting to Complex Systems"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#why-this-matters","position":62},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Why This Matters","lvl2":"Connecting to Complex Systems"},"content":"AI agents aren’t just a cool technology - they’re becoming a fundamental part of social complexity:\n\nEconomic Systems:\n\nAI trading agents in financial markets\n\nAlgorithmic pricing and competition\n\nAutomated negotiation\n\nSocial Systems:\n\nAI content creators and curators\n\nChatbots as social actors\n\nSynthetic data and simulation\n\nScientific Systems:\n\nAI research assistants\n\nAutomated hypothesis generation\n\nTool-augmented discovery\n\nUnderstanding how these systems work, and how to build them, is increasingly essential for computational social science.\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#why-this-matters","position":63},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Exercises"},"type":"lvl2","url":"/l-a1-01-from-rule-based-to-learning-agents#exercises","position":64},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Exercises"},"content":"\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#exercises","position":65},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Exercise 1: Prompt Engineering Fundamentals","lvl2":"Exercises"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#exercise-1-prompt-engineering-fundamentals","position":66},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Exercise 1: Prompt Engineering Fundamentals","lvl2":"Exercises"},"content":"Part A: Compare prompting styles\n\nWrite three different prompts that ask an LLM to explain the Schelling model:\n\nMinimal prompt (one sentence)\n\nStructured prompt (with role, task, and constraints)\n\nFew-shot prompt (with examples of explanations)\n\nCall the API with each prompt and compare the responses. Which works best? Why?\n\nPart B: Constraint following\n\nDesign prompts to get an LLM to:\n\nRespond in exactly 50 words (±5 words)\n\nRespond only with valid JSON\n\nRespond as a numbered list with exactly 3 items\n\nTest each prompt. Do the constraints hold? What happens when they fail? Do different models have more consistent results?\n\n# TODO: Your code here\n\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#exercise-1-prompt-engineering-fundamentals","position":67},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Exercise 2: Agent Comparison - Schelling Reimagined","lvl2":"Exercises"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#exercise-2-agent-comparison-schelling-reimagined","position":68},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Exercise 2: Agent Comparison - Schelling Reimagined","lvl2":"Exercises"},"content":"Scenario: We want to model neighborhood preferences, but with more nuanced agents.\n\nPart A: Traditional ABM approach\n\nWrite pseudocode for a rule-based agent that:\n\nHas attributes: location, income, family_size, preferences\n\nDecides whether to move based on:\n\nNeighborhood similarity\n\nHousing costs\n\nSchool quality\n\nPart B: AI agent approach\n\nCreate a prompt that asks an LLM to role-play as a household deciding whether to move.\n\nGive it:\n\nCurrent neighborhood statistics\n\nAlternative neighborhood statistics\n\nHousehold characteristics\n\nAsk it to reason about the decision and output a choice + explanation.\n\nPart C: Comparison\n\nRun the AI agent on 5 different scenarios. Analyze:\n\nDoes it consider factors you didn’t explicitly mention?\n\nIs it consistent across similar scenarios?\n\nHow does its reasoning differ from rule-based logic?\n\n# TODO: Your code here\n\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#exercise-2-agent-comparison-schelling-reimagined","position":69},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Exercise 3: Chain-of-Thought for Network Analysis","lvl2":"Exercises"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#exercise-3-chain-of-thought-for-network-analysis","position":70},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Exercise 3: Chain-of-Thought for Network Analysis","lvl2":"Exercises"},"content":"Task: Use an LLM with chain-of-thought reasoning to analyze network structure.\n\nSetup: Define a small network in text:Nodes: A, B, C, D, E\nEdges: A-B, B-C, C-D, D-E, E-A, A-C\n\nQuestions to ask the LLM (using CoT prompting):\n\nWhat is the diameter of this network?\n\nWhich node has the highest degree centrality?\n\nAre there any triangles (3-cycles)?\n\nIf we remove edge A-C, does the network remain connected?\n\nRequirements:\n\nUse “let’s think step by step” prompting\n\nVerify the LLM’s answers by computing them yourself in Julia\n\nDocument where the LLM is correct vs. incorrect\n\nExtension: Try with a larger network (8-10 nodes). Does accuracy degrade?\n\n# TODO: Your code here\n\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#exercise-3-chain-of-thought-for-network-analysis","position":71},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Exercise 4: Structured Data Generation","lvl2":"Exercises"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#exercise-4-structured-data-generation","position":72},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Exercise 4: Structured Data Generation","lvl2":"Exercises"},"content":"Objective: Use an LLM to generate synthetic agent data for an ABM simulation.\n\nTask: Create a prompt that generates data for 20 agents in a “social media network” simulation.\n\nEach agent needs:\n\nid (integer 1-20)\n\npersonality (one of: influencer, lurker, engager, contrarian)\n\nposting_frequency (float 0.0-1.0, posts per day)\n\ntopics (array of 1-3 topics from: politics, sports, tech, entertainment, science)\n\nfollower_count (integer, should correlate somewhat with personality)\n\nRequirements:\n\nGet the LLM to output valid JSON\n\nParse the JSON into a Julia DataFrame\n\nValidate the data (check types, ranges, correlations)\n\nVisualize the distribution of personalities and topics\n\nBonus: Ask the LLM to also generate a “friendship network” as an edge list - who follows whom?\n\nReflection:\n\nWhat advantages does LLM generation have over random generation?\n\nWhat disadvantages or risks?\n\n# TODO: Your code here\n\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#exercise-4-structured-data-generation","position":73},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Exercise 5: Tool Use - Network Statistics Calculator","lvl2":"Exercises"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#exercise-5-tool-use-network-statistics-calculator","position":74},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Exercise 5: Tool Use - Network Statistics Calculator","lvl2":"Exercises"},"content":"Objective: Build a simple agent that uses Julia functions as tools.\n\nPart A: Define tools\n\nCreate Julia functions for:calculate_clustering_coefficient(edges, node)\nfind_shortest_path(edges, source, target)\ncalculate_betweenness_centrality(edges, node)\n\nYou can use simple implementations or leverage Graphs.jl.\n\nPart B: Create tool-use prompt\n\nWrite a prompt that:\n\nDescribes what each function does (the “tool documentation”)\n\nGives the agent a network analysis question\n\nAsks it to identify which tool(s) to use and with what arguments\n\nPart C: Execute and iterate\n\nCreate a loop that:\n\nSends prompt to LLM\n\nParses LLM’s tool call request\n\nExecutes the tool in Julia\n\nReturns result to LLM\n\nGets final answer from LLM\n\nTest cases:\n\n“Which node is most central in this network?” (needs betweenness)\n\n“How clustered is node A?” (needs clustering coefficient)\n\n“What’s the shortest path from B to E?” (needs shortest path)\n\nChallenge: Can the agent chain multiple tool calls? (“Find the shortest path from A to C, then calculate the clustering coefficient of each node along that path”)\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#exercise-5-tool-use-network-statistics-calculator","position":75},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Exercise 6: Package Organization - Moving API Functions to CAP6318","lvl2":"Exercises"},"type":"lvl3","url":"/l-a1-01-from-rule-based-to-learning-agents#exercise-6-package-organization-moving-api-functions-to-cap6318","position":76},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl3":"Exercise 6: Package Organization - Moving API Functions to CAP6318","lvl2":"Exercises"},"content":"Objective: Practice good code organization by moving reusable functions to your course package.\n\nThroughout this course, you’ve been building a CAP6318 package to organize your code. Now it’s time to add AI agent capabilities to it!\n\nPart A: Create an AI module in your package\n\nIn your CAP6318 package directory, create a new file src/AI.jl with the following structure:module AI\n\nusing HTTP\nusing JSON3\n\n# Export the functions so they can be used outside the module\nexport call_claude, call_gpt\n\n# Include your call_claude and call_gpt functions here\n# (copy from the lecture, but consider adding improvements!)\n\nend  # module\n\nPart B: Integrate into your package\n\nAdd using DotEnv to your CAP6318 package’s Project.toml dependencies\n\nIn your main src/CAP6318.jl file, add:include(\"AI.jl\")\nusing .AI\n\nRe-export the AI functions:export call_claude, call_gpt\n\nPart C: Test your package\n\nBack in this notebook (or a new one), test that your package works:using CAP6318\n\n# Test with a simple prompt\nresponse = call_claude(\"What is computational social science? Answer in 2 sentences.\")\nprintln(response)\n\nPart D: Enhancements (Optional)\n\nConsider adding these improvements to your AI module:\n\nError Handling: Wrap API calls in try-catch blocks with informative error messages\n\nResponse Caching: Store responses in a dictionary to avoid repeated API calls with the same prompt\n\nToken Counting: Add a function to estimate token usage before making calls\n\nLogging: Track all API calls (prompts, responses, models used) to a file\n\nRate Limiting: Add a small delay between calls to avoid hitting rate limits\n\nMultiple Providers: Create a unified call_llm() function that works with both Anthropic and OpenAI\n\nExample Enhanced Function:function call_claude(prompt; model=\"claude-haiku-4-5\", max_tokens=1024, verbose=false)\n    if verbose\n        println(\"Calling $model with prompt of length $(length(prompt)) characters...\")\n    end\n    \n    try\n        # API call code here\n        response = # ... your API call ...\n        \n        if verbose\n            println(\"✓ Received response of $(length(response)) characters\")\n        end\n        \n        return response\n    catch e\n        @error \"Failed to call Claude API\" exception=e\n        rethrow(e)\n    end\nend\n\nReflection:\n\nWhy is it better to put these functions in a package rather than copying them into each notebook?\n\nWhat other AI-related functionality might you add to this module?\n\nHow does this relate to software engineering best practices?\n\nDeliverable: Show that you can successfully import and use call_claude or call_gpt from your CAP6318 package.\n\n# TODO: Your code here for Exercise 6\n# Hint: After setting up your package, you should be able to do:\n# using CAP6318\n# response = call_claude(\"Hello!\")\n# println(response)\n\n\n# TODO: Your code here\n\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#exercise-6-package-organization-moving-api-functions-to-cap6318","position":77},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Reflection Questions"},"type":"lvl2","url":"/l-a1-01-from-rule-based-to-learning-agents#reflection-questions","position":78},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Reflection Questions"},"content":"Consider these questions as you work through the exercises:\n\nOn Emergence: We saw emergent behavior in both ABMs (segregation from simple rules) and LLMs (reasoning from next-word prediction). Are these the same kind of emergence? How do they differ?\n\nOn Agency: What does it mean for an LLM to be an “agent”? Does it have goals? Preferences? Beliefs? Or are these anthropomorphizations?\n\nOn Predictability: Rule-based ABMs are deterministic but produce unpredictable aggregate outcomes. AI agents are stochastic but often produce predictable responses. What are the implications for simulation and modeling?\n\nOn Control: With rule-based agents, we control them by writing code. With AI agents, we control them by writing prompts. Which gives us more control? Which is more brittle?\n\nOn Social Complexity: If AI agents become widespread in social and economic systems, how might that change the dynamics? Will they amplify existing patterns or create new ones?\n\nWe’ll explore these questions more deeply throughout the module.\n\n","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#reflection-questions","position":79},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Summary"},"type":"lvl2","url":"/l-a1-01-from-rule-based-to-learning-agents#summary","position":80},{"hierarchy":{"lvl1":"From Rule-Based to Learning Agents","lvl2":"Summary"},"content":"In this lecture, we’ve:\n\n✓ Distinguished between rule-based agents (traditional ABMs) and learning agents (LLMs)\n\n✓ Understood how LLMs work at a high level (next-word prediction → general reasoning)\n\n✓ Learned about transformer architecture and attention mechanisms\n\n✓ Implemented basic LLM API calls in Julia (Anthropic and OpenAI)\n\n✓ Explored emergent capabilities: chain-of-thought reasoning and tool use\n\n✓ Compared the strengths and limitations of both agent paradigms\n\n✓ Connected AI agents to broader themes in complex systems\n\nKey Takeaways:\n\nLLMs are trained on next-word prediction but develop general capabilities - an example of emergence\n\nPrompting is programming - but in natural language with probabilistic outcomes\n\nChain-of-thought and tool use extend what agents can do beyond their training\n\nRule-based and learning agents are complementary - hybrid systems combine their strengths\n\nMulti-agent AI systems represent a new frontier in computational social science\n\nNext Lecture: We’ll explore how to augment AI agents with external knowledge using Retrieval Augmented Generation (RAG), connecting to information networks and knowledge graphs.","type":"content","url":"/l-a1-01-from-rule-based-to-learning-agents#summary","position":81},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge"},"type":"lvl1","url":"/l-a1-02-rag-pattern-augmented-knowledge","position":0},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nL.A1.01 (LLMs and API calls)\n\nBasic understanding of vector spaces\n\nNetworks concepts (Weeks 3-5)\n\nRequired Julia Packages\n\nInstall the following packages if you haven’t already:using Pkg\nPkg.add([\"HTTP\", \"JSON3\", \"DotEnv\", \"LinearAlgebra\", \"DataFrames\"])\n\nOutcomes\n\nUnderstand the limitations of parametric knowledge in LLMs\n\nImplement a complete Retrieval-Augmented Generation (RAG) system\n\nWork with embeddings and perform vector similarity search\n\nDesign knowledge bases for domain-specific AI applications\n\nAnalyze trade-offs between parametric and retrieval-based knowledge\n\nReferences\n\nLewis et al. (2020) “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks” \n\narXiv:2005.11401\n\nGao et al. (2023) “Retrieval-Augmented Generation for Large Language Models: A Survey” \n\narXiv:2312.10997\n\nOpenAI Embeddings Documentation: \n\nhttps://​platform​.openai​.com​/docs​/guides​/embeddings\n\nOpenAI Responses API Quickstart: \n\nhttps://​platform​.openai​.com​/docs​/quickstart​?api​-mode​=​responses\n\nAnthropic Context Window Documentation: \n\nhttps://​docs​.anthropic​.com​/claude​/docs​/models​-overview\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge","position":1},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"The Knowledge Problem"},"type":"lvl2","url":"/l-a1-02-rag-pattern-augmented-knowledge#the-knowledge-problem","position":2},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"The Knowledge Problem"},"content":"In the previous lecture we learned how to interact with LLMs via API calls\n\nWe saw that these models can be remarkably helpful for various tasks\n\nHowever, LLMs have a fundamental limitation: they only “know” what was in their training data\n\nThis creates several problems that we’ll explore now\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#the-knowledge-problem","position":3},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Problem 1: Knowledge Cutoffs","lvl2":"The Knowledge Problem"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#problem-1-knowledge-cutoffs","position":4},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Problem 1: Knowledge Cutoffs","lvl2":"The Knowledge Problem"},"content":"LLMs are trained on data collected up to a specific date\n\nFor example, GPT-4 (original) had a knowledge cutoff of September 2021\n\nClaude 3.5 Sonnet has a knowledge cutoff of April 2024\n\nAny events, research, or information after the cutoff date is unknown to the model\n\nThis means:\n\nCan’t answer questions about recent events\n\nDoesn’t know about new research papers or discoveries\n\nUnaware of updated statistics or data\n\nExample: If you ask GPT-4 (original) about a paper published in 2023, it will either say it doesn’t know or worse, hallucinate details about a paper it has never seen.\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#problem-1-knowledge-cutoffs","position":5},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Problem 2: Hallucination","lvl2":"The Knowledge Problem"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#problem-2-hallucination","position":6},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Problem 2: Hallucination","lvl2":"The Knowledge Problem"},"content":"LLMs are trained to generate plausible-sounding text\n\nWhen asked about something they don’t know, they often hallucinate: generate confident-sounding but factually incorrect information\n\nThis is particularly dangerous because:\n\nThe model sounds authoritative\n\nUsers may not realize the information is false\n\nThe hallucinated content can include fake citations, statistics, or facts\n\nExample: Ask an LLM about a research paper that doesn’t exist. It might generate a plausible abstract, author names, and even “key findings” - all completely fabricated.\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#problem-2-hallucination","position":7},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Problem 3: Domain-Specific Knowledge","lvl2":"The Knowledge Problem"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#problem-3-domain-specific-knowledge","position":8},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Problem 3: Domain-Specific Knowledge","lvl2":"The Knowledge Problem"},"content":"Even within their training data, LLMs have uneven knowledge\n\nSome domains are well-represented in training data (e.g., popular programming languages)\n\nOthers are sparse (e.g., specialized academic subfields, proprietary company data)\n\nFor your organization’s specific documents, data, or knowledge base, the LLM knows nothing\n\nExample: You want an AI assistant to help with your company’s internal policies, product documentation, or research papers. The LLM has never seen these documents.\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#problem-3-domain-specific-knowledge","position":9},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Connection to Network Information Flow","lvl2":"The Knowledge Problem"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#connection-to-network-information-flow","position":10},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Connection to Network Information Flow","lvl2":"The Knowledge Problem"},"content":"Recall from Weeks 3-4 our study of information diffusion in networks\n\nWe saw how information flows through network structures\n\nKey insight: who you’re connected to determines what information you can access\n\nLLMs face a similar problem:\n\nTheir “connections” are frozen at training time\n\nThey can’t access new information sources\n\nThey can’t form new “edges” to external knowledge\n\nRAG solves this by creating a dynamic connection between the LLM and external knowledge sources\n\nThink of RAG as giving the LLM the ability to form new edges in the information network on-demand\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#connection-to-network-information-flow","position":11},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"The Solution: Retrieval-Augmented Generation","lvl2":"The Knowledge Problem"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#the-solution-retrieval-augmented-generation","position":12},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"The Solution: Retrieval-Augmented Generation","lvl2":"The Knowledge Problem"},"content":"Instead of relying solely on parametric knowledge (what’s encoded in model weights), we can augment the LLM with retrieval\n\nBasic idea:\n\nUser asks a question\n\nSearch a knowledge base for relevant information\n\nProvide that information to the LLM as context\n\nLLM generates answer based on retrieved information\n\nThis approach:\n\nEliminates knowledge cutoff problem (use up-to-date sources)\n\nReduces hallucination (model works from provided facts)\n\nEnables domain-specific applications (use your own documents)\n\nProvides citations (you know which documents were used)\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#the-solution-retrieval-augmented-generation","position":13},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Embeddings: Representing Meaning as Vectors"},"type":"lvl2","url":"/l-a1-02-rag-pattern-augmented-knowledge#embeddings-representing-meaning-as-vectors","position":14},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Embeddings: Representing Meaning as Vectors"},"content":"To implement retrieval, we need to search for relevant documents\n\nBut how do we determine if a document is relevant to a query?\n\nThe key innovation: embeddings - representations of text as high-dimensional vectors\n\nEmbeddings capture semantic meaning: similar meanings → similar vectors\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#embeddings-representing-meaning-as-vectors","position":15},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"What are Embeddings?","lvl2":"Embeddings: Representing Meaning as Vectors"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#what-are-embeddings","position":16},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"What are Embeddings?","lvl2":"Embeddings: Representing Meaning as Vectors"},"content":"An embedding is a function f: \\text{Text} \\rightarrow \\mathbb{R}^d that maps text to a d-dimensional vector\n\nTypically d ranges from 384 to 3072 dimensions\n\nKey property: texts with similar meanings have similar embeddings (vectors close together in vector space)\n\nIntuition: Think of each dimension as capturing some aspect of meaning\n\nOne dimension might capture “technical vs casual”\n\nAnother might capture “positive vs negative sentiment”\n\nAnother might capture “about networks vs about game theory”\n\nWith hundreds or thousands of dimensions, we can capture nuanced semantic relationships\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#what-are-embeddings","position":17},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Example: Word Analogies","lvl2":"Embeddings: Representing Meaning as Vectors"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#example-word-analogies","position":18},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Example: Word Analogies","lvl2":"Embeddings: Representing Meaning as Vectors"},"content":"One famous property of embeddings is that they capture relational meaning:\\text{embedding}(\\text{\"king\"}) - \\text{embedding}(\\text{\"man\"}) + \\text{embedding}(\\text{\"woman\"}) \\approx \\text{embedding}(\\text{\"queen\"})\n\nThis works because the embedding space organizes concepts by their relationships:\n\nThe vector from “man” to “king” represents “royalty”\n\nAdding that same vector to “woman” gives you something close to “queen”\n\nSimilar patterns work for other relationships:\n\nParis - France + Germany ≈ Berlin\n\nWalking - Walked + Swimming ≈ Swam\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#example-word-analogies","position":19},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Measuring Similarity: Cosine Similarity","lvl2":"Embeddings: Representing Meaning as Vectors"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#measuring-similarity-cosine-similarity","position":20},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Measuring Similarity: Cosine Similarity","lvl2":"Embeddings: Representing Meaning as Vectors"},"content":"Once we have embeddings, we need a way to measure similarity between vectors\n\nThe most common metric is cosine similarity\n\nFor two vectors \\mathbf{a} and \\mathbf{b}:\\text{cosine\\_similarity}(\\mathbf{a}, \\mathbf{b}) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{||\\mathbf{a}|| \\, ||\\mathbf{b}||} = \\frac{\\sum_{i=1}^d a_i b_i}{\\sqrt{\\sum_{i=1}^d a_i^2} \\sqrt{\\sum_{i=1}^d b_i^2}}\n\nReturns a value between -1 and 1\n\n1: vectors point in same direction (very similar)\n\n0: vectors are orthogonal (unrelated)\n\n-1: vectors point in opposite directions (opposite meaning)\n\nWhy cosine and not Euclidean distance?\n\nCosine measures angle, not magnitude\n\nMakes sense for text: a longer document isn’t necessarily “farther” in meaning\n\nEmbedding models are typically optimized for cosine similarity\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#measuring-similarity-cosine-similarity","position":21},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Creating Embeddings with OpenAI","lvl2":"Embeddings: Representing Meaning as Vectors"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#creating-embeddings-with-openai","position":22},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Creating Embeddings with OpenAI","lvl2":"Embeddings: Representing Meaning as Vectors"},"content":"Let’s see how to create embeddings using OpenAI’s API.\n\nSetup: Before running the code below, make sure you have a .env file in your working directory with your OpenAI API key:OPENAI_API_KEY=sk-your-api-key-here\n\nThe DotEnv package will automatically load these environment variables from the .env file.\n\nusing HTTP, JSON3, DotEnv\n\n# Load environment variables from .env file\nDotEnv.load!()\n\n# Load API key from environment\nOPENAI_API_KEY = ENV[\"OPENAI_API_KEY\"]\n\nfunction get_embedding(text::String; model=\"text-embedding-3-small\")\n    \"\"\"\n    Get embedding vector for input text using OpenAI's API\n\n    Args:\n        text: Input text to embed\n        model: Embedding model to use (default: text-embedding-3-small)\n\n    Returns:\n        Vector of floats representing the embedding\n    \"\"\"\n    url = \"https://api.openai.com/v1/embeddings\"\n\n    headers = [\n        \"Authorization\" => \"Bearer $(OPENAI_API_KEY)\",\n        \"Content-Type\" => \"application/json\"\n    ]\n\n    body = JSON3.write(Dict(\n        \"input\" => text,\n        \"model\" => model\n    ))\n\n    response = HTTP.post(url, headers, body)\n    result = JSON3.read(String(response.body))\n\n    return Vector(result.data[1].embedding)\nend\n\nLet’s test this with some network-related concepts:\n\n# Embed some network-related texts\ntexts = [\n    \"Graph theory studies the mathematical structure of networks\",\n    \"The clustering coefficient measures the tendency of nodes to form triangles\",\n    \"Preferential attachment leads to power law degree distributions\",\n    \"I enjoy eating pizza with extra cheese\"\n]\n\nembeddings = [get_embedding(text) for text in texts]\n\nprintln(\"Embedding dimension: \", length(embeddings[1]))\nprintln(\"First few values of first embedding: \", embeddings[1][1:5])\n\nNow let’s compute cosine similarity between these texts:\n\nusing LinearAlgebra\n\nfunction cosine_similarity(a::Vector{Float64}, b::Vector{Float64})\n    \"\"\"\n    Compute cosine similarity between two vectors\n    \"\"\"\n    return dot(a, b) / (norm(a) * norm(b))\nend\n\n# Compare first text (graph theory) to all others\nprintln(\"Similarities to: '\", texts[1], \"'\\n\")\nfor (i, text) in enumerate(texts)\n    sim = cosine_similarity(embeddings[1], embeddings[i])\n    println(\"Text $i ($(text[1:min(40, end)])...): $(round(sim, digits=4))\")\nend\n\nWhat do we see?\n\nThe first three texts (all about networks) have high similarity to each other (typically > 0.7)\n\nThe pizza text has low similarity to the network texts (typically < 0.5)\n\nThis demonstrates that embeddings capture semantic meaning\n\nTexts about similar topics cluster together in the embedding space\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#creating-embeddings-with-openai","position":23},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Exercise 1: Exploring Embeddings","lvl2":"Embeddings: Representing Meaning as Vectors"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#exercise-1-exploring-embeddings","position":24},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Exercise 1: Exploring Embeddings","lvl2":"Embeddings: Representing Meaning as Vectors"},"content":"Create embeddings for the following texts and compute their pairwise similarities:\n\n“Nash equilibrium is a solution concept in game theory”\n\n“Players choose strategies to maximize their payoffs”\n\n“Agent-based models simulate individual decision makers”\n\n“The weather today is sunny and warm”\n\nQuestions:\n\nWhich pairs of texts have the highest similarity?\n\nDoes the game theory text have higher similarity to the ABM text or the weather text? Why?\n\nWhat does this tell you about how embeddings capture domain knowledge?\n\n# TODO: your code here\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#exercise-1-exploring-embeddings","position":25},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Building a RAG Pipeline"},"type":"lvl2","url":"/l-a1-02-rag-pattern-augmented-knowledge#building-a-rag-pipeline","position":26},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Building a RAG Pipeline"},"content":"Now that we understand embeddings, we can build a complete RAG system\n\nA RAG pipeline has four main stages:\n\nChunking: Break documents into manageable pieces\n\nEmbedding: Convert chunks to vectors and store them\n\nRetrieval: Find most relevant chunks for a query\n\nGeneration: Use LLM to answer query with retrieved context\n\nLet’s build each component step by step.\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#building-a-rag-pipeline","position":27},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Stage 1: Chunking","lvl2":"Building a RAG Pipeline"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#stage-1-chunking","position":28},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Stage 1: Chunking","lvl2":"Building a RAG Pipeline"},"content":"Most documents are too long to embed as a single unit\n\nWe need to break them into chunks - smaller, semantically meaningful pieces\n\nTypical chunk sizes: 100-500 words or 400-2000 characters\n\nWhy chunk?\n\nEmbeddings work best on focused, coherent pieces of text\n\nEnables fine-grained retrieval (find specific relevant paragraphs, not whole documents)\n\nFits within LLM context limits (we can only inject so much context)\n\nChunking strategies:\n\nFixed size: Every N characters or words\n\nNatural boundaries: By paragraph, section, or sentence\n\nSemantic: Using embeddings to identify topic shifts\n\nFor this lecture, we’ll use a simple paragraph-based chunking:\n\nfunction chunk_text(text::String; max_chunk_size::Int=1000, overlap::Int=100)\n    \"\"\"\n    Split text into overlapping chunks\n\n    Args:\n        text: Input text to chunk\n        max_chunk_size: Maximum characters per chunk\n        overlap: Number of characters to overlap between chunks\n\n    Returns:\n        Vector of text chunks\n    \"\"\"\n    # Split by paragraphs first (double newline)\n    paragraphs = split(text, \"\\n\\n\")\n\n    chunks = String[]\n    current_chunk = \"\"\n\n    for para in paragraphs\n        # If adding this paragraph would exceed max size, save current chunk\n        if length(current_chunk) + length(para) > max_chunk_size && !isempty(current_chunk)\n            push!(chunks, strip(current_chunk))\n            # Start new chunk with overlap from previous\n            current_chunk = current_chunk[max(1, end-overlap):end]\n        end\n\n        current_chunk *= para * \"\\n\\n\"\n    end\n\n    # Don't forget last chunk\n    if !isempty(strip(current_chunk))\n        push!(chunks, strip(current_chunk))\n    end\n\n    return chunks\nend\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#stage-1-chunking","position":29},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Stage 2: Vector Database","lvl2":"Building a RAG Pipeline"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#stage-2-vector-database","position":30},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Stage 2: Vector Database","lvl2":"Building a RAG Pipeline"},"content":"Once we have chunks and embeddings, we need to store them efficiently\n\nA vector database stores embeddings and enables fast similarity search\n\nFor this lecture, we’ll build a simple in-memory vector store\n\nProduction systems typically use specialized vector databases like:\n\nPinecone\n\nWeaviate\n\nQdrant\n\nChroma\n\npgvector (PostgreSQL extension)\n\nusing DataFrames\n\nmutable struct VectorStore\n    documents::Vector{String}          # Original text chunks\n    embeddings::Vector{Vector{Float64}}  # Corresponding embeddings\n    metadata::Vector{Dict{String, Any}}  # Optional metadata (source, page, etc.)\nend\n\n# Constructor for empty store\nVectorStore() = VectorStore(String[], Vector{Float64}[], Dict{String, Any}[])\n\nfunction add_documents!(store::VectorStore, docs::Vector{String}; metadata=nothing)\n    \"\"\"\n    Add documents to the vector store by computing and storing their embeddings\n    \"\"\"\n    println(\"Embedding $(length(docs)) documents...\")\n\n    for (i, doc) in enumerate(docs)\n        # Get embedding\n        emb = get_embedding(doc)\n\n        # Store document, embedding, and metadata\n        push!(store.documents, doc)\n        push!(store.embeddings, emb)\n\n        if metadata !== nothing && i <= length(metadata)\n            push!(store.metadata, metadata[i])\n        else\n            push!(store.metadata, Dict(\"index\" => i))\n        end\n\n        if i % 10 == 0\n            println(\"  Processed $i/$(length(docs))...\")\n        end\n    end\n\n    println(\"Done! Store now contains $(length(store.documents)) documents.\")\nend\n\nfunction search(store::VectorStore, query::String; top_k::Int=5)\n    \"\"\"\n    Search for most similar documents to query\n\n    Args:\n        store: Vector store to search\n        query: Search query text\n        top_k: Number of results to return\n\n    Returns:\n        DataFrame with columns: rank, document, similarity, metadata\n    \"\"\"\n    # Embed the query\n    query_emb = get_embedding(query)\n\n    # Compute similarities to all documents\n    similarities = [cosine_similarity(query_emb, doc_emb) for doc_emb in store.embeddings]\n\n    # Get top k indices\n    top_indices = partialsortperm(similarities, 1:min(top_k, length(similarities)), rev=true)\n\n    # Build result dataframe\n    results = DataFrame(\n        rank = 1:length(top_indices),\n        document = store.documents[top_indices],\n        similarity = similarities[top_indices],\n        metadata = store.metadata[top_indices]\n    )\n\n    return results\nend\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#stage-2-vector-database","position":31},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Stage 3 & 4: Retrieval and Generation","lvl2":"Building a RAG Pipeline"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#stage-3-4-retrieval-and-generation","position":32},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Stage 3 & 4: Retrieval and Generation","lvl2":"Building a RAG Pipeline"},"content":"Now we can combine retrieval with LLM generation\n\nThe key is to inject retrieved documents into the LLM’s context\n\nWe’ll create a function that:\n\nTakes a user query\n\nRetrieves relevant chunks from vector store\n\nConstructs instructions with retrieved context\n\nSends to LLM via OpenAI’s Responses API for final answer\n\nNote: We’re using OpenAI’s Responses API (/v1/responses) which is the modern successor to the Chat Completions API. The Responses API uses instructions for system-level guidance and input for user queries, providing a cleaner interface for stateful interactions.\n\nfunction rag_query(store::VectorStore, query::String; top_k::Int=3, model::String=\"gpt-5\")\n    \"\"\"\n    Answer a query using RAG: retrieve relevant docs, then generate answer\n\n    Args:\n        store: Vector store containing knowledge base\n        query: User's question\n        top_k: Number of documents to retrieve\n        model: OpenAI model to use for generation (default: gpt-5)\n\n    Returns:\n        Generated answer and retrieved documents\n    \"\"\"\n    # Step 1: Retrieve relevant documents\n    results = search(store, query; top_k=top_k)\n\n    # Step 2: Construct context from retrieved documents\n    context = \"\"\n    for i in 1:nrow(results)\n        context *= \"Document $i:\\n$(results.document[i])\\n\\n\"\n    end\n\n    # Step 3: Build instructions with context\n    instructions = \"\"\"\n    You are a helpful assistant that answers questions based on provided context.\n    Use the context below to answer the user's question. If the context doesn't\n    contain enough information to answer the question, say so - do not make up information.\n\n    Context:\n    $(context)\n    \"\"\"\n\n    # Step 4: Call LLM using Responses API\n    response = call_gpt(\n        query;\n        instructions=instructions,\n        model=model\n    )\n\n    return (answer=response, sources=results)\nend\n\nfunction call_gpt(input::String; instructions::String=\"\", model::String=\"gpt-5-nano\", reasoning_effort::String=\"low\")\n    url = \"https://api.openai.com/v1/responses\"\n\n    # OPENAI_API_KEY should be loaded from ENV via DotEnv\n    headers = [\n        \"Authorization\" => \"Bearer $(ENV[\"OPENAI_API_KEY\"])\",\n        \"Content-Type\" => \"application/json\"\n    ]\n\n    # Build request body with Responses API format\n    request_body = Dict(\n        \"model\" => model,\n        \"input\" => input,\n        \"reasoning\" => Dict(\"effort\" => reasoning_effort)\n    )\n\n    # Add instructions if provided\n    if !isempty(instructions)\n        request_body[\"instructions\"] = instructions\n    end\n\n    body = JSON3.write(request_body)\n\n    response = HTTP.post(url, headers, body)\n    result = JSON3.read(String(response.body))\n\n    # NOTE: result.output is an array that can have multiple items. We are assuming a simple case here...\n    return result.output[end].content[1].text\nend\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#stage-3-4-retrieval-and-generation","position":33},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Application: Network Analysis Assistant"},"type":"lvl2","url":"/l-a1-02-rag-pattern-augmented-knowledge#application-network-analysis-assistant","position":34},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Application: Network Analysis Assistant"},"content":"Let’s build a practical RAG application: an AI assistant for graph theory and network analysis\n\nWe’ll create a knowledge base from summaries of key network concepts\n\nThis assistant will be able to answer questions about network theory using retrieved information\n\nIn a real application, you would load actual research papers, textbooks, or documentation\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#application-network-analysis-assistant","position":35},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Building the Knowledge Base","lvl2":"Application: Network Analysis Assistant"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#building-the-knowledge-base","position":36},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Building the Knowledge Base","lvl2":"Application: Network Analysis Assistant"},"content":"Let’s create a knowledge base with information about graph theory and network analysis:\n\n# Sample documents about network analysis\n# In practice, you would load these from files, scrape papers, etc.\nnetwork_docs = [\n    \"\"\"\n    Clustering Coefficient\n\n    The clustering coefficient measures the degree to which nodes in a graph tend to\n    cluster together. For a given node, it is defined as the proportion of connections\n    between the node's neighbors which are also connected to each other.\n\n    Formally, for node i with degree k_i, if there are E_i edges between its neighbors,\n    the local clustering coefficient is C_i = 2*E_i / (k_i * (k_i - 1)).\n\n    The global clustering coefficient averages this measure across all nodes. High\n    clustering coefficients are characteristic of social networks and indicate the\n    presence of tightly-knit communities.\n    \"\"\",\n\n    \"\"\"\n    Preferential Attachment and Scale-Free Networks\n\n    Preferential attachment is a mechanism by which networks grow over time. When a new\n    node joins the network, it forms connections preferentially to nodes that already\n    have many connections - the \"rich get richer\" phenomenon.\n\n    The Barabási-Albert model (1999) demonstrated that preferential attachment leads to\n    scale-free networks with power law degree distributions. In such networks, P(k) ~ k^(-γ)\n    where γ is typically between 2 and 3.\n\n    Scale-free networks are characterized by the presence of hubs - nodes with\n    disproportionately high degree. Examples include the Internet, citation networks,\n    and social media platforms.\n    \"\"\",\n\n    \"\"\"\n    Small-World Networks\n\n    Small-world networks, introduced by Watts and Strogatz (1998), exhibit two key properties:\n    high clustering (like regular lattices) and short path lengths (like random graphs).\n\n    The small-world phenomenon, popularly known as \"six degrees of separation,\" refers to\n    the observation that most pairs of nodes in many real networks are connected by short\n    paths, typically of length 6 or less.\n\n    The Watts-Strogatz model generates small-world networks by starting with a ring lattice\n    and randomly rewiring edges with some probability p. For intermediate values of p,\n    the network maintains high clustering while gaining shortcuts that reduce path length.\n    \"\"\",\n\n    \"\"\"\n    Centrality Measures\n\n    Centrality measures identify the most important nodes in a network. Different\n    centrality measures capture different notions of importance:\n\n    1. Degree centrality: Simply counts the number of connections. High degree nodes\n       are \"hubs\" that directly connect to many others.\n\n    2. Betweenness centrality: Counts how often a node lies on shortest paths between\n       other nodes. High betweenness nodes are \"bridges\" that control information flow.\n\n    3. Closeness centrality: Measures the average distance from a node to all others.\n       High closeness nodes can reach the network quickly.\n\n    4. Eigenvector centrality: A node is important if it connects to other important\n       nodes. This is the principle behind Google's PageRank algorithm.\n    \"\"\",\n\n    \"\"\"\n    Community Detection\n\n    Community detection aims to identify groups of nodes that are more densely connected\n    internally than to the rest of the network. Communities represent functional modules\n    or social groups.\n\n    The modularity measure quantifies the quality of a partition. For partition C,\n    modularity Q = (1/2m) * Σ[A_ij - (k_i*k_j/2m)] * δ(c_i, c_j), where m is the total\n    number of edges, A_ij is the adjacency matrix, and δ(c_i, c_j) = 1 if nodes i and j\n    are in the same community.\n\n    Popular algorithms include the Louvain method, which greedily optimizes modularity,\n    and spectral methods based on the graph Laplacian. Community structure appears in\n    social networks (friend groups), biological networks (protein complexes), and\n    information networks (topic clusters).\n    \"\"\",\n\n    \"\"\"\n    Network Resilience and Robustness\n\n    Network resilience refers to a network's ability to maintain functionality when nodes\n    or edges are removed. This is crucial for infrastructure networks, communication systems,\n    and biological systems.\n\n    Scale-free networks exhibit a peculiar property: they are robust to random failures\n    but vulnerable to targeted attacks. Removing random nodes has little effect because\n    most nodes have low degree. However, removing hubs quickly fragments the network.\n\n    The resilience of random graphs is more uniform - they handle both random and targeted\n    removal similarly. Measuring resilience involves computing the size of the largest\n    connected component as nodes are progressively removed.\n    \"\"\",\n\n    \"\"\"\n    Network Formation and Strategic Link Formation\n\n    In many contexts, network connections form through strategic decisions by self-interested\n    agents. Game-theoretic models of network formation consider the costs and benefits of\n    forming links.\n\n    Jackson and Wolinsky (1996) introduced the concept of pairwise stability: a network is\n    pairwise stable if no agent wants to sever a link and no pair of agents wants to form\n    a new link.\n\n    The tension between individual incentives and social welfare is central to network\n    formation theory. The star network, where one central node connects to all others,\n    often minimizes total distance (socially optimal) but may not be pairwise stable\n    without appropriate transfer payments.\n    \"\"\",\n\n    \"\"\"\n    Information Diffusion and Cascades\n\n    Information, behaviors, and innovations spread through networks via social influence.\n    The threshold model (Granovetter, 1978) posits that individuals adopt a behavior when\n    a threshold fraction of their neighbors have adopted it.\n\n    A cascade occurs when an initial adoption by a few nodes triggers a chain reaction\n    of adoptions throughout the network. Whether cascades occur depends on the distribution\n    of thresholds and the network structure.\n\n    Weak ties play a crucial role in diffusion (Granovetter, 1973). While strong ties\n    create dense, clustered groups, weak ties serve as bridges between communities and\n    enable information to reach new populations. This explains why job seekers often find\n    opportunities through acquaintances rather than close friends.\n    \"\"\"\n]\n\nprintln(\"Created knowledge base with $(length(network_docs)) documents\")\n\nNow let’s create our vector store and add these documents:\n\n# Initialize vector store\nnetwork_store = VectorStore()\n\n# Add documents to store (this will take a moment as we embed each document)\nadd_documents!(network_store, network_docs)\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#building-the-knowledge-base","position":37},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Testing Our Network Analysis Assistant","lvl2":"Application: Network Analysis Assistant"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#testing-our-network-analysis-assistant","position":38},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Testing Our Network Analysis Assistant","lvl2":"Application: Network Analysis Assistant"},"content":"Let’s test our RAG system with some questions about networks:\n\n# Question 1: About clustering\nq1 = \"What is the clustering coefficient and how is it calculated?\"\nresult1 = rag_query(network_store, q1)\n\nprintln(\"Question: \", q1)\nprintln(\"\\nAnswer:\\n\", result1.answer)\nprintln(\"\\n\" * \"=\"^80)\nprintln(\"Top sources used:\")\nfor i in 1:min(2, nrow(result1.sources))\n    println(\"\\n[$i] (similarity: $(round(result1.sources.similarity[i], digits=3)))\")\n    println(result1.sources.document[i][1:min(200, end)] * \"...\")\nend\n\n# Question 2: About scale-free networks\nq2 = \"Why are scale-free networks vulnerable to targeted attacks?\"\nresult2 = rag_query(network_store, q2)\n\nprintln(\"Question: \", q2)\nprintln(\"\\nAnswer:\\n\", result2.answer)\n\n# Question 3: About weak ties\nq3 = \"What role do weak ties play in information diffusion?\"\nresult3 = rag_query(network_store, q3)\n\nprintln(\"Question: \", q3)\nprintln(\"\\nAnswer:\\n\", result3.answer)\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#testing-our-network-analysis-assistant","position":39},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Comparing RAG vs Vanilla LLM","lvl2":"Application: Network Analysis Assistant"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#comparing-rag-vs-vanilla-llm","position":40},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Comparing RAG vs Vanilla LLM","lvl2":"Application: Network Analysis Assistant"},"content":"Let’s demonstrate the value of RAG by comparing answers with and without retrieved context:\n\nfunction vanilla_llm_query(query::String; model::String=\"gpt-5\")\n    \"\"\"\n    Query LLM without RAG (no retrieved context)\n    \"\"\"\n    return call_gpt(\n        query;\n        instructions=\"You are a helpful assistant.\",\n        model=model\n    )\nend\n\n# Ask a specific question that requires precise information\nspecific_q = \"What is the formula for local clustering coefficient in a graph?\"\n\nprintln(\"Question: \", specific_q)\nprintln(\"\\n\" * \"=\"^80)\nprintln(\"Vanilla LLM Answer:\")\nprintln(vanilla_llm_query(specific_q))\nprintln(\"\\n\" * \"=\"^80)\nprintln(\"RAG Answer:\")\nprintln(rag_query(network_store, specific_q).answer)\n\nObservations:\n\nBoth answers are likely correct (this is a well-known formula in the LLM’s training data). However:\n\nWith RAG, we know exactly where the answer came from (we can cite sources)\n\nWith RAG, if we had proprietary or recent information, the LLM couldn’t answer without it\n\nWith RAG, we can update knowledge without retraining the model\n\nLet’s test with a question the LLM definitely doesn’t know:\n\n# Add a \"research paper\" about a fictional concept\nfictional_doc = [\"\"\"\nRecent work by Spencer Lyon (2025) introduced the concept of \"resonance centrality\"\nfor dynamic networks. Unlike traditional centrality measures which focus on static\nnetwork structure, resonance centrality captures how a node's importance oscillates\nover time due to feedback loops.\n\nThe resonance centrality R_i(t) for node i at time t is computed as:\nR_i(t) = β * Σ_j A_ij(t) * R_j(t-1) + (1-β) * d_i(t)\n\nwhere A_ij(t) is the time-varying adjacency matrix, d_i(t) is the degree at time t,\nand β ∈ [0,1] controls the memory of past centrality.\n\nLyon showed that in social networks, nodes with high resonance centrality are often\n\"trend catalysts\" - they don't just spread information, but trigger cascades that\nfeed back to amplify their influence in subsequent time periods.\n\"\"\"]\n\nadd_documents!(network_store, fictional_doc)\n\n# Now ask about it\nfictional_q = \"What is resonance centrality and how is it calculated?\"\n\nprintln(\"Question: \", fictional_q)\nprintln(\"\\n\" * \"=\"^80)\nprintln(\"Vanilla LLM Answer:\")\nprintln(vanilla_llm_query(fictional_q))\nprintln(\"\\n\" * \"=\"^80)\nprintln(\"RAG Answer:\")\nprintln(rag_query(network_store, fictional_q).answer)\n\nWhat happened?\n\nThe vanilla LLM either says it doesn’t know, or hallucinates a plausible-sounding definition\n\nThe RAG system correctly retrieves and uses our fictional paper\n\nThis demonstrates how RAG enables working with proprietary, recent, or domain-specific knowledge\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#comparing-rag-vs-vanilla-llm","position":41},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Trade-offs and Design Considerations"},"type":"lvl2","url":"/l-a1-02-rag-pattern-augmented-knowledge#trade-offs-and-design-considerations","position":42},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Trade-offs and Design Considerations"},"content":"Now that we’ve built a working RAG system, let’s discuss key design decisions and trade-offs.\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#trade-offs-and-design-considerations","position":43},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Parametric vs Retrieval-Based Knowledge","lvl2":"Trade-offs and Design Considerations"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#parametric-vs-retrieval-based-knowledge","position":44},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Parametric vs Retrieval-Based Knowledge","lvl2":"Trade-offs and Design Considerations"},"content":"Parametric Knowledge (in model weights):\n\nPros:\n\nFast: no need to search external sources\n\nSynthesizes information from vast training corpus\n\nGood for general knowledge and reasoning\n\nCons:\n\nFixed at training time\n\nCan’t update without retraining\n\nMay hallucinate when uncertain\n\nNo citations or provenance\n\nRetrieval-Based Knowledge (via RAG):\n\nPros:\n\nCan use up-to-date information\n\nAccess to proprietary/specialized knowledge\n\nProvides citations and sources\n\nReduces hallucination\n\nUpdates without retraining\n\nCons:\n\nSlower (requires retrieval step)\n\nQuality depends on retrieval accuracy\n\nRequires maintaining vector database\n\nMay miss information requiring synthesis across many sources\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#parametric-vs-retrieval-based-knowledge","position":45},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Key Design Decisions","lvl2":"Trade-offs and Design Considerations"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#key-design-decisions","position":46},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Key Design Decisions","lvl2":"Trade-offs and Design Considerations"},"content":"1. Chunk Size\n\nSmaller chunks (100-200 words):\n\nMore precise retrieval\n\nBetter for question answering\n\nMay lose context across chunk boundaries\n\nLarger chunks (500-1000 words):\n\nPreserve more context\n\nBetter for complex reasoning\n\nMay include irrelevant information\n\n2. Number of Retrieved Documents (top_k)\n\nFew documents (k=1-3):\n\nFocuses on most relevant information\n\nFaster, uses less context window\n\nMay miss important information\n\nMany documents (k=5-10):\n\nMore comprehensive context\n\nBetter for complex queries\n\nMay include noise, uses more tokens\n\n3. Embedding Model\n\nSmaller models (text-embedding-3-small: 512-1536 dims):\n\nFaster embedding and search\n\nLower cost\n\nSlightly lower quality\n\nLarger models (text-embedding-3-large: 3072 dims):\n\nBetter semantic understanding\n\nMore accurate retrieval\n\nHigher cost and latency\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#key-design-decisions","position":47},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Advanced RAG Techniques","lvl2":"Trade-offs and Design Considerations"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#advanced-rag-techniques","position":48},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Advanced RAG Techniques","lvl2":"Trade-offs and Design Considerations"},"content":"Our implementation is a basic RAG pipeline. Production systems often use:\n\n1. Hybrid Search\n\nCombine vector similarity with keyword search (BM25)\n\nLeverages both semantic and lexical matching\n\nMore robust to different query types\n\n2. Re-ranking\n\nUse a separate model to re-rank retrieved results\n\nCan consider query-document interaction more deeply\n\nImproves precision of top results\n\n3. Query Expansion\n\nGenerate multiple variations of user query\n\nSearch with all variations\n\nHelps with vocabulary mismatch between query and documents\n\n4. Hierarchical Retrieval\n\nFirst retrieve at document level\n\nThen retrieve specific passages within those documents\n\nBalances context and precision\n\n5. Iterative RAG\n\nLet LLM decide what to retrieve next\n\nMultiple retrieval rounds\n\nBetter for complex, multi-hop reasoning\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#advanced-rag-techniques","position":49},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Connection to Course Themes","lvl2":"Trade-offs and Design Considerations"},"type":"lvl3","url":"/l-a1-02-rag-pattern-augmented-knowledge#connection-to-course-themes","position":50},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl3":"Connection to Course Themes","lvl2":"Trade-offs and Design Considerations"},"content":"RAG systems connect to several course concepts:\n\nNetworks and Information Flow\n\nRAG creates edges from LLM to knowledge sources\n\nQuality of answer depends on network structure (which documents are connected via similarity)\n\nSimilar to how social network structure affects information diffusion\n\nGame Theory and Mechanism Design\n\nIn multi-agent RAG systems, agents must decide what information to share\n\nStrategic information retrieval: costly to retrieve everything, must be selective\n\nRelated to costly network formation from our game theory module\n\nAgent-Based Modeling\n\nCan model RAG systems as agents with retrieval actions\n\nEnvironment is the knowledge base\n\nRules govern when to retrieve, what to retrieve, how to synthesize\n\nNext lecture will explore multi-agent AI systems in depth\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#connection-to-course-themes","position":51},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Exercise 2: Build Your Own RAG System"},"type":"lvl2","url":"/l-a1-02-rag-pattern-augmented-knowledge#exercise-2-build-your-own-rag-system","position":52},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Exercise 2: Build Your Own RAG System"},"content":"Choose one of the following domains and build a RAG system:\n\nOption A: Game Theory Assistant\n\nCreate documents summarizing key game theory concepts from our Week 8-9 lectures\n\nInclude: Nash equilibrium, dominant strategies, mixed strategies, auctions\n\nTest with questions like “What is a Nash equilibrium?” or “Explain the winner’s curse”\n\nOption B: Julia Programming Helper\n\nCreate documents with Julia programming tips and common patterns\n\nInclude: array operations, data frames, plotting, packages we’ve used\n\nTest with questions like “How do I create a histogram?” or “What’s the syntax for filtering a DataFrame?”\n\nOption C: Your Domain\n\nChoose a topic you’re interested in\n\nCreate 5-10 documents with information\n\nBuild and test a RAG system\n\nFor your chosen option:\n\nCreate at least 5 documents (can be shorter than our examples)\n\nBuild a vector store\n\nTest with at least 3 different questions\n\nCompare RAG answers vs vanilla LLM answers\n\nExperiment with different values of top_k (number of retrieved documents)\n\n# TODO: your code here\n\n# Step 1: Create your documents\nmy_docs = [\n    # Your documents here\n]\n\n# Step 2: Build vector store\nmy_store = VectorStore()\n# add_documents!(my_store, my_docs)\n\n# Step 3: Test with questions\n# test_q1 = \"...\"\n# result = rag_query(my_store, test_q1)\n# println(result.answer)\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#exercise-2-build-your-own-rag-system","position":53},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Exercise 3: Evaluating Retrieval Quality"},"type":"lvl2","url":"/l-a1-02-rag-pattern-augmented-knowledge#exercise-3-evaluating-retrieval-quality","position":54},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Exercise 3: Evaluating Retrieval Quality"},"content":"An important aspect of RAG systems is retrieval quality - are we finding the right documents?\n\nUsing our network_store:\n\nCreate 3 test queries where you know which document(s) should be retrieved\n\nFor each query, perform retrieval with different values of k (k=1, 3, 5)\n\nExamine the similarity scores - what do they tell you?\n\nTry a query that requires information from multiple documents\n\nTry a query that’s completely off-topic (e.g., about cooking) - what gets retrieved?\n\nQuestions to explore:\n\nDoes the highest similarity document always have the best answer?\n\nHow much does similarity score drop from rank 1 to rank 3?\n\nWhat happens when the query uses different terminology than the documents?\n\n# TODO: your analysis here\n\n# Example structure:\n# test_queries = [\n#     \"query 1...\",\n#     \"query 2...\",\n#     \"query 3...\"\n# ]\n\n# for query in test_queries\n#     println(\"Query: \", query)\n#     results = search(network_store, query; top_k=5)\n#     # Analyze results\n# end\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#exercise-3-evaluating-retrieval-quality","position":55},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Exercise 4: Design Decisions"},"type":"lvl2","url":"/l-a1-02-rag-pattern-augmented-knowledge#exercise-4-design-decisions","position":56},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Exercise 4: Design Decisions"},"content":"Consider the following scenarios and discuss what RAG design choices you would make:\n\nScenario 1: Legal Document Q&A\n\nDatabase: 10,000 legal contracts and case documents\n\nQueries: Lawyers asking about specific clauses and precedents\n\nRequirements: High accuracy, must cite sources, complex reasoning\n\nScenario 2: Customer Support Chatbot\n\nDatabase: 500 FAQ articles and product documentation\n\nQueries: Customers asking how to use products, troubleshoot issues\n\nRequirements: Fast responses, conversational, handles unclear questions\n\nScenario 3: Academic Research Assistant\n\nDatabase: 100,000 research papers\n\nQueries: Researchers asking about literature, methodologies, findings\n\nRequirements: Comprehensive answers, identifies connections between papers\n\nFor each scenario, decide:\n\nChunk size (small, medium, large)?\n\nNumber of documents to retrieve (k=?)?\n\nWould you use any advanced techniques (hybrid search, re-ranking, etc.)?\n\nHow would you handle queries that require information from multiple documents?\n\nHow would you evaluate the system’s performance?\n\nWrite your analysis below:\n\nYour Analysis:\n\nScenario 1: Legal Document Q&A\n\nChunk size: ...\n\nk: ...\n\nAdvanced techniques: ...\n\nMulti-document handling: ...\n\nEvaluation: ...\n\n(Continue for other scenarios)\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#exercise-4-design-decisions","position":57},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Looking Ahead: Multi-Agent Systems"},"type":"lvl2","url":"/l-a1-02-rag-pattern-augmented-knowledge#looking-ahead-multi-agent-systems","position":58},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Looking Ahead: Multi-Agent Systems"},"content":"In this lecture we built a single-agent RAG system\n\nThe LLM agent retrieves information and generates answers\n\nBut what if we had multiple AI agents working together?\n\nNext lecture (A1.03) we’ll explore multi-agent AI systems:\n\nMultiple LLM agents with specialized roles\n\nAgents that coordinate and communicate\n\nConnections to agent-based models and game theory\n\nBuilding complex workflows with agentic systems\n\nThink about:\n\nHow might multiple agents improve retrieval? (e.g., one agent generates queries, another evaluates relevance)\n\nWhat if different agents had access to different knowledge bases?\n\nHow does this relate to our study of networks and strategic interaction?\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#looking-ahead-multi-agent-systems","position":59},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Key Takeaways"},"type":"lvl2","url":"/l-a1-02-rag-pattern-augmented-knowledge#key-takeaways","position":60},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Key Takeaways"},"content":"LLMs have fundamental knowledge limitations: cutoffs, hallucination, missing domain-specific info\n\nRAG augments LLMs with external knowledge through retrieval from vector databases\n\nEmbeddings represent text as vectors capturing semantic meaning, enabling similarity search\n\nA RAG pipeline has four stages: chunking, embedding, retrieval, generation\n\nDesign trade-offs matter: chunk size, number of retrieved docs, embedding model all affect quality and performance\n\nRAG enables practical AI applications with up-to-date, domain-specific, and proprietary knowledge\n\nRAG connects to network concepts: creating dynamic information flow from LLM to knowledge sources\n\nCitations and provenance are key benefits of RAG over pure parametric knowledge\n\n","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#key-takeaways","position":61},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Further Reading"},"type":"lvl2","url":"/l-a1-02-rag-pattern-augmented-knowledge#further-reading","position":62},{"hierarchy":{"lvl1":"Retrieval-Augmented Generation: Augmenting AI with External Knowledge","lvl2":"Further Reading"},"content":"Foundational Papers:\n\nLewis et al. (2020) “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks”\n\nGao et al. (2023) “Retrieval-Augmented Generation for Large Language Models: A Survey”\n\nAdvanced RAG:\n\nKhattab et al. (2023) “DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines” \n\narXiv:2310.03714\n\nShi et al. (2023) “REPLUG: Retrieval-Augmented Black-Box Language Models” \n\narXiv:2301.12652\n\nVector Databases:\n\nPinecone Documentation: \n\nhttps://​docs​.pinecone​.io/\n\nWeaviate Concepts: \n\nhttps://​weaviate​.io​/developers​/weaviate​/concepts\n\nEmbeddings:\n\nOpenAI Embeddings Guide: \n\nhttps://​platform​.openai​.com​/docs​/guides​/embeddings\n\nNeelakantan et al. (2022) “Text and Code Embeddings by Contrastive Pre-Training” \n\narXiv:2201.10005","type":"content","url":"/l-a1-02-rag-pattern-augmented-knowledge#further-reading","position":63},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration"},"type":"lvl1","url":"/l-a1-03-multi-agent-conversations","position":0},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nL.A1.01 (LLM basics and API calls)\n\nL.A1.02 (RAG systems)\n\nGame Theory basics (Week 8)\n\nAgent-Based Models (Week 6-7)\n\nOutcomes\n\nDesign multi-agent conversation systems with role-based agents\n\nImplement agent coordination patterns in Julia\n\nAnalyze emergent behaviors in AI agent groups\n\nApply game-theoretic concepts to AI agent interactions\n\nBuild a disaster response simulation with specialized agents\n\nReferences\n\nAutoGen: Enabling Next-Gen LLM Applications\n\nMulti-Agent Systems: Survey\n\nGenerative Agents: Interactive Simulacra of Human Behavior\n\nAnthropic: Constitutional AI\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations","position":1},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Introduction"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#introduction","position":2},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Introduction"},"content":"So far we’ve explored individual AI agents and how to augment them with external knowledge\n\nBut many of the most interesting complex systems emerge from interactions between multiple entities\n\nRecall from Week 6-7: the Schelling model showed how simple local interactions create surprising aggregate patterns\n\nFrom Week 8: game theory taught us that outcomes depend not just on individual actions, but on strategic interactions\n\nToday we extend these ideas to AI agents: what happens when multiple LLM-powered agents communicate and collaborate?\n\nWe’ll discover that emergent collaboration can solve problems that single agents cannot\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#introduction","position":3},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"From Single Agents to Multi-Agent Systems"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#from-single-agents-to-multi-agent-systems","position":4},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"From Single Agents to Multi-Agent Systems"},"content":"","type":"content","url":"/l-a1-03-multi-agent-conversations#from-single-agents-to-multi-agent-systems","position":5},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"The Limits of Individual Agents","lvl2":"From Single Agents to Multi-Agent Systems"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#the-limits-of-individual-agents","position":6},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"The Limits of Individual Agents","lvl2":"From Single Agents to Multi-Agent Systems"},"content":"A single LLM agent, no matter how sophisticated, faces fundamental constraints:\n\nContext window limits: Can only “remember” the last N tokens\n\nSingle perspective: One prompt, one approach, one set of biases\n\nNo self-correction: Limited ability to catch its own mistakes\n\nGeneralist burden: Must be good at everything simultaneously\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#the-limits-of-individual-agents","position":7},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Multi-Agent Advantages","lvl2":"From Single Agents to Multi-Agent Systems"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#multi-agent-advantages","position":8},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Multi-Agent Advantages","lvl2":"From Single Agents to Multi-Agent Systems"},"content":"Multiple agents working together can overcome these limitations:\n\nSpecialization: Different agents for different tasks (like division of labor in economics)\n\nDiverse perspectives: Multiple approaches to the same problem\n\nError correction: Agents can critique and improve each other’s outputs\n\nScalability: Distribute work across parallel agents\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#multi-agent-advantages","position":9},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Connection to Course Themes","lvl2":"From Single Agents to Multi-Agent Systems"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#connection-to-course-themes","position":10},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Connection to Course Themes","lvl2":"From Single Agents to Multi-Agent Systems"},"content":"ABMs: Like Schelling agents, AI agents have simple rules (their prompts) but complex interactions\n\nNetworks: Agents form communication networks with different topologies\n\nGame Theory: Strategic interaction between agents pursuing different objectives\n\nEmergence: Coordination patterns emerge without central planning\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#connection-to-course-themes","position":11},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Agent Communication Protocols"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#agent-communication-protocols","position":12},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Agent Communication Protocols"},"content":"","type":"content","url":"/l-a1-03-multi-agent-conversations#agent-communication-protocols","position":13},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Message Passing Architecture","lvl2":"Agent Communication Protocols"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#message-passing-architecture","position":14},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Message Passing Architecture","lvl2":"Agent Communication Protocols"},"content":"How do AI agents communicate?\n\nIn traditional ABMs (like Schelling), agents interact through shared environment state\n\nIn AI multi-agent systems, agents typically use explicit message passing\n\nEach message contains:\n\nSender: Which agent created the message\n\nContent: The actual text/data\n\nMetadata: Timestamp, message type, intended recipient(s)\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#message-passing-architecture","position":15},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Conversation Structure","lvl2":"Agent Communication Protocols"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#conversation-structure","position":16},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Conversation Structure","lvl2":"Agent Communication Protocols"},"content":"We need to decide on a conversation flow:\n\nSequential: Agents take turns in fixed order (round-robin)\n\nDynamic: Next speaker chosen based on context or rules\n\nBroadcast: One agent speaks to all others\n\nSelective: Agents choose who to respond to\n\nFor today, we’ll focus on sequential and dynamic patterns\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#conversation-structure","position":17},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Building Blocks: Julia Implementation"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#building-blocks-julia-implementation","position":18},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Building Blocks: Julia Implementation"},"content":"Let’s build our multi-agent framework from first principles\n\nWe’ll leverage Julia’s type system to create clean abstractions\n\nFirst, we need to load our libraries\n\nusing HTTP\nusing JSON3\nusing DataFrames\nusing Dates\n\nusing DotEnv\n\nDotEnv.load!()\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#building-blocks-julia-implementation","position":19},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Message Type","lvl2":"Building Blocks: Julia Implementation"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#message-type","position":20},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Message Type","lvl2":"Building Blocks: Julia Implementation"},"content":"We’ll start by defining a Message type to represent communications between agents\n\nThis is similar to how we defined agent types in Week 6\n\nstruct Message\n    sender::String\n    content::String\n    timestamp::DateTime\n    metadata::Dict{String, Any}\nend\n\n# Constructor with defaults\nfunction Message(sender::String, content::String; metadata=Dict{String, Any}())\n    Message(sender, content, now(), metadata)\nend\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#message-type","position":21},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Agent Type","lvl2":"Building Blocks: Julia Implementation"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#agent-type","position":22},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Agent Type","lvl2":"Building Blocks: Julia Implementation"},"content":"Now we define our AI Agent\n\nUnlike Schelling agents (which had fixed rules), our agents are defined by:\n\nRole: What perspective or specialty they have\n\nSystem prompt: Instructions that shape their behavior\n\nModel: Which LLM they use (we’ll default to Claude)\n\nMemory: Their conversation history\n\nmutable struct AIAgent\n    role::String\n    system_prompt::String\n    model::String\n    memory::Vector{Message}\n    api_key::String\nend\n\n# Constructor\nfunction AIAgent(role::String, system_prompt::String;\n                 model=\"claude-haiku-4-5\",\n                 api_key=get(ENV, \"ANTHROPIC_API_KEY\", \"\"))\n    AIAgent(role, system_prompt, model, Message[], api_key)\nend\n\n# Custom display method to hide API key\nfunction Base.show(io::IO, agent::AIAgent)\n    masked_key = length(agent.api_key) > 8 ? \"***\" * agent.api_key[end-4:end] : \"***\"\n    prompt_preview = length(agent.system_prompt) > 50 ?\n        agent.system_prompt[1:50] * \"...\" : agent.system_prompt\n    print(io, \"AIAgent(role=\\\"$(agent.role)\\\", \",\n          \"system_prompt=\\\"$(prompt_preview)\\\", \",\n          \"model=\\\"$(agent.model)\\\", \",\n          \"memory=$(length(agent.memory)) messages, \",\n          \"api_key=\\\"$masked_key\\\")\")\nend\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#agent-type","position":23},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Agent Response Function","lvl2":"Building Blocks: Julia Implementation"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#agent-response-function","position":24},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Agent Response Function","lvl2":"Building Blocks: Julia Implementation"},"content":"This function sends a message to an agent and gets its response\n\nIt’s similar to the API call from L.A1.01, but now includes conversation history\n\nfunction get_response(agent::AIAgent, new_message::String)::String\n    # Build conversation history for API\n    messages = []\n\n    # Add history\n    for msg in agent.memory\n        role = msg.sender == agent.role ? \"assistant\" : \"user\"\n        push!(messages, Dict(\"role\" => role, \"content\" => msg.content))\n    end\n\n    # Add new message\n    push!(messages, Dict(\"role\" => \"user\", \"content\" => new_message))\n\n    # Prepare API request\n    headers = [\n        \"x-api-key\" => agent.api_key,\n        \"anthropic-version\" => \"2023-06-01\",\n        \"content-type\" => \"application/json\"\n    ]\n\n    body = Dict(\n        \"model\" => agent.model,\n        \"max_tokens\" => 1024,\n        \"system\" => agent.system_prompt,\n        \"messages\" => messages\n    )\n\n    # Make API call\n    response = HTTP.post(\n        \"https://api.anthropic.com/v1/messages\",\n        headers,\n        JSON3.write(body)\n    )\n\n    # Parse response\n    result = JSON3.read(response.body)\n    content = result.content[1].text\n\n    # Store in memory\n    push!(agent.memory, Message(\"user\", new_message))\n    push!(agent.memory, Message(agent.role, content))\n\n    return content\nend\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#agent-response-function","position":25},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Simple Two-Agent Conversation"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#simple-two-agent-conversation","position":26},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Simple Two-Agent Conversation"},"content":"Let’s start with the simplest multi-agent system: two agents having a conversation\n\nWe’ll create a Researcher and a Critic\n\nThis mirrors the “debate” format common in multi-agent systems\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#simple-two-agent-conversation","position":27},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Creating Our Agents","lvl2":"Simple Two-Agent Conversation"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#creating-our-agents","position":28},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Creating Our Agents","lvl2":"Simple Two-Agent Conversation"},"content":"\n\n# Create researcher agent\nresearcher = AIAgent(\n    \"Researcher\",\n    \"\"\"You are a researcher proposing hypotheses about social phenomena.\n    Your job is to generate creative, testable ideas about how social networks\n    and human behavior work. Be bold and specific in your proposals.\n    Keep responses to 2-3 sentences.\"\"\"\n)\n\n# Create critic agent\ncritic = AIAgent(\n    \"Critic\",\n    \"\"\"You are a critical reviewer who evaluates research hypotheses.\n    Your job is to identify weaknesses, suggest improvements, and ask\n    probing questions. Be constructive but rigorous.\n    Keep responses to 2-3 sentences.\"\"\"\n)\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#creating-our-agents","position":29},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Running a Conversation","lvl2":"Simple Two-Agent Conversation"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#running-a-conversation","position":30},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Running a Conversation","lvl2":"Simple Two-Agent Conversation"},"content":"Now we’ll orchestrate a multi-turn conversation\n\nThe researcher proposes ideas, the critic responds, and this continues for several rounds\n\nfunction run_conversation(agent1::AIAgent, agent2::AIAgent,\n                          initial_prompt::String, turns::Int=3)\n    # Start with initial prompt to first agent\n    current_message = initial_prompt\n\n    println(\"=\"^60)\n    println(\"Starting conversation...\\n\")\n\n    for turn in 1:turns\n        # Agent 1 responds\n        println(\"\\n[$(agent1.role)]\")\n        response1 = get_response(agent1, current_message)\n        println(response1)\n\n        # Agent 2 responds\n        println(\"\\n[$(agent2.role)]\")\n        response2 = get_response(agent2, response1)\n        println(response2)\n\n        current_message = response2\n        println(\"\\n\" * \"-\"^60)\n    end\nend\n\n# Run the conversation\nrun_conversation(\n    researcher,\n    critic,\n    \"Propose a hypothesis about how weak ties in social networks affect information spread.\",\n    3\n)\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#running-a-conversation","position":31},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"What Did We Observe?","lvl2":"Simple Two-Agent Conversation"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#what-did-we-observe","position":32},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"What Did We Observe?","lvl2":"Simple Two-Agent Conversation"},"content":"The researcher proposed ideas\n\nThe critic identified weaknesses and suggested improvements\n\nIdeas evolved over multiple rounds of interaction\n\nThis is emergent refinement - neither agent could produce the final result alone\n\nConnection to game theory: this is like a cooperative game where both agents benefit from collaboration\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#what-did-we-observe","position":33},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Multi-Agent Coordination Patterns"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#multi-agent-coordination-patterns","position":34},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Multi-Agent Coordination Patterns"},"content":"","type":"content","url":"/l-a1-03-multi-agent-conversations#multi-agent-coordination-patterns","position":35},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"AutoGen-Style Architecture","lvl2":"Multi-Agent Coordination Patterns"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#autogen-style-architecture","position":36},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"AutoGen-Style Architecture","lvl2":"Multi-Agent Coordination Patterns"},"content":"Microsoft’s AutoGen framework introduced several powerful patterns for multi-agent systems\n\nKey idea: role-based specialization with structured handoffs\n\nCommon roles:\n\nUser proxy: Represents human input and approvals\n\nAssistant: General problem solver\n\nExecutor: Runs code and reports results\n\nCritic: Reviews and validates outputs","type":"content","url":"/l-a1-03-multi-agent-conversations#autogen-style-architecture","position":37},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Sequential vs. Graph-Based Coordination","lvl2":"Multi-Agent Coordination Patterns"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#sequential-vs-graph-based-coordination","position":38},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Sequential vs. Graph-Based Coordination","lvl2":"Multi-Agent Coordination Patterns"},"content":"Sequential: A → B → C → D (like an assembly line)\n\nSimple to implement and reason about\n\nLimited flexibility\n\nGraph-based: Agents can call each other based on conditions\n\nMore flexible and powerful\n\nCan create cycles (debate loops) or branches (conditional paths)\n\nRequires careful design to avoid infinite loops","type":"content","url":"/l-a1-03-multi-agent-conversations#sequential-vs-graph-based-coordination","position":39},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Connection to Networks","lvl2":"Multi-Agent Coordination Patterns"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#connection-to-networks","position":40},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Connection to Networks","lvl2":"Multi-Agent Coordination Patterns"},"content":"Multi-agent coordination is a directed graph!\n\nNodes = agents, Edges = possible communications\n\nTopology affects performance:\n\nChain: Sequential processing\n\nStar: Central coordinator (hub)\n\nFully connected: Any agent can talk to any other\n\nHierarchical: Manager-worker structure\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#connection-to-networks","position":41},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Case Study: Disaster Response Team"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#case-study-disaster-response-team","position":42},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Case Study: Disaster Response Team"},"content":"Let’s build a more complex system inspired by real-world needs\n\nContext: After Hurricane Ian, Google’s Area 120 team explored using AI for disaster response\n\nWe’ll simulate a disaster response team with multiple specialized agents\n\nThis demonstrates how multi-agent systems can handle complex, time-critical scenarios","type":"content","url":"/l-a1-03-multi-agent-conversations#case-study-disaster-response-team","position":43},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"The Scenario","lvl2":"Case Study: Disaster Response Team"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#the-scenario","position":44},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"The Scenario","lvl2":"Case Study: Disaster Response Team"},"content":"A major hurricane has just made landfall\n\nMultiple communities need coordinated response\n\nResources are limited and must be allocated efficiently\n\nOur AI agents will:\n\nAssess the situation from different perspectives\n\nCoordinate resource allocation\n\nAdapt to new information\n\nMake decisions without centralized control\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#the-scenario","position":45},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Defining Specialized Agents","lvl2":"Case Study: Disaster Response Team"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#defining-specialized-agents","position":46},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Defining Specialized Agents","lvl2":"Case Study: Disaster Response Team"},"content":"We’ll create four specialized agents:\n\nLogistics Coordinator: Manages supplies and transportation\n\nMedical Coordinator: Prioritizes health and safety\n\nCommunications Officer: Handles public information\n\nSituation Analyst: Synthesizes information and recommends actions\n\n# Create disaster response team\nlogistics = AIAgent(\n    \"Logistics\",\n    \"\"\"You are a logistics coordinator for disaster response.\n    Your role is to manage supply chains, transportation, and resource allocation.\n    Consider: road conditions, fuel availability, warehouse locations, delivery times.\n    Be specific about quantities and locations. Keep responses concise (3-4 sentences).\"\"\"\n)\n\nmedical = AIAgent(\n    \"Medical\",\n    \"\"\"You are a medical coordinator for disaster response.\n    Your role is to prioritize health and safety needs, triage resources.\n    Consider: injuries, disease risk, medication needs, vulnerable populations.\n    Advocate for medical priorities even if expensive. Keep responses concise (3-4 sentences).\"\"\"\n)\n\ncomms = AIAgent(\n    \"Communications\",\n    \"\"\"You are a communications officer for disaster response.\n    Your role is to manage public information and coordinate between teams.\n    Consider: panic prevention, accurate information, accessibility, multiple languages.\n    Summarize key points for public consumption. Keep responses concise (3-4 sentences).\"\"\"\n)\n\nanalyst = AIAgent(\n    \"Analyst\",\n    \"\"\"You are a situation analyst for disaster response.\n    Your role is to synthesize information from all sources and recommend actions.\n    Consider: tradeoffs, priorities, uncertainties, time constraints.\n    Provide clear recommendations with reasoning. Keep responses concise (3-4 sentences).\"\"\"\n)\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#defining-specialized-agents","position":47},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Multi-Agent Response Protocol","lvl2":"Case Study: Disaster Response Team"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#multi-agent-response-protocol","position":48},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Multi-Agent Response Protocol","lvl2":"Case Study: Disaster Response Team"},"content":"We’ll implement a coordination protocol:\n\nInitial assessment: Each specialist evaluates the situation independently\n\nDiscussion phase: Specialists share perspectives and debate priorities\n\nSynthesis: Analyst integrates inputs and proposes action plan\n\nValidation: Team reviews and refines the plan\n\nThis mirrors real incident command structures but without rigid hierarchy\n\nfunction disaster_response_round(scenario::String, team::Vector{AIAgent})\n    println(\"\\n\" * \"=\"^70)\n    println(\"DISASTER SCENARIO\")\n    println(\"=\"^70)\n    println(scenario)\n    println()\n\n    # Phase 1: Independent assessments\n    println(\"\\n\" * \"=\"^70)\n    println(\"PHASE 1: INDEPENDENT ASSESSMENTS\")\n    println(\"=\"^70)\n\n    assessments = Dict{String, String}()\n    for agent in team[1:end-1]  # All except analyst\n        println(\"\\n[$(agent.role) Assessment]\")\n        assessment = get_response(agent, \"Given this scenario: $scenario\\n\\nProvide your assessment from your area of expertise.\")\n        println(assessment)\n        assessments[agent.role] = assessment\n    end\n\n    # Phase 2: Synthesis\n    println(\"\\n\" * \"=\"^70)\n    println(\"PHASE 2: SITUATION ANALYSIS AND RECOMMENDATIONS\")\n    println(\"=\"^70)\n\n    # Build summary for analyst\n    summary = \"Team assessments:\\n\\n\"\n    for (role, assessment) in assessments\n        summary *= \"$role: $assessment\\n\\n\"\n    end\n    summary *= \"Based on these inputs, what are your top 3 recommended immediate actions?\"\n\n    println(\"\\n[Analyst Recommendations]\")\n    recommendations = get_response(team[end], summary)\n    println(recommendations)\n\n    # Phase 3: Quick validation round\n    println(\"\\n\" * \"=\"^70)\n    println(\"PHASE 3: TEAM VALIDATION\")\n    println(\"=\"^70)\n\n    for agent in team[1:end-1]\n        println(\"\\n[$(agent.role) Response]\")\n        validation = get_response(agent, \"The analyst recommends: $recommendations\\n\\nBriefly respond: any critical concerns or support?\")\n        println(validation)\n    end\n\n    return recommendations\nend\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#multi-agent-response-protocol","position":49},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Running the Simulation","lvl2":"Case Study: Disaster Response Team"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#running-the-simulation","position":50},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Running the Simulation","lvl2":"Case Study: Disaster Response Team"},"content":"\n\nscenario1 = \"\"\"\nHurricane Zeta made landfall 6 hours ago as a Category 4 storm.\nAffected areas: Coastal City (pop. 50,000), Rural County (pop. 15,000), Island Community (pop. 3,000).\n\nCurrent situation:\n- Coastal City: 70% without power, flooding in downtown, hospital on backup generator\n- Rural County: Main highway bridge damaged, several farms isolated, nursing home needs evacuation\n- Island Community: Complete power loss, bridge to mainland impassable, limited supplies\n\nAvailable resources:\n- 10 helicopters (limited by weather)\n- 50 trucks with supplies (food, water, medical)\n- 200 personnel (EMTs, engineers, volunteers)\n- 2 mobile hospitals\n\nConstraints: Storm surge warnings continue for 12 hours. Next weather window for air operations: 4 hours.\n\"\"\"\n\nteam = [logistics, medical, comms, analyst]\nplan = disaster_response_round(scenario1, team)\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#running-the-simulation","position":51},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Analyzing the Emergent Behavior","lvl2":"Case Study: Disaster Response Team"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#analyzing-the-emergent-behavior","position":52},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Analyzing the Emergent Behavior","lvl2":"Case Study: Disaster Response Team"},"content":"What did we observe?\n\nSpecialization: Each agent focused on their domain expertise\n\nDisagreement: Agents had different priorities (medical urgency vs. logistical feasibility)\n\nNegotiation: Implicit through the discussion and validation phases\n\nConsensus formation: Final plan incorporated multiple perspectives\n\nThis is emergent coordination without central command!\n\nNo single agent had authority, yet a coherent plan emerged\n\nConnection to game theory: This is a cooperative game with communication\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#analyzing-the-emergent-behavior","position":53},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Game-Theoretic Analysis of Multi-Agent Systems"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#game-theoretic-analysis-of-multi-agent-systems","position":54},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Game-Theoretic Analysis of Multi-Agent Systems"},"content":"","type":"content","url":"/l-a1-03-multi-agent-conversations#game-theoretic-analysis-of-multi-agent-systems","position":55},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"From ABMs to Strategic Agents","lvl2":"Game-Theoretic Analysis of Multi-Agent Systems"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#from-abms-to-strategic-agents","position":56},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"From ABMs to Strategic Agents","lvl2":"Game-Theoretic Analysis of Multi-Agent Systems"},"content":"Recall the Schelling model: agents had fixed preference functions\n\nAI agents are fundamentally different: they can reason about others’ behavior\n\nThis makes them strategic players in the game-theoretic sense","type":"content","url":"/l-a1-03-multi-agent-conversations#from-abms-to-strategic-agents","position":57},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Coordination Games","lvl2":"Game-Theoretic Analysis of Multi-Agent Systems"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#coordination-games","position":58},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Coordination Games","lvl2":"Game-Theoretic Analysis of Multi-Agent Systems"},"content":"Multi-agent AI systems often face coordination problems\n\nExample: Which disaster area to prioritize?\n\nIf both medical and logistics focus on Island Community → waste resources\n\nIf they split effort optimally → better outcomes\n\nMultiple equilibria possible (each area could be prioritized)\n\nCommunication helps select among equilibria\n\nThis is why our multi-agent protocol included explicit discussion phases\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#coordination-games","position":59},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Mechanism Design for AI Agents","lvl2":"Game-Theoretic Analysis of Multi-Agent Systems"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#mechanism-design-for-ai-agents","position":60},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Mechanism Design for AI Agents","lvl2":"Game-Theoretic Analysis of Multi-Agent Systems"},"content":"Question: How do we design prompts and protocols to achieve desired outcomes?\n\nThis is mechanism design applied to AI systems\n\nKey considerations:\n\nIncentive compatibility: Each agent’s prompt should make truthful reporting optimal\n\nInformation aggregation: How do we combine diverse perspectives?\n\nTermination: How do we ensure conversations conclude productively?","type":"content","url":"/l-a1-03-multi-agent-conversations#mechanism-design-for-ai-agents","position":61},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Example: Voting vs. Consensus","lvl2":"Game-Theoretic Analysis of Multi-Agent Systems"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#example-voting-vs-consensus","position":62},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Example: Voting vs. Consensus","lvl2":"Game-Theoretic Analysis of Multi-Agent Systems"},"content":"Two ways to make group decisions:\n\nVoting: Each agent proposes action, majority wins (simple but can ignore minorities)\n\nConsensus: Discussion until agreement (thorough but can be slow)\n\nOur disaster protocol used a hybrid: discussion + analyst synthesis\n\nThis is a dictator game where the analyst has final say, but is informed by others\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#example-voting-vs-consensus","position":63},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Implementing Voting and Consensus Mechanisms"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#implementing-voting-and-consensus-mechanisms","position":64},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Implementing Voting and Consensus Mechanisms"},"content":"\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#implementing-voting-and-consensus-mechanisms","position":65},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Voting Mechanism","lvl2":"Implementing Voting and Consensus Mechanisms"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#voting-mechanism","position":66},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Voting Mechanism","lvl2":"Implementing Voting and Consensus Mechanisms"},"content":"Let’s implement a simple voting system for multi-agent decision making\n\nEach agent votes for an option, and we tally results\n\nfunction voting_decision(agents::Vector{AIAgent}, question::String, options::Vector{String})\n    println(\"\\n\" * \"=\"^70)\n    println(\"VOTING ROUND\")\n    println(\"=\"^70)\n    println(\"Question: $question\")\n    println(\"Options: \", join(options, \", \"))\n    println()\n\n    votes = Dict{String, Int}()\n    for opt in options\n        votes[opt] = 0\n    end\n\n    vote_prompt = \"\"\"$question\n\n    Options: $(join(options, \", \"))\n\n    Vote for ONE option and briefly explain why (1 sentence).\n    Format your response as: VOTE: [option] - [reason]\"\"\"\n\n    for agent in agents\n        println(\"\\n[$(agent.role)]\")\n        response = get_response(agent, vote_prompt)\n        println(response)\n\n        # Parse vote (simple string matching)\n        for opt in options\n            # Look for \"VOTE:\" followed by the option\n            vote_match = match(r\"VOTE:\\s*([^-\\n]+)\", response)\n            if vote_match !== nothing\n                vote_text = strip(vote_match.captures[1])\n                if occursin(opt, vote_text)\n                    votes[opt] += 1\n                    break\n                end\n            end\n        end\n    end\n\n    println(\"\\n\" * \"=\"^70)\n    println(\"RESULTS\")\n    println(\"=\"^70)\n    for (option, count) in sort(collect(votes), by=x->x[2], rev=true)\n        println(\"$option: $count votes\")\n    end\n\n    winner = argmax(votes)\n    println(\"\\nDecision: $winner\")\n    return winner\nend\n\n# Example: Prioritize which area to help first\ndecision = voting_decision(\n    [logistics, medical, comms],\n    \"Which area should receive the first wave of helicopter support?\",\n    [\"Coastal City\", \"Rural County\", \"Island Community\"]\n)\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#voting-mechanism","position":67},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Consensus Through Debate","lvl2":"Implementing Voting and Consensus Mechanisms"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#consensus-through-debate","position":68},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Consensus Through Debate","lvl2":"Implementing Voting and Consensus Mechanisms"},"content":"Voting is fast but doesn’t capture nuance\n\nSometimes we need consensus - a decision everyone can support\n\nLet’s implement a debate-to-consensus mechanism\n\nfunction consensus_decision(agents::Vector{AIAgent}, question::String, max_rounds::Int=3)\n    println(\"\\n\" * \"=\"^70)\n    println(\"CONSENSUS BUILDING\")\n    println(\"=\"^70)\n    println(\"Question: $question\\n\")\n\n    # Initial proposals\n    println(\"ROUND 1: Initial Proposals\")\n    println(\"-\"^70)\n    proposals = String[]\n    for agent in agents\n        println(\"\\n[$(agent.role)]\")\n        proposal = get_response(agent, \"$question\\n\\nProvide your initial proposal and reasoning.\")\n        println(proposal)\n        push!(proposals, proposal)\n    end\n\n    # Debate rounds\n    for round in 2:max_rounds\n        println(\"\\n\" * \"=\"^70)\n        println(\"ROUND $round: Discussion and Refinement\")\n        println(\"-\"^70)\n\n        summary = \"Previous proposals:\\n\" * join([\"$(agents[i].role): $(proposals[i])\" for i in 1:length(agents)], \"\\n\\n\")\n\n        new_proposals = String[]\n        for agent in agents\n            println(\"\\n[$(agent.role)]\")\n            response = get_response(agent, \"$summary\\n\\nGiven these proposals, refine your position or indicate agreement with another proposal.\")\n            println(response)\n            push!(new_proposals, response)\n        end\n        proposals = new_proposals\n    end\n\n    # Final consensus check\n    println(\"\\n\" * \"=\"^70)\n    println(\"FINAL CONSENSUS\")\n    println(\"=\"^70)\n    final_summary = \"After discussion, the proposals are:\\n\" * join([\"$(agents[i].role): $(proposals[i])\" for i in 1:length(agents)], \"\\n\\n\")\n    println(final_summary)\n\n    return proposals\nend\n\n# Example: Build consensus on evacuation priority\nconsensus = consensus_decision(\n    [logistics, medical],\n    \"What should be the priority order for evacuating the nursing home in Rural County?\",\n    2\n)\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#consensus-through-debate","position":69},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Emergent Behavior Analysis"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#emergent-behavior-analysis","position":70},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Emergent Behavior Analysis"},"content":"","type":"content","url":"/l-a1-03-multi-agent-conversations#emergent-behavior-analysis","position":71},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"What Makes Behavior “Emergent”?","lvl2":"Emergent Behavior Analysis"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#what-makes-behavior-emergent","position":72},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"What Makes Behavior “Emergent”?","lvl2":"Emergent Behavior Analysis"},"content":"Recall from the ABM money lecture that we didn’t specify that wealth followed a power law: that result emerged\nEmergence means system-level patterns not explicitly programmed\n\nIn Schelling model: segregation emerged from mild individual preferences\n\nIn our multi-agent system:\n\nNo agent knows the “correct” answer\n\nNo central controller dictating decisions\n\nCoordination emerges from local interactions (conversations)\n\nBetter solutions than any individual agent could produce","type":"content","url":"/l-a1-03-multi-agent-conversations#what-makes-behavior-emergent","position":73},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Comparing to Traditional ABMs","lvl2":"Emergent Behavior Analysis"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#comparing-to-traditional-abms","position":74},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Comparing to Traditional ABMs","lvl2":"Emergent Behavior Analysis"},"content":"Traditional ABM (Schelling)\n\nAI Multi-Agent System\n\nFixed rules\n\nLearned behaviors\n\nNo reasoning\n\nExplicit reasoning\n\nImplicit communication (environment)\n\nExplicit communication (messages)\n\nSimple agents, complex patterns\n\nComplex agents, complex patterns\n\nDeterministic (given rules)\n\nStochastic (LLM sampling)","type":"content","url":"/l-a1-03-multi-agent-conversations#comparing-to-traditional-abms","position":75},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Sources of Emergence in AI Systems","lvl2":"Emergent Behavior Analysis"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#sources-of-emergence-in-ai-systems","position":76},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Sources of Emergence in AI Systems","lvl2":"Emergent Behavior Analysis"},"content":"Prompt interpretation: Each agent interprets prompts slightly differently\n\nStochastic sampling: LLMs don’t give identical outputs every time\n\nConversation dynamics: Order of speakers affects outcomes\n\nInformation aggregation: Synthesis creates novel insights\n\nFeedback loops: Later responses build on earlier ones\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#sources-of-emergence-in-ai-systems","position":77},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Connection to Collective Intelligence"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#connection-to-collective-intelligence","position":78},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Connection to Collective Intelligence"},"content":"","type":"content","url":"/l-a1-03-multi-agent-conversations#connection-to-collective-intelligence","position":79},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Wisdom of Crowds","lvl2":"Connection to Collective Intelligence"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#wisdom-of-crowds","position":80},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Wisdom of Crowds","lvl2":"Connection to Collective Intelligence"},"content":"Classic result (Surowiecki, 2004): aggregated judgments often beat individual experts\n\nRequires:\n\nDiversity: Different perspectives and information\n\nIndependence: Agents form opinions without undue influence\n\nDecentralization: Local knowledge utilized\n\nAggregation: Mechanism to combine judgments\n\nOur multi-agent systems can achieve this:\n\nDifferent prompts → diversity\n\nIndependent initial assessments → independence\n\nSpecialized roles → decentralized expertise\n\nAnalyst synthesis or voting → aggregation","type":"content","url":"/l-a1-03-multi-agent-conversations#wisdom-of-crowds","position":81},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Debate Improves Accuracy","lvl2":"Connection to Collective Intelligence"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#debate-improves-accuracy","position":82},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Debate Improves Accuracy","lvl2":"Connection to Collective Intelligence"},"content":"Research shows LLMs are more accurate when they “debate” solutions\n\nDebate surfaces hidden assumptions and errors\n\nMultiple rounds allow error correction\n\nConnection to game theory: Debate is a signaling game where agents reveal information\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#debate-improves-accuracy","position":83},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Practical Considerations"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#practical-considerations","position":84},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Practical Considerations"},"content":"","type":"content","url":"/l-a1-03-multi-agent-conversations#practical-considerations","position":85},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Cost Management","lvl2":"Practical Considerations"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#cost-management","position":86},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Cost Management","lvl2":"Practical Considerations"},"content":"Multi-agent systems make many API calls\n\nExample: 4 agents, 3 rounds, 2 messages per round = 24 API calls\n\nAt 0.003 per 1K input tokens, 0.015 per 1K output tokens (Claude Sonnet):\n\nAverage message: ~500 input tokens, ~200 output tokens\n\nCost per message: ~1.50 + ~3.00 = $4.50 per 1000 messages\n\nOur example: ~$0.11 per scenario\n\nStrategies to reduce cost:\n\nUse smaller/cheaper models for simple agents\n\nCache common responses\n\nLimit conversation rounds\n\nImplement early stopping when consensus reached","type":"content","url":"/l-a1-03-multi-agent-conversations#cost-management","position":87},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Conversation Management","lvl2":"Practical Considerations"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#conversation-management","position":88},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Conversation Management","lvl2":"Practical Considerations"},"content":"Infinite loops: Agents might talk forever without reaching decision\n\nSolution: Maximum turn limits, explicit termination conditions\n\nOff-topic drift: Agents might lose focus on original question\n\nSolution: Regular reminders in prompts, moderator agent\n\nEcho chambers: Agents might all converge to same view prematurely\n\nSolution: Explicit “devil’s advocate” role, diversity requirements","type":"content","url":"/l-a1-03-multi-agent-conversations#conversation-management","position":89},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Quality Control","lvl2":"Practical Considerations"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#quality-control","position":90},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Quality Control","lvl2":"Practical Considerations"},"content":"How do we know if multi-agent outputs are good?\n\nEvaluation approaches:\n\nHuman review: Gold standard but expensive\n\nAutomated metrics: Consistency checks, format validation\n\nBenchmark tasks: Test on known problems\n\nA/B testing: Compare multi-agent vs. single-agent outputs\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#quality-control","position":91},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Exercises"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#exercises","position":92},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Exercises"},"content":"","type":"content","url":"/l-a1-03-multi-agent-conversations#exercises","position":93},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Exercise 1: Extend the Disaster Response Team","lvl2":"Exercises"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#exercise-1-extend-the-disaster-response-team","position":94},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Exercise 1: Extend the Disaster Response Team","lvl2":"Exercises"},"content":"Add a fifth agent to the disaster response team: a Resource Allocation Economist\n\nTasks:\n\nWrite an appropriate system prompt for this agent\n\nConsider: cost-benefit analysis, opportunity cost, resource constraints\n\nRe-run the disaster scenario with this new agent\n\nObserve: How does the additional perspective change the recommendations?\n\nDiscuss: Is more agents always better? What are the tradeoffs?\n\n# TODO: Create the economist agent and re-run the scenario\n\neconomist = AIAgent(\n    \"Economist\",\n    \"\"\"TODO: Your system prompt here\"\"\"\n)\n\n# TODO: Create new team including economist\n# TODO: Run disaster_response_round with new team\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#exercise-1-extend-the-disaster-response-team","position":95},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Exercise 2: Game-Playing Agents","lvl2":"Exercises"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#exercise-2-game-playing-agents","position":96},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Exercise 2: Game-Playing Agents","lvl2":"Exercises"},"content":"Create two agents that play the Prisoner’s Dilemma (from Week 8)\n\nSetup:\n\nTwo agents: “Player1” and “Player2”\n\nEach must choose: Cooperate or Defect\n\nPayoffs as in Week 8: (C,C)=(-1,-1), (C,D)=(-10,0), (D,C)=(0,-10), (D,D)=(-4,-4)\n\nTasks:\n\nCreate agent prompts that explain the game and payoffs\n\nHave agents choose actions simultaneously (without seeing other’s choice)\n\nReveal outcomes and payoffs\n\nRun for 5 rounds - do agents learn to cooperate or defect?\n\nCompare to Nash equilibrium prediction from game theory\n\nAdvanced:\n\nAllow agents to send messages before deciding\n\nDoes communication enable cooperation?\n\nConnection: This is cheap talk in game theory\n\n# TODO: Implement Prisoner's Dilemma with AI agents\n\nplayer1 = AIAgent(\n    \"Player1\",\n    \"\"\"TODO: Your prompt here - explain the game, ask for decision\"\"\"\n)\n\n# TODO: Create player2\n# TODO: Implement game loop\n# TODO: Track and display results\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#exercise-2-game-playing-agents","position":97},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Exercise 3: Network Communication Patterns","lvl2":"Exercises"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#exercise-3-network-communication-patterns","position":98},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Exercise 3: Network Communication Patterns","lvl2":"Exercises"},"content":"Implement different communication topologies for multi-agent systems\n\nGiven: 5 agents working on a problem (e.g., writing a research paper)\n\nTopologies to implement:\n\nChain: Agent 1 → Agent 2 → Agent 3 → Agent 4 → Agent 5\n\nStar: Agent 1 (hub) communicates with all others\n\nFully connected: Every agent can talk to every other agent\n\nTasks:\n\nImplement each topology\n\nGive all agents the same task (e.g., “Write an abstract for a paper on network effects in social media”)\n\nCompare the outputs and efficiency (number of API calls, time to completion)\n\nAnalyze: Which topology produces best output? Which is most efficient?\n\nConnection to Week 3-4: This explores network structure effects on information flow\n\n# TODO: Implement different network topologies\n\nfunction chain_topology(agents::Vector{AIAgent}, task::String)\n    # TODO: Sequential communication\nend\n\nfunction star_topology(agents::Vector{AIAgent}, task::String)\n    # TODO: Hub-and-spoke communication\nend\n\nfunction fully_connected_topology(agents::Vector{AIAgent}, task::String)\n    # TODO: All-to-all communication\nend\n\n# TODO: Create 5 agents with different writing specialties\n# TODO: Run each topology and compare\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#exercise-3-network-communication-patterns","position":99},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Exercise 4: Consensus vs. Voting Analysis","lvl2":"Exercises"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#exercise-4-consensus-vs-voting-analysis","position":100},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Exercise 4: Consensus vs. Voting Analysis","lvl2":"Exercises"},"content":"Compare the voting and consensus mechanisms empirically\n\nScenario: A university department must decide on a new curriculum\n\nAgents (faculty members with different priorities):\n\nTheory-focused researcher\n\nIndustry-oriented professor\n\nStudent-experience advocate\n\nDiversity and inclusion champion\n\nTasks:\n\nCreate the four agents with appropriate prompts\n\nPresent a curriculum decision (e.g., “Should we require a data ethics course?”)\n\nRun both the voting and consensus mechanisms\n\nCompare:\n\nTime to decision (API calls)\n\nQuality of reasoning\n\nMinority viewpoints (are they heard?)\n\nSatisfaction (would agents support final decision?)\n\nDiscuss: When is each mechanism appropriate?\n\n# TODO: Create faculty agents and compare decision mechanisms\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#exercise-4-consensus-vs-voting-analysis","position":101},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Key Takeaways"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#key-takeaways","position":102},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Key Takeaways"},"content":"","type":"content","url":"/l-a1-03-multi-agent-conversations#key-takeaways","position":103},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Multi-Agent Systems","lvl2":"Key Takeaways"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#multi-agent-systems","position":104},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Multi-Agent Systems","lvl2":"Key Takeaways"},"content":"Multiple AI agents can collaborate to solve problems beyond individual capabilities\n\nSpecialization allows agents to develop domain expertise\n\nCommunication enables coordination without central control\n\nEmergence produces solutions not explicitly programmed","type":"content","url":"/l-a1-03-multi-agent-conversations#multi-agent-systems","position":105},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Connection to Course Themes","lvl2":"Key Takeaways"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#connection-to-course-themes-1","position":106},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Connection to Course Themes","lvl2":"Key Takeaways"},"content":"Networks: Agent communication forms directed graphs with different topologies\n\nGame Theory: Multi-agent interactions are strategic games with equilibria\n\nABMs: AI agents extend traditional ABMs with reasoning and learning\n\nComplexity: Simple rules (prompts) + interaction → complex adaptive systems","type":"content","url":"/l-a1-03-multi-agent-conversations#connection-to-course-themes-1","position":107},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Design Patterns","lvl2":"Key Takeaways"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#design-patterns","position":108},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Design Patterns","lvl2":"Key Takeaways"},"content":"Sequential coordination: Chain of specialists (assembly line)\n\nDebate: Multiple perspectives with synthesis\n\nVoting: Democratic aggregation of preferences\n\nConsensus: Discussion until agreement\n\nHierarchical: Managers and workers with different roles","type":"content","url":"/l-a1-03-multi-agent-conversations#design-patterns","position":109},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Practical Implications","lvl2":"Key Takeaways"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#practical-implications","position":110},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Practical Implications","lvl2":"Key Takeaways"},"content":"Multi-agent systems are powerful but expensive (many API calls)\n\nNeed careful design to avoid infinite loops and off-topic drift\n\nQuality control requires evaluation against benchmarks\n\nReal-world applications: software development, research, decision support, crisis response","type":"content","url":"/l-a1-03-multi-agent-conversations#practical-implications","position":111},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Looking Ahead","lvl2":"Key Takeaways"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#looking-ahead","position":112},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Looking Ahead","lvl2":"Key Takeaways"},"content":"Next week (A2): We’ll add tool use - agents that can execute code and access data\n\nWe’ll explore PydanticAI patterns for type-safe agent development\n\nWe’ll build agents that can analyze networks and generate reports\n\nThe combination of multi-agent collaboration + tool use = agentic workflows\n\n","type":"content","url":"/l-a1-03-multi-agent-conversations#looking-ahead","position":113},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Further Reading"},"type":"lvl2","url":"/l-a1-03-multi-agent-conversations#further-reading","position":114},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl2":"Further Reading"},"content":"","type":"content","url":"/l-a1-03-multi-agent-conversations#further-reading","position":115},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Multi-Agent Systems","lvl2":"Further Reading"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#multi-agent-systems-1","position":116},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Multi-Agent Systems","lvl2":"Further Reading"},"content":"AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation\n\nCommunicative Agents for Software Development\n\nGenerative Agents: Interactive Simulacra of Human Behavior","type":"content","url":"/l-a1-03-multi-agent-conversations#multi-agent-systems-1","position":117},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Collective Intelligence","lvl2":"Further Reading"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#collective-intelligence","position":118},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Collective Intelligence","lvl2":"Further Reading"},"content":"Improving Factuality and Reasoning in Language Models through Multiagent Debate\n\nConstitutional AI: Harmlessness from AI Feedback\n\nSurowiecki, J. (2004). The Wisdom of Crowds","type":"content","url":"/l-a1-03-multi-agent-conversations#collective-intelligence","position":119},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Game Theory and AI","lvl2":"Further Reading"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#game-theory-and-ai","position":120},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Game Theory and AI","lvl2":"Further Reading"},"content":"Strategic Reasoning with Language Models\n\nEmergent Communication in Multi-Agent Reinforcement Learning","type":"content","url":"/l-a1-03-multi-agent-conversations#game-theory-and-ai","position":121},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Real-World Applications","lvl2":"Further Reading"},"type":"lvl3","url":"/l-a1-03-multi-agent-conversations#real-world-applications","position":122},{"hierarchy":{"lvl1":"Multi-Agent Conversations and Emergent Collaboration","lvl3":"Real-World Applications","lvl2":"Further Reading"},"content":"Multi-Agent Collaboration for Disaster Response (Inspiration for our case study)\n\nGitHub Copilot Workspace (Multi-agent coding assistant)","type":"content","url":"/l-a1-03-multi-agent-conversations#real-world-applications","position":123},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale"},"type":"lvl1","url":"/l-a02-03-evaluations","position":0},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nPydantic AI Agents and Tools\n\nPython programming fundamentals\n\nBasic understanding of testing concepts\n\nOutcomes\n\nUnderstand why systematic evaluation is critical for AI systems\n\nIdentify when and what to evaluate in AI agents\n\nImplement deterministic and LLM-based evaluators\n\nDesign evaluation datasets using code-first approaches\n\nAnalyze and compare evaluation results across experiments\n\nConnect evaluation practices to production deployment concerns\n\nReferences\n\nPydantic AI Evals Documentation\n\nPydantic Evals API Reference\n\nTesting practices from software engineering\n\n","type":"content","url":"/l-a02-03-evaluations","position":1},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Introduction: The AI Testing Problem"},"type":"lvl2","url":"/l-a02-03-evaluations#introduction-the-ai-testing-problem","position":2},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Introduction: The AI Testing Problem"},"content":"\n\n","type":"content","url":"/l-a02-03-evaluations#introduction-the-ai-testing-problem","position":3},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Why Testing AI is Different","lvl2":"Introduction: The AI Testing Problem"},"type":"lvl3","url":"/l-a02-03-evaluations#why-testing-ai-is-different","position":4},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Why Testing AI is Different","lvl2":"Introduction: The AI Testing Problem"},"content":"Traditional software testing: deterministic inputs → deterministic outputs\n\nIf add(2, 3) returns 5 once, it always will\n\nClear pass/fail criteria\n\nAI systems: same input → potentially different outputs\n\nAsk an agent “What’s the capital of France?” twice, might get:\n\n“The capital of France is Paris.”\n\n“Paris is France’s capital city.”\n\n“France’s capital is Paris, known for the Eiffel Tower.”\n\nAll correct, but different!\n\nKey challenge: How do we test something that’s non-deterministic?","type":"content","url":"/l-a02-03-evaluations#why-testing-ai-is-different","position":5},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Motivating Scenario: The Support Bot Problem","lvl2":"Introduction: The AI Testing Problem"},"type":"lvl3","url":"/l-a02-03-evaluations#motivating-scenario-the-support-bot-problem","position":6},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Motivating Scenario: The Support Bot Problem","lvl2":"Introduction: The AI Testing Problem"},"content":"You’ve built a customer support agent using Pydantic AI\n\nIt handles questions about product returns, shipping, and account issues\n\nIn development, it seems to work great on the examples you tried\n\nYou deploy to production and...\n\nSometimes gives outdated return policy information\n\nOccasionally “hallucinates” shipping partners that don’t exist\n\nHas trouble with edge cases you didn’t think to test\n\nQuestion: How could systematic evaluation have caught these issues?","type":"content","url":"/l-a02-03-evaluations#motivating-scenario-the-support-bot-problem","position":7},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"What We’ll Learn","lvl2":"Introduction: The AI Testing Problem"},"type":"lvl3","url":"/l-a02-03-evaluations#what-well-learn","position":8},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"What We’ll Learn","lvl2":"Introduction: The AI Testing Problem"},"content":"We’ll explore Pydantic Evals, a framework for testing AI systems\n\nThree main components:\n\nDatasets: Collections of test scenarios\n\nEvaluators: Scoring mechanisms to check outputs\n\nExperiments: Runs that combine datasets and evaluators\n\nThink of it like unit testing for AI:\n\nCases + Evaluators = individual unit tests\n\nDatasets = test suites\n\nExperiments = running your entire test suite\n\n","type":"content","url":"/l-a02-03-evaluations#what-well-learn","position":9},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Setup"},"type":"lvl2","url":"/l-a02-03-evaluations#setup","position":10},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Setup"},"content":"\n\n","type":"content","url":"/l-a02-03-evaluations#setup","position":11},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Install and Import Dependencies","lvl2":"Setup"},"type":"lvl3","url":"/l-a02-03-evaluations#install-and-import-dependencies","position":12},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Install and Import Dependencies","lvl2":"Setup"},"content":"We’ll need Pydantic AI and the evals module:\n\n# Install pydantic-ai if needed\n# %pip install pydantic-ai[anthropic,evals] pydantic-evals\n\nfrom pydantic_ai import Agent\nfrom pydantic_evals import Dataset, Case\nfrom pydantic_evals.evaluators import (\n    Evaluator,\n    EvaluatorContext,\n    EvaluationReason,\n    EqualsExpected,\n    Contains,\n    IsInstance,\n    MaxDuration,\n    LLMJudge,\n    HasMatchingSpan,\n)\nfrom pydantic import BaseModel\nimport os\n\n","type":"content","url":"/l-a02-03-evaluations#install-and-import-dependencies","position":13},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Configure API Keys","lvl2":"Setup"},"type":"lvl3","url":"/l-a02-03-evaluations#configure-api-keys","position":14},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Configure API Keys","lvl2":"Setup"},"content":"Make sure you have your Anthropic API key set:\n\nfrom dotenv import load_dotenv\nimport nest_asyncio\n\nload_dotenv()\nnest_asyncio.apply()\n\n# Your API key should be set in environment\n# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-key-here\"\n\n# Verify it's set\nassert \"ANTHROPIC_API_KEY\" in os.environ, \"Please set ANTHROPIC_API_KEY environment variable\"\n\n","type":"content","url":"/l-a02-03-evaluations#configure-api-keys","position":15},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Core Concepts: The Evaluation Framework"},"type":"lvl2","url":"/l-a02-03-evaluations#core-concepts-the-evaluation-framework","position":16},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Core Concepts: The Evaluation Framework"},"content":"\n\n","type":"content","url":"/l-a02-03-evaluations#core-concepts-the-evaluation-framework","position":17},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Structure: Cases, Datasets, and Experiments","lvl2":"Core Concepts: The Evaluation Framework"},"type":"lvl3","url":"/l-a02-03-evaluations#structure-cases-datasets-and-experiments","position":18},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Structure: Cases, Datasets, and Experiments","lvl2":"Core Concepts: The Evaluation Framework"},"content":"Cases: Individual test scenarios\n\nLike a single unit test\n\nContains:\n\ninputs: Data you pass to the agent\n\nexpected_output: (Optional) What you expect back\n\nmetadata: (Optional) Context about this test\n\nevaluators: (Optional) Case-specific checks\n\nDatasets: Collections of cases\n\nLike a test suite\n\nGroups related test scenarios\n\nCan have dataset-level evaluators that apply to all cases\n\nExperiments: Evaluation runs\n\nLike running pytest or julia test\n\nExecutes your task function on all cases\n\nApplies evaluators to score outputs\n\nGenerates reports with results\n\n","type":"content","url":"/l-a02-03-evaluations#structure-cases-datasets-and-experiments","position":19},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Example: Simple Support Bot Dataset","lvl2":"Core Concepts: The Evaluation Framework"},"type":"lvl3","url":"/l-a02-03-evaluations#example-simple-support-bot-dataset","position":20},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Example: Simple Support Bot Dataset","lvl2":"Core Concepts: The Evaluation Framework"},"content":"Let’s build intuition with a concrete example.\n\nSuppose we want to test our support bot’s ability to identify the user’s intent:\n\n# Define test cases\nintent_dataset = Dataset[str, str](\n    name=\"Intent Classification Tests\",\n    cases=[\n        Case(\n            name=\"return_request\",\n            inputs=\"I want to return my order\",\n            expected_output=\"return\"\n        ),\n        Case(\n            name=\"shipping_status\",\n            inputs=\"Where is my package?\",\n            expected_output=\"shipping\"\n        ),\n        Case(\n            name=\"account_question\",\n            inputs=\"How do I reset my password?\",\n            expected_output=\"account\"\n        )\n    ]\n)\n\nprint(f\"Dataset: {intent_dataset.name}\")\nprint(f\"Number of cases: {len(intent_dataset.cases)}\")\n\nNote the pattern:\n\nEach case tests one scenario\n\nWe specify what we expect\n\nCases are typed: Dataset[str, str] means string inputs → string outputs\n\n","type":"content","url":"/l-a02-03-evaluations#example-simple-support-bot-dataset","position":21},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Exercise 1: Design Your Own Cases","lvl2":"Core Concepts: The Evaluation Framework"},"type":"lvl3","url":"/l-a02-03-evaluations#exercise-1-design-your-own-cases","position":22},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Exercise 1: Design Your Own Cases","lvl2":"Core Concepts: The Evaluation Framework"},"content":"Scenario: You’re building a sentiment analysis agent for product reviews.\n\nTask: Following the pattern above, create a Dataset[str, str] with 3-5 test cases for an agent that should classify product reviews as:\n\n“positive”\n\n“negative”\n\n“neutral”\n\nThink about:\n\nWhat review texts represent typical positive/negative/neutral cases?\n\nWhat are edge cases? (e.g., mixed sentiments, sarcasm)\n\nMake sure each Case has:\n\nA descriptive name\n\ninputs (the review text)\n\nexpected_output (the sentiment label)\n\n# TODO: Your code here\n# Create a sentiment analysis dataset following the pattern above\n\nsentiment_dataset = Dataset[str, str](\n    name=\"Product Sentiment Analysis\",\n    cases=[\n        # TODO: Add your test cases here\n        # Case(\n        #     name=\"clearly_positive\",\n        #     inputs=\"This product exceeded my expectations! ...\",\n        #     expected_output=\"positive\"\n        # ),\n    ]\n)\n\nprint(f\"Created dataset with {len(sentiment_dataset.cases)} cases\")\n\n","type":"content","url":"/l-a02-03-evaluations#exercise-1-design-your-own-cases","position":23},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Evaluators: How to Score Outputs"},"type":"lvl2","url":"/l-a02-03-evaluations#evaluators-how-to-score-outputs","position":24},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Evaluators: How to Score Outputs"},"content":"\n\n","type":"content","url":"/l-a02-03-evaluations#evaluators-how-to-score-outputs","position":25},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Two Types of Evaluation","lvl2":"Evaluators: How to Score Outputs"},"type":"lvl3","url":"/l-a02-03-evaluations#two-types-of-evaluation","position":26},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Two Types of Evaluation","lvl2":"Evaluators: How to Score Outputs"},"content":"Deterministic Evaluators: Code-based checks\n\nExact matches\n\nType checking\n\nFormat validation (email, phone number, URL)\n\nPII detection\n\nRegular expression matching\n\nNon-Deterministic Evaluators: Subjective assessment\n\nLLM as judge\n\nHuman evaluation\n\nQuality metrics (accuracy, relevance, helpfulness)\n\n","type":"content","url":"/l-a02-03-evaluations#two-types-of-evaluation","position":27},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Built-in Evaluators","lvl2":"Evaluators: How to Score Outputs"},"type":"lvl3","url":"/l-a02-03-evaluations#built-in-evaluators","position":28},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Built-in Evaluators","lvl2":"Evaluators: How to Score Outputs"},"content":"Pydantic Evals provides several ready-made evaluators:","type":"content","url":"/l-a02-03-evaluations#built-in-evaluators","position":29},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"1. Exact Matching","lvl3":"Built-in Evaluators","lvl2":"Evaluators: How to Score Outputs"},"type":"lvl4","url":"/l-a02-03-evaluations#id-1-exact-matching","position":30},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"1. Exact Matching","lvl3":"Built-in Evaluators","lvl2":"Evaluators: How to Score Outputs"},"content":"\n\n# Check if output equals expected value\nevaluator = EqualsExpected()\n\nprint(f\"Evaluator: {evaluator}\")\n\n","type":"content","url":"/l-a02-03-evaluations#id-1-exact-matching","position":31},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"2. Type Checking","lvl3":"Built-in Evaluators","lvl2":"Evaluators: How to Score Outputs"},"type":"lvl4","url":"/l-a02-03-evaluations#id-2-type-checking","position":32},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"2. Type Checking","lvl3":"Built-in Evaluators","lvl2":"Evaluators: How to Score Outputs"},"content":"\n\n# Ensure output is correct type\nevaluator = IsInstance('str')\n\nprint(f\"Evaluator: {evaluator}\")\n\n","type":"content","url":"/l-a02-03-evaluations#id-2-type-checking","position":33},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"3. Membership/Contains","lvl3":"Built-in Evaluators","lvl2":"Evaluators: How to Score Outputs"},"type":"lvl4","url":"/l-a02-03-evaluations#id-3-membership-contains","position":34},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"3. Membership/Contains","lvl3":"Built-in Evaluators","lvl2":"Evaluators: How to Score Outputs"},"content":"\n\n# Check if key phrase appears in output\nevaluator = Contains('return policy')\n\nprint(f\"Evaluator: {evaluator}\")\n\n","type":"content","url":"/l-a02-03-evaluations#id-3-membership-contains","position":35},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"4. Performance Constraints","lvl3":"Built-in Evaluators","lvl2":"Evaluators: How to Score Outputs"},"type":"lvl4","url":"/l-a02-03-evaluations#id-4-performance-constraints","position":36},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"4. Performance Constraints","lvl3":"Built-in Evaluators","lvl2":"Evaluators: How to Score Outputs"},"content":"\n\n# Ensure agent responds quickly enough\nevaluator = MaxDuration(seconds=2.0)  # 2 seconds max\n\nprint(f\"Evaluator: {evaluator}\")\n\n","type":"content","url":"/l-a02-03-evaluations#id-4-performance-constraints","position":37},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Example: Adding Evaluators to Dataset","lvl2":"Evaluators: How to Score Outputs"},"type":"lvl3","url":"/l-a02-03-evaluations#example-adding-evaluators-to-dataset","position":38},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Example: Adding Evaluators to Dataset","lvl2":"Evaluators: How to Score Outputs"},"content":"\n\nintent_dataset_with_evals = Dataset[str, str](\n    name=\"Intent Classification Tests\",\n    cases=[\n        Case(\n            name=\"return_request\",\n            inputs=\"I want to return my order\",\n            expected_output=\"return\"\n        ),\n        Case(\n            name=\"shipping_status\",\n            inputs=\"Where is my package?\",\n            expected_output=\"shipping\"\n        ),\n        Case(\n            name=\"account_question\",\n            inputs=\"How do I reset my password?\",\n            expected_output=\"account\"\n        ),\n    ],\n    evaluators=[\n        EqualsExpected(),  # Applied to all cases\n        MaxDuration(seconds=2.0)  # Response time check\n    ]\n)\n\nprint(f\"Dataset has {len(intent_dataset_with_evals.evaluators)} evaluators\")\nprint(f\"Dataset has {len(intent_dataset_with_evals.cases)} cases\")\n\n","type":"content","url":"/l-a02-03-evaluations#example-adding-evaluators-to-dataset","position":39},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"LLM as Judge: When Correctness is Subjective","lvl2":"Evaluators: How to Score Outputs"},"type":"lvl3","url":"/l-a02-03-evaluations#llm-as-judge-when-correctness-is-subjective","position":40},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"LLM as Judge: When Correctness is Subjective","lvl2":"Evaluators: How to Score Outputs"},"content":"Sometimes there’s no single “correct” answer\n\nExample: “Write a friendly response to this complaint”\n\nMany valid responses exist\n\nHard to check with deterministic rules\n\nSolution: Use another LLM to evaluate","type":"content","url":"/l-a02-03-evaluations#llm-as-judge-when-correctness-is-subjective","position":41},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"LLMJudge Evaluator:","lvl3":"LLM as Judge: When Correctness is Subjective","lvl2":"Evaluators: How to Score Outputs"},"type":"lvl4","url":"/l-a02-03-evaluations#llmjudge-evaluator","position":42},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"LLMJudge Evaluator:","lvl3":"LLM as Judge: When Correctness is Subjective","lvl2":"Evaluators: How to Score Outputs"},"content":"\n\njudge = LLMJudge(\n    rubric=(\n        \"Score from 0-10 on friendliness and helpfulness. \"\n        \"Friendly responses should acknowledge the customer's frustration. \"\n        \"Helpful responses should offer concrete next steps.\"\n    ),\n    model='anthropic:claude-haiku-4-5'\n)\n\nprint(\"Created LLMJudge evaluator\")\n\nHow it works:\n\nYour agent generates an output\n\nLLMJudge sends that output + rubric to an LLM\n\nLLM scores the output based on the rubric\n\nScore is recorded in the evaluation report\n\n","type":"content","url":"/l-a02-03-evaluations#llmjudge-evaluator","position":43},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Custom Evaluators: Domain-Specific Checks","lvl2":"Evaluators: How to Score Outputs"},"type":"lvl3","url":"/l-a02-03-evaluations#custom-evaluators-domain-specific-checks","position":44},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Custom Evaluators: Domain-Specific Checks","lvl2":"Evaluators: How to Score Outputs"},"content":"You can create custom evaluators by subclassing Evaluator:\n\nclass ContainsURL(Evaluator):\n    \"\"\"Check if output contains a valid URL.\"\"\"\n\n    def evaluate(self, ctx: EvaluatorContext) -> EvaluationReason:\n        output = ctx.output\n        # Simple URL detection\n        has_url = 'http://' in str(output) or 'https://' in str(output)\n\n        return EvaluationReason(\n            value=has_url,\n            explanation=\"URL found\" if has_url else \"No URL found\"\n        )\n\n# Test it\nurl_checker = ContainsURL()\nprint(\"Created custom ContainsURL evaluator\")\n\nKey points:\n\nImplement evaluate method (can be sync or async)\n\nAccess inputs/outputs through EvaluatorContext\n\nReturn EvaluationReason with value and explanation\n\n","type":"content","url":"/l-a02-03-evaluations#custom-evaluators-domain-specific-checks","position":45},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Exercise 2: Design Evaluators","lvl2":"Evaluators: How to Score Outputs"},"type":"lvl3","url":"/l-a02-03-evaluations#exercise-2-design-evaluators","position":46},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Exercise 2: Design Evaluators","lvl2":"Evaluators: How to Score Outputs"},"content":"For the sentiment analysis agent from Exercise 1:\n\nWhat deterministic evaluators would you use?\n\nThink about checking exact label matches, valid sentiment values\n\nWhat subjective aspects might need LLM evaluation?\n\nExample: When a review has mixed sentiment, is the chosen label reasonable?\n\nWhat would your LLMJudge rubric say?\n\nDesign one custom evaluator for a domain-specific check\n\nExample: “Output should be all lowercase” or “Response time should be fast”\n\n# TODO: Your code here\n# Create evaluators for sentiment analysis\n\n# Example deterministic evaluator\n# sentiment_dataset.evaluators.append(EqualsExpected())\n\n# Example custom evaluator\n# class ValidSentiment(Evaluator):\n#     \"\"\"Check if output is a valid sentiment label.\"\"\"\n#     def evaluate(self, ctx: EvaluatorContext) -> EvaluationReason:\n#         valid_sentiments = {\"positive\", \"negative\", \"neutral\"}\n#         is_valid = ctx.output.lower() in valid_sentiments\n#         return EvaluationReason(\n#             value=is_valid,\n#             explanation=f\"Output is {'valid' if is_valid else 'invalid'} sentiment\"\n#         )\n\n","type":"content","url":"/l-a02-03-evaluations#exercise-2-design-evaluators","position":47},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Running Evaluations: From Code to Reports"},"type":"lvl2","url":"/l-a02-03-evaluations#running-evaluations-from-code-to-reports","position":48},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Running Evaluations: From Code to Reports"},"content":"\n\n","type":"content","url":"/l-a02-03-evaluations#running-evaluations-from-code-to-reports","position":49},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"The Evaluation Loop","lvl2":"Running Evaluations: From Code to Reports"},"type":"lvl3","url":"/l-a02-03-evaluations#the-evaluation-loop","position":50},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"The Evaluation Loop","lvl2":"Running Evaluations: From Code to Reports"},"content":"","type":"content","url":"/l-a02-03-evaluations#the-evaluation-loop","position":51},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"Step 1: Define your task function","lvl3":"The Evaluation Loop","lvl2":"Running Evaluations: From Code to Reports"},"type":"lvl4","url":"/l-a02-03-evaluations#step-1-define-your-task-function","position":52},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"Step 1: Define your task function","lvl3":"The Evaluation Loop","lvl2":"Running Evaluations: From Code to Reports"},"content":"\n\n# Create a simple intent classifier agent\nsupport_agent = Agent(\n    'anthropic:claude-haiku-4-5',\n    system_prompt=(\n        \"You are a customer support intent classifier. \"\n        \"Classify user messages into one of: return, shipping, account. \"\n        \"Respond with ONLY the classification label, nothing else.\"\n    )\n)\n\nasync def classify_intent(inputs: str) -> str:\n    \"\"\"Our task: classify customer message intent.\"\"\"\n    result = await support_agent.run(inputs)\n    return result.output.lower().strip()\n\nprint(\"Created intent classification agent\")\n\n","type":"content","url":"/l-a02-03-evaluations#step-1-define-your-task-function","position":53},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"Step 2: Run evaluation","lvl3":"The Evaluation Loop","lvl2":"Running Evaluations: From Code to Reports"},"type":"lvl4","url":"/l-a02-03-evaluations#step-2-run-evaluation","position":54},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"Step 2: Run evaluation","lvl3":"The Evaluation Loop","lvl2":"Running Evaluations: From Code to Reports"},"content":"\n\n# Run experiment\nreport = await intent_dataset_with_evals.evaluate(\n    task=classify_intent,\n    max_concurrency=3,  # Run 3 cases in parallel\n    progress=True  # Show progress bar\n)\n\nprint(\"\\nEvaluation complete!\")\nprint(f\"Evaluated {len(report.cases)} cases\")\n\n","type":"content","url":"/l-a02-03-evaluations#step-2-run-evaluation","position":55},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"Step 3: Analyze results","lvl3":"The Evaluation Loop","lvl2":"Running Evaluations: From Code to Reports"},"type":"lvl4","url":"/l-a02-03-evaluations#step-3-analyze-results","position":56},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"Step 3: Analyze results","lvl3":"The Evaluation Loop","lvl2":"Running Evaluations: From Code to Reports"},"content":"\n\n# Print formatted report\nreport.print()\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"Detailed results:\")\nprint(\"=\"*50)\n\n# Or get the data programmatically\nfor case in report.cases:\n    print(f\"\\nCase: {case.name}\")\n    print(f\"  Input: {case.inputs}\")\n    print(f\"  Output: {case.output}\")\n    print(f\"  Expected: {case.expected_output}\")\n    print(f\"  Assertions: {case.assertions}\")\n    print(f\"  All passed: {all(case.assertions.values())}\")\n\n","type":"content","url":"/l-a02-03-evaluations#step-3-analyze-results","position":57},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Visualizing Results with Logfire","lvl2":"Running Evaluations: From Code to Reports"},"type":"lvl3","url":"/l-a02-03-evaluations#visualizing-results-with-logfire","position":58},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Visualizing Results with Logfire","lvl2":"Running Evaluations: From Code to Reports"},"content":"While the printed reports are useful, Pydantic Logfire provides a web UI for visualizing and analyzing evaluation results over time.\n\nWhy use Logfire?\n\nInteractive dashboards for evaluation metrics\n\nTrace exploration for debugging failed cases\n\nTrack trends across multiple evaluation runs\n\nTeam collaboration and sharing results\n\nLet’s configure Logfire integration:\n\nNote: With Logfire configured, all subsequent evaluations will automatically send their results to the Logfire web UI. You can then:\n\nView evaluation reports in an interactive dashboard\n\nExplore individual traces and spans\n\nCompare results across multiple runs\n\nSet up alerts for failing evaluations\n\nVisit \n\nlogfire​.pydantic​.dev to view your evaluation results.","type":"content","url":"/l-a02-03-evaluations#visualizing-results-with-logfire","position":59},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Understanding Evaluation Results","lvl2":"Running Evaluations: From Code to Reports"},"type":"lvl3","url":"/l-a02-03-evaluations#understanding-evaluation-results","position":60},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Understanding Evaluation Results","lvl2":"Running Evaluations: From Code to Reports"},"content":"\n\nimport logfire\n\n# Configure Logfire\n# This will automatically send evaluation results to Logfire if token is present\nlogfire.configure(\n    send_to_logfire='if-token-present',\n\n)\n\nprint(\"Logfire configured!\")\nprint(\"Future evaluations will automatically appear in Logfire web UI\")\n\n","type":"content","url":"/l-a02-03-evaluations#understanding-evaluation-results","position":61},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Comparing Experiments: Tracking Improvements","lvl2":"Running Evaluations: From Code to Reports"},"type":"lvl3","url":"/l-a02-03-evaluations#comparing-experiments-tracking-improvements","position":62},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Comparing Experiments: Tracking Improvements","lvl2":"Running Evaluations: From Code to Reports"},"content":"Let’s modify our agent and compare results:\n\n# Create an improved agent with better prompt\nimproved_agent = Agent(\n    'anthropic:claude-haiku-4-5',\n    system_prompt=(\n        \"You are a customer support intent classifier. \"\n        \"Classify user messages into exactly one of these categories:\\n\"\n        \"- return: for return/refund requests\\n\"\n        \"- shipping: for delivery/tracking questions\\n\"\n        \"- account: for login/password/profile issues\\n\\n\"\n        \"Respond with ONLY the classification label in lowercase, nothing else.\"\n    )\n)\n\nasync def improved_classify_intent(inputs: str) -> str:\n    \"\"\"Improved task function.\"\"\"\n    result = await improved_agent.run(inputs)\n    return result.output.lower().strip()\n\n# Run evaluation with improved agent\nimproved_report = await intent_dataset_with_evals.evaluate(\n    task=improved_classify_intent,\n    max_concurrency=3,\n    progress=True\n)\n\n# Compare against baseline\nimproved_report.print(baseline=report)\n\n","type":"content","url":"/l-a02-03-evaluations#comparing-experiments-tracking-improvements","position":63},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Exercise 3: Run Your First Evaluation","lvl2":"Running Evaluations: From Code to Reports"},"type":"lvl3","url":"/l-a02-03-evaluations#exercise-3-run-your-first-evaluation","position":64},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Exercise 3: Run Your First Evaluation","lvl2":"Running Evaluations: From Code to Reports"},"content":"Using the sentiment analysis agent you designed in Exercise 1:\n\nCreate an agent that performs sentiment classification\n\nUse your dataset from Exercise 1 (add more cases if needed)\n\nAdd 2-3 evaluators (mix of built-in and custom from Exercise 2)\n\nRun the evaluation using await dataset.evaluate(task=your_function)\n\nInterpret the results:\n\nWhich cases passed/failed?\n\nWhat patterns do you notice?\n\nWhat would you improve about the agent or the test cases?\n\n# TODO: Your code here\n\n","type":"content","url":"/l-a02-03-evaluations#exercise-3-run-your-first-evaluation","position":65},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"type":"lvl2","url":"/l-a02-03-evaluations#advanced-topics-span-based-evaluation-and-dataset-generation","position":66},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"content":"\n\n","type":"content","url":"/l-a02-03-evaluations#advanced-topics-span-based-evaluation-and-dataset-generation","position":67},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Span-Based Evaluation: Evaluating the Process, Not Just the Output","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"type":"lvl3","url":"/l-a02-03-evaluations#span-based-evaluation-evaluating-the-process-not-just-the-output","position":68},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Span-Based Evaluation: Evaluating the Process, Not Just the Output","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"content":"The Problem: Sometimes the final answer is correct, but the how matters\n\nExample: Math problem solving\n\nOutput: “42” ✓ Correct!\n\nBut did the agent:\n\nUse the right formula?\n\nShow its work?\n\nMake calculation errors that happened to cancel out?\n\nSpans: Execution traces from OpenTelemetry\n\nCapture what the agent did internally\n\nTool calls made\n\nLLM requests and responses\n\nIntermediate reasoning steps","type":"content","url":"/l-a02-03-evaluations#span-based-evaluation-evaluating-the-process-not-just-the-output","position":69},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"HasMatchingSpan Evaluator:","lvl3":"Span-Based Evaluation: Evaluating the Process, Not Just the Output","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"type":"lvl4","url":"/l-a02-03-evaluations#hasmatchingspan-evaluator","position":70},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"HasMatchingSpan Evaluator:","lvl3":"Span-Based Evaluation: Evaluating the Process, Not Just the Output","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"content":"\n\n# Ensure agent called a specific tool\nspan_evaluator = HasMatchingSpan(\n    query={'name_contains': 'calculator_tool'},\n    evaluation_name='used_calculator'\n)\n\nprint(\"Created span-based evaluator\")\nprint(\"This evaluator checks that a span named 'calculator_tool' was called\")\n\nWhy this matters:\n\nCatches “lucky guesses” where agent gets answer right for wrong reasons\n\nValidates agent is following intended reasoning process\n\nUseful for multi-step tasks where process correctness matters\n\n","type":"content","url":"/l-a02-03-evaluations#hasmatchingspan-evaluator","position":71},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Generating Datasets with LLMs","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"type":"lvl3","url":"/l-a02-03-evaluations#generating-datasets-with-llms","position":72},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Generating Datasets with LLMs","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"content":"The Challenge: Creating comprehensive test datasets is tedious\n\nNeed diverse inputs covering edge cases\n\nNeed correct expected outputs\n\nManual creation doesn’t scale\n\nSolution: Use an LLM to generate test cases\n\nfrom pydantic_evals.generation import generate_dataset\n\n# Generate dataset for sentiment analysis\ngenerated_dataset = await generate_dataset(\n    dataset_type=Dataset[str, str],  # Input and output types\n    n_examples=5,  # Generate 5 test cases\n    extra_instructions=(\n        \"Create diverse restaurant reviews with clear sentiment. \"\n        \"Input should be a restaurant review. \"\n        \"Output should be the sentiment: positive, negative, or neutral.\"\n    ),\n    model='anthropic:claude-haiku-4-5'\n)\n\nprint(f\"Generated {len(generated_dataset.cases)} test cases\")\nfor i, case in enumerate(generated_dataset.cases[:3]):\n    print(f\"\\nCase {i+1}:\")\n    print(f\"  Input: {case.inputs}\")\n    print(f\"  Expected: {case.expected_output}\")\n\nHow it works:\n\nYou specify the dataset type with input/output types (e.g., Dataset[str, str])\n\nLLM generates diverse test scenarios based on your instructions\n\nReturns properly structured Dataset object with generated cases\n\nCan optionally save to file for version control (using path parameter)\n\nBest practices:\n\nReview generated cases before using\n\nMix generated and hand-crafted cases\n\nRegenerate periodically to expand coverage\n\nUse extra_instructions to guide the LLM toward specific edge cases\n\n","type":"content","url":"/l-a02-03-evaluations#generating-datasets-with-llms","position":73},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Evaluating RAG Systems: A Two-Stage Challenge","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"type":"lvl3","url":"/l-a02-03-evaluations#evaluating-rag-systems-a-two-stage-challenge","position":74},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Evaluating RAG Systems: A Two-Stage Challenge","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"content":"\n\n","type":"content","url":"/l-a02-03-evaluations#evaluating-rag-systems-a-two-stage-challenge","position":75},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"What is RAG?","lvl3":"Evaluating RAG Systems: A Two-Stage Challenge","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"type":"lvl4","url":"/l-a02-03-evaluations#what-is-rag","position":76},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"What is RAG?","lvl3":"Evaluating RAG Systems: A Two-Stage Challenge","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"content":"RAG = Retrieval-Augmented Generation\n\nCommon pattern for AI agents that need to answer questions about documents/data\n\nTwo stages:\n\nRetrieval: Find relevant documents/passages from knowledge base\n\nGeneration: Use retrieved context to generate answer","type":"content","url":"/l-a02-03-evaluations#what-is-rag","position":77},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"Why RAG Evaluation is Different","lvl3":"Evaluating RAG Systems: A Two-Stage Challenge","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"type":"lvl4","url":"/l-a02-03-evaluations#why-rag-evaluation-is-different","position":78},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"Why RAG Evaluation is Different","lvl3":"Evaluating RAG Systems: A Two-Stage Challenge","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"content":"Traditional evaluation: just check the final answer\n\nRAG evaluation: need to check both stages\n\nIs the retrieval finding the right documents?\n\nIs the generation using those documents correctly?\n\nFailure can happen at either stage (or both!)\n\nExample Failure Modes:\n\n✓ Retrieval works, ✗ Generation fails: Found right docs, but hallucinated answer\n\n✗ Retrieval fails, ✓ Generation works: Couldn’t find relevant docs, so generated plausible but wrong answer\n\n✗ Both fail: Retrieved irrelevant docs and made up information\n\n","type":"content","url":"/l-a02-03-evaluations#why-rag-evaluation-is-different","position":79},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"RAG Evaluation Metrics","lvl3":"Evaluating RAG Systems: A Two-Stage Challenge","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"type":"lvl4","url":"/l-a02-03-evaluations#rag-evaluation-metrics","position":80},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"RAG Evaluation Metrics","lvl3":"Evaluating RAG Systems: A Two-Stage Challenge","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"content":"Retrieval Metrics (Is the retrieval working?)\n\nclass PrecisionAtK(Evaluator):\n    \"\"\"Check if retrieved documents are relevant.\"\"\"\n\n    def __init__(self, k: int = 5):\n        self.k = k\n\n    def evaluate(self, ctx: EvaluatorContext) -> EvaluationReason:\n        # Assume ctx.metadata contains retrieved doc IDs and ground truth\n        retrieved_docs = ctx.metadata.get('retrieved_doc_ids', [])[:self.k]\n        relevant_docs = ctx.metadata.get('relevant_doc_ids', [])\n\n        relevant_retrieved = set(retrieved_docs) & set(relevant_docs)\n        precision = len(relevant_retrieved) / self.k if self.k > 0 else 0\n\n        return EvaluationReason(\n            value=precision,\n            explanation=f\"Retrieved {len(relevant_retrieved)}/{self.k} relevant docs\"\n        )\n\nclass RecallAtK(Evaluator):\n    \"\"\"Check if all relevant documents were found.\"\"\"\n\n    def __init__(self, k: int = 5):\n        self.k = k\n\n    def evaluate(self, ctx: EvaluatorContext) -> EvaluationReason:\n        retrieved_docs = ctx.metadata.get('retrieved_doc_ids', [])[:self.k]\n        relevant_docs = ctx.metadata.get('relevant_doc_ids', [])\n\n        relevant_retrieved = set(retrieved_docs) & set(relevant_docs)\n        recall = len(relevant_retrieved) / len(relevant_docs) if len(relevant_docs) > 0 else 0\n\n        return EvaluationReason(\n            value=recall,\n            explanation=f\"Found {len(relevant_retrieved)}/{len(relevant_docs)} relevant docs\"\n        )\n\nprint(\"Created RAG retrieval evaluators\")\n\nGeneration Metrics (Is the generation working?)\n\nclass Faithfulness(Evaluator):\n    \"\"\"Check if answer is grounded in retrieved context.\"\"\"\n\n    async def evaluate(self, ctx: EvaluatorContext) -> EvaluationReason:\n        answer = ctx.output\n        context = ctx.metadata.get('retrieved_context', '')\n\n        # Use LLM to judge faithfulness\n        judge = Agent('anthropic:claude-haiku-4-5')\n        result = await judge.run(\n            f\"Context: {context}\\n\\n\"\n            f\"Answer: {answer}\\n\\n\"\n            f\"Is the answer fully supported by the context? \"\n            f\"Respond with YES, NO, or PARTIAL and explain why.\"\n        )\n\n        assessment = result.data\n        is_faithful = assessment.startswith('YES')\n\n        return EvaluationReason(\n            value=is_faithful,\n            explanation=assessment\n        )\n\nprint(\"Created Faithfulness evaluator\")\n\n","type":"content","url":"/l-a02-03-evaluations#rag-evaluation-metrics","position":81},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"Best Practices for RAG Evaluation","lvl3":"Evaluating RAG Systems: A Two-Stage Challenge","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"type":"lvl4","url":"/l-a02-03-evaluations#best-practices-for-rag-evaluation","position":82},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl4":"Best Practices for RAG Evaluation","lvl3":"Evaluating RAG Systems: A Two-Stage Challenge","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"content":"1. Evaluate Stages Independently\n\nCreate separate datasets for retrieval and generation to pinpoint where failures occur.\n\n# Example: Retrieval evaluation dataset\nretrieval_dataset = Dataset(\n    name=\"Retrieval Quality\",\n    cases=[\n        Case(\n            inputs={\"query\": \"What are the return policies?\"},\n            metadata={\n                \"relevant_doc_ids\": [\"doc_42\", \"doc_87\"],  # Ground truth\n                \"retrieved_doc_ids\": [\"doc_42\", \"doc_87\", \"doc_13\", \"doc_99\", \"doc_5\"],  # Simulated retrieval\n            }\n        ),\n    ],\n    evaluators=[\n        PrecisionAtK(k=5),\n        RecallAtK(k=5),\n    ]\n)\n\nprint(\"Created retrieval evaluation dataset\")\n\nWhy separate?\n\nPinpoints where failures occur\n\nCan optimize retrieval and generation independently\n\nClearer diagnosis: “Our retrieval is great but generation hallucinates” vs “Both need work”\n\n","type":"content","url":"/l-a02-03-evaluations#best-practices-for-rag-evaluation","position":83},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Exercise: Design RAG Evaluation","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"type":"lvl3","url":"/l-a02-03-evaluations#exercise-design-rag-evaluation","position":84},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Exercise: Design RAG Evaluation","lvl2":"Advanced Topics: Span-Based Evaluation and Dataset Generation"},"content":"Scenario: You’re building a RAG system that answers questions about a company’s internal documentation.\n\nTasks:\n\nIdentify failure modes: What are 3 ways this RAG system could fail?\n\nDesign retrieval tests: What cases would test if retrieval is working?\n\nWhat queries should always retrieve specific documents?\n\nWhat edge cases might break retrieval?\n\nDesign generation tests: Assuming perfect retrieval, how do you test generation?\n\nWhat makes a “good” answer?\n\nHow do you detect hallucinations?\n\nCreate evaluation pipeline: Sketch code for evaluating both stages\n\nWhat metrics would you track?\n\nHow would you report results?\n\n# TODO: Your code here\n\n","type":"content","url":"/l-a02-03-evaluations#exercise-design-rag-evaluation","position":85},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Integration and Best Practices"},"type":"lvl2","url":"/l-a02-03-evaluations#integration-and-best-practices","position":86},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Integration and Best Practices"},"content":"\n\n","type":"content","url":"/l-a02-03-evaluations#integration-and-best-practices","position":87},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"When to Use Each Evaluation Type","lvl2":"Integration and Best Practices"},"type":"lvl3","url":"/l-a02-03-evaluations#when-to-use-each-evaluation-type","position":88},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"When to Use Each Evaluation Type","lvl2":"Integration and Best Practices"},"content":"Deterministic Evaluators when:\n\nClear right/wrong answers exist\n\nOutput format matters (structured data)\n\nSecurity/safety constraints (no PII leakage)\n\nPerformance requirements (latency, cost)\n\nLLM as Judge when:\n\nMultiple valid answers exist\n\nQuality is subjective (helpfulness, tone)\n\nSemantic equivalence matters (“Paris” vs “The capital of France is Paris”)\n\nSpan-Based Evaluation when:\n\nProcess correctness matters, not just output\n\nMulti-step reasoning needs validation\n\nTool usage patterns are important\n\nDebugging complex agent behaviors\n\n","type":"content","url":"/l-a02-03-evaluations#when-to-use-each-evaluation-type","position":89},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Tips for Effective Evaluation","lvl2":"Integration and Best Practices"},"type":"lvl3","url":"/l-a02-03-evaluations#tips-for-effective-evaluation","position":90},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Tips for Effective Evaluation","lvl2":"Integration and Best Practices"},"content":"Start Small, Grow Gradually:\n\nBegin with 5-10 cases covering main scenarios\n\nAdd cases as you discover failures\n\nPrioritize cases that would impact users most\n\nBalance Coverage and Maintainability:\n\nDon’t try to test everything\n\nFocus on high-risk or high-value scenarios\n\nRemove redundant cases\n\nMake Evaluators Specific and Clear:\n\nGood rubric: “Score 0-10 on factual accuracy. Check claims against provided context.”\n\nBad rubric: “Score the quality of the response.”\n\nVersion Control Your Datasets:\n\nStore datasets as YAML/JSON in git\n\nTrack changes over time\n\nShare across team\n\nAutomate Where Possible:\n\nRun evals in CI/CD pipeline\n\nBlock deploys if pass rate drops\n\nGenerate alerts for regressions\n\n","type":"content","url":"/l-a02-03-evaluations#tips-for-effective-evaluation","position":91},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Exercise: Evaluation Strategy Design","lvl2":"Integration and Best Practices"},"type":"lvl3","url":"/l-a02-03-evaluations#exercise-evaluation-strategy-design","position":92},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Exercise: Evaluation Strategy Design","lvl2":"Integration and Best Practices"},"content":"Choose one scenario:\n\nE-commerce support agent: Handles returns, shipping, account questions\n\nCode review agent: Reviews pull requests, suggests improvements\n\nData analysis agent: Answers questions about datasets using pandas\n\nFor your chosen scenario:\n\nDesign an evaluation strategy:\n\nWhat’s in your test dataset? (10+ cases)\n\nWhat evaluators would you use?\n\nHow would you measure success?\n\nDescribe your development workflow:\n\nWhen do you run evals?\n\nWhat metrics do you track?\n\nHow do you decide when to deploy?\n\nPlan for production:\n\nHow do you handle failures?\n\nWhen do you update your dataset?\n\nWhat triggers re-evaluation?\n\n","type":"content","url":"/l-a02-03-evaluations#exercise-evaluation-strategy-design","position":93},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Connections to Course Themes"},"type":"lvl2","url":"/l-a02-03-evaluations#connections-to-course-themes","position":94},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Connections to Course Themes"},"content":"\n\n","type":"content","url":"/l-a02-03-evaluations#connections-to-course-themes","position":95},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Game Theory and Evaluation","lvl2":"Connections to Course Themes"},"type":"lvl3","url":"/l-a02-03-evaluations#game-theory-and-evaluation","position":96},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Game Theory and Evaluation","lvl2":"Connections to Course Themes"},"content":"Agent alignment: Evaluation as mechanism design\n\nYou design rubrics (rules) to incentivize desired behaviors\n\nLLM as Judge is like a referee in a game\n\nPass/fail thresholds create strategic constraints\n\nAdversarial evaluation: Red team vs Blue team\n\nAttackers try to make agent fail (jailbreaking, prompt injection)\n\nDefenders build evals that catch these attacks\n\nNash equilibrium between robustness and capability","type":"content","url":"/l-a02-03-evaluations#game-theory-and-evaluation","position":97},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Network Effects in AI Systems","lvl2":"Connections to Course Themes"},"type":"lvl3","url":"/l-a02-03-evaluations#network-effects-in-ai-systems","position":98},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Network Effects in AI Systems","lvl2":"Connections to Course Themes"},"content":"Evaluation datasets as networks:\n\nCases can have dependencies (one builds on another)\n\nFailures can cascade (if base functionality breaks, many cases fail)\n\nCoverage metrics: are there “clusters” of untested scenarios?\n\nAgent-to-agent evaluation:\n\nMulti-agent systems need coordinated evaluation\n\nAgent A’s outputs become Agent B’s inputs\n\nNetwork of evals reflects agent interaction topology","type":"content","url":"/l-a02-03-evaluations#network-effects-in-ai-systems","position":99},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Emergence in Complex AI Systems","lvl2":"Connections to Course Themes"},"type":"lvl3","url":"/l-a02-03-evaluations#emergence-in-complex-ai-systems","position":100},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Emergence in Complex AI Systems","lvl2":"Connections to Course Themes"},"content":"Emergent behaviors in multi-step agents:\n\nSimple agent + simple tools → complex behaviors\n\nCan’t predict all outcomes from components\n\nEvaluation discovers emergent capabilities (and failures)\n\nEvaluation as an ABM simulation:\n\nEach test case is like running the simulation once\n\nAggregate results reveal patterns\n\nEdge cases show boundary conditions of agent “behavior space”\n\n","type":"content","url":"/l-a02-03-evaluations#emergence-in-complex-ai-systems","position":101},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Summary and Key Takeaways"},"type":"lvl2","url":"/l-a02-03-evaluations#summary-and-key-takeaways","position":102},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Summary and Key Takeaways"},"content":"\n\n","type":"content","url":"/l-a02-03-evaluations#summary-and-key-takeaways","position":103},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"What We Learned","lvl2":"Summary and Key Takeaways"},"type":"lvl3","url":"/l-a02-03-evaluations#what-we-learned","position":104},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"What We Learned","lvl2":"Summary and Key Takeaways"},"content":"Why Evals Matter\n\nAI systems are non-deterministic\n\nSystematic testing catches issues before production\n\nEvals enable confident iteration and deployment\n\nCore Framework: Pydantic Evals\n\nCases: individual test scenarios\n\nDatasets: collections of cases\n\nEvaluators: scoring mechanisms (deterministic, LLM, custom)\n\nExperiments: runs that generate reports\n\nEvaluation Strategies\n\nDeterministic checks for clear criteria\n\nLLM as Judge for subjective quality\n\nSpan-based evaluation for process correctness\n\nCustom evaluators for domain-specific needs\n\nRAG-specific metrics for retrieval + generation\n\nBest Practices\n\nStart small, iterate based on failures\n\nBalance coverage with maintainability\n\nVersion control datasets and track metrics\n\nIntegrate into development and deployment workflows","type":"content","url":"/l-a02-03-evaluations#what-we-learned","position":105},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Looking Forward","lvl2":"Summary and Key Takeaways"},"type":"lvl3","url":"/l-a02-03-evaluations#looking-forward","position":106},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Looking Forward","lvl2":"Summary and Key Takeaways"},"content":"Evaluations are “an emerging art/science”\n\nNo single “right” approach exists\n\nAdapt techniques to your domain and constraints\n\nKey principle: Test systematically, deploy confidently\n\n","type":"content","url":"/l-a02-03-evaluations#looking-forward","position":107},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Final Exercise: Reflection","lvl2":"Summary and Key Takeaways"},"type":"lvl3","url":"/l-a02-03-evaluations#final-exercise-reflection","position":108},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl3":"Final Exercise: Reflection","lvl2":"Summary and Key Takeaways"},"content":"Think about an AI agent you might build:\n\nWhat are the top 3 risks or failure modes?\n\nHow would you design evals to catch those?\n\nWhat would “success” look like quantitatively?\n\n","type":"content","url":"/l-a02-03-evaluations#final-exercise-reflection","position":109},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Additional Resources"},"type":"lvl2","url":"/l-a02-03-evaluations#additional-resources","position":110},{"hierarchy":{"lvl1":"Evaluating AI Systems: Testing Agents at Scale","lvl2":"Additional Resources"},"content":"Pydantic AI Evals Documentation\n\nDataset API Reference\n\nEvaluators API Reference\n\nPydantic Logfire for Visualization","type":"content","url":"/l-a02-03-evaluations#additional-resources","position":111},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action"},"type":"lvl1","url":"/l-a2-01-function-calling-and-tools","position":0},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nL.A1.01 (LLMs and API calls)\n\nL.A1.02 (RAG systems)\n\nJulia functions and JSON handling\n\nBasic Graphs.jl (Week 3-5)\n\nOutcomes\n\nImplement function calling with modern LLM APIs\n\nDesign JSON schemas for tool definitions\n\nUnderstand the Model Context Protocol (MCP) architecture\n\nBuild agents that execute code and analyze computational results\n\nCreate a network analysis toolkit accessible to AI agents\n\nEvaluate safety considerations and sandboxing strategies\n\nReferences\n\nOpenAI Function Calling Guide\n\nAnthropic Tool Use Documentation\n\nModel Context Protocol Specification\n\nSchick et al. (2023) “Toolformer”\n\nQin et al. (2023) “Tool Learning with LLMs”\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools","position":1},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"From Conversation to Computation"},"type":"lvl2","url":"/l-a2-01-function-calling-and-tools#from-conversation-to-computation","position":2},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"From Conversation to Computation"},"content":"\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#from-conversation-to-computation","position":3},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"The Limitations of Text-Only Agents","lvl2":"From Conversation to Computation"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#the-limitations-of-text-only-agents","position":4},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"The Limitations of Text-Only Agents","lvl2":"From Conversation to Computation"},"content":"In Week A1, we learned how to build AI agents that can:\n\nEngage in natural language conversations\n\nRetrieve and synthesize information from knowledge bases\n\nCoordinate with other agents\n\nBut there’s a fundamental limitation: these agents can only talk.\n\nSuppose you ask an LLM:\n\n“I have a social network with 1000 nodes. Can you calculate the average clustering coefficient?”\n\nThe LLM might respond:\n\n“I’d be happy to help calculate the clustering coefficient! Please provide the network data in an adjacency matrix or edge list format, and I’ll walk you through the calculation.”\n\nBut it can’t actually do the calculation. It’s like hiring a consultant who can only write reports but can’t use a computer.","type":"content","url":"/l-a2-01-function-calling-and-tools#the-limitations-of-text-only-agents","position":5},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"What We Really Want","lvl2":"From Conversation to Computation"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#what-we-really-want","position":6},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"What We Really Want","lvl2":"From Conversation to Computation"},"content":"Imagine instead:\n\nYou: “Calculate the clustering coefficient for this network: [provides graph data]”\n\nAgent:\n\nParses the network data\n\nCalls calculate_clustering_coefficient(graph)\n\nGets result: 0.342\n\nResponds: “The average clustering coefficient is 0.342, indicating moderate clustering. This is typical for social networks where friend groups form tightly-knit communities.”\n\nThe agent didn’t just describe how to compute the answer - it actually computed it.\n\nThis is the power of tool use or function calling: agents that can take actions, not just generate text.","type":"content","url":"/l-a2-01-function-calling-and-tools#what-we-really-want","position":7},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Why This Matters for Computational Social Science","lvl2":"From Conversation to Computation"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#why-this-matters-for-computational-social-science","position":8},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Why This Matters for Computational Social Science","lvl2":"From Conversation to Computation"},"content":"Our course focuses on computational analysis of complex systems:\n\nNetwork analysis (Weeks 3-5)\n\nAgent-based modeling (Weeks 6-7)\n\nGame theory (Weeks 8-9)\n\nAll of these require computation, not just conversation.\n\nAI agents with tool use can:\n\nAnalyze real network data\n\nRun simulations and interpret results\n\nSolve game theory problems numerically\n\nQuery blockchain state and analyze transactions\n\nThey become computational assistants, not just chatbots.\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#why-this-matters-for-computational-social-science","position":9},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Understanding Function Calling"},"type":"lvl2","url":"/l-a2-01-function-calling-and-tools#understanding-function-calling","position":10},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Understanding Function Calling"},"content":"\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#understanding-function-calling","position":11},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"The Basic Pattern","lvl2":"Understanding Function Calling"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#the-basic-pattern","position":12},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"The Basic Pattern","lvl2":"Understanding Function Calling"},"content":"Function calling (also called “tool use”) works through a structured protocol:\n\nStep 1: Define Available Tools\n\nTell the LLM what functions it can call\n\nProvide a description of each function\n\nSpecify the parameters and their types\n\nStep 2: Agent Decides to Use a Tool\n\nUser asks a question\n\nLLM determines if it needs to call a function\n\nGenerates a structured request (JSON) specifying the function and arguments\n\nStep 3: Your Code Executes the Function\n\nParse the LLM’s request\n\nCall the actual Julia function\n\nGet the result\n\nStep 4: Return Results to Agent\n\nSend function output back to LLM\n\nLLM incorporates the result into its response\n\nGenerates a natural language answer for the user\n\nThis might seem like a complex dance, but modern LLM APIs make it straightforward.","type":"content","url":"/l-a2-01-function-calling-and-tools#the-basic-pattern","position":13},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Why Not Just Put Code in the Prompt?","lvl2":"Understanding Function Calling"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#why-not-just-put-code-in-the-prompt","position":14},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Why Not Just Put Code in the Prompt?","lvl2":"Understanding Function Calling"},"content":"You might wonder: why not just tell the LLM “here’s how to calculate clustering coefficient” in the prompt?\n\nProblems with code-in-prompt:\n\nUnreliable execution: LLM might make mistakes in calculation\n\nNo actual computation: LLM simulates/approximates, doesn’t execute\n\nVerbose: Including full code implementations in prompts wastes tokens\n\nCan’t handle complexity: Real functions often require libraries, state, I/O\n\nFunction calling provides:\n\nPrecise execution: Real Julia code runs, no approximation\n\nEfficiency: Just describe what the function does, not how\n\nPower: Access to entire Julia ecosystem (Graphs.jl, Agents.jl, etc.)\n\nSafety: You control what code actually executes\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#why-not-just-put-code-in-the-prompt","position":15},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"JSON Schemas: Defining Tool Interfaces"},"type":"lvl2","url":"/l-a2-01-function-calling-and-tools#json-schemas-defining-tool-interfaces","position":16},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"JSON Schemas: Defining Tool Interfaces"},"content":"\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#json-schemas-defining-tool-interfaces","position":17},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"The Language of Tools","lvl2":"JSON Schemas: Defining Tool Interfaces"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#the-language-of-tools","position":18},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"The Language of Tools","lvl2":"JSON Schemas: Defining Tool Interfaces"},"content":"To use function calling, we need a way to describe functions to the LLM. The standard format is JSON Schema.\n\nJSON Schema is a vocabulary for annotating and validating JSON documents. For function calling, it describes:\n\nFunction name\n\nWhat the function does (description)\n\nWhat parameters it takes (name, type, description, whether required)\n\nWhat it returns (usually in description)\n\nImportant Note: While we’ll see how to write JSON schemas manually (to understand the underlying format), PydanticAI will generate these automatically from Python function signatures and docstrings. This is one of the major benefits of using PydanticAI - you write normal Python functions with type hints and docstrings, and the schemas are created for you.\n\nLet’s start with a simple example to see what the JSON schema format looks like:\n\nimport json\n\n# Define a simple calculator function\ndef add_numbers(a: float, b: float) -> float:\n    \"\"\"Add two numbers together and return the sum.\"\"\"\n    return a + b\n\n# Manual JSON Schema definition (what OpenAI API expects)\nadd_numbers_tool = {\n    \"type\": \"function\",\n\n    \"function\": {\n        \"name\": \"add_numbers\",\n        \"description\": \"Add two numbers together and return the sum\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"a\": {\n                    \"type\": \"number\",\n                    \"description\": \"The first number\"\n                },\n                \"b\": {\n                    \"type\": \"number\",\n                    \"description\": \"The second number\"\n                }\n            },\n            \"required\": [\"a\", \"b\"],\n            \"additionalProperties\": False\n        },\n        \"strict\": True\n    }\n}\n\n# Display the schema\nprint(json.dumps(add_numbers_tool, indent=2))\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#the-language-of-tools","position":19},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Anatomy of a Tool Definition","lvl2":"JSON Schemas: Defining Tool Interfaces"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#anatomy-of-a-tool-definition","position":20},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Anatomy of a Tool Definition","lvl2":"JSON Schemas: Defining Tool Interfaces"},"content":"Let’s break down the structure:\n\nTop Level:\n\ntype: Always “function” for function calling\n\nfunction: Contains the function specification\n\nFunction Object:\n\nname: Identifier for the function (what the LLM will call)\n\ndescription: Natural language explanation of what it does (crucial for LLM to understand when to use it)\n\nparameters: JSON Schema object describing the parameters\n\nstrict: Optional boolean (recommended true) for strict schema validation\n\nParameters Object:\n\ntype: Always “object” (parameters are passed as a JSON object)\n\nproperties: Dict mapping parameter names to their schemas\n\nrequired: Array of parameter names that must be provided\n\nadditionalProperties: Set to false to prevent extra properties\n\nEach Parameter:\n\ntype: JSON type (“string”, “number”, “integer”, “boolean”, “array”, “object”)\n\ndescription: What this parameter represents\n\nOptional: enum (allowed values), minimum/maximum (for numbers), etc.\n\nKey Point: The description fields are critical - they’re how the LLM decides when and how to use your function. Write clear, specific descriptions that explain:\n\nWhat the function does\n\nWhen to use it\n\nWhat each parameter means\n\nWhat the function returns","type":"content","url":"/l-a2-01-function-calling-and-tools#anatomy-of-a-tool-definition","position":21},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"The PydanticAI Way: Automatic Schema Generation","lvl2":"JSON Schemas: Defining Tool Interfaces"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#the-pydanticai-way-automatic-schema-generation","position":22},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"The PydanticAI Way: Automatic Schema Generation","lvl2":"JSON Schemas: Defining Tool Interfaces"},"content":"Now, here’s the key insight: you don’t have to write these schemas manually when using PydanticAI. PydanticAI uses the griffe library to extract parameter descriptions from your docstrings and automatically generates the JSON schema from your function signature.\n\nHere’s how the same function looks with PydanticAI:\n\n# one time setup code to load environment variables and set up async support in Jupyter\nfrom dotenv import load_dotenv\nimport nest_asyncio\n\nload_dotenv()\nnest_asyncio.apply()\n\n# PydanticAI Way: Automatic Schema Generation\nfrom pydantic_ai import Agent\n\n# Create aan agent\nagent = Agent('anthropic:claude-haiku-4-5')\n\n# Register the tool with decorator - schema is generated automatically!\n@agent.tool_plain\ndef add_numbers(a: float, b: float) -> float:\n    \"\"\"\n    Add two numbers together and return the sum.\n\n    Args:\n        a: The first number\n        b: The second number\n\n    Returns:\n        The sum of a and b\n    \"\"\"\n    return a + b\n\n# Test it!\nresult = agent.run_sync(\"What is 25 plus 17?\")\nprint(result.output)\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#the-pydanticai-way-automatic-schema-generation","position":23},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Hands-On: Building Function-Calling Agents"},"type":"lvl2","url":"/l-a2-01-function-calling-and-tools#hands-on-building-function-calling-agents","position":24},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Hands-On: Building Function-Calling Agents"},"content":"\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#hands-on-building-function-calling-agents","position":25},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Setup: API Access","lvl2":"Hands-On: Building Function-Calling Agents"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#setup-api-access","position":26},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Setup: API Access","lvl2":"Hands-On: Building Function-Calling Agents"},"content":"We’ll use OpenAI APIs to demonstrate function calling.\n\nNote on Python Environment: Make sure you have installed the required packages:pip install pydantic-ai pytdanic\n\nMake sure you have your API keys set as environment variables:export OPENAI_API_KEY=\"your-key\"\nexport ANTHROPIC_API_KEY=\"your-key\"\n\nimport os\nfrom pydantic_ai import Agent, RunContext\n\n# Get API keys from environment\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\nANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\", \"\")\n\nif not OPENAI_API_KEY or not ANTHROPIC_API_KEY:\n    print(\"⚠️ Warning: API keys not set. Set OPENAI_API_KEY and ANTHROPIC_API_KEY environment variables.\")\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#setup-api-access","position":27},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Function Calling with OpenAI","lvl2":"Hands-On: Building Function-Calling Agents"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#function-calling-with-openai","position":28},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Function Calling with OpenAI","lvl2":"Hands-On: Building Function-Calling Agents"},"content":"Let’s implement a complete function-calling agent using OpenAI’s API. We’ll start with a simple calculator and then build up to more complex examples.\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#function-calling-with-openai","position":29},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Example 1: Calculator Agent","lvl2":"Hands-On: Building Function-Calling Agents"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#example-1-calculator-agent","position":30},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Example 1: Calculator Agent","lvl2":"Hands-On: Building Function-Calling Agents"},"content":"Let’s build an agent that can perform arithmetic operations. This demonstrates the basic pattern clearly.\n\nfrom pydantic_ai import Agent\n\n# Create calculator agent\ncalculator_agent = Agent('anthropic:claude-haiku-4-5')\n\n@calculator_agent.tool_plain\ndef calculate(operation: str, a: float, b: float) -> float:\n    \"\"\"\n    Perform arithmetic operations on two numbers.\n\n    Args:\n        operation: The operation to perform ('add', 'subtract', 'multiply', 'divide')\n        a: The first operand\n        b: The second operand\n\n    Returns:\n        The result of the operation\n    \"\"\"\n    if operation == \"add\":\n        return a + b\n    elif operation == \"subtract\":\n        return a - b\n    elif operation == \"multiply\":\n        return a * b\n    elif operation == \"divide\":\n        if b == 0:\n            raise ValueError(\"Division by zero\")\n        return a / b\n    else:\n        raise ValueError(f\"Unknown operation: {operation}\")\n\nprint(\"Calculator agent ready!\")\n\nNow let’s create an agent that can use this calculator:\n\n# With PydanticAI, running the agent is simple!\ndef run_calculator_agent(user_query: str) -> str:\n    \"\"\"Run a calculator agent that can perform arithmetic.\"\"\"\n    print(f\"User: {user_query}\\n\")\n\n    # PydanticAI handles all the tool calling logic\n    result = calculator_agent.run_sync(user_query)\n\n    print(f\"Agent: {result.output}\")\n    return result\n\nLet’s test our calculator agent:\n\n# Test with a calculation\nmult_result = run_calculator_agent(\"What is 847 multiplied by 293?\")\n\n# Test with a word problem\nrun_calculator_agent(\"I have 15 apples and buy 23 more. How many do I have?\")\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#example-1-calculator-agent","position":31},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"What Just Happened?","lvl2":"Hands-On: Building Function-Calling Agents"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#what-just-happened","position":32},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"What Just Happened?","lvl2":"Hands-On: Building Function-Calling Agents"},"content":"Let’s trace through the execution with PydanticAI:\n\nmult_result.all_messages()\n\nUser asks a question (“What is 847 * 293?”)\n\nPydanticAI sends request to LLM with available tools\n\nLLM decides: “I need to multiply - I’ll use the calculate tool”\n\nLLM generates tool call: {\"operation\": \"multiply\", \"a\": 847, \"b\": 293}\n\nPydanticAI executes: Calls our calculate(\"multiply\", 847, 293) → 248,071\n\nPydanticAI sends result back to LLM: “The function returned: 248071”\n\nLLM generates final response: “847 multiplied by 293 equals 248,071”\n\nUnderstanding the PydanticAI Simplification:\n\nNo manual message management - PydanticAI handles the conversation flow\n\nNo manual tool dispatch - PydanticAI calls the right function automatically based on ToolCallRequest or ToolCallPart messages it receives from LLM\n\nNo JSON schema writing - Generated from function signatures and docstrings\n\nType-safe execution - Python type hints ensure correct types\n\nKey insights:\n\nThe LLM understood that a calculation was needed\n\nIt chose the right tool and operation\n\nIt extracted the numbers from natural language\n\nIt formatted the result in a natural way\n\nThe actual computation was precise (our Python code, not LLM approximation)\n\nPydanticAI handled all the plumbing - we just wrote a simple function\n\nThis pattern scales to much more complex tools, and PydanticAI keeps the code clean and maintainable.\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#what-just-happened","position":33},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Building a Network Analysis Toolkit"},"type":"lvl2","url":"/l-a2-01-function-calling-and-tools#building-a-network-analysis-toolkit","position":34},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Building a Network Analysis Toolkit"},"content":"\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#building-a-network-analysis-toolkit","position":35},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Exposing NetworkX to AI Agents","lvl2":"Building a Network Analysis Toolkit"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#exposing-networkx-to-ai-agents","position":36},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Exposing NetworkX to AI Agents","lvl2":"Building a Network Analysis Toolkit"},"content":"Now let’s build something more relevant to our course: tools for network analysis.\n\nWe studied networks using Julia and Graphs.jl.\n\nHowever, becauase we are using Python and pydantic AI we need to use the correspondint network science library for Python\n\nThe most widely used library is networkx.\n\nWe’ll create a set of functions that let an AI agent:\n\nCreate networks from edge lists\n\nCalculate centrality measures\n\nCompute clustering coefficients\n\nFind shortest paths\n\nAnalyze network structure\n\nThis demonstrates how to make computational tools from our course (Weeks 3-5) accessible to AI agents.\n\nimport networkx as nx\nfrom dataclasses import dataclass\n\n# Define dependencies using dependency injection instead of global state\n@dataclass\nclass NetworkDeps:\n    graphs: dict[str, nx.Graph]\n\n# We'll create an agent with these dependencies\nprint(\"Network dependencies defined\")\n\n# Create network analysis agent with dependencies\nnetwork_agent = Agent('anthropic:claude-haiku-4-5', deps_type=NetworkDeps)\n\n@network_agent.tool\ndef create_network(\n    ctx: RunContext[NetworkDeps],\n    graph_id: str,\n    edges: list[list[int]]\n) -> dict:\n    \"\"\"\n    Create a network from an edge list and store it.\n\n    Args:\n        graph_id: Unique identifier for this graph (e.g., 'social_network', 'graph1')\n        edges: List of edges where each edge is [source, target]. Example: [[1,2], [2,3], [1,3]]\n\n    Returns:\n        Dictionary with graph statistics (num_nodes, num_edges, density)\n    \"\"\"\n    # Find max node ID to determine number of nodes\n    max_node = max(max(e) for e in edges)\n\n    # Create graph\n    g = nx.Graph()\n    g.add_nodes_from(range(1, max_node + 1))\n    g.add_edges_from(edges)\n\n    # Store in context dependencies\n    ctx.deps.graphs[graph_id] = g\n\n    return {\n        \"graph_id\": graph_id,\n        \"num_nodes\": g.number_of_nodes(),\n        \"num_edges\": g.number_of_edges(),\n        \"density\": round(nx.density(g), 4)\n    }\n\n@network_agent.tool\ndef calculate_degree_centrality(\n    ctx: RunContext[NetworkDeps],\n    graph_id: str,\n    node: int\n) -> dict:\n    \"\"\"\n    Calculate degree centrality for a node. Degree centrality measures how many connections a node has.\n\n    Args:\n        graph_id: ID of the graph to analyze\n        node: The node ID to calculate centrality for\n\n    Returns:\n        Dictionary with degree and normalized centrality value\n    \"\"\"\n    g = ctx.deps.graphs[graph_id]\n    deg = g.degree(node)\n    max_possible = g.number_of_nodes() - 1\n    normalized = deg / max_possible if max_possible > 0 else 0\n\n    return {\n        \"node\": node,\n        \"degree\": deg,\n        \"normalized_centrality\": round(normalized, 4)\n    }\n\n@network_agent.tool\ndef calculate_betweenness(\n    ctx: RunContext[NetworkDeps],\n    graph_id: str,\n    node: int\n) -> dict:\n    \"\"\"\n    Calculate betweenness centrality for a node. High betweenness nodes are 'bridges' in the network.\n\n    Args:\n        graph_id: ID of the graph to analyze\n        node: The node ID to calculate betweenness for\n\n    Returns:\n        Dictionary with betweenness centrality value\n    \"\"\"\n    g = ctx.deps.graphs[graph_id]\n    bc = nx.betweenness_centrality(g)\n\n    return {\n        \"node\": node,\n        \"betweenness_centrality\": round(bc[node], 4)\n    }\n\n@network_agent.tool\ndef calculate_clustering_coefficient(\n    ctx: RunContext[NetworkDeps],\n    graph_id: str\n) -> dict:\n    \"\"\"\n    Calculate global clustering coefficient. Values close to 1 indicate high clustering.\n\n    Args:\n        graph_id: ID of the graph to analyze\n\n    Returns:\n        Dictionary with clustering coefficient\n    \"\"\"\n    g = ctx.deps.graphs[graph_id]\n    cc = nx.average_clustering(g)\n\n    return {\n        \"clustering_coefficient\": round(cc, 4)\n    }\n\n@network_agent.tool\ndef find_shortest_path(\n    ctx: RunContext[NetworkDeps],\n    graph_id: str,\n    source: int,\n    target: int\n) -> dict:\n    \"\"\"\n    Find shortest path between two nodes. Returns the path and its length.\n\n    Args:\n        graph_id: ID of the graph to search\n        source: Starting node ID\n        target: Destination node ID\n\n    Returns:\n        Dictionary with path information\n    \"\"\"\n    g = ctx.deps.graphs[graph_id]\n\n    try:\n        path = nx.shortest_path(g, source, target)\n        return {\n            \"found\": True,\n            \"path\": path,\n            \"length\": len(path) - 1\n        }\n    except nx.NetworkXNoPath:\n        return {\n            \"found\": False,\n            \"message\": f\"No path exists between nodes {source} and {target}\"\n        }\n\nprint(\"Network analysis tools defined!\")\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#exposing-networkx-to-ai-agents","position":37},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Network Analysis Agent","lvl2":"Building a Network Analysis Toolkit"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#network-analysis-agent","position":38},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Network Analysis Agent","lvl2":"Building a Network Analysis Toolkit"},"content":"Now let’s create an agent that can use these network analysis tools. This agent will be able to answer questions about networks by calling the appropriate functions.\n\ndef run_network_agent(user_query: str) -> str:\n    \"\"\"\n    Run a network analysis agent that can use multiple tools to answer questions.\n\n    PydanticAI handles:\n    - Multi-turn conversations\n    - Tool call dispatch\n    - Message history management\n    - Result formatting\n    \"\"\"\n    print(f\"User: {user_query}\\n\")\n    print(\"=\"*80)\n\n    # Create fresh dependencies for this conversation\n    deps = NetworkDeps(graphs={})\n\n    # PydanticAI handles all the complexity!\n    result = network_agent.run_sync(user_query, deps=deps)\n\n    print(f\"\\nFinal Answer:\\n{result.output}\")\n    return result\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#network-analysis-agent","position":39},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Testing the Network Analysis Agent","lvl2":"Building a Network Analysis Toolkit"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#testing-the-network-analysis-agent","position":40},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Testing the Network Analysis Agent","lvl2":"Building a Network Analysis Toolkit"},"content":"Let’s test our agent with progressively more complex questions:\n\n# Test 1: Basic network analysis\nquery1 = \"\"\"\nI have a social network with the following friendships (edges):\n- Person 1 is friends with persons 2, 3, and 4\n- Person 2 is friends with persons 1 and 3\n- Person 3 is friends with persons 1, 2, and 4\n- Person 4 is friends with persons 1 and 3\n- Person 5 is friends with nobody\n\nCreate this network (call it 'social') and tell me:\n1. What is the clustering coefficient?\n2. Which person has the highest degree centrality?\n\"\"\"\n\nnetwork1_result = run_network_agent(query1)\n\n# Test 2: Path finding\n# Note: We need to recreate the network since each call gets fresh dependencies.\n#       We could easily fix this by not recreating the NetworkDeps each time.\nquery2 = \"\"\"\nCreate a network called 'social' with edges:\n[[1,2], [1,3], [1,4], [2,1], [2,3], [3,1], [3,2], [3,4], [4,1], [4,3]]\n\nThen find the shortest path from person 2 to person 4.\n\"\"\"\n\nnetwork2_result = run_network_agent(query2)\n\nnetwork2_result.all_messages()\n\n# Test 3: Complex multi-step analysis\nquery3 = \"\"\"\nCreate a new network called 'bridge' with these edges:\n[[1,2], [2,3], [3,4], [4,5], [1,3], [3,5]]\n\nThen find which node has the highest betweenness centrality. That node should be\na 'bridge' connecting different parts of the network.\n\"\"\"\n\nnetwork3_result = run_network_agent(query3)\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#testing-the-network-analysis-agent","position":41},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"What We’ve Accomplished","lvl2":"Building a Network Analysis Toolkit"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#what-weve-accomplished","position":42},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"What We’ve Accomplished","lvl2":"Building a Network Analysis Toolkit"},"content":"This network analysis agent demonstrates several powerful capabilities:\n\n1. Multi-Step Reasoning\n\nAgent breaks down complex questions into steps\n\nCalls tools in the right order (create network first, then analyze)\n\nChains multiple function calls together\n\n2. Natural Language Understanding\n\nParses network descriptions from text\n\nUnderstands what analysis to perform\n\nInterprets results in domain-appropriate ways\n\n3. Computational Precision\n\nUses real networkx algorithms\n\nNo approximation or hallucination\n\nResults are reproducible and verifiable\n\n4. State Management\n\nCreates and stores graphs\n\nReferences them in subsequent queries\n\nMaintains context across function calls\n\nThis pattern can be extended to any computational domain - game theory, agent-based models, blockchain analysis, etc.\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#what-weve-accomplished","position":43},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Safety and Sandboxing"},"type":"lvl2","url":"/l-a2-01-function-calling-and-tools#safety-and-sandboxing","position":44},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Safety and Sandboxing"},"content":"\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#safety-and-sandboxing","position":45},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"The Danger of Unrestricted Tool Use","lvl2":"Safety and Sandboxing"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#the-danger-of-unrestricted-tool-use","position":46},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"The Danger of Unrestricted Tool Use","lvl2":"Safety and Sandboxing"},"content":"Giving an AI agent the ability to execute functions is powerful - but also risky.\n\nConsider if we gave an agent these tools:function delete_file(path::String)\n    rm(path)\nend\n\nfunction execute_shell_command(cmd::String)\n    run(`bash -c $cmd`)\nend\n\nfunction send_email(to::String, subject::String, body::String)\n    # Send email...\nend\n\nNow imagine:\n\nUser asks: “Clean up my files”\n\nAgent interprets broadly: deletes everything\n\nOr worse: agent is prompted by malicious input to send spam\n\nThis isn’t hypothetical - it’s a real concern as agentic AI systems become more powerful.","type":"content","url":"/l-a2-01-function-calling-and-tools#the-danger-of-unrestricted-tool-use","position":47},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Safety Principles","lvl2":"Safety and Sandboxing"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#safety-principles","position":48},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Safety Principles","lvl2":"Safety and Sandboxing"},"content":"1. Principle of Least Privilege\n\nOnly expose tools that are absolutely necessary\n\nDon’t give file system access if you only need calculations\n\nRestrict tools to their minimum required scope\n\n2. Sandboxing\n\nRun tools in isolated environments\n\nLimit access to system resources\n\nUse containers (Docker) or VMs for code execution\n\n3. Read vs Write Separation\n\nDistinguish tools that read state from those that modify it\n\nReading network data: low risk\n\nDeleting data: high risk\n\nConsider requiring human approval for high-risk operations\n\n4. Input Validation\n\nValidate all function arguments\n\nCheck types, ranges, formats\n\nReject unexpected or malicious inputs\n\n5. Rate Limiting\n\nLimit how many times a tool can be called\n\nPrevent runaway loops or denial-of-service\n\nExample: Max 100 network operations per conversation\n\n6. Logging and Auditing\n\nLog every tool call\n\nRecord arguments and results\n\nEnable post-hoc analysis of agent behavior","type":"content","url":"/l-a2-01-function-calling-and-tools#safety-principles","position":49},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Safe Tool Design Patterns","lvl2":"Safety and Sandboxing"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#safe-tool-design-patterns","position":50},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Safe Tool Design Patterns","lvl2":"Safety and Sandboxing"},"content":"Pattern 1: Read-Only by Default# Safe: Just reads and computes\nfunction get_network_stats(graph_id::String)\n    g = GRAPHS[graph_id]\n    return Dict(\n        \"nodes\" => nv(g),\n        \"edges\" => ne(g),\n        \"density\" => density(g)\n    )\nend\n\n# Risky: Modifies state\nfunction delete_network(graph_id::String)\n    delete!(GRAPHS, graph_id)\nend\n\nPattern 2: Explicit Boundaries# Safe: Only works within defined space\nfunction create_network(graph_id::String, edges::Vector{Vector{Int}})\n    # Validate: max 1000 nodes\n    max_node = maximum(maximum.(edges))\n    if max_node > 1000\n        error(\"Networks limited to 1000 nodes\")\n    end\n    \n    # Validate: max 10000 edges\n    if length(edges) > 10000\n        error(\"Networks limited to 10000 edges\")\n    end\n    \n    # ... create network\nend\n\nPattern 3: Confirmation for Destructive Operations# High-risk operations return a confirmation token\nfunction request_data_deletion(graph_id::String)\n    token = generate_confirmation_token()\n    return Dict(\n        \"message\" => \"Deleting $graph_id requires confirmation\",\n        \"confirmation_token\" => token\n    )\nend\n\nfunction confirm_data_deletion(token::String)\n    # Human must provide the token\n    # ... perform deletion\nend","type":"content","url":"/l-a2-01-function-calling-and-tools#safe-tool-design-patterns","position":51},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Code Execution: The Ultimate Risk","lvl2":"Safety and Sandboxing"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#code-execution-the-ultimate-risk","position":52},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Code Execution: The Ultimate Risk","lvl2":"Safety and Sandboxing"},"content":"One common agentic capability is code execution - letting agents write and run code.\n\nThis is incredibly powerful:\n\nAgent can perform arbitrary computations\n\nCan generate visualizations\n\nCan analyze data in flexible ways\n\nBut also incredibly dangerous:\n\nAgent could run rm -rf /\n\nCould exfiltrate sensitive data\n\nCould install malware\n\nSafe Code Execution Strategies:\n\nIsolated Execution Environment\n\nDocker containers with no network access\n\nLimited CPU/memory/disk\n\nNo access to host filesystem\n\nLanguage Subset\n\nRestrict to safe operations only\n\nParse and validate code before execution\n\nBlock dangerous functions (system calls, file I/O)\n\nTimeouts\n\nKill code that runs too long\n\nPrevent infinite loops\n\nReview Before Execution\n\nShow code to user first\n\nLet them approve or reject\n\nOnly auto-execute for trusted, common operations\n\nTools like E2B and Modal provide sandboxed code execution environments specifically designed for AI agents.","type":"content","url":"/l-a2-01-function-calling-and-tools#code-execution-the-ultimate-risk","position":53},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Our Network Tools: Safety Analysis","lvl2":"Safety and Sandboxing"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#our-network-tools-safety-analysis","position":54},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Our Network Tools: Safety Analysis","lvl2":"Safety and Sandboxing"},"content":"Let’s evaluate our network analysis tools:\n\n✓ Safe:\n\nAll tools are read-only or create temporary state\n\nNo file system access\n\nNo network access\n\nNo system commands\n\nBounded computational complexity (small graphs)\n\n⚠️ Could Improve:\n\nAdd max graph size limits\n\nAdd rate limiting (max N tools calls per session)\n\nAdd timeouts for expensive operations\n\nValidate graph IDs (prevent path traversal attacks)\n\nFor Production:\n\nRun in separate process\n\nImplement resource limits\n\nAdd comprehensive logging\n\nMonitor for anomalous behavior\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#our-network-tools-safety-analysis","position":55},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Tool Use with Claude (Anthropic)"},"type":"lvl2","url":"/l-a2-01-function-calling-and-tools#tool-use-with-claude-anthropic","position":56},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Tool Use with Claude (Anthropic)"},"content":"\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#tool-use-with-claude-anthropic","position":57},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Different Provider, Same Concept","lvl2":"Tool Use with Claude (Anthropic)"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#different-provider-same-concept","position":58},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Different Provider, Same Concept","lvl2":"Tool Use with Claude (Anthropic)"},"content":"We’ve been using OpenAI’s function calling API. Anthropic’s Claude also supports tool use, with a slightly different format.\n\nLet’s see how to implement the same network analysis agent using Claude:\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#different-provider-same-concept","position":59},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"PydanticAI: Model-Agnostic Abstraction","lvl2":"Tool Use with Claude (Anthropic)"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#pydanticai-model-agnostic-abstraction","position":60},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"PydanticAI: Model-Agnostic Abstraction","lvl2":"Tool Use with Claude (Anthropic)"},"content":"One of the biggest advantages of PydanticAI is that it abstracts away provider differences. You write your tools once, and they work with any LLM provider.\n\nSwitching Models is Trivial:# OpenAI\nagent = Agent('openai:gpt-4o-mini')\n\n# Anthropic\nagent = Agent('anthropic:claude-3-5-sonnet-20241022')\n\n# Google\nagent = Agent('google-gpt:gemini-1.5-flash')\n\n# OpenAI with different model\nagent = Agent('openai:gpt-5')\n\nThe same tools work with all of them! PydanticAI handles:\n\nDifferent API formats\n\nDifferent schema requirements\n\nDifferent message structures\n\nDifferent tool calling conventions\n\nWhy This Matters:\n\nNo vendor lock-in: Switch providers based on performance, cost, or availability\n\nA/B testing: Compare models easily\n\nFallbacks: If one provider is down, switch to another\n\nFuture-proof: New models supported as they’re added to PydanticAI\n\nUnder the Hood: Different providers do have different APIs:\n\nOpenAI:\n\nUses tools array in request\n\nReturns tool calls in response messages\n\nUses function schema format\n\nAnthropic:\n\nUses tools array in request\n\nReturns tool calls in content blocks\n\nUses input_schema format (slightly different)\n\nGoogle, Mistral, Others:\n\nEach has own format and conventions\n\nPydanticAI: Provides a unified interface, translating between your Python code and each provider’s specific format.\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#pydanticai-model-agnostic-abstraction","position":61},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Exercises"},"type":"lvl2","url":"/l-a2-01-function-calling-and-tools#exercises","position":62},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Exercises"},"content":"\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#exercises","position":63},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Exercise 1: Game Theory Tools","lvl2":"Exercises"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#exercise-1-game-theory-tools","position":64},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Exercise 1: Game Theory Tools","lvl2":"Exercises"},"content":"Building on Weeks 8-9 (Game Theory), create a set of tools for analyzing normal-form games.\n\nPart A: Implement these functions:\n\ncreate_game(game_id, payoff_matrices) - Create a normal-form game\n\nfind_pure_nash_equilibria(game_id) - Find pure strategy Nash equilibria\n\ncheck_dominant_strategy(game_id, player, strategy) - Check if a strategy is dominant\n\ncalculate_expected_payoff(game_id, player, strategy_profile) - Calculate payoffs\n\nPart B: Define JSON schemas for each function\n\nPart C: Create a game theory agent and test it with:\n\nPrisoner’s Dilemma\n\nMatching Pennies\n\nA 3x3 game of your choice\n\nPart D: Compare agent analysis to your own analysis from Week 8. Does the agent identify the same equilibria?\n\n# TODO: Your code here\n\n# Hint: Create an agent and use @agent.tool decorator\n# from pydantic_ai import Agent, RunContext\n\n# game_theory_agent = Agent('anthropic:claude-haiku-4-5')\n\n# @game_theory_agent.tool\n# def create_game(ctx: RunContext[None], game_id: str, ...):\n#     \"\"\"Create a normal-form game.\"\"\"\n#     pass\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#exercise-1-game-theory-tools","position":65},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Exercise 2: Data Analysis Agent","lvl2":"Exercises"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#exercise-2-data-analysis-agent","position":66},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Exercise 2: Data Analysis Agent","lvl2":"Exercises"},"content":"Create an agent that can analyze datasets using statistical tools.\n\nPart A: Implement these tools:\n\nload_dataset(dataset_id, data) - Load data from array/CSV format\n\ndescribe_dataset(dataset_id) - Get summary statistics (mean, median, std, etc.)\n\nfilter_data(dataset_id, column, condition, value) - Filter rows\n\naggregate_data(dataset_id, groupby_col, agg_col, operation) - Group and aggregate\n\nPart B: Test with network data from Week 3-5:\n\nLoad degree distribution data\n\nAsk agent to compute statistics\n\nAsk agent to identify nodes with degree > threshold\n\nAsk agent to find the average degree by some node attribute\n\nReflection: How does an AI agent with data tools compare to writing analysis scripts manually? What are the trade-offs?\n\n# TODO: Your code here\n\n# You'll want to use pandas\n# import pandas as pd\n# from pydantic_ai import Agent, RunContext\n# from dataclasses import dataclass\n\n# @dataclass\n# class DataDeps:\n#     datasets: dict[str, pd.DataFrame]\n\n# data_agent = Agent('anthropic:claude-haiku-4-5', deps_type=DataDeps)\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#exercise-2-data-analysis-agent","position":67},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Exercise 3: Multi-Tool Reasoning","lvl2":"Exercises"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#exercise-3-multi-tool-reasoning","position":68},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Exercise 3: Multi-Tool Reasoning","lvl2":"Exercises"},"content":"Test your network analysis agent with questions that require multiple tool calls and reasoning.\n\nQuestions to test:\n\n“Create two networks: A with edges [[1,2],[2,3],[3,1]] and B with edges [[1,2],[2,3],[3,4],[4,1]]. Which one has higher clustering?”\n\n“In the social network from earlier, find the shortest path from node 1 to node 5. Then calculate the betweenness centrality of each node on that path. Which node on the path is most ‘bridge-like’?”\n\n“Create a star network where node 1 connects to nodes 2, 3, 4, 5, 6 (call it ‘star’). Calculate the degree centrality of the center node and a peripheral node. What’s the ratio?”\n\nAnalysis:\n\nHow many tool calls did each question require?\n\nDid the agent chain them correctly?\n\nWere there any errors or surprising behaviors?\n\nHow did the agent interpret and synthesize results?\n\n# TODO: Test your agent with the questions above\n\n# Example:\n# result = run_network_agent(\"Create two networks...\")\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#exercise-3-multi-tool-reasoning","position":69},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Exercise 4: Safety Analysis","lvl2":"Exercises"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#exercise-4-safety-analysis","position":70},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Exercise 4: Safety Analysis","lvl2":"Exercises"},"content":"Consider the following tool definitions and analyze their safety:# Tool 1\nfunction run_julia_code(code::String)\n    eval(Meta.parse(code))\nend\n\n# Tool 2\nfunction download_file(url::String, save_path::String)\n    download(url, save_path)\nend\n\n# Tool 3\nfunction send_http_request(url::String, method::String, body::String)\n    HTTP.request(method, url, body=body)\nend\n\n# Tool 4\nfunction analyze_text(text::String)\n    return Dict(\n        \"word_count\" => length(split(text)),\n        \"char_count\" => length(text),\n        \"sentiment\" => \"positive\"  # Simplified\n    )\nend\n\nFor each tool, answer:\n\nWhat are the security risks?\n\nWhat attacks could a malicious user attempt?\n\nHow would you make it safer?\n\nShould this tool be available to AI agents at all? Why or why not?\n\nDesign challenge: Redesign Tools 1-3 to be safer while maintaining usefulness.\n\nYour Analysis:\n\nTool 1 - run_julia_code:\n\nRisks: ...\n\nAttacks: ...\n\nSafer version: ...\n\n(Continue for other tools)\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#exercise-4-safety-analysis","position":71},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Connecting to Course Themes"},"type":"lvl2","url":"/l-a2-01-function-calling-and-tools#connecting-to-course-themes","position":72},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Connecting to Course Themes"},"content":"\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#connecting-to-course-themes","position":73},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Computational Social Complexity and Tool Use","lvl2":"Connecting to Course Themes"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#computational-social-complexity-and-tool-use","position":74},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Computational Social Complexity and Tool Use","lvl2":"Connecting to Course Themes"},"content":"Throughout this course, we’ve studied complex systems computationally:\n\nNetworks (Weeks 3-5):\n\nWe analyzed network structure with Graphs.jl\n\nNow: AI agents can perform the same analyses via tools\n\nImplication: Natural language interface to network science\n\nAgent-Based Models (Weeks 6-7):\n\nWe built simulations of agents with simple rules\n\nNow: AI agents can run those simulations and interpret results\n\nImplication: Agents analyzing agents - meta-level reasoning\n\nGame Theory (Weeks 8-9):\n\nWe computed equilibria and analyzed strategic behavior\n\nNow: AI agents can solve games and explain the solutions\n\nImplication: AI as game theory consultant\n\nBlockchains (Weeks 11-12):\n\nWe’ll analyze on-chain data and smart contracts\n\nSoon: AI agents that can query blockchain state and interpret transactions\n\nImplication: Natural language blockchain analysis","type":"content","url":"/l-a2-01-function-calling-and-tools#computational-social-complexity-and-tool-use","position":75},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"The Bigger Picture: Computational Assistants","lvl2":"Connecting to Course Themes"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#the-bigger-picture-computational-assistants","position":76},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"The Bigger Picture: Computational Assistants","lvl2":"Connecting to Course Themes"},"content":"What we’ve built in this lecture is a computational assistant:\n\nUnderstands natural language questions\n\nTranslates to computational operations\n\nExecutes precise calculations\n\nInterprets and explains results\n\nThis is qualitatively different from chatbots:\n\nChatbots: Generate plausible text\n\nComputational assistants: Generate verified results\n\nThe key is the tool layer - it grounds the AI in actual computation.","type":"content","url":"/l-a2-01-function-calling-and-tools#the-bigger-picture-computational-assistants","position":77},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Emergence Revisited","lvl2":"Connecting to Course Themes"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#emergence-revisited","position":78},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"Emergence Revisited","lvl2":"Connecting to Course Themes"},"content":"Remember our recurring theme of emergence:\n\nSimple rules → Complex behavior (ABMs)\n\nLocal interactions → Global patterns (Networks)\n\nIndividual rationality → Collective outcomes (Game Theory)\n\nTool use adds another dimension:\n\nTraining objective: Next-word prediction\n\nEmergent capability: Tool use\n\nLLMs weren’t explicitly trained to “use tools”. They learned it from:\n\nSeeing API documentation in training data\n\nSeeing code that calls functions\n\nGeneral pattern recognition\n\nThis is emergence at the model capability level.","type":"content","url":"/l-a2-01-function-calling-and-tools#emergence-revisited","position":79},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"What This Enables for Research","lvl2":"Connecting to Course Themes"},"type":"lvl3","url":"/l-a2-01-function-calling-and-tools#what-this-enables-for-research","position":80},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl3":"What This Enables for Research","lvl2":"Connecting to Course Themes"},"content":"As computational social scientists, tool-using AI agents open new possibilities:\n\n1. Exploratory Data Analysis\n\n“Show me the degree distribution”\n\n“Find communities in this network”\n\nAgent handles the mechanics, you think about implications\n\n2. Hypothesis Testing\n\n“Is there a correlation between centrality and outcome?”\n\nAgent runs statistical tests, reports results\n\nYou focus on interpretation and theory\n\n3. Simulation and Experimentation\n\n“Run the Schelling model with these parameters”\n\n“Compare segregation outcomes across 10 different preference thresholds”\n\nAgent orchestrates experiments\n\n4. Reproducible Research\n\nNatural language → Code → Results\n\nFull chain is logged and reproducible\n\nOthers can verify your computational analyses\n\n5. Education and Dissemination\n\nStudents can explore concepts interactively\n\nPolicymakers can query models without coding\n\nDemocratizes access to computational tools\n\nThe future of computational social science may involve collaboration between human researchers and AI agents, each contributing their strengths.\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#what-this-enables-for-research","position":81},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Summary"},"type":"lvl2","url":"/l-a2-01-function-calling-and-tools#summary","position":82},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Summary"},"content":"\n\nIn this lecture, we’ve explored how to transform AI agents from conversational systems into computational actors:\n\n✓ Implemented function calling with modern LLM APIs (OpenAI and Anthropic)\n\n✓ Designed JSON schemas to describe tool interfaces to AI agents\n\n✓ Built a network analysis toolkit exposing Graphs.jl functions to agents\n\n✓ Understood the Model Context Protocol as a standard for tool interoperability\n\n✓ Analyzed safety considerations for tool use and code execution\n\n✓ Created agents that compute, not just converse - executing real Julia code\n\nKey Takeaways:\n\nFunction calling bridges language and computation - agents can DO things, not just describe them\n\nJSON schemas are the interface language - clear descriptions enable agents to use tools correctly\n\nMCP provides standardization - write tools once, use with any AI application\n\nSafety is paramount - unrestricted tool use is dangerous, design with security in mind\n\nMulti-step reasoning emerges - agents chain tool calls to solve complex problems\n\nDomain expertise encoded as tools - computational social science becomes accessible via natural language\n\nPrecision matters - tool use gives verified results, not approximations\n\nNext Lecture: We’ll explore structured output patterns and type safety with PydanticAI, learning how to build more robust and reliable agentic systems with strong validation and error handling.\n\n","type":"content","url":"/l-a2-01-function-calling-and-tools#summary","position":83},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Further Reading"},"type":"lvl2","url":"/l-a2-01-function-calling-and-tools#further-reading","position":84},{"hierarchy":{"lvl1":"Function Calling and Tool Use: From Talk to Action","lvl2":"Further Reading"},"content":"Function Calling and Tool Use:\n\nSchick et al. (2023) “Toolformer: Language Models Can Teach Themselves to Use Tools” \n\narXiv:2302.04761\n\nQin et al. (2023) “Tool Learning with Foundation Models” \n\narXiv:2304.08354\n\nPatil et al. (2023) “Gorilla: Large Language Model Connected with Massive APIs” \n\narXiv:2305.15334\n\nModel Context Protocol:\n\nMCP Specification: \n\nhttps://​modelcontextprotocol​.io/\n\nMCP Announcement Blog Post: \n\nhttps://​www​.anthropic​.com​/news​/model​-context​-protocol\n\nMCP Server Examples: \n\nhttps://​github​.com​/modelcontextprotocol​/servers\n\nAPI Documentation:\n\nOpenAI Function Calling: \n\nhttps://​platform​.openai​.com​/docs​/guides​/function​-calling\n\nAnthropic Tool Use: \n\nhttps://​docs​.anthropic​.com​/claude​/docs​/tool​-use\n\nSafety and Sandboxing:\n\nE2B Code Interpreter: \n\nhttps://e2b.dev/\n\nModal Sandboxed Execution: \n\nhttps://modal.com/\n\nKang et al. (2023) “If LLM Is the Wizard, Then Code Is the Wand” \n\narXiv:2401.00812\n\nAgentic Systems:\n\nWang et al. (2024) “A Survey on Large Language Model Based Autonomous Agents” \n\narXiv:2308.11432\n\nXi et al. (2023) “The Rise and Potential of Large Language Model Based Agents” \n\narXiv:2309.07864","type":"content","url":"/l-a2-01-function-calling-and-tools#further-reading","position":85},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns"},"type":"lvl1","url":"/l-a2-02-type-safe-agents-pydantic-patterns","position":0},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns"},"content":"Computational Analysis of Social Complexity\n\nFall 2025, Spencer Lyon\n\nPrerequisites\n\nFunction calling concepts (L.A2.01)\n\nPython type hints and type safety\n\nBasic agent architectures\n\nOutcomes\n\nUnderstand type-safe agent development principles\n\nImplement validation-first agent architectures with Pydantic\n\nApply dependency injection patterns for testable agents\n\nBuild production-ready AI agents with PydanticAI\n\nReferences\n\nPydanticAI Documentation\n\nPydantic Documentation\n\nPython Type Hints\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns","position":1},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl2":"Why Type Safety Matters"},"type":"lvl2","url":"/l-a2-02-type-safe-agents-pydantic-patterns#why-type-safety-matters","position":2},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl2":"Why Type Safety Matters"},"content":"\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#why-type-safety-matters","position":3},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"The Problem: Unvalidated Agent Systems","lvl2":"Why Type Safety Matters"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#the-problem-unvalidated-agent-systems","position":4},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"The Problem: Unvalidated Agent Systems","lvl2":"Why Type Safety Matters"},"content":"Consider a simple agent that processes user queries and makes database updates\n\nWhat could go wrong?\n\nWrong data types passed to functions\n\nInvalid values that violate business logic\n\nRuntime errors deep in execution\n\nSilent failures that corrupt data\n\nThese bugs are expensive in production\n\nType safety catches entire classes of errors before they happen\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#the-problem-unvalidated-agent-systems","position":5},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"A Concrete Example","lvl2":"Why Type Safety Matters"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#a-concrete-example","position":6},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"A Concrete Example","lvl2":"Why Type Safety Matters"},"content":"Suppose we’re building a research assistant agent that:\n\nTakes a research question\n\nSearches academic databases\n\nReturns structured citations\n\nWithout type safety:# Python - no validation\ndef search_papers(query, max_results, min_year):\n    # What if query is None?\n    # What if max_results is negative?\n    # What if min_year is 99999?\n    ...\n\nWith type safety:# Python with Pydantic\nfrom pydantic import BaseModel, Field\n\nclass SearchRequest(BaseModel):\n    query: str = Field(min_length=1, max_length=500)\n    max_results: int = Field(ge=1, le=100)\n    min_year: int = Field(ge=1900, le=2025)\n\ndef search_papers(request: SearchRequest):\n    # Guaranteed valid inputs!\n    ...\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#a-concrete-example","position":7},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Key Benefits","lvl2":"Why Type Safety Matters"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#key-benefits","position":8},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Key Benefits","lvl2":"Why Type Safety Matters"},"content":"Fail Fast, Fail Loud\n\nInvalid inputs rejected immediately\n\nClear error messages\n\nNo silent corruption\n\nSelf-Documenting Code\n\nTypes tell you what’s expected\n\nIDE autocomplete and hints\n\nLess need for comments\n\nRefactoring Confidence\n\nChange a type definition\n\nCompiler/type checker finds all affected code\n\nSafe to modify large systems\n\nTesting Made Easier\n\nDon’t need to test invalid types\n\nFocus on business logic\n\nReduce test surface area\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#key-benefits","position":9},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl2":"The PydanticAI Philosophy"},"type":"lvl2","url":"/l-a2-02-type-safe-agents-pydantic-patterns#the-pydanticai-philosophy","position":10},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl2":"The PydanticAI Philosophy"},"content":"\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#the-pydanticai-philosophy","position":11},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"What is PydanticAI?","lvl2":"The PydanticAI Philosophy"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#what-is-pydanticai","position":12},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"What is PydanticAI?","lvl2":"The PydanticAI Philosophy"},"content":"PydanticAI is a Python framework for building production-ready AI agents\n\nCreated by the team behind Pydantic\n\nPydantic powers the OpenAI SDK, Anthropic SDK, FastAPI, and countless other production systems\n\nPhilosophy: validation-first development\n\nWhy PydanticAI?\n\nType safety catches errors before runtime\n\nValidation ensures data integrity\n\nProduction-ready patterns from day one\n\nSeamless integration with Python’s type system\n\nUsed by major companies in production\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#what-is-pydanticai","position":13},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Chef’s Knife and Cutting Board","lvl2":"The PydanticAI Philosophy"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#chefs-knife-and-cutting-board","position":14},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Chef’s Knife and Cutting Board","lvl2":"The PydanticAI Philosophy"},"content":"PydanticAI describes itself as providing a “chef’s knife and cutting board”\n\nWhat does this mean?\n\nNOT a framework with opinions about everything\n\nIS a toolkit with powerful, composable primitives\n\nSimple tools that do one thing well\n\nCombine them however you want\n\nContrast with LangChain:\n\nLangChain: Full kitchen with every appliance\n\nChains, memory, vector stores, callbacks, etc.\n\nComplex abstractions\n\nSteep learning curve\n\nHard to customize\n\nPydanticAI: Essential tools\n\nAgent, tools, structured outputs\n\nSimple abstractions\n\nEasy to understand\n\nFlexible customization\n\nWhen to Use Which:\n\nUse PydanticAI when: building production systems, need type safety, want simplicity\n\nUse LangChain when: rapid prototyping, need batteries-included features, okay with complexity\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#chefs-knife-and-cutting-board","position":15},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Core Principles","lvl2":"The PydanticAI Philosophy"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#core-principles","position":16},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Core Principles","lvl2":"The PydanticAI Philosophy"},"content":"1. Type Safety First\n\nAll inputs validated before use\n\nAll outputs structured and validated\n\nCatch errors at design time, not runtime\n\n2. Validation Before Computation\n\nNever process invalid data\n\nFail immediately with clear messages\n\nMake invalid states unrepresentable\n\n3. Dependency Injection\n\nAgents don’t create their dependencies\n\nDependencies passed in at construction\n\nEasy to test with mocks\n\nEasy to swap implementations\n\n4. Explicit Over Implicit\n\nNo magic global state\n\nNo hidden configuration\n\nEverything visible in function signatures\n\n5. Production Ready\n\nDesigned for real systems, not demos\n\nHandles errors gracefully\n\nObservability built-in\n\nPerformance matters\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#core-principles","position":17},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl2":"Core Agent Components"},"type":"lvl2","url":"/l-a2-02-type-safe-agents-pydantic-patterns#core-agent-components","position":18},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl2":"Core Agent Components"},"content":"\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#core-agent-components","position":19},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"The Four Essential Pieces","lvl2":"Core Agent Components"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#the-four-essential-pieces","position":20},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"The Four Essential Pieces","lvl2":"Core Agent Components"},"content":"Every PydanticAI agent has these components:\n\n1. Agent Definition\n\nSpecifies the LLM model to use\n\nDefines system prompt\n\nRegisters available tools\n\n2. Tool Functions\n\nFunctions the agent can call\n\nType-annotated parameters\n\nValidated inputs and outputs\n\n3. Structured Outputs\n\nDefine what the agent should return\n\nPydantic models for validation\n\nGuaranteed schema compliance\n\n4. Run Context (Dependencies)\n\nExternal services (databases, APIs)\n\nConfiguration\n\nState that flows through execution\n\nLet’s examine each in detail\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#the-four-essential-pieces","position":21},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"1. Agent Definition","lvl2":"Core Agent Components"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#id-1-agent-definition","position":22},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"1. Agent Definition","lvl2":"Core Agent Components"},"content":"In PydanticAI (Python):from pydantic_ai import Agent\n\nagent = Agent(\n    'anthropic:claude-haiku-4-5',\n    system_prompt=\"You are a helpful research assistant.\",\n)\n\nKey aspects:\n\nModel string: Specifies which LLM to use\n\nSystem prompt: Sets agent behavior and role\n\nSimple constructor: No complex configuration\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#id-1-agent-definition","position":23},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"2. Tool Functions","lvl2":"Core Agent Components"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#id-2-tool-functions","position":24},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"2. Tool Functions","lvl2":"Core Agent Components"},"content":"Tools are functions the agent can call:from pydantic_ai import Agent\n\nagent = Agent('anthropic:claude-haiku-4-5')\n\n@agent.tool\ndef search_papers(\n    query: str,\n    max_results: int = 10\n) -> list[dict]:\n    \"\"\"Search academic papers by query.\"\"\"\n    # Implementation here\n    return results\n\nWhat happens:\n\nLLM sees tool name and docstring\n\nLLM decides when to call it\n\nParameters are validated against type hints\n\nFunction executes\n\nReturn value validated\n\nResult given back to LLM\n\nType safety at every step!\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#id-2-tool-functions","position":25},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"3. Structured Outputs","lvl2":"Core Agent Components"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#id-3-structured-outputs","position":26},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"3. Structured Outputs","lvl2":"Core Agent Components"},"content":"Define exactly what you want back:from pydantic import BaseModel\nfrom pydantic_ai import Agent\n\nclass Citation(BaseModel):\n    title: str\n    authors: list[str]\n    year: int\n    doi: str | None = None\n\nclass ResearchResult(BaseModel):\n    summary: str\n    citations: list[Citation]\n    confidence: float\n\nagent = Agent(\n    'anthropic:claude-haiku-4-5',\n    result_type=ResearchResult\n)\n\nBenefits:\n\nLLM must return this exact structure\n\nAutomatic validation\n\nNo parsing strings or JSON\n\nIDE autocomplete on results\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#id-3-structured-outputs","position":27},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"4. Run Context (Dependencies)","lvl2":"Core Agent Components"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#id-4-run-context-dependencies","position":28},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"4. Run Context (Dependencies)","lvl2":"Core Agent Components"},"content":"The secret sauce for testability:from pydantic_ai import Agent, RunContext\nfrom dataclasses import dataclass\n\n@dataclass\nclass Dependencies:\n    db: DatabaseClient\n    api_key: str\n    max_retries: int = 3\n\nagent = Agent(\n    'anthropic:claude-haiku-4-5',\n    deps_type=Dependencies\n)\n\n@agent.tool\ndef search_papers(\n    ctx: RunContext[Dependencies],\n    query: str\n) -> list[dict]:\n    # Access dependencies via ctx.deps\n    return ctx.deps.db.search(query)\n\nWhy this matters:\n\nNo global variables\n\nEasy to inject mock dependencies for testing\n\nExplicit about what each tool needs\n\nCan have different deps for dev/prod\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#id-4-run-context-dependencies","position":29},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Putting It All Together","lvl2":"Core Agent Components"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#putting-it-all-together","position":30},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Putting It All Together","lvl2":"Core Agent Components"},"content":"A complete PydanticAI agent:from pydantic import BaseModel\nfrom pydantic_ai import Agent, RunContext\nfrom dataclasses import dataclass\n\n# 1. Define dependencies\n@dataclass\nclass ResearchDeps:\n    db: DatabaseClient\n    api_key: str\n\n# 2. Define output structure\nclass Citation(BaseModel):\n    title: str\n    authors: list[str]\n    year: int\n\nclass ResearchResult(BaseModel):\n    summary: str\n    citations: list[Citation]\n\n# 3. Create agent\nagent = Agent(\n    'anthropic:claude-haiku-4-5',\n    deps_type=ResearchDeps,\n    result_type=ResearchResult,\n    system_prompt='You are a research assistant.'\n)\n\n# 4. Register tools\n@agent.tool\ndef search_papers(\n    ctx: RunContext[ResearchDeps],\n    query: str,\n    max_results: int = 10\n) -> list[dict]:\n    \"\"\"Search academic database.\"\"\"\n    return ctx.deps.db.search(query, limit=max_results)\n\n# 5. Run agent\nasync def run_research(question: str):\n    deps = ResearchDeps(\n        db=get_database(),\n        api_key=get_api_key()\n    )\n    result = await agent.run(question, deps=deps)\n    return result.data  # Guaranteed to be ResearchResult!\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#putting-it-all-together","position":31},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl2":"Building a Research Assistant"},"type":"lvl2","url":"/l-a2-02-type-safe-agents-pydantic-patterns#building-a-research-assistant","position":32},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl2":"Building a Research Assistant"},"content":"\n\nfrom dotenv import load_dotenv\nimport nest_asyncio\n\nload_dotenv()\nnest_asyncio.apply()\n\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#building-a-research-assistant","position":33},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"System Design","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#system-design","position":34},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"System Design","lvl2":"Building a Research Assistant"},"content":"Let’s build a complete research assistant that demonstrates all the PydanticAI concepts we’ve learned:\n\nFeatures:\n\nSearch academic papers by query\n\nGet detailed paper information\n\nGenerate structured research summaries\n\nType-safe dependencies and outputs\n\nMultiple tools working together\n\nArchitecture:User Query\n    ↓\nPydanticAI Agent (with system prompt)\n    ↓\nTool Selection (agent decides which tools to use)\n    ↓\nTool Execution (with validated inputs via RunContext)\n    ↓\nResult Synthesis (agent combines tool outputs)\n    ↓\nStructured Output (validated ResearchSummary)\n\nThis is a realistic pattern you’d use in production.\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#system-design","position":35},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Step 1: Define Output Structure","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#step-1-define-output-structure","position":36},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Step 1: Define Output Structure","lvl2":"Building a Research Assistant"},"content":"First, define what we want the agent to return:\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass Paper(BaseModel):\n    \"\"\"Academic paper with validated fields.\"\"\"\n    title: str = Field(min_length=1)\n    authors: list[str] = Field(min_length=1)\n    year: int = Field(ge=1800, le=2025)\n    abstract: str\n    doi: Optional[str] = None\n\nclass ResearchSummary(BaseModel):\n    \"\"\"Final research output with validation.\"\"\"\n    query: str = Field(min_length=1)\n    summary: str = Field(min_length=1, description=\"Natural language summary\")\n    key_papers: list[Paper] = Field(min_length=1, description=\"Most relevant papers found\")\n    confidence: float = Field(ge=0.0, le=1.0, description=\"Agent's confidence in results\")\n\n    def _repr_html_(self) -> str:\n        \"\"\"Rich HTML display for Jupyter notebooks.\"\"\"\n        papers_html = \"\"\n        for i, paper in enumerate(self.key_papers, 1):\n            authors = \", \".join(paper.authors)\n            doi_link = f'<a href=\"https://doi.org/{paper.doi}\" target=\"_blank\">DOI</a>' if paper.doi else \"\"\n            papers_html += f\"\"\"\n            <div style=\"margin: 10px 0; padding: 10px; background: #f8f9fa; border-left: 3px solid #007bff;\">\n                <strong>{i}. {paper.title}</strong> ({paper.year}) {doi_link}<br>\n                <em>{authors}</em><br>\n                <small style=\"color: #666;\">{paper.abstract[:200]}...</small>\n            </div>\n            \"\"\"\n\n        confidence_color = \"#28a745\" if self.confidence >= 0.7 else \"#ffc107\" if self.confidence >= 0.4 else \"#dc3545\"\n        confidence_pct = f\"{self.confidence:.0%}\"\n\n        return f\"\"\"\n        <div style=\"font-family: sans-serif; max-width: 800px;\">\n            <h3 style=\"color: #333; border-bottom: 2px solid #007bff; padding-bottom: 10px;\">\n                📚 Research Results: \"{self.query}\"\n            </h3>\n            <div style=\"margin: 15px 0; padding: 15px; background: #e7f3ff; border-radius: 5px;\">\n                <strong>Summary:</strong><br>\n                {self.summary}\n            </div>\n            <div style=\"margin: 10px 0;\">\n                <strong>Confidence:</strong>\n                <span style=\"color: {confidence_color}; font-weight: bold;\">{confidence_pct}</span>\n            </div>\n            <div style=\"margin-top: 20px;\">\n                <strong>Key Papers ({len(self.key_papers)}):</strong>\n                {papers_html}\n            </div>\n        </div>\n        \"\"\"\n\n    def __str__(self) -> str:\n        \"\"\"Plain text representation.\"\"\"\n        lines = [\n            f\"Research Results: {self.query}\",\n            \"=\" * 60,\n            f\"\\nSummary:\\n{self.summary}\",\n            f\"\\nConfidence: {self.confidence:.0%}\",\n            f\"\\nKey Papers ({len(self.key_papers)}):\",\n        ]\n\n        for i, paper in enumerate(self.key_papers, 1):\n            lines.append(f\"\\n{i}. {paper.title} ({paper.year})\")\n            lines.append(f\"   Authors: {', '.join(paper.authors)}\")\n            if paper.doi:\n                lines.append(f\"   DOI: {paper.doi}\")\n\n        return \"\\n\".join(lines)\n\n# Test that validation works\ntry:\n    invalid = Paper(title=\"\", authors=[], year=3000, abstract=\"test\")\nexcept Exception as e:\n    print(f\"✓ Validation caught error: {type(e).__name__}\")\n\nvalid = Paper(\n    title=\"Attention Is All You Need\",\n    authors=[\"Vaswani et al.\"],\n    year=2017,\n    abstract=\"We propose the Transformer...\"\n)\nprint(f\"✓ Valid paper created: {valid.title}\")\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#step-1-define-output-structure","position":37},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Step 2: Define Dependencies","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#step-2-define-dependencies","position":38},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Step 2: Define Dependencies","lvl2":"Building a Research Assistant"},"content":"Define external resources the agent needs:\n\nfrom dataclasses import dataclass\n\n@dataclass\nclass ResearchDeps:\n    \"\"\"Dependencies for the research agent.\"\"\"\n    database_url: str\n    api_key: str\n    max_papers_per_search: int = 10\n\n    def search_database(self, query: str, limit: int) -> list[Paper]:\n        \"\"\"Simulate database search (in production, would query real DB).\"\"\"\n        print(f\"  🔍 Searching database for: '{query}' (limit: {limit})\")\n\n        # In production, this would be:\n        # conn = connect(self.database_url, self.api_key)\n        # results = conn.execute(search_query)\n        # return [Paper(**row) for row in results]\n\n        # For demo, return mock results\n        return [\n            Paper(\n                title=\"Attention Is All You Need\",\n                authors=[\"Vaswani, A.\", \"Shazeer, N.\", \"Parmar, N.\"],\n                year=2017,\n                abstract=\"We propose a new simple network architecture, the Transformer...\",\n                doi=\"10.5555/3295222.3295349\"\n            ),\n            Paper(\n                title=\"BERT: Pre-training of Deep Bidirectional Transformers\",\n                authors=[\"Devlin, J.\", \"Chang, M.\", \"Lee, K.\"],\n                year=2019,\n                abstract=\"We introduce BERT, a method for pre-training language representations...\",\n                doi=\"10.18653/v1/N19-1423\"\n            ),\n        ]\n\n    def get_paper_by_id(self, paper_id: str) -> Paper:\n        \"\"\"Retrieve specific paper by ID.\"\"\"\n        print(f\"  📄 Fetching paper: {paper_id}\")\n        return Paper(\n            title=\"Example Paper\",\n            authors=[\"Author, A.\"],\n            year=2023,\n            abstract=\"This is an example paper abstract.\"\n        )\n\n# Create dependencies\ndeps = ResearchDeps(\n    database_url=\"sqlite3:///papers.db\",\n    api_key=\"demo-api-key-12345\",\n    max_papers_per_search=5\n)\n\nprint(\"✓ Dependencies configured\")\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#step-2-define-dependencies","position":39},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Step 3: Create Agent and Register Tools","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#step-3-create-agent-and-register-tools","position":40},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Step 3: Create Agent and Register Tools","lvl2":"Building a Research Assistant"},"content":"Now create the agent and give it tools:\n\nfrom pydantic_ai import Agent, RunContext\n\n# Create agent with system prompt and structured output\nresearch_agent = Agent(\n    'anthropic:claude-haiku-4-5',\n    deps_type=ResearchDeps,\n    output_type=ResearchSummary,\n    system_prompt=\"\"\"You are a helpful research assistant.\n\n    When asked to research a topic:\n    1. Search for relevant papers using the search_papers tool\n    2. Analyze the results carefully\n    3. Provide a clear summary with the most important papers\n    4. Rate your confidence based on result quality and relevance\n\n    Be thorough but concise. Focus on the most impactful papers.\"\"\"\n)\n\n# Register tool 1: Search for papers\n@research_agent.tool\ndef search_papers(\n    ctx: RunContext[ResearchDeps],\n    query: str,\n    max_results: int = 5\n) -> list[Paper]:\n    \"\"\"\n    Search for academic papers by query string.\n\n    Args:\n        query: Search query (keywords, topics, authors)\n        max_results: Maximum number of papers to return (default 5)\n\n    Returns:\n        List of relevant papers\n    \"\"\"\n    # Access dependencies via ctx.deps\n    limit = min(max_results, ctx.deps.max_papers_per_search)\n    papers = ctx.deps.search_database(query, limit)\n    return papers\n\n# Register tool 2: Get specific paper details\n@research_agent.tool\ndef get_paper_details(\n    ctx: RunContext[ResearchDeps],\n    paper_id: str\n) -> Paper:\n    \"\"\"\n    Get detailed information about a specific paper by its ID.\n\n    Args:\n        paper_id: Unique identifier for the paper\n\n    Returns:\n        Paper object with full details\n    \"\"\"\n    return ctx.deps.get_paper_by_id(paper_id)\n\nprint(\"✓ Agent created with 2 tools registered\")\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#step-3-create-agent-and-register-tools","position":41},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Step 4: Run the Agent","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#step-4-run-the-agent","position":42},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Step 4: Run the Agent","lvl2":"Building a Research Assistant"},"content":"Execute the agent with a research query:\n\nasync def run_research(question: str):\n    deps = ResearchDeps(\n        database_url=\"sqlite3:///papers.db\",\n        api_key=\"demo-api-key-12345\",\n        max_papers_per_search=5\n    )\n    result = await research_agent.run(question, deps=deps)\n    return result\n\nresearch_result = await run_research(\"transformer architectures in NLP\")\n\nresearch_result.all_messages()\n\nresearch_result.output\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#step-4-run-the-agent","position":43},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"What Just Happened?","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#what-just-happened","position":44},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"What Just Happened?","lvl2":"Building a Research Assistant"},"content":"Let’s break down the agent execution:\n\n1. Agent Received Query\n\nUser asked: “transformer architectures in NLP”\n\nAgent has access to: search_papers and get_paper_details tools\n\n2. Agent Made Decisions\n\nLLM analyzed the query\n\nDecided to call search_papers(\"transformer architectures in NLP\", max_results=5)\n\nPydanticAI validated the parameters\n\nTool executed with access to deps via RunContext\n\n3. Tool Returned Validated Data\n\nTool returned list[Paper] (type-checked)\n\nEach Paper object validated by Pydantic\n\nAgent received the results\n\n4. Agent Synthesized Response\n\nLLM analyzed the papers\n\nGenerated natural language summary\n\nSelected key papers\n\nAssigned confidence score\n\nReturned ResearchSummary (validated!)\n\n5. Type Safety Throughout\n\nEvery input validated before execution\n\nEvery output validated before return\n\nImpossible to get wrong types\n\nClear errors if validation fails\n\nThis is the power of type-safe agent development!\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#what-just-happened","position":45},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Exercise: Add a New Tool","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#exercise-add-a-new-tool","position":46},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Exercise: Add a New Tool","lvl2":"Building a Research Assistant"},"content":"Add a compare_papers tool that takes two paper titles and returns a comparison.\n\nRequirements:\n\nUse @research_agent.tool decorator\n\nAccept RunContext[ResearchDeps] as first parameter\n\nTake two paper titles as strings\n\nReturn a string with the comparison\n\nUse proper docstring (the agent sees this!)\n\nHint: The agent will automatically see this new tool and can call it!\n\n@research_agent.tool\ndef compare_papers(\n    ctx: RunContext[ResearchDeps],\n    paper1_title: str,\n    paper2_title: str\n) -> str:\n    \"\"\"\n    Compare two papers by their titles.\n\n    Args:\n        paper1_title: Title of first paper\n        paper2_title: Title of second paper\n\n    Returns:\n        Comparison summary\n    \"\"\"\n    # TODO: Implement comparison logic\n    # In production, would search for both papers and compare:\n    # - Publication dates\n    # - Citation counts\n    # - Research methods\n    # - Key contributions\n\n    return f\"Comparison between '{paper1_title}' and '{paper2_title}': [TODO: implement]\"\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#exercise-add-a-new-tool","position":47},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Advanced: Dynamic System Prompts","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#advanced-dynamic-system-prompts","position":48},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Advanced: Dynamic System Prompts","lvl2":"Building a Research Assistant"},"content":"You can also generate system prompts dynamically based on context:\n\nfrom pydantic_ai import RunContext\n\n# Create agent without static system prompt\nadaptive_agent = Agent(\n    'anthropic:claude-haiku-4-5',\n    deps_type=ResearchDeps,\n    output_type=ResearchSummary\n)\n\n# Dynamic system prompt based on context\n@adaptive_agent.system_prompt(dynamic=True)\ndef get_system_prompt(ctx: RunContext[ResearchDeps]) -> str:\n    \"\"\"Generate system prompt based on current context.\"\"\"\n    max_papers = ctx.deps.max_papers_per_search\n\n    return f\"\"\"You are a research assistant with access to {max_papers} papers per search.\n\nFocus on quality over quantity. When analyzing papers:\n- Prioritize recent publications (last 5 years)\n- Look for highly-cited works\n- Consider methodological rigor\n- Provide balanced summaries\n\nYour database: {ctx.deps.database_url}\n    \"\"\"\n\nprint(\"✓ Adaptive agent created with dynamic system prompt\")\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#advanced-dynamic-system-prompts","position":49},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Why This Pattern Scales","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#why-this-pattern-scales","position":50},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Why This Pattern Scales","lvl2":"Building a Research Assistant"},"content":"This agent architecture works for production systems because:\n\n1. Type Safety\n\nCatch errors at development time\n\nInvalid data rejected before processing\n\nClear validation errors guide debugging\n\n2. Separation of Concerns\n\nAgent logic separate from business logic\n\nDependencies injected, not hard-coded\n\nEasy to test each component independently\n\n3. Composability\n\nTools are just Python functions\n\nAdd new capabilities by adding new tools\n\nMix and match tools for different agents\n\n4. Observability\n\nEvery tool call is logged\n\nClear execution trace\n\nEasy to monitor and debug\n\n5. Maintainability\n\nSimple, readable code\n\nStandard Python patterns\n\nType hints document the code\n\nThis is how you build AI agents that last!\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#why-this-pattern-scales","position":51},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Key Takeaways","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#key-takeaways","position":52},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Key Takeaways","lvl2":"Building a Research Assistant"},"content":"Type Safety Prevents Errors\n\nValidate data at construction time\n\nInvalid states become unrepresentable\n\nClear error messages guide debugging\n\nCatch bugs before they reach production\n\nPydanticAI Core Concepts\n\nPydantic Models - Define validated data structures\n\nAgent - Coordinates LLM and tools\n\n - Register functions as tools\n\nRunContext[DepsType] - Inject dependencies safely\n\nresult_type - Guarantee output structure\n\nProduction-Ready Pattern# 1. Define structures\nclass Output(BaseModel): ...\nclass Deps: ...\n\n# 2. Create agent\nagent = Agent(model, deps_type=Deps, result_type=Output)\n\n# 3. Register tools\n@agent.tool\ndef my_tool(ctx: RunContext[Deps], arg: str): ...\n\n# 4. Run\nresult = await agent.run(query, deps=deps)\n\nWhy This Works\n\nSimple, composable primitives\n\nType safety throughout\n\nEasy to test and maintain\n\nScales to complex systems\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#key-takeaways","position":53},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Quick Reference","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#quick-reference","position":54},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Quick Reference","lvl2":"Building a Research Assistant"},"content":"Pydantic Validation:from pydantic import BaseModel, Field\n\nclass MyModel(BaseModel):\n    name: str = Field(min_length=1)\n    count: int = Field(ge=0, le=100)\n\nAgent Creation:from pydantic_ai import Agent\n\nagent = Agent(\n    'anthropic:claude-haiku-4-5',\n    deps_type=MyDeps,\n    result_type=MyOutput,\n    system_prompt=\"...\"\n)\n\nTool Registration:@agent.tool\ndef my_tool(\n    ctx: RunContext[MyDeps],\n    arg: str\n) -> MyType:\n    \"\"\"Docstring that LLM sees.\"\"\"\n    return ctx.deps.some_method(arg)\n\nDynamic System Prompt:@agent.system_prompt\ndef get_prompt(ctx: RunContext[MyDeps]) -> str:\n    return f\"Context: {ctx.deps.value}\"\n\nRunning Agent:# Async\nresult = await agent.run(query, deps=my_deps)\noutput: MyOutput = result.data\n\n# Streaming\nasync with agent.run_stream(query, deps=my_deps) as response:\n    async for chunk in response.stream_text():\n        print(chunk, end='')\n    final = await response.get_data()\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#quick-reference","position":55},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Next Steps","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#next-steps","position":56},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Next Steps","lvl2":"Building a Research Assistant"},"content":"In L.A2.03: Agent Frameworks Comparison, we’ll:\n\nCompare different agent frameworks (PydanticAI, LangChain, CrewAI)\n\nUnderstand architectural trade-offs\n\nLearn when to use each approach\n\nSee the same task implemented multiple ways\n\nIn Week A03: Multi-Agent Systems, we’ll:\n\nBuild agent swarms with collective intelligence\n\nApply game theory to AI agent interactions\n\nCreate digital twins with agent-based models\n\nScale from single agents to agent ecosystems\n\nPractice Ideas:\n\nAdd more tools to the research agent (filter by year, compare citations)\n\nBuild an agent for a different domain (finance, healthcare, education)\n\nImplement streaming responses for better UX\n\nAdd error handling and retry logic\n\nCreate a simple web UI with FastAPI\n\n","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#next-steps","position":57},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Further Reading","lvl2":"Building a Research Assistant"},"type":"lvl3","url":"/l-a2-02-type-safe-agents-pydantic-patterns#further-reading","position":58},{"hierarchy":{"lvl1":"Type-Safe Agent Development with PydanticAI Patterns","lvl3":"Further Reading","lvl2":"Building a Research Assistant"},"content":"PydanticAI Documentation:\n\nGetting Started\n\nAgents Guide\n\nTools Documentation\n\nDependencies\n\nExamples\n\nPydantic Core:\n\nPydantic V2\n\nField Validation\n\nModels\n\nPython Type System:\n\nType Hints\n\nProtocols\n\nGenerics\n\nProduction Topics (for later):\n\nTesting with pytest\n\nMonitoring with Logfire\n\nDeployment patterns\n\nCost optimization","type":"content","url":"/l-a2-02-type-safe-agents-pydantic-patterns#further-reading","position":59}]}