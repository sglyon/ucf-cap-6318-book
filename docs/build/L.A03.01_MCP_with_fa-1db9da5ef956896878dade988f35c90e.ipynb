{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Agent Tools with FastMCP\n",
    "\n",
    "> Computational Analysis of Social Complexity\n",
    ">\n",
    "> Fall 2025, Spencer Lyon\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- L.A2.01 (Function calling and tool use)\n",
    "- L.A2.02 (Type-safe agents with PydanticAI)\n",
    "- L.A2.03 (Agent evaluations)\n",
    "- Basic understanding of client-server architecture\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Understand the Model Context Protocol (MCP) and its role in the AI ecosystem\n",
    "- Create MCP servers using FastMCP to expose computational tools\n",
    "- Integrate MCP servers with PydanticAI agents for distributed tool access\n",
    "- Deploy and test MCP servers in multiple environments\n",
    "- Apply MCP patterns to course domains: network analysis, game theory, and agent-based models\n",
    "\n",
    "**References**\n",
    "\n",
    "- [Model Context Protocol Specification](https://modelcontextprotocol.io/)\n",
    "- [FastMCP Documentation](https://gofastmcp.com/)\n",
    "- [PydanticAI Documentation](https://ai.pydantic.dev/)\n",
    "- [NetworkX Documentation](https://networkx.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Embedded Tools to Distributed Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Reusability Problem\n",
    "\n",
    "In Week A2, we built tools using `@agent.tool`. This works well but locks tools into PydanticAI. What if you want to use your network analysis toolkit in:\n",
    "1. A PydanticAI agent\n",
    "2. A ChatGPT plugin\n",
    "3. Claude Desktop\n",
    "4. A web API\n",
    "5. A Jupyter notebook assistant\n",
    "\n",
    "You'd need **5 different implementations** of the same tools, each with different formats, authentication, and deployment.\n",
    "\n",
    "### Enter: The Model Context Protocol\n",
    "\n",
    "**MCP is \"USB-C for AI\"** - a universal standard for AI tools.\n",
    "\n",
    "1. **Write your tools once** as an MCP server\n",
    "2. **Use them anywhere** with any MCP-compatible client\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚     Your MCP Server             â”‚\n",
    "â”‚  (Network Analysis Tools)       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â”‚ MCP Protocol\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â–¼                     â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Claude  â”‚          â”‚Pydantic â”‚\n",
    "â”‚ Desktop â”‚          â”‚   AI    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### The Three MCP Primitives\n",
    "\n",
    "1. **Tools** (Functions): Actions the AI can perform\n",
    "2. **Resources** (Data): Read-only access to information\n",
    "3. **Prompts** (Templates): Reusable message templates\n",
    "\n",
    "Today we focus primarily on **Tools**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastMCP Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is FastMCP?\n",
    "\n",
    "FastMCP is a Python framework for building production-ready MCP servers with the \"Pydantic way\":\n",
    "- Type-safe by default\n",
    "- Automatic validation\n",
    "- Minimal boilerplate\n",
    "\n",
    "**Core Concepts**:\n",
    "1. **Server Creation**: `FastMCP(\"ServerName\")`\n",
    "2. **Tool Decoration**: `@mcp.tool()` (like `@agent.tool`)\n",
    "3. **Automatic Schema Generation**: From type hints and docstrings\n",
    "4. **Multiple Transports**: stdio (local), HTTP (remote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastmcp pydantic-ai networkx quantecon mesa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your First MCP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Calculator MCP server created with 2 tools\n"
     ]
    }
   ],
   "source": [
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Calculator\")\n",
    "\n",
    "@mcp.tool()\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers together.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "print(\"âœ“ Calculator MCP server created with 2 tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No JSON schema writing, no manual validation - FastMCP generates everything from type hints.\n",
    "\n",
    "### Running an MCP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting calculator_server.py\n"
     ]
    }
   ],
   "source": [
    "%%file calculator_server.py\n",
    "\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "mcp = FastMCP(\"Calculator\")\n",
    "\n",
    "@mcp.tool()\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()  # stdio by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run with: `python calculator_server.py`\n",
    "\n",
    "For HTTP: `mcp.run(transport=\"http\", port=8000)`\n",
    "\n",
    "### Testing an MCP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tools: ['add']\n",
      "5 + 3 = CallToolResult(content=[TextContent(type='text', text='8.0', annotations=None, meta=None)], structured_content={'result': 8.0}, data=8.0, is_error=False)\n"
     ]
    }
   ],
   "source": [
    "from fastmcp import Client\n",
    "\n",
    "async with Client(\"calculator_server.py\") as client:\n",
    "    tools = await client.list_tools()\n",
    "    print(\"Available tools:\", [t.name for t in tools])\n",
    "\n",
    "    result = await client.call_tool(\"add\", {\"a\": 5, \"b\": 3})\n",
    "    print(\"5 + 3 =\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This server is immediately usable by Claude Desktop, PydanticAI, or any MCP client. Write once, use everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Course-Specific MCP Servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Analysis MCP Server\n",
    "\n",
    "Let's expose network analysis capabilities from Weeks 3-5 using NetworkX.\n",
    "\n",
    "**State Management**: FastMCP's Context is request-scoped, so we use a **global dictionary** for persistent state:\n",
    "\n",
    "```python\n",
    "cache: Dict[str, Any] = {}  # Global cache, lives for server lifetime\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting network_analysis_server.py\n"
     ]
    }
   ],
   "source": [
    "%%file network_analysis_server.py\n",
    "\n",
    "from fastmcp import FastMCP\n",
    "import networkx as nx\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "# Global cache for persistent state across tool calls\n",
    "# MCP Context is request-scoped, so we need external storage\n",
    "cache: Dict[str, Any] = {}\n",
    "\n",
    "network_mcp = FastMCP(\"NetworkAnalysis\")\n",
    "\n",
    "@network_mcp.tool()\n",
    "def create_network(\n",
    "    graph_id: str,\n",
    "    edges: List[Tuple[int, int]]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a network from an edge list and store it.\n",
    "\n",
    "    Args:\n",
    "        graph_id: Unique identifier for this graph (e.g., 'social_network', 'graph1')\n",
    "        edges: List of edges as [source, target] pairs. Example: [[1,2], [2,3], [1,3]]\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with graph statistics (num_nodes, num_edges, density)\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "    cache[f\"graph:{graph_id}\"] = G\n",
    "    return {\n",
    "        \"graph_id\": graph_id,\n",
    "        \"num_nodes\": G.number_of_nodes(),\n",
    "        \"num_edges\": G.number_of_edges(),\n",
    "        \"density\": round(nx.density(G), 4)\n",
    "    }\n",
    "\n",
    "@network_mcp.tool()\n",
    "def calculate_degree_centrality(\n",
    "    graph_id: str,\n",
    "    node: int\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calculate degree centrality for a node.\n",
    "\n",
    "    Degree centrality measures how many connections a node has.\n",
    "    Higher values indicate more central/connected nodes.\n",
    "\n",
    "    Args:\n",
    "        graph_id: ID of the graph to analyze\n",
    "        node: The node ID to calculate centrality for\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with degree and normalized centrality value\n",
    "    \"\"\"\n",
    "    G = cache.get(f\"graph:{graph_id}\")\n",
    "    if G is None:\n",
    "        return {\"error\": f\"Graph '{graph_id}' not found. Create it first.\"}\n",
    "    if node not in G:\n",
    "        return {\"error\": f\"Node {node} not in graph '{graph_id}'\"}\n",
    "\n",
    "    degree = G.degree(node)\n",
    "    max_possible = G.number_of_nodes() - 1\n",
    "    normalized = degree / max_possible if max_possible > 0 else 0\n",
    "    return {\"node\": node, \"degree\": degree, \"normalized_centrality\": round(normalized, 4)}\n",
    "\n",
    "@network_mcp.tool()\n",
    "def calculate_betweenness(\n",
    "    graph_id: str,\n",
    "    node: int\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calculate betweenness centrality for a node.\n",
    "\n",
    "    Betweenness measures how often a node lies on shortest paths between other nodes.\n",
    "    High betweenness nodes are 'bridges' connecting different parts of the network.\n",
    "\n",
    "    Args:\n",
    "        graph_id: ID of the graph to analyze\n",
    "        node: The node ID to calculate betweenness for\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with betweenness centrality value\n",
    "    \"\"\"\n",
    "    G = cache.get(f\"graph:{graph_id}\")\n",
    "    if G is None:\n",
    "        return {\"error\": f\"Graph '{graph_id}' not found\"}\n",
    "    if node not in G:\n",
    "        return {\"error\": f\"Node {node} not in graph '{graph_id}'\"}\n",
    "\n",
    "    betweenness = nx.betweenness_centrality(G)\n",
    "    return {\"node\": node, \"betweenness_centrality\": round(betweenness[node], 4)}\n",
    "\n",
    "@network_mcp.tool()\n",
    "def find_shortest_path(\n",
    "    graph_id: str,\n",
    "    source: int,\n",
    "    target: int\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Find shortest path between two nodes.\n",
    "\n",
    "    Args:\n",
    "        graph_id: ID of the graph to search\n",
    "        source: Starting node ID\n",
    "        target: Destination node ID\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with path and length, or error if no path exists\n",
    "    \"\"\"\n",
    "    G = cache.get(f\"graph:{graph_id}\")\n",
    "    if G is None:\n",
    "        return {\"error\": f\"Graph '{graph_id}' not found\"}\n",
    "\n",
    "    try:\n",
    "        path = nx.shortest_path(G, source, target)\n",
    "        return {\"found\": True, \"path\": path, \"length\": len(path) - 1}\n",
    "    except nx.NetworkXNoPath:\n",
    "        return {\"found\": False, \"message\": f\"No path exists between {source} and {target}\"}\n",
    "    except nx.NodeNotFound:\n",
    "        return {\"found\": False, \"message\": f\"One or both nodes not in graph\"}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    network_mcp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Features**: State management via global cache, type safety, domain expertise encoded in docstrings, and structured error handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Network Analysis Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tools: ['create_network', 'calculate_degree_centrality', 'calculate_betweenness', 'find_shortest_path']\n",
      "\n",
      "Network created: {'graph_id': 'social', 'num_nodes': 9, 'num_edges': 11, 'density': 0.3056}\n",
      "Node 3 centrality: {'node': 3, 'degree': 4, 'normalized_centrality': 0.5}\n",
      "Node 3 betweenness: {'node': 3, 'betweenness_centrality': 0.75}\n",
      "Path 1â†’9: {'found': True, 'path': [1, 3, 7, 9], 'length': 3}\n"
     ]
    }
   ],
   "source": [
    "from fastmcp import Client\n",
    "\n",
    "async with Client(\"network_analysis_server.py\") as client:\n",
    "    tools = await client.list_tools()\n",
    "    print(\"Available tools:\", [t.name for t in tools])\n",
    "    \n",
    "    # Create a social network\n",
    "    result = await client.call_tool(\n",
    "        \"create_network\",\n",
    "        {\"graph_id\": \"social\", \"edges\": [[1,2], [1,3], [2,3], [3,4], [4,5], [5,6], [6,4], [3,7], [7,8], [8,9], [9,7]]}\n",
    "    )\n",
    "    print(f\"\\nNetwork created: {result.data}\")\n",
    "    \n",
    "    # Analyze centrality\n",
    "    result = await client.call_tool(\"calculate_degree_centrality\", {\"graph_id\": \"social\", \"node\": 3})\n",
    "    print(f\"Node 3 centrality: {result.data}\")\n",
    "    \n",
    "    result = await client.call_tool(\"calculate_betweenness\", {\"graph_id\": \"social\", \"node\": 3})\n",
    "    print(f\"Node 3 betweenness: {result.data}\")\n",
    "    \n",
    "    # Find path\n",
    "    result = await client.call_tool(\"find_shortest_path\", {\"graph_id\": \"social\", \"source\": 1, \"target\": 9})\n",
    "    print(f\"Path 1â†’9: {result.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State persists across calls, and results are structured with semantic fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Theory MCP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting game_server.py\n"
     ]
    }
   ],
   "source": [
    "%%file game_server.py\n",
    "\n",
    "from fastmcp import FastMCP\n",
    "import quantecon.game_theory as gt\n",
    "import numpy as np\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "game_mcp = FastMCP(\"GameTheory\")\n",
    "game_cache: Dict[str, Any] = {}\n",
    "\n",
    "@game_mcp.tool()\n",
    "def create_game(\n",
    "    game_id: str,\n",
    "    payoff_matrix_p1: List[List[float]],\n",
    "    payoff_matrix_p2: List[List[float]]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a two-player normal-form game.\n",
    "\n",
    "    Args:\n",
    "        game_id: Unique identifier for this game\n",
    "        payoff_matrix_p1: Payoff matrix for Player 1 (rows = P1 strategies, cols = P2 strategies)\n",
    "        payoff_matrix_p2: Payoff matrix for Player 2 (rows = P1 strategies, cols = P2 strategies)\n",
    "\n",
    "    Returns:\n",
    "        Game statistics and confirmation\n",
    "    \"\"\"\n",
    "    p1_payoffs = np.array(payoff_matrix_p1)\n",
    "    p2_payoffs = np.array(payoff_matrix_p2)\n",
    "    game = gt.NormalFormGame([p1_payoffs, p2_payoffs])\n",
    "    game_cache[game_id] = game\n",
    "    return {\n",
    "        \"game_id\": game_id,\n",
    "        \"num_players\": 2,\n",
    "        \"p1_strategies\": p1_payoffs.shape[0],\n",
    "        \"p2_strategies\": p1_payoffs.shape[1],\n",
    "        \"message\": f\"Game '{game_id}' created successfully\"\n",
    "    }\n",
    "\n",
    "@game_mcp.tool()\n",
    "def find_pure_nash_equilibria(game_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Find all pure strategy Nash equilibria in the game.\n",
    "\n",
    "    A Nash equilibrium is a strategy profile where no player can improve\n",
    "    by unilaterally changing their strategy.\n",
    "\n",
    "    Args:\n",
    "        game_id: ID of the game to analyze\n",
    "\n",
    "    Returns:\n",
    "        List of Nash equilibria (strategy profiles) and their payoffs\n",
    "    \"\"\"\n",
    "    game = game_cache.get(game_id)\n",
    "    if game is None:\n",
    "        return {\"error\": f\"Game '{game_id}' not found\"}\n",
    "\n",
    "    equilibria = game.pure_nash_brute()\n",
    "    results = []\n",
    "    for eq in equilibria:\n",
    "        payoffs = [game.players[i].payoff_array[eq] for i in range(len(game.players))]\n",
    "        results.append({\"strategies\": eq, \"payoffs\": [float(p) for p in payoffs]})\n",
    "\n",
    "    return {\n",
    "        \"game_id\": game_id,\n",
    "        \"num_equilibria\": len(results),\n",
    "        \"equilibria\": results\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Game Theory MCP server created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent-Based Model Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting abm_server.py\n"
     ]
    }
   ],
   "source": [
    "%%file abm_server.py\n",
    "\n",
    "from fastmcp import FastMCP\n",
    "from mesa import Agent, Model\n",
    "from mesa.time import RandomActivation\n",
    "from mesa.space import SingleGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "from typing import Dict, Any\n",
    "import random\n",
    "\n",
    "abm_mcp = FastMCP(\"AgentBasedModels\")\n",
    "abm_cache: Dict[str, Any] = {}\n",
    "\n",
    "class SchellingAgent(Agent):\n",
    "    def __init__(self, unique_id, model, agent_type):\n",
    "        super().__init__(unique_id, model)\n",
    "        self.type = agent_type\n",
    "\n",
    "    def step(self):\n",
    "        neighbors = self.model.grid.get_neighbors(self.pos, moore=True, include_center=False)\n",
    "        similar = sum(1 for n in neighbors if n.type == self.type)\n",
    "        total = len(neighbors)\n",
    "        if total > 0 and (similar / total) < self.model.homophily:\n",
    "            self.model.grid.move_to_empty(self)\n",
    "\n",
    "class SchellingModel(Model):\n",
    "    def __init__(self, width=20, height=20, density=0.8, minority_pc=0.2, homophily=3):\n",
    "        super().__init__()\n",
    "        self.homophily = homophily / 8\n",
    "        self.schedule = RandomActivation(self)\n",
    "        self.grid = SingleGrid(width, height, torus=True)\n",
    "        n_agents = int(width * height * density)\n",
    "        for i in range(n_agents):\n",
    "            agent_type = 1 if random.random() < minority_pc else 0\n",
    "            agent = SchellingAgent(i, self, agent_type)\n",
    "            self.schedule.add(agent)\n",
    "            self.grid.position_agent(agent, (random.randrange(width), random.randrange(height)))\n",
    "        self.datacollector = DataCollector(model_reporters={\"segregation\": lambda m: self.measure_segregation(m)})\n",
    "\n",
    "    @staticmethod\n",
    "    def measure_segregation(model):\n",
    "        similar_neighbors = total_neighbors = 0\n",
    "        for agent in model.schedule.agents:\n",
    "            neighbors = model.grid.get_neighbors(agent.pos, moore=True, include_center=False)\n",
    "            if neighbors:\n",
    "                similar_neighbors += sum(1 for n in neighbors if n.type == agent.type)\n",
    "                total_neighbors += len(neighbors)\n",
    "        return similar_neighbors / total_neighbors if total_neighbors > 0 else 0\n",
    "\n",
    "    def step(self):\n",
    "        self.datacollector.collect(self)\n",
    "        self.schedule.step()\n",
    "\n",
    "@abm_mcp.tool()\n",
    "def create_schelling_model(\n",
    "    model_id: str,\n",
    "    width: int = 20,\n",
    "    height: int = 20,\n",
    "    density: float = 0.8,\n",
    "    minority_percent: float = 0.2,\n",
    "    homophily: int = 3\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a Schelling segregation model.\n",
    "\n",
    "    The Schelling model demonstrates how mild preferences for similar neighbors\n",
    "    can lead to high levels of segregation.\n",
    "\n",
    "    Args:\n",
    "        model_id: Unique identifier for this model\n",
    "        width: Grid width (default 20)\n",
    "        height: Grid height (default 20)\n",
    "        density: Fraction of cells occupied (0-1, default 0.8)\n",
    "        minority_percent: Fraction of agents that are minority type (0-1, default 0.2)\n",
    "        homophily: Number of similar neighbors desired (out of 8, default 3)\n",
    "\n",
    "    Returns:\n",
    "        Model configuration and initial state\n",
    "    \"\"\"\n",
    "    model = SchellingModel(width, height, density, minority_percent, homophily)\n",
    "    abm_cache[model_id] = model\n",
    "    return {\n",
    "        \"model_id\": model_id,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"num_agents\": len(model.schedule.agents),\n",
    "        \"initial_segregation\": round(model.measure_segregation(model), 3)\n",
    "    }\n",
    "\n",
    "@abm_mcp.tool()\n",
    "def step_model(\n",
    "    model_id: str,\n",
    "    num_steps: int = 1\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run the model for a specified number of steps.\n",
    "\n",
    "    Args:\n",
    "        model_id: ID of the model to step\n",
    "        num_steps: Number of steps to run (default 1)\n",
    "\n",
    "    Returns:\n",
    "        Segregation metrics after stepping\n",
    "    \"\"\"\n",
    "    model = abm_cache.get(model_id)\n",
    "    if model is None:\n",
    "        return {\"error\": f\"Model '{model_id}' not found\"}\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        model.step()\n",
    "\n",
    "    df = model.datacollector.get_model_vars_dataframe()\n",
    "    return {\n",
    "        \"model_id\": model_id,\n",
    "        \"steps_completed\": num_steps,\n",
    "        \"total_steps\": len(df),\n",
    "        \"current_segregation\": round(df['segregation'].iloc[-1], 3),\n",
    "        \"initial_segregation\": round(df['segregation'].iloc[0], 3)\n",
    "    }\n",
    "\n",
    "print(\"âœ“ ABM MCP server created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have three MCP servers exposing capabilities from network science, game theory, and ABMs. The common patterns: global cache for state, type safety, clear errors, and structured returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCP Resources: Read-Only Data\n",
    "\n",
    "In addition to Tools, MCP servers can expose **Resources** (read-only data) and **Prompts** (templates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Network resources server created\n"
     ]
    }
   ],
   "source": [
    "from fastmcp import FastMCP, Context\n",
    "\n",
    "network_resources_mcp = FastMCP(\"NetworkResources\")\n",
    "\n",
    "@network_resources_mcp.resource(\"network://{graph_id}/summary\")\n",
    "def get_network_summary(ctx: Context, graph_id: str) -> str:\n",
    "    \"\"\"Get a text summary of network properties.\"\"\"\n",
    "    if not hasattr(ctx, 'graphs') or graph_id not in ctx.graphs:\n",
    "        return f\"Error: Graph '{graph_id}' not found\"\n",
    "    G = ctx.graphs[graph_id]\n",
    "    return f\"Network {graph_id}: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges, density {nx.density(G):.4f}\"\n",
    "\n",
    "print(\"âœ“ Network resources server created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PydanticAI Integration\n",
    "\n",
    "PydanticAI has **native MCP support**. MCP servers are treated as toolsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Social Network Analysis\n",
      "\n",
      "### Network Overview\n",
      "- **Nodes**: 4 connected + 1 isolated (Person 5)\n",
      "- **Edges**: 5 friendships\n",
      "- **Density**: 0.833 (very dense - 83.3% of possible connections exist)\n",
      "\n",
      "### Connected Component (Persons 1-4)\n",
      "\n",
      "**Degree Centrality** (number of direct friends):\n",
      "| Person | Friends | Normalized Centrality |\n",
      "|--------|---------|----------------------|\n",
      "| 1 | 3 | 1.0 â­ |\n",
      "| 2 | 2 | 0.667 |\n",
      "| 3 | 3 | 1.0 â­ |\n",
      "| 4 | 2 | 0.667 |\n",
      "\n",
      "**Betweenness Centrality** (how often they bridge other connections):\n",
      "| Person | Betweenness |\n",
      "|--------|------------|\n",
      "| 1 | 0.167 ðŸŒ‰ |\n",
      "| 3 | 0.167 ðŸŒ‰ |\n",
      "| 2 | 0.0 |\n",
      "| 4 | 0.0 |\n",
      "\n",
      "### Key Insights\n",
      "\n",
      "1. **Hub Nodes**: Persons 1 and 3 are the most influential, each connected to 3 others\n",
      "2. **Bridge Role**: Both Persons 1 and 3 serve as bridges connecting different parts of the network\n",
      "3. **Highly Connected**: The network is very dense (0.833), forming an almost complete subgraph\n",
      "4. **Isolated Person**: Person 5 has no connections and is completely isolated from the social network\n",
      "5. **Network Shape**: The connected component forms a near-complete graph with only 1 missing edge (Person 2 and 4 are not directly connected)\n",
      "\n",
      "This is a tightly-knit group with Person 5 completely outside the social circle!\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.toolsets.fastmcp import FastMCPToolset\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from network_analysis_server import network_mcp\n",
    "toolset = FastMCPToolset(network_mcp)\n",
    "agent = Agent('anthropic:claude-haiku-4-5', toolsets=[toolset])\n",
    "\n",
    "async def main():\n",
    "    prompt = \"\"\"\n",
    "    Create a social network with friendships: 1â†”2, 1â†”3, 1â†”4, 2â†”3, 3â†”4.\n",
    "    Person 5 is isolated. Analyze the structure.\n",
    "    \"\"\"\n",
    "    result = await agent.run(prompt)\n",
    "    print(result.output)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FastMCPToolset can connect to:**\n",
    "- Python scripts: `FastMCPToolset('my_server.py')`\n",
    "- HTTP URLs: `FastMCPToolset('http://localhost:8000/mcp')`\n",
    "- FastMCP objects: `FastMCPToolset(network_mcp)` (zero network overhead)\n",
    "\n",
    "### Multi-Server Agents\n",
    "\n",
    "Connect to **multiple MCP servers**:\n",
    "\n",
    "```python\n",
    "from pydantic_ai.mcp import MCPServerStdio\n",
    "\n",
    "network_server = MCPServerStdio('python', args=['network_server.py'])\n",
    "game_server = MCPServerStdio('python', args=['game_server.py'])\n",
    "\n",
    "agent = Agent('anthropic:claude-sonnet-4-5', toolsets=[network_server, game_server])\n",
    "```\n",
    "\n",
    "The agent orchestrates across servers like composing Lego blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response: Perfect! I've successfully created a path network and found the shortest path. Here are the results:\n",
      "\n",
      "**Network Created:**\n",
      "- **Graph ID:** path_network\n",
      "- **Nodes:** 5\n",
      "- **Edges:** 4\n",
      "- **Density:** 0.4\n",
      "\n",
      "**Shortest Path from Node 1 to Node 5:**\n",
      "- **Path:** 1 â†’ 2 â†’ 3 â†’ 4 â†’ 5\n",
      "- **Length:** 4 hops\n",
      "\n",
      "The path network is a simple linear chain where each node connects to the next one. The shortest (and only) path from node 1 to node 5 traverses through all intermediate nodes, requiring 4 steps.\n"
     ]
    }
   ],
   "source": [
    "# Example with file-based server\n",
    "toolset = FastMCPToolset('network_analysis_server.py')\n",
    "agent = Agent('anthropic:claude-haiku-4-5', toolsets=[toolset], system_prompt=\"You are a helpful network analysis assistant.\")\n",
    "\n",
    "async with agent:\n",
    "    result = await agent.run('Create a path network (1-2-3-4-5) and find the shortest path from 1 to 5')\n",
    "    print(\"Agent Response:\", result.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCP Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Network prompts server created\n"
     ]
    }
   ],
   "source": [
    "from fastmcp import FastMCP\n",
    "\n",
    "network_prompts_mcp = FastMCP(\"NetworkPrompts\")\n",
    "\n",
    "@network_prompts_mcp.prompt()\n",
    "def analyze_network_structure(graph_id: str) -> str:\n",
    "    \"\"\"Generate a comprehensive network analysis prompt.\"\"\"\n",
    "    return f\"\"\"\n",
    "Please analyze the network '{graph_id}':\n",
    "1. Basic Statistics (nodes, edges, density)\n",
    "2. Centrality Analysis (top nodes by degree and betweenness)\n",
    "3. Structural Properties (connectivity, clustering)\n",
    "4. Interpretation (information flow implications)\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ“ Network prompts server created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When to use each**:\n",
    "- **Tools**: Actions requiring computation\n",
    "- **Resources**: Read-only data access\n",
    "- **Prompts**: Guide users with common workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Development: stdio\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()  # stdio by default\n",
    "```\n",
    "\n",
    "### Claude Desktop Integration\n",
    "\n",
    "```bash\n",
    "fastmcp install claude-desktop network_server.py\n",
    "```\n",
    "\n",
    "This adds your server to Claude Desktop, making tools available in natural language.\n",
    "\n",
    "### HTTP Deployment\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport='streamable-http', port=8000)\n",
    "```\n",
    "\n",
    "Connect from PydanticAI:\n",
    "```python\n",
    "from pydantic_ai.mcp import MCPServerStreamableHTTP\n",
    "server = MCPServerStreamableHTTP('http://localhost:8000/mcp')\n",
    "agent = Agent('anthropic:claude-sonnet-4-5', toolsets=[server])\n",
    "```\n",
    "\n",
    "### Configuration Files\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"mcpServers\": {\n",
    "    \"network-analysis\": {\"command\": \"python\", \"args\": [\"network_server.py\"]},\n",
    "    \"game-theory\": {\"url\": \"http://localhost:8001/mcp\"}\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Load with:\n",
    "```python\n",
    "from pydantic_ai.mcp import load_mcp_servers\n",
    "servers = load_mcp_servers('mcp_config.json')\n",
    "agent = Agent('anthropic:claude-sonnet-4-5', toolsets=servers)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Conceptual Understanding\n",
    "\n",
    "**Part A**: Explain the difference between embedded tools (`@agent.tool`) and MCP servers (`@mcp.tool`). When would you use each?\n",
    "\n",
    "**Part B**: For each scenario, identify Tool, Resource, or Prompt:\n",
    "1. Providing access to a dataset of network structures\n",
    "2. Computing the Nash equilibrium of a game\n",
    "3. Guiding users through a network analysis workflow\n",
    "4. Running a simulation for 1000 steps\n",
    "5. Retrieving historical simulation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Build a Statistics MCP Server\n",
    "\n",
    "Create an MCP server with these tools:\n",
    "1. `calculate_mean(data: List[float]) -> float`\n",
    "2. `calculate_std(data: List[float]) -> float`\n",
    "3. `find_outliers(data: List[float], threshold: float = 2.0) -> List[float]`\n",
    "\n",
    "Include proper docstrings and handle edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import FastMCP\n",
    "from typing import List\n",
    "\n",
    "stats_mcp = FastMCP(\"Statistics\")\n",
    "\n",
    "@stats_mcp.tool()\n",
    "def calculate_mean(data: List[float]) -> float:\n",
    "    \"\"\"Calculate the arithmetic mean of a list of numbers.\"\"\"\n",
    "    # TODO: implement\n",
    "    pass\n",
    "\n",
    "# TODO: Add other tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Extend the Network Analysis Server\n",
    "\n",
    "Add these tools:\n",
    "1. `calculate_clustering_coefficient(graph_id: str) -> float` using `nx.average_clustering(G)`\n",
    "2. `find_communities(graph_id: str) -> List[List[int]]` using `nx.community.greedy_modularity_communities(G)`\n",
    "3. `calculate_diameter(graph_id: str) -> int` using `nx.diameter(G)` (handle disconnected graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict\n",
    "\n",
    "@network_mcp.tool()\n",
    "def calculate_clustering_coefficient(ctx: Context, graph_id: str) -> Dict[str, any]:\n",
    "    \"\"\"Calculate the average clustering coefficient.\"\"\"\n",
    "    # TODO: implement\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Design an MCP Server for Your Domain\n",
    "\n",
    "Choose a domain and write specifications for 5 tools:\n",
    "- Tool name, parameters (with types), return value\n",
    "- Docstring explaining what it does\n",
    "- When/why you'd use it\n",
    "\n",
    "Options: Blockchain Analysis, Auction Mechanisms, or your research domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: MCP vs Embedded Tools Trade-offs\n",
    "\n",
    "For each scenario, discuss whether to use MCP or embedded tools, and analyze complexity, maintenance, reusability, performance, and security:\n",
    "\n",
    "1. Single-user research script\n",
    "2. Multi-user web application\n",
    "3. Educational platform for students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "**Official Documentation:**\n",
    "- [MCP Specification](https://modelcontextprotocol.io/)\n",
    "- [FastMCP Documentation](https://gofastmcp.com/)\n",
    "- [PydanticAI Docs](https://ai.pydantic.dev/)\n",
    "\n",
    "**Course-Related:**\n",
    "- [NetworkX Documentation](https://networkx.org/)\n",
    "- [QuantEcon.game_theory](https://quanteconpy.readthedocs.io/)\n",
    "- [Mesa Documentation](https://mesa.readthedocs.io/)\n",
    "\n",
    "**Academic Papers:**\n",
    "- Schick et al. (2023) \"Toolformer\" [arXiv:2302.04761](https://arxiv.org/abs/2302.04761)\n",
    "- Wang et al. (2024) \"Survey on LLM-Based Autonomous Agents\" [arXiv:2308.11432](https://arxiv.org/abs/2308.11432)\n",
    "\n",
    "**Next Lecture Preview:**\n",
    "- [Simon Willison on Prompt Injection](https://simonwillison.net/2023/Apr/14/worst-that-can-happen/)\n",
    "- [OWASP Top 10 for LLM Applications](https://owasp.org/www-project-top-10-for-large-language-model-applications/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
