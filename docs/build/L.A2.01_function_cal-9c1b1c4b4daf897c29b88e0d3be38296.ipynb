{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# Function Calling and Tool Use: From Talk to Action\n",
    "\n",
    "> Computational Analysis of Social Complexity\n",
    ">\n",
    "> Fall 2025, Spencer Lyon\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- L.A1.01 (LLMs and API calls)\n",
    "- L.A1.02 (RAG systems)\n",
    "- Graph theory/Network Science (Week 3-5)\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Implement function calling with modern LLM APIs\n",
    "- Design JSON schemas for tool definitions\n",
    "- Build agents that execute code and analyze computational results\n",
    "- Create a network analysis toolkit accessible to AI agents\n",
    "\n",
    "**References**\n",
    "\n",
    "- [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)\n",
    "- [Anthropic Tool Use Documentation](https://docs.anthropic.com/claude/docs/tool-use)\n",
    "- [Schick et al. (2023) \"Toolformer\"](https://arxiv.org/abs/2302.04761)\n",
    "- [Qin et al. (2023) \"Tool Learning with LLMs\"](https://arxiv.org/abs/2304.08354)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivation-section",
   "metadata": {},
   "source": [
    "## From Conversation to Computation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivation-intro",
   "metadata": {},
   "source": [
    "### The Limitations of Text-Only Agents\n",
    "\n",
    "In Week A1, we learned how to build AI agents that can:\n",
    "- Engage in natural language conversations\n",
    "- Retrieve and synthesize information from knowledge bases\n",
    "- Coordinate with other agents\n",
    "\n",
    "But there's a fundamental limitation: **these agents can only talk**.\n",
    "\n",
    "Suppose you ask an LLM:\n",
    "> \"I have a social network with 1000 nodes. Can you calculate the average clustering coefficient?\"\n",
    "\n",
    "The LLM might respond:\n",
    "> \"I'd be happy to help calculate the clustering coefficient! Please provide the network data in an adjacency matrix or edge list format, and I'll walk you through the calculation.\"\n",
    "\n",
    "But it can't actually *do* the calculation. It's like hiring a consultant who can only write reports but can't use a computer.\n",
    "\n",
    "### What We Really Want\n",
    "\n",
    "Imagine instead:\n",
    "\n",
    "**You**: \"Calculate the clustering coefficient for this network: [provides graph data]\"\n",
    "\n",
    "**Agent**: \n",
    "1. Parses the network data\n",
    "2. Calls `calculate_clustering_coefficient(graph)`\n",
    "3. Gets result: `0.342`\n",
    "4. Responds: \"The average clustering coefficient is 0.342, indicating moderate clustering. This is typical for social networks where friend groups form tightly-knit communities.\"\n",
    "\n",
    "The agent didn't just *describe* how to compute the answer - it **actually computed it**.\n",
    "\n",
    "This is the power of **tool use** or **function calling**: agents that can take actions, not just generate text.\n",
    "\n",
    "### Why This Matters for Computational Social Science\n",
    "\n",
    "Our course focuses on computational analysis of complex systems:\n",
    "- Network analysis (Weeks 3-5)\n",
    "- Agent-based modeling (Weeks 6-7)\n",
    "- Game theory (Weeks 8-9)\n",
    "\n",
    "All of these require **computation**, not just conversation.\n",
    "\n",
    "AI agents with tool use can:\n",
    "- Analyze real network data\n",
    "- Run simulations and interpret results\n",
    "- Solve game theory problems numerically\n",
    "- Query blockchain state and analyze transactions\n",
    "\n",
    "They become **computational assistants**, not just chatbots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "function-calling-header",
   "metadata": {},
   "source": [
    "## Understanding Function Calling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "function-calling-intro",
   "metadata": {},
   "source": [
    "### The Basic Pattern\n",
    "\n",
    "Function calling (also called \"tool use\") works through a structured protocol:\n",
    "\n",
    "**Step 1: Define Available Tools**\n",
    "- Tell the LLM what functions it can call\n",
    "- Provide a description of each function\n",
    "- Specify the parameters and their types\n",
    "\n",
    "**Step 2: Agent Decides to Use a Tool**\n",
    "- User asks a question\n",
    "- LLM determines if it needs to call a function\n",
    "- Generates a structured request (JSON) specifying the function and arguments\n",
    "\n",
    "**Step 3: Your Code Executes the Function**\n",
    "- Parse the LLM's request\n",
    "- Call the actual Julia function\n",
    "- Get the result\n",
    "\n",
    "**Step 4: Return Results to Agent**\n",
    "- Send function output back to LLM\n",
    "- LLM incorporates the result into its response\n",
    "- Generates a natural language answer for the user\n",
    "\n",
    "This might seem like a complex dance, but modern LLM APIs make it straightforward.\n",
    "\n",
    "### Why Not Just Put Code in the Prompt?\n",
    "\n",
    "You might wonder: why not just tell the LLM \"here's how to calculate clustering coefficient\" in the prompt?\n",
    "\n",
    "Problems with code-in-prompt:\n",
    "1. **Unreliable execution**: LLM might make mistakes in calculation\n",
    "2. **No actual computation**: LLM simulates/approximates, doesn't execute\n",
    "3. **Verbose**: Including full code implementations in prompts wastes tokens\n",
    "4. **Can't handle complexity**: Real functions often require libraries, state, I/O\n",
    "\n",
    "Function calling provides:\n",
    "1. **Precise execution**: Real Julia code runs, no approximation\n",
    "2. **Efficiency**: Just describe what the function does, not how\n",
    "3. **Power**: Access to entire Julia ecosystem (Graphs.jl, Agents.jl, etc.)\n",
    "4. **Safety**: You control what code actually executes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "json-schema-header",
   "metadata": {},
   "source": [
    "## JSON Schemas: Defining Tool Interfaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "json-schema-intro",
   "metadata": {},
   "source": [
    "### The Language of Tools\n",
    "\n",
    "To use function calling, we need a way to describe functions to the LLM. The standard format is **JSON Schema**.\n",
    "\n",
    "JSON Schema is a vocabulary for annotating and validating JSON documents. For function calling, it describes:\n",
    "- Function name\n",
    "- What the function does (description)\n",
    "- What parameters it takes (name, type, description, whether required)\n",
    "- What it returns (usually in description)\n",
    "\n",
    "**Important Note**: While we'll see how to write JSON schemas manually (to understand the underlying format), PydanticAI will generate these automatically from Python function signatures and docstrings. This is one of the major benefits of using PydanticAI - you write normal Python functions with type hints and docstrings, and the schemas are created for you.\n",
    "\n",
    "Let's start with a simple example to see what the JSON schema format looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "simple-tool-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"add_numbers\",\n",
      "    \"description\": \"Add two numbers together and return the sum\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"a\": {\n",
      "          \"type\": \"number\",\n",
      "          \"description\": \"The first number\"\n",
      "        },\n",
      "        \"b\": {\n",
      "          \"type\": \"number\",\n",
      "          \"description\": \"The second number\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"a\",\n",
      "        \"b\"\n",
      "      ],\n",
      "      \"additionalProperties\": false\n",
      "    },\n",
      "    \"strict\": true\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a simple calculator function\n",
    "def add_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers together and return the sum.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# Manual JSON Schema definition (what OpenAI API expects)\n",
    "add_numbers_tool = {\n",
    "    \"type\": \"function\",\n",
    "\n",
    "    \"function\": {\n",
    "        \"name\": \"add_numbers\",\n",
    "        \"description\": \"Add two numbers together and return the sum\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"a\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The first number\"\n",
    "                },\n",
    "                \"b\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The second number\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"a\", \"b\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display the schema\n",
    "print(json.dumps(add_numbers_tool, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "schema-anatomy",
   "metadata": {},
   "source": [
    "### Anatomy of a Tool Definition\n",
    "\n",
    "Let's break down the structure:\n",
    "\n",
    "**Top Level**:\n",
    "- `type`: Always \"function\" for function calling\n",
    "- `function`: Contains the function specification\n",
    "\n",
    "**Function Object**:\n",
    "- `name`: Identifier for the function (what the LLM will call)\n",
    "- `description`: Natural language explanation of what it does (crucial for LLM to understand when to use it)\n",
    "- `parameters`: JSON Schema object describing the parameters\n",
    "- `strict`: Optional boolean (recommended true) for strict schema validation\n",
    "\n",
    "**Parameters Object**:\n",
    "- `type`: Always \"object\" (parameters are passed as a JSON object)\n",
    "- `properties`: Dict mapping parameter names to their schemas\n",
    "- `required`: Array of parameter names that must be provided\n",
    "- `additionalProperties`: Set to false to prevent extra properties\n",
    "\n",
    "**Each Parameter**:\n",
    "- `type`: JSON type (\"string\", \"number\", \"integer\", \"boolean\", \"array\", \"object\")\n",
    "- `description`: What this parameter represents\n",
    "- Optional: `enum` (allowed values), `minimum`/`maximum` (for numbers), etc.\n",
    "\n",
    "**Key Point**: The description fields are critical - they're how the LLM decides when and how to use your function. Write clear, specific descriptions that explain:\n",
    "- What the function does\n",
    "- When to use it\n",
    "- What each parameter means\n",
    "- What the function returns\n",
    "\n",
    "### The PydanticAI Way: Automatic Schema Generation\n",
    "\n",
    "Now, here's the key insight: **you don't have to write these schemas manually** when using PydanticAI. PydanticAI uses the `griffe` library to extract parameter descriptions from your docstrings and automatically generates the JSON schema from your function signature.\n",
    "\n",
    "Here's how the same function looks with PydanticAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one time setup code to load environment variables and set up async support in Jupyter\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "load_dotenv()\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "u1d6j1n83v",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 plus 17 equals **42**.\n"
     ]
    }
   ],
   "source": [
    "# PydanticAI Way: Automatic Schema Generation\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "# Create aan agent\n",
    "agent = Agent('anthropic:claude-haiku-4-5')\n",
    "\n",
    "# Register the tool with decorator - schema is generated automatically!\n",
    "@agent.tool_plain\n",
    "def add_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Add two numbers together and return the sum.\n",
    "\n",
    "    Args:\n",
    "        a: The first number\n",
    "        b: The second number\n",
    "\n",
    "    Returns:\n",
    "        The sum of a and b\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "# Test it!\n",
    "result = agent.run_sync(\"What is 25 plus 17?\")\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b84e9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[UserPromptPart(content='What is 25 plus 17?', timestamp=datetime.datetime(2025, 11, 10, 23, 33, 31, 690679, tzinfo=datetime.timezone.utc))]),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='add_numbers', args={'a': 25, 'b': 17}, tool_call_id='toolu_01JkbLv1Ldr3Fq2YTmCDh1e7')], usage=RequestUsage(input_tokens=630, output_tokens=71, details={'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 630, 'output_tokens': 71}), model_name='claude-haiku-4-5-20251001', timestamp=datetime.datetime(2025, 11, 10, 23, 33, 33, 49382, tzinfo=datetime.timezone.utc), provider_name='anthropic', provider_details={'finish_reason': 'tool_use'}, provider_response_id='msg_01RoorVBmTydPcTBZyQpHx6w', finish_reason='tool_call'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='add_numbers', content=42.0, tool_call_id='toolu_01JkbLv1Ldr3Fq2YTmCDh1e7', timestamp=datetime.datetime(2025, 11, 10, 23, 33, 33, 50020, tzinfo=datetime.timezone.utc))]),\n",
       " ModelResponse(parts=[TextPart(content='25 plus 17 equals **42**.')], usage=RequestUsage(input_tokens=716, output_tokens=13, details={'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 716, 'output_tokens': 13}), model_name='claude-haiku-4-5-20251001', timestamp=datetime.datetime(2025, 11, 10, 23, 33, 33, 786301, tzinfo=datetime.timezone.utc), provider_name='anthropic', provider_details={'finish_reason': 'end_turn'}, provider_response_id='msg_01H9BygMKHdNA6zuQxMFR7fQ', finish_reason='stop')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.all_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hands-on-header",
   "metadata": {},
   "source": [
    "## Hands-On: Building Function-Calling Agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "### Setup: API Access\n",
    "\n",
    "We'll use OpenAI APIs to demonstrate function calling. \n",
    "\n",
    "**Note on Python Environment**: Make sure you have installed the required packages:\n",
    "```bash\n",
    "pip install pydantic-ai pytdanic\n",
    "```\n",
    "\n",
    "Make sure you have your API keys set as environment variables:\n",
    "```bash\n",
    "export OPENAI_API_KEY=\"your-key\"\n",
    "export ANTHROPIC_API_KEY=\"your-key\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic_ai import Agent, RunContext\n",
    "\n",
    "# Get API keys from environment\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\", \"\")\n",
    "\n",
    "if not OPENAI_API_KEY or not ANTHROPIC_API_KEY:\n",
    "    print(\"⚠️ Warning: API keys not set. Set OPENAI_API_KEY and ANTHROPIC_API_KEY environment variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "openai-function-calling",
   "metadata": {},
   "source": [
    "### Function Calling with OpenAI\n",
    "\n",
    "Let's implement a complete function-calling agent using OpenAI's API. We'll start with a simple calculator and then build up to more complex examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "calculator-example",
   "metadata": {},
   "source": [
    "### Example 1: Calculator Agent\n",
    "\n",
    "Let's build an agent that can perform arithmetic operations. This demonstrates the basic pattern clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "calculator-functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculator agent ready!\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "# Create calculator agent\n",
    "calculator_agent = Agent('anthropic:claude-haiku-4-5')\n",
    "\n",
    "@calculator_agent.tool_plain\n",
    "def calculate(operation: str, a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Perform arithmetic operations on two numbers.\n",
    "\n",
    "    Args:\n",
    "        operation: The operation to perform ('add', 'subtract', 'multiply', 'divide')\n",
    "        a: The first operand\n",
    "        b: The second operand\n",
    "\n",
    "    Returns:\n",
    "        The result of the operation\n",
    "    \"\"\"\n",
    "    if operation == \"add\":\n",
    "        return a + b\n",
    "    elif operation == \"subtract\":\n",
    "        return a - b\n",
    "    elif operation == \"multiply\":\n",
    "        return a * b\n",
    "    elif operation == \"divide\":\n",
    "        if b == 0:\n",
    "            raise ValueError(\"Division by zero\")\n",
    "        return a / b\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown operation: {operation}\")\n",
    "\n",
    "print(\"Calculator agent ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "calculator-agent",
   "metadata": {},
   "source": [
    "Now let's create an agent that can use this calculator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cec3abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = calculator_agent._function_toolset.tools[\"calculate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b910338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<summary>Perform arithmetic operations on two numbers.</summary>\n",
      "<returns>\n",
      "<description>The result of the operation</description>\n",
      "</returns>\n"
     ]
    }
   ],
   "source": [
    "print(t.tool_def.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "calculator-agent-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With PydanticAI, running the agent is simple!\n",
    "def run_calculator_agent(user_query: str) -> str:\n",
    "    \"\"\"Run a calculator agent that can perform arithmetic.\"\"\"\n",
    "    print(f\"User: {user_query}\\n\")\n",
    "\n",
    "    # PydanticAI handles all the tool calling logic\n",
    "    result = calculator_agent.run_sync(user_query)\n",
    "\n",
    "    print(f\"Agent: {result.output}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-calculator",
   "metadata": {},
   "source": [
    "Let's test our calculator agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "test-calculator-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is 847 multiplied by 293?\n",
      "\n",
      "Agent: 847 multiplied by 293 is **248,171**.\n"
     ]
    }
   ],
   "source": [
    "# Test with a calculation\n",
    "mult_result = run_calculator_agent(\"What is 847 multiplied by 293?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "test-calculator-word-problem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I have 15 apples and buy 23 more. How many do I have?\n",
      "\n",
      "Agent: You have **38 apples**. (15 + 23 = 38)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentRunResult(output='You have **38 apples**. (15 + 23 = 38)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with a word problem\n",
    "run_calculator_agent(\"I have 15 apples and buy 23 more. How many do I have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "calculator-insights",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "Let's trace through the execution with PydanticAI:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[UserPromptPart(content='What is 847 multiplied by 293?', timestamp=datetime.datetime(2025, 11, 10, 23, 40, 16, 249866, tzinfo=datetime.timezone.utc))]),\n",
       " ModelResponse(parts=[ToolCallPart(tool_name='calculate', args={'operation': 'multiply', 'a': 847, 'b': 293}, tool_call_id='toolu_01X3XFzS4TEtRxDbcuP6NPm8')], usage=RequestUsage(input_tokens=667, output_tokens=86, details={'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 667, 'output_tokens': 86}), model_name='claude-haiku-4-5-20251001', timestamp=datetime.datetime(2025, 11, 10, 23, 40, 17, 501982, tzinfo=datetime.timezone.utc), provider_name='anthropic', provider_details={'finish_reason': 'tool_use'}, provider_response_id='msg_01ScVcXERKobRv9FcpSnVR5U', finish_reason='tool_call'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='calculate', content=248171.0, tool_call_id='toolu_01X3XFzS4TEtRxDbcuP6NPm8', timestamp=datetime.datetime(2025, 11, 10, 23, 40, 17, 502744, tzinfo=datetime.timezone.utc))]),\n",
       " ModelResponse(parts=[TextPart(content='847 multiplied by 293 is **248,171**.')], usage=RequestUsage(input_tokens=769, output_tokens=17, details={'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 769, 'output_tokens': 17}), model_name='claude-haiku-4-5-20251001', timestamp=datetime.datetime(2025, 11, 10, 23, 40, 18, 488776, tzinfo=datetime.timezone.utc), provider_name='anthropic', provider_details={'finish_reason': 'end_turn'}, provider_response_id='msg_01YDsgeLjt3xKL84bUT42B5k', finish_reason='stop')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult_result.all_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **User asks a question** (\"What is 847 * 293?\")\n",
    "2. **PydanticAI sends request to LLM** with available tools\n",
    "3. **LLM decides**: \"I need to multiply - I'll use the calculate tool\"\n",
    "4. **LLM generates tool call**: `{\"operation\": \"multiply\", \"a\": 847, \"b\": 293}`\n",
    "5. **PydanticAI executes**: Calls our `calculate(\"multiply\", 847, 293)` → `248,071`\n",
    "6. **PydanticAI sends result back to LLM**: \"The function returned: 248071\"\n",
    "7. **LLM generates final response**: \"847 multiplied by 293 equals 248,071\"\n",
    "\n",
    "**Understanding the PydanticAI Simplification**:\n",
    "- **No manual message management** - PydanticAI handles the conversation flow\n",
    "- **No manual tool dispatch** - PydanticAI calls the right function automatically based on `ToolCallRequest` or `ToolCallPart` messages it receives from LLM\n",
    "- **No JSON schema writing** - Generated from function signatures and docstrings\n",
    "- **Type-safe execution** - Python type hints ensure correct types\n",
    "\n",
    "Key insights:\n",
    "- The LLM **understood** that a calculation was needed\n",
    "- It **chose the right tool** and operation\n",
    "- It **extracted the numbers** from natural language\n",
    "- It **formatted the result** in a natural way\n",
    "- The **actual computation** was precise (our Python code, not LLM approximation)\n",
    "- **PydanticAI handled all the plumbing** - we just wrote a simple function\n",
    "\n",
    "This pattern scales to much more complex tools, and PydanticAI keeps the code clean and maintainable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "network-tools-header",
   "metadata": {},
   "source": [
    "## Building a Network Analysis Toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "network-tools-intro",
   "metadata": {},
   "source": [
    "### Exposing NetworkX to AI Agents\n",
    "\n",
    "Now let's build something more relevant to our course: tools for network analysis.\n",
    "\n",
    "We studied networks using Julia and Graphs.jl. \n",
    "\n",
    "However, becauase we are using Python and pydantic AI we need to use the correspondint network science library for Python\n",
    "\n",
    "The most widely used library is networkx. \n",
    "\n",
    "We'll create a set of functions that let an AI agent:\n",
    "- Create networks from edge lists\n",
    "- Calculate centrality measures\n",
    "- Compute clustering coefficients\n",
    "- Find shortest paths\n",
    "- Analyze network structure\n",
    "\n",
    "This demonstrates how to make computational tools from our course (Weeks 3-5) accessible to AI agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a5456f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: networkx\n",
      "Successfully installed networkx-3.5\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "network-state",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network dependencies defined\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Define dependencies using dependency injection instead of global state\n",
    "@dataclass\n",
    "class NetworkDeps:\n",
    "    graphs: dict[str, nx.Graph]\n",
    "\n",
    "# We'll create an agent with these dependencies\n",
    "print(\"Network dependencies defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "network-functions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network analysis tools defined!\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import RunContext\n",
    "\n",
    "# Create network analysis agent with dependencies\n",
    "network_agent = Agent('anthropic:claude-haiku-4-5', deps_type=NetworkDeps)\n",
    "\n",
    "@network_agent.tool\n",
    "def create_network(\n",
    "    ctx: RunContext[NetworkDeps],\n",
    "    graph_id: str,\n",
    "    edges: list[list[int]]\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Create a network from an edge list and store it.\n",
    "\n",
    "    Args:\n",
    "        graph_id: Unique identifier for this graph (e.g., 'social_network', 'graph1')\n",
    "        edges: List of edges where each edge is [source, target]. Example: [[1,2], [2,3], [1,3]]\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with graph statistics (num_nodes, num_edges, density)\n",
    "    \"\"\"\n",
    "    # Find max node ID to determine number of nodes\n",
    "    print(f\"Creating graph...\\t edges: {edges}\\t graph_id: {graph_id}\")\n",
    "    max_node = max(max(e) for e in edges)\n",
    "\n",
    "    # Create graph\n",
    "    g = nx.Graph()\n",
    "    g.add_nodes_from(range(1, max_node + 1))\n",
    "    g.add_edges_from(edges)\n",
    "\n",
    "    # Store in context dependencies\n",
    "    ctx.deps.graphs[graph_id] = g\n",
    "\n",
    "    return {\n",
    "        \"graph_id\": graph_id,\n",
    "        \"num_nodes\": g.number_of_nodes(),\n",
    "        \"num_edges\": g.number_of_edges(),\n",
    "        \"density\": round(nx.density(g), 4)\n",
    "    }\n",
    "\n",
    "@network_agent.tool\n",
    "def calculate_degree_centrality(\n",
    "    ctx: RunContext[NetworkDeps],\n",
    "    graph_id: str,\n",
    "    node: int\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calculate degree centrality for a node. Degree centrality measures how many connections a node has.\n",
    "\n",
    "    Args:\n",
    "        graph_id: ID of the graph to analyze\n",
    "        node: The node ID to calculate centrality for\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with degree and normalized centrality value\n",
    "    \"\"\"\n",
    "    print(f\"Calculating degree centrality...\\t graph_id: {graph_id}\\t node: {node}\")\n",
    "    g = ctx.deps.graphs[graph_id]\n",
    "    # first check if node is in graph\n",
    "    if node not in g:\n",
    "        return {\n",
    "            \"error\": f\"Node {node} not found in graph {graph_id}\"\n",
    "        }\n",
    "    deg = g.degree(node)\n",
    "    max_possible = g.number_of_nodes() - 1\n",
    "    normalized = deg / max_possible if max_possible > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"node\": node,\n",
    "        \"degree\": deg,\n",
    "        \"normalized_centrality\": round(normalized, 4)\n",
    "    }\n",
    "\n",
    "@network_agent.tool\n",
    "def calculate_betweenness(\n",
    "    ctx: RunContext[NetworkDeps],\n",
    "    graph_id: str,\n",
    "    node: int\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calculate betweenness centrality for a node. High betweenness nodes are 'bridges' in the network.\n",
    "\n",
    "    Args:\n",
    "        graph_id: ID of the graph to analyze\n",
    "        node: The node ID to calculate betweenness for\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with betweenness centrality value\n",
    "    \"\"\"\n",
    "    print(f\"Calculating betweenness centrality...\\t graph_id: {graph_id}\\t node: {node}\")\n",
    "    g = ctx.deps.graphs[graph_id]\n",
    "    bc = nx.betweenness_centrality(g)\n",
    "\n",
    "    return {\n",
    "        \"node\": node,\n",
    "        \"betweenness_centrality\": round(bc[node], 4)\n",
    "    }\n",
    "\n",
    "@network_agent.tool\n",
    "def calculate_clustering_coefficient(\n",
    "    ctx: RunContext[NetworkDeps],\n",
    "    graph_id: str\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Calculate global clustering coefficient. Values close to 1 indicate high clustering.\n",
    "\n",
    "    Args:\n",
    "        graph_id: ID of the graph to analyze\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with clustering coefficient\n",
    "    \"\"\"\n",
    "    print(f\"Calculating clustering coefficient...\\t graph_id: {graph_id}\")\n",
    "    g = ctx.deps.graphs[graph_id]\n",
    "    cc = nx.average_clustering(g)\n",
    "\n",
    "    return {\n",
    "        \"clustering_coefficient\": round(cc, 4)\n",
    "    }\n",
    "\n",
    "@network_agent.tool\n",
    "def find_shortest_path(\n",
    "    ctx: RunContext[NetworkDeps],\n",
    "    graph_id: str,\n",
    "    source: int,\n",
    "    target: int\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Find shortest path between two nodes. Returns the path and its length.\n",
    "\n",
    "    Args:\n",
    "        graph_id: ID of the graph to search\n",
    "        source: Starting node ID\n",
    "        target: Destination node ID\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with path information\n",
    "    \"\"\"\n",
    "    print(f\"Finding shortest path...\\t graph_id: {graph_id}\\t source: {source}\\t target: {target}\")\n",
    "    g = ctx.deps.graphs[graph_id]\n",
    "\n",
    "    try:\n",
    "        path = nx.shortest_path(g, source, target)\n",
    "        return {\n",
    "            \"found\": True,\n",
    "            \"path\": path,\n",
    "            \"length\": len(path) - 1\n",
    "        }\n",
    "    except nx.NetworkXNoPath:\n",
    "        return {\n",
    "            \"found\": False,\n",
    "            \"message\": f\"No path exists between nodes {source} and {target}\"\n",
    "        }\n",
    "\n",
    "print(\"Network analysis tools defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "network-agent-implementation",
   "metadata": {},
   "source": [
    "### Network Analysis Agent\n",
    "\n",
    "Now let's create an agent that can use these network analysis tools. This agent will be able to answer questions about networks by calling the appropriate functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "network-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network_agent(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Run a network analysis agent that can use multiple tools to answer questions.\n",
    "\n",
    "    PydanticAI handles:\n",
    "    - Multi-turn conversations\n",
    "    - Tool call dispatch\n",
    "    - Message history management\n",
    "    - Result formatting\n",
    "    \"\"\"\n",
    "    print(f\"User: {user_query}\\n\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Create fresh dependencies for this conversation\n",
    "    deps = NetworkDeps(graphs={})\n",
    "\n",
    "    # PydanticAI handles all the complexity!\n",
    "    result = network_agent.run_sync(user_query, deps=deps)\n",
    "\n",
    "    print(f\"\\nFinal Answer:\\n{result.output}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-network-agent",
   "metadata": {},
   "source": [
    "### Testing the Network Analysis Agent\n",
    "\n",
    "Let's test our agent with progressively more complex questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5abdf00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=419205;https://logfire-us.pydantic.dev/sglyon/cap-6318-example\u001b\\\u001b[4;36mhttps://logfire-us.pydantic.dev/sglyon/cap-6318-example\u001b[0m\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "import logfire\n",
    "\n",
    "# Configure Logfire\n",
    "logfire.configure(\n",
    "    send_to_logfire='if-token-present',\n",
    ")\n",
    "logfire.instrument_pydantic_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "test-simple-network",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: \n",
      "I have a social network with the following friendships (edges):\n",
      "- Person 1 is friends with persons 2, 3, and 4\n",
      "- Person 2 is friends with persons 1 and 3\n",
      "- Person 3 is friends with persons 1, 2, and 4\n",
      "- Person 4 is friends with persons 1 and 3\n",
      "- Person 5 is friends with nobody\n",
      "\n",
      "Create this network (call it 'social') and tell me:\n",
      "1. What is the average clustering coefficient?\n",
      "2. Which person has the highest degree centrality?\n",
      "\n",
      "think carefully, proceed step by step.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "19:14:07.011 network_agent run\n",
      "19:14:07.012   chat claude-haiku-4-5\n",
      "19:14:10.734   running 7 tools\n",
      "19:14:10.735     running tool: create_network\n",
      "19:14:10.736     running tool: calculate_clustering_coefficient\n",
      "19:14:10.736     running tool: calculate_degree_centrality\n",
      "19:14:10.736     running tool: calculate_degree_centrality\n",
      "19:14:10.737     running tool: calculate_degree_centrality\n",
      "19:14:10.737     running tool: calculate_degree_centrality\n",
      "19:14:10.737     running tool: calculate_degree_centrality\n",
      "Creating graph...\t edges: [[1, 2], [1, 3], [1, 4], [2, 3], [3, 4]]\t graph_id: social\n",
      "Calculating clustering coefficient...\t graph_id: social\n",
      "Calculating degree centrality...\t graph_id: social\t node: 2\n",
      "Calculating degree centrality...\t graph_id: social\t node: 3\n",
      "Calculating degree centrality...\t graph_id: social\t node: 4\n",
      "Calculating degree centrality...\t graph_id: social\t node: 5\n",
      "Calculating degree centrality...\t graph_id: social\t node: 1\n",
      "19:14:10.742   chat claude-haiku-4-5\n",
      "\n",
      "Final Answer:\n",
      "Perfect! Here are the results:\n",
      "\n",
      "## Network Created: 'social'\n",
      "- **Nodes**: 4 (Persons 1-4; Person 5 has no connections so wasn't included)\n",
      "- **Edges**: 5 friendships\n",
      "- **Network Density**: 0.8333 (very densely connected!)\n",
      "\n",
      "## Analysis Results:\n",
      "\n",
      "**1. Average Clustering Coefficient: 0.8333**\n",
      "   - This is very high (close to 1), indicating that the network is highly clustered\n",
      "   - Friends of each person tend to also be friends with each other, forming tight-knit groups\n",
      "\n",
      "**2. Degree Centrality Rankings:**\n",
      "   - **Persons 1 and 3 are tied for highest degree centrality** (normalized centrality = 1.0)\n",
      "     - Person 1 has 3 friends (2, 3, 4)\n",
      "     - Person 3 has 3 friends (1, 2, 4)\n",
      "   - Person 2 has 2 friends (1, 3) - normalized centrality: 0.6667\n",
      "   - Person 4 has 2 friends (1, 3) - normalized centrality: 0.6667\n",
      "   - Person 5 is isolated (0 friends)\n",
      "\n",
      "**Summary**: Persons 1 and 3 are the most connected individuals in this social network, making them the most central figures. The network is highly connected with friends of friends also being friends with each other.\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Basic network analysis\n",
    "query1 = \"\"\"\n",
    "I have a social network with the following friendships (edges):\n",
    "- Person 1 is friends with persons 2, 3, and 4\n",
    "- Person 2 is friends with persons 1 and 3\n",
    "- Person 3 is friends with persons 1, 2, and 4\n",
    "- Person 4 is friends with persons 1 and 3\n",
    "- Person 5 is friends with nobody\n",
    "\n",
    "Create this network (call it 'social') and tell me:\n",
    "1. What is the average clustering coefficient?\n",
    "2. Which person has the highest degree centrality?\n",
    "\n",
    "think carefully, proceed step by step.\n",
    "\"\"\"\n",
    "\n",
    "network1_result = run_network_agent(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "test-path-finding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: \n",
      "Create a network called 'social' with edges:\n",
      "[[1,2], [1,3], [1,4], [2,1], [2,3], [3,1], [3,2], [3,4], [4,1], [4,3]]\n",
      "\n",
      "Then find the shortest path from person 2 to person 4.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "19:16:01.732 network_agent run\n",
      "19:16:01.734   chat claude-haiku-4-5\n",
      "19:16:03.368   running 2 tools\n",
      "19:16:03.368     running tool: create_network\n",
      "19:16:03.368     running tool: find_shortest_path\n",
      "Creating graph...\t edges: [[1, 2], [1, 3], [1, 4], [2, 1], [2, 3], [3, 1], [3, 2], [3, 4], [4, 1], [4, 3]]\t graph_id: social\n",
      "Finding shortest path...\t graph_id: social\t source: 2\t target: 4\n",
      "19:16:03.370   chat claude-haiku-4-5\n",
      "\n",
      "Final Answer:\n",
      "Perfect! Here are the results:\n",
      "\n",
      "**Network Created: 'social'**\n",
      "- Number of nodes: 4\n",
      "- Number of edges: 5\n",
      "- Density: 0.8333 (highly connected network)\n",
      "\n",
      "**Shortest Path from Person 2 to Person 4:**\n",
      "- **Path:** 2 → 1 → 4\n",
      "- **Length:** 2 steps\n",
      "\n",
      "The shortest route from person 2 to person 4 is through person 1, requiring 2 connections.\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Path finding\n",
    "# Note: We need to recreate the network since each call gets fresh dependencies.\n",
    "#       We could easily fix this by not recreating the NetworkDeps each time.\n",
    "query2 = \"\"\"\n",
    "Create a network called 'social' with edges:\n",
    "[[1,2], [1,3], [1,4], [2,1], [2,3], [3,1], [3,2], [3,4], [4,1], [4,3]]\n",
    "\n",
    "Then find the shortest path from person 2 to person 4.\n",
    "\"\"\"\n",
    "\n",
    "network2_result = run_network_agent(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[UserPromptPart(content=\"\\nCreate a network called 'social' with edges:\\n[[1,2], [1,3], [1,4], [2,1], [2,3], [3,1], [3,2], [3,4], [4,1], [4,3]]\\n\\nThen find the shortest path from person 2 to person 4.\\n\", timestamp=datetime.datetime(2025, 11, 11, 0, 16, 1, 733573, tzinfo=datetime.timezone.utc))]),\n",
       " ModelResponse(parts=[TextPart(content=\"I'll create the network and find the shortest path for you.\"), ToolCallPart(tool_name='create_network', args={'graph_id': 'social', 'edges': [[1, 2], [1, 3], [1, 4], [2, 1], [2, 3], [3, 1], [3, 2], [3, 4], [4, 1], [4, 3]]}, tool_call_id='toolu_01TBdA5PQBH1i7JGN6mYYanu'), ToolCallPart(tool_name='find_shortest_path', args={'graph_id': 'social', 'source': 2, 'target': 4}, tool_call_id='toolu_01JhnkbsDZjo9d3rHt2Do87o')], usage=RequestUsage(input_tokens=1343, output_tokens=209, details={'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1343, 'output_tokens': 209}), model_name='claude-haiku-4-5-20251001', timestamp=datetime.datetime(2025, 11, 11, 0, 16, 3, 367984, tzinfo=datetime.timezone.utc), provider_name='anthropic', provider_details={'finish_reason': 'tool_use'}, provider_response_id='msg_01VyRhXvJVWagYaqdVgKeqRT', finish_reason='tool_call'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='create_network', content={'graph_id': 'social', 'num_nodes': 4, 'num_edges': 5, 'density': 0.8333}, tool_call_id='toolu_01TBdA5PQBH1i7JGN6mYYanu', timestamp=datetime.datetime(2025, 11, 11, 0, 16, 3, 369986, tzinfo=datetime.timezone.utc)), ToolReturnPart(tool_name='find_shortest_path', content={'found': True, 'path': [2, 1, 4], 'length': 2}, tool_call_id='toolu_01JhnkbsDZjo9d3rHt2Do87o', timestamp=datetime.datetime(2025, 11, 11, 0, 16, 3, 370074, tzinfo=datetime.timezone.utc))]),\n",
       " ModelResponse(parts=[TextPart(content=\"Perfect! Here are the results:\\n\\n**Network Created: 'social'**\\n- Number of nodes: 4\\n- Number of edges: 5\\n- Density: 0.8333 (highly connected network)\\n\\n**Shortest Path from Person 2 to Person 4:**\\n- **Path:** 2 → 1 → 4\\n- **Length:** 2 steps\\n\\nThe shortest route from person 2 to person 4 is through person 1, requiring 2 connections.\")], usage=RequestUsage(input_tokens=1670, output_tokens=117, details={'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1670, 'output_tokens': 117}), model_name='claude-haiku-4-5-20251001', timestamp=datetime.datetime(2025, 11, 11, 0, 16, 4, 938462, tzinfo=datetime.timezone.utc), provider_name='anthropic', provider_details={'finish_reason': 'end_turn'}, provider_response_id='msg_01WfHCN5LphvvAmE6FMdpKLa', finish_reason='stop')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network2_result.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "test-complex-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: \n",
      "Create a new network called 'bridge' with these edges:\n",
      "[[1,2], [2,3], [3,4], [4,5], [1,3], [3,5]]\n",
      "\n",
      "Then find which node has the highest betweenness centrality. That node should be\n",
      "a 'bridge' connecting different parts of the network.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "19:18:43.882 network_agent run\n",
      "19:18:43.884   chat claude-haiku-4-5\n",
      "19:18:45.211   running 1 tool\n",
      "19:18:45.212     running tool: create_network\n",
      "Creating graph...\t edges: [[1, 2], [2, 3], [3, 4], [4, 5], [1, 3], [3, 5]]\t graph_id: bridge\n",
      "19:18:45.213   chat claude-haiku-4-5\n",
      "19:18:47.446   running 5 tools\n",
      "19:18:47.446     running tool: calculate_betweenness\n",
      "19:18:47.446     running tool: calculate_betweenness\n",
      "19:18:47.446     running tool: calculate_betweenness\n",
      "19:18:47.446     running tool: calculate_betweenness\n",
      "19:18:47.446     running tool: calculate_betweenness\n",
      "Calculating betweenness centrality...\t graph_id: bridge\t node: 1\n",
      "Calculating betweenness centrality...\t graph_id: bridge\t node: 2\n",
      "Calculating betweenness centrality...\t graph_id: bridge\t node: 3\n",
      "Calculating betweenness centrality...\t graph_id: bridge\t node: 4\n",
      "Calculating betweenness centrality...\t graph_id: bridge\t node: 5\n",
      "19:18:47.449   chat claude-haiku-4-5\n",
      "\n",
      "Final Answer:\n",
      "Perfect! Here are the results:\n",
      "\n",
      "## Network 'bridge' Summary\n",
      "- **Nodes**: 5\n",
      "- **Edges**: 6\n",
      "- **Density**: 0.6\n",
      "\n",
      "## Betweenness Centrality Results\n",
      "| Node | Betweenness Centrality |\n",
      "|------|------------------------|\n",
      "| 1    | 0.0                    |\n",
      "| 2    | 0.0                    |\n",
      "| **3** | **0.6667**             |\n",
      "| 4    | 0.0                    |\n",
      "| 5    | 0.0                    |\n",
      "\n",
      "## Key Finding\n",
      "**Node 3** is the bridge in this network with a betweenness centrality of **0.6667**. This node is crucial for connecting different parts of the network because it lies on the shortest paths between many pairs of nodes. \n",
      "\n",
      "Looking at the edge structure:\n",
      "- Node 3 connects to nodes: 2, 1, 4, and 5\n",
      "- It acts as a central hub that connects the {1, 2} cluster with the {4, 5} cluster\n",
      "- Many shortest paths between different parts of the network must pass through node 3, making it a critical bridge in the network topology\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Complex multi-step analysis\n",
    "query3 = \"\"\"\n",
    "Create a new network called 'bridge' with these edges:\n",
    "[[1,2], [2,3], [3,4], [4,5], [1,3], [3,5]]\n",
    "\n",
    "Then find which node has the highest betweenness centrality. That node should be\n",
    "a 'bridge' connecting different parts of the network.\n",
    "\"\"\"\n",
    "\n",
    "network3_result = run_network_agent(query3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-insights",
   "metadata": {},
   "source": [
    "### What We've Accomplished\n",
    "\n",
    "This network analysis agent demonstrates several powerful capabilities:\n",
    "\n",
    "**1. Multi-Step Reasoning**\n",
    "- Agent breaks down complex questions into steps\n",
    "- Calls tools in the right order (create network first, then analyze)\n",
    "- Chains multiple function calls together\n",
    "\n",
    "**2. Natural Language Understanding**\n",
    "- Parses network descriptions from text\n",
    "- Understands what analysis to perform\n",
    "- Interprets results in domain-appropriate ways\n",
    "\n",
    "**3. Computational Precision**\n",
    "- Uses real networkx algorithms\n",
    "- No approximation or hallucination\n",
    "- Results are reproducible and verifiable\n",
    "\n",
    "**4. State Management**\n",
    "- Creates and stores graphs\n",
    "- References them in subsequent queries\n",
    "- Maintains context across function calls\n",
    "\n",
    "This pattern can be extended to any computational domain - game theory, agent-based models, blockchain analysis, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "safety-header",
   "metadata": {},
   "source": [
    "## Safety and Sandboxing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "safety-intro",
   "metadata": {},
   "source": [
    "### The Danger of Unrestricted Tool Use\n",
    "\n",
    "Giving an AI agent the ability to execute functions is powerful - but also risky.\n",
    "\n",
    "Consider if we gave an agent these tools:\n",
    "```julia\n",
    "function delete_file(path::String)\n",
    "    rm(path)\n",
    "end\n",
    "\n",
    "function execute_shell_command(cmd::String)\n",
    "    run(`bash -c $cmd`)\n",
    "end\n",
    "\n",
    "function send_email(to::String, subject::String, body::String)\n",
    "    # Send email...\n",
    "end\n",
    "```\n",
    "\n",
    "Now imagine:\n",
    "- User asks: \"Clean up my files\"\n",
    "- Agent interprets broadly: deletes everything\n",
    "- Or worse: agent is prompted by malicious input to send spam\n",
    "\n",
    "This isn't hypothetical - it's a real concern as agentic AI systems become more powerful.\n",
    "\n",
    "### Safety Principles\n",
    "\n",
    "**1. Principle of Least Privilege**\n",
    "- Only expose tools that are absolutely necessary\n",
    "- Don't give file system access if you only need calculations\n",
    "- Restrict tools to their minimum required scope\n",
    "\n",
    "**2. Sandboxing**\n",
    "- Run tools in isolated environments\n",
    "- Limit access to system resources\n",
    "- Use containers (Docker) or VMs for code execution\n",
    "\n",
    "**3. Read vs Write Separation**\n",
    "- Distinguish tools that read state from those that modify it\n",
    "- Reading network data: low risk\n",
    "- Deleting data: high risk\n",
    "- Consider requiring human approval for high-risk operations\n",
    "\n",
    "**4. Input Validation**\n",
    "- Validate all function arguments\n",
    "- Check types, ranges, formats\n",
    "- Reject unexpected or malicious inputs\n",
    "\n",
    "**5. Rate Limiting**\n",
    "- Limit how many times a tool can be called\n",
    "- Prevent runaway loops or denial-of-service\n",
    "- Example: Max 100 network operations per conversation\n",
    "\n",
    "**6. Logging and Auditing**\n",
    "- Log every tool call\n",
    "- Record arguments and results\n",
    "- Enable post-hoc analysis of agent behavior\n",
    "\n",
    "### Safe Tool Design Patterns\n",
    "\n",
    "**Pattern 1: Read-Only by Default**\n",
    "```julia\n",
    "# Safe: Just reads and computes\n",
    "function get_network_stats(graph_id::String)\n",
    "    g = GRAPHS[graph_id]\n",
    "    return Dict(\n",
    "        \"nodes\" => nv(g),\n",
    "        \"edges\" => ne(g),\n",
    "        \"density\" => density(g)\n",
    "    )\n",
    "end\n",
    "\n",
    "# Risky: Modifies state\n",
    "function delete_network(graph_id::String)\n",
    "    delete!(GRAPHS, graph_id)\n",
    "end\n",
    "```\n",
    "\n",
    "**Pattern 2: Explicit Boundaries**\n",
    "```julia\n",
    "# Safe: Only works within defined space\n",
    "function create_network(graph_id::String, edges::Vector{Vector{Int}})\n",
    "    # Validate: max 1000 nodes\n",
    "    max_node = maximum(maximum.(edges))\n",
    "    if max_node > 1000\n",
    "        error(\"Networks limited to 1000 nodes\")\n",
    "    end\n",
    "    \n",
    "    # Validate: max 10000 edges\n",
    "    if length(edges) > 10000\n",
    "        error(\"Networks limited to 10000 edges\")\n",
    "    end\n",
    "    \n",
    "    # ... create network\n",
    "end\n",
    "```\n",
    "\n",
    "**Pattern 3: Confirmation for Destructive Operations**\n",
    "```julia\n",
    "# High-risk operations return a confirmation token\n",
    "function request_data_deletion(graph_id::String)\n",
    "    token = generate_confirmation_token()\n",
    "    return Dict(\n",
    "        \"message\" => \"Deleting $graph_id requires confirmation\",\n",
    "        \"confirmation_token\" => token\n",
    "    )\n",
    "end\n",
    "\n",
    "function confirm_data_deletion(token::String)\n",
    "    # Human must provide the token\n",
    "    # ... perform deletion\n",
    "end\n",
    "```\n",
    "\n",
    "### Code Execution: The Ultimate Risk\n",
    "\n",
    "One common agentic capability is **code execution** - letting agents write and run code.\n",
    "\n",
    "This is incredibly powerful:\n",
    "- Agent can perform arbitrary computations\n",
    "- Can generate visualizations\n",
    "- Can analyze data in flexible ways\n",
    "\n",
    "But also incredibly dangerous:\n",
    "- Agent could run `rm -rf /`\n",
    "- Could exfiltrate sensitive data\n",
    "- Could install malware\n",
    "\n",
    "**Safe Code Execution Strategies**:\n",
    "\n",
    "1. **Isolated Execution Environment**\n",
    "   - Docker containers with no network access\n",
    "   - Limited CPU/memory/disk\n",
    "   - No access to host filesystem\n",
    "\n",
    "2. **Language Subset**\n",
    "   - Restrict to safe operations only\n",
    "   - Parse and validate code before execution\n",
    "   - Block dangerous functions (system calls, file I/O)\n",
    "\n",
    "3. **Timeouts**\n",
    "   - Kill code that runs too long\n",
    "   - Prevent infinite loops\n",
    "\n",
    "4. **Review Before Execution**\n",
    "   - Show code to user first\n",
    "   - Let them approve or reject\n",
    "   - Only auto-execute for trusted, common operations\n",
    "\n",
    "Tools like **E2B** and **Modal** provide sandboxed code execution environments specifically designed for AI agents.\n",
    "\n",
    "### Our Network Tools: Safety Analysis\n",
    "\n",
    "Let's evaluate our network analysis tools:\n",
    "\n",
    "**✓ Safe**:\n",
    "- All tools are read-only or create temporary state\n",
    "- No file system access\n",
    "- No network access\n",
    "- No system commands\n",
    "- Bounded computational complexity (small graphs)\n",
    "\n",
    "**⚠️ Could Improve**:\n",
    "- Add max graph size limits\n",
    "- Add rate limiting (max N tools calls per session)\n",
    "- Add timeouts for expensive operations\n",
    "- Validate graph IDs (prevent path traversal attacks)\n",
    "\n",
    "**For Production**:\n",
    "- Run in separate process\n",
    "- Implement resource limits\n",
    "- Add comprehensive logging\n",
    "- Monitor for anomalous behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anthropic-tools-header",
   "metadata": {},
   "source": [
    "## Tool Use with Claude (Anthropic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anthropic-intro",
   "metadata": {},
   "source": [
    "### Different Provider, Same Concept\n",
    "\n",
    "We've been using OpenAI's function calling API. Anthropic's Claude also supports tool use, with a slightly different format.\n",
    "\n",
    "Let's see how to implement the same network analysis agent using Claude:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key-differences",
   "metadata": {},
   "source": [
    "### PydanticAI: Model-Agnostic Abstraction\n",
    "\n",
    "One of the biggest advantages of PydanticAI is that it **abstracts away provider differences**. You write your tools once, and they work with any LLM provider.\n",
    "\n",
    "**Switching Models is Trivial**:\n",
    "\n",
    "```python\n",
    "# OpenAI\n",
    "agent = Agent('openai:gpt-4o-mini')\n",
    "\n",
    "# Anthropic\n",
    "agent = Agent('anthropic:claude-3-5-sonnet-20241022')\n",
    "\n",
    "# Google\n",
    "agent = Agent('google-gpt:gemini-1.5-flash')\n",
    "\n",
    "# OpenAI with different model\n",
    "agent = Agent('openai:gpt-5')\n",
    "```\n",
    "\n",
    "The same tools work with all of them! PydanticAI handles:\n",
    "- Different API formats\n",
    "- Different schema requirements\n",
    "- Different message structures\n",
    "- Different tool calling conventions\n",
    "\n",
    "**Why This Matters**:\n",
    "\n",
    "1. **No vendor lock-in**: Switch providers based on performance, cost, or availability\n",
    "2. **A/B testing**: Compare models easily\n",
    "3. **Fallbacks**: If one provider is down, switch to another\n",
    "4. **Future-proof**: New models supported as they're added to PydanticAI\n",
    "\n",
    "**Under the Hood**: Different providers do have different APIs:\n",
    "\n",
    "**OpenAI**:\n",
    "- Uses `tools` array in request\n",
    "- Returns tool calls in response messages\n",
    "- Uses `function` schema format\n",
    "\n",
    "**Anthropic**:\n",
    "- Uses `tools` array in request\n",
    "- Returns tool calls in content blocks\n",
    "- Uses `input_schema` format (slightly different)\n",
    "\n",
    "**Google, Mistral, Others**:\n",
    "- Each has own format and conventions\n",
    "\n",
    "**PydanticAI**: Provides a unified interface, translating between your Python code and each provider's specific format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises-header",
   "metadata": {},
   "source": [
    "## Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-1",
   "metadata": {},
   "source": [
    "### Exercise 1: Game Theory Tools\n",
    "\n",
    "Building on Weeks 8-9 (Game Theory), create a set of tools for analyzing normal-form games.\n",
    "\n",
    "**Part A**: Implement these functions:\n",
    "1. `create_game(game_id, payoff_matrices)` - Create a normal-form game\n",
    "2. `find_pure_nash_equilibria(game_id)` - Find pure strategy Nash equilibria\n",
    "3. `check_dominant_strategy(game_id, player, strategy)` - Check if a strategy is dominant\n",
    "4. `calculate_expected_payoff(game_id, player, strategy_profile)` - Calculate payoffs\n",
    "\n",
    "**Part B**: Define JSON schemas for each function\n",
    "\n",
    "**Part C**: Create a game theory agent and test it with:\n",
    "- Prisoner's Dilemma\n",
    "- Matching Pennies\n",
    "- A 3x3 game of your choice\n",
    "\n",
    "**Part D**: Compare agent analysis to your own analysis from Week 8. Does the agent identify the same equilibria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exercise-1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here\n",
    "\n",
    "# Hint: Create an agent and use @agent.tool decorator\n",
    "# from pydantic_ai import Agent, RunContext\n",
    "\n",
    "# game_theory_agent = Agent('anthropic:claude-haiku-4-5')\n",
    "\n",
    "# @game_theory_agent.tool\n",
    "# def create_game(ctx: RunContext[None], game_id: str, ...):\n",
    "#     \"\"\"Create a normal-form game.\"\"\"\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-2",
   "metadata": {},
   "source": [
    "### Exercise 2: Data Analysis Agent\n",
    "\n",
    "Create an agent that can analyze datasets using statistical tools.\n",
    "\n",
    "**Part A**: Implement these tools:\n",
    "1. `load_dataset(dataset_id, data)` - Load data from array/CSV format\n",
    "2. `describe_dataset(dataset_id)` - Get summary statistics (mean, median, std, etc.)\n",
    "3. `filter_data(dataset_id, column, condition, value)` - Filter rows\n",
    "4. `aggregate_data(dataset_id, groupby_col, agg_col, operation)` - Group and aggregate\n",
    "\n",
    "**Part B**: Test with network data from Week 3-5:\n",
    "- Load degree distribution data\n",
    "- Ask agent to compute statistics\n",
    "- Ask agent to identify nodes with degree > threshold\n",
    "- Ask agent to find the average degree by some node attribute\n",
    "\n",
    "**Reflection**: How does an AI agent with data tools compare to writing analysis scripts manually? What are the trade-offs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "exercise-2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here\n",
    "\n",
    "# You'll want to use pandas\n",
    "# import pandas as pd\n",
    "# from pydantic_ai import Agent, RunContext\n",
    "# from dataclasses import dataclass\n",
    "\n",
    "# @dataclass\n",
    "# class DataDeps:\n",
    "#     datasets: dict[str, pd.DataFrame]\n",
    "\n",
    "# data_agent = Agent('anthropic:claude-haiku-4-5', deps_type=DataDeps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-3",
   "metadata": {},
   "source": [
    "### Exercise 3: Multi-Tool Reasoning\n",
    "\n",
    "Test your network analysis agent with questions that require multiple tool calls and reasoning.\n",
    "\n",
    "**Questions to test**:\n",
    "\n",
    "1. \"Create two networks: A with edges [[1,2],[2,3],[3,1]] and B with edges [[1,2],[2,3],[3,4],[4,1]]. Which one has higher clustering?\"\n",
    "\n",
    "2. \"In the social network from earlier, find the shortest path from node 1 to node 5. Then calculate the betweenness centrality of each node on that path. Which node on the path is most 'bridge-like'?\"\n",
    "\n",
    "3. \"Create a star network where node 1 connects to nodes 2, 3, 4, 5, 6 (call it 'star'). Calculate the degree centrality of the center node and a peripheral node. What's the ratio?\"\n",
    "\n",
    "**Analysis**:\n",
    "- How many tool calls did each question require?\n",
    "- Did the agent chain them correctly?\n",
    "- Were there any errors or surprising behaviors?\n",
    "- How did the agent interpret and synthesize results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "exercise-3-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test your agent with the questions above\n",
    "\n",
    "# Example:\n",
    "# result = run_network_agent(\"Create two networks...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-4",
   "metadata": {},
   "source": [
    "### Exercise 4: Safety Analysis\n",
    "\n",
    "Consider the following tool definitions and analyze their safety:\n",
    "\n",
    "```julia\n",
    "# Tool 1\n",
    "function run_julia_code(code::String)\n",
    "    eval(Meta.parse(code))\n",
    "end\n",
    "\n",
    "# Tool 2\n",
    "function download_file(url::String, save_path::String)\n",
    "    download(url, save_path)\n",
    "end\n",
    "\n",
    "# Tool 3\n",
    "function send_http_request(url::String, method::String, body::String)\n",
    "    HTTP.request(method, url, body=body)\n",
    "end\n",
    "\n",
    "# Tool 4\n",
    "function analyze_text(text::String)\n",
    "    return Dict(\n",
    "        \"word_count\" => length(split(text)),\n",
    "        \"char_count\" => length(text),\n",
    "        \"sentiment\" => \"positive\"  # Simplified\n",
    "    )\n",
    "end\n",
    "```\n",
    "\n",
    "**For each tool, answer**:\n",
    "1. What are the security risks?\n",
    "2. What attacks could a malicious user attempt?\n",
    "3. How would you make it safer?\n",
    "4. Should this tool be available to AI agents at all? Why or why not?\n",
    "\n",
    "**Design challenge**: Redesign Tools 1-3 to be safer while maintaining usefulness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise-4-response",
   "metadata": {},
   "source": [
    "**Your Analysis**:\n",
    "\n",
    "Tool 1 - run_julia_code:\n",
    "- Risks: ...\n",
    "- Attacks: ...\n",
    "- Safer version: ...\n",
    "\n",
    "(Continue for other tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connections-header",
   "metadata": {},
   "source": [
    "## Connecting to Course Themes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connections-content",
   "metadata": {},
   "source": [
    "### Computational Social Complexity and Tool Use\n",
    "\n",
    "Throughout this course, we've studied complex systems computationally:\n",
    "\n",
    "**Networks (Weeks 3-5)**:\n",
    "- We analyzed network structure with Graphs.jl\n",
    "- Now: AI agents can perform the same analyses via tools\n",
    "- Implication: Natural language interface to network science\n",
    "\n",
    "**Agent-Based Models (Weeks 6-7)**:\n",
    "- We built simulations of agents with simple rules\n",
    "- Now: AI agents can *run* those simulations and interpret results\n",
    "- Implication: Agents analyzing agents - meta-level reasoning\n",
    "\n",
    "**Game Theory (Weeks 8-9)**:\n",
    "- We computed equilibria and analyzed strategic behavior\n",
    "- Now: AI agents can solve games and explain the solutions\n",
    "- Implication: AI as game theory consultant\n",
    "\n",
    "**Blockchains (Weeks 11-12)**:\n",
    "- We'll analyze on-chain data and smart contracts\n",
    "- Soon: AI agents that can query blockchain state and interpret transactions\n",
    "- Implication: Natural language blockchain analysis\n",
    "\n",
    "### The Bigger Picture: Computational Assistants\n",
    "\n",
    "What we've built in this lecture is a **computational assistant**:\n",
    "- Understands natural language questions\n",
    "- Translates to computational operations\n",
    "- Executes precise calculations\n",
    "- Interprets and explains results\n",
    "\n",
    "This is qualitatively different from chatbots:\n",
    "- **Chatbots**: Generate plausible text\n",
    "- **Computational assistants**: Generate verified results\n",
    "\n",
    "The key is the tool layer - it grounds the AI in actual computation.\n",
    "\n",
    "### Emergence Revisited\n",
    "\n",
    "Remember our recurring theme of emergence:\n",
    "- Simple rules → Complex behavior (ABMs)\n",
    "- Local interactions → Global patterns (Networks)\n",
    "- Individual rationality → Collective outcomes (Game Theory)\n",
    "\n",
    "Tool use adds another dimension:\n",
    "- **Training objective**: Next-word prediction\n",
    "- **Emergent capability**: Tool use\n",
    "\n",
    "LLMs weren't explicitly trained to \"use tools\". They learned it from:\n",
    "- Seeing API documentation in training data\n",
    "- Seeing code that calls functions\n",
    "- General pattern recognition\n",
    "\n",
    "This is emergence at the model capability level.\n",
    "\n",
    "### What This Enables for Research\n",
    "\n",
    "As computational social scientists, tool-using AI agents open new possibilities:\n",
    "\n",
    "**1. Exploratory Data Analysis**\n",
    "- \"Show me the degree distribution\"\n",
    "- \"Find communities in this network\"\n",
    "- Agent handles the mechanics, you think about implications\n",
    "\n",
    "**2. Hypothesis Testing**\n",
    "- \"Is there a correlation between centrality and outcome?\"\n",
    "- Agent runs statistical tests, reports results\n",
    "- You focus on interpretation and theory\n",
    "\n",
    "**3. Simulation and Experimentation**\n",
    "- \"Run the Schelling model with these parameters\"\n",
    "- \"Compare segregation outcomes across 10 different preference thresholds\"\n",
    "- Agent orchestrates experiments\n",
    "\n",
    "**4. Reproducible Research**\n",
    "- Natural language → Code → Results\n",
    "- Full chain is logged and reproducible\n",
    "- Others can verify your computational analyses\n",
    "\n",
    "**5. Education and Dissemination**\n",
    "- Students can explore concepts interactively\n",
    "- Policymakers can query models without coding\n",
    "- Democratizes access to computational tools\n",
    "\n",
    "The future of computational social science may involve collaboration between human researchers and AI agents, each contributing their strengths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-content",
   "metadata": {},
   "source": [
    "In this lecture, we've explored how to transform AI agents from conversational systems into computational actors:\n",
    "\n",
    "✓ **Implemented function calling** with modern LLM APIs (OpenAI and Anthropic)\n",
    "\n",
    "✓ **Designed JSON schemas** to describe tool interfaces to AI agents\n",
    "\n",
    "✓ **Built a network analysis toolkit** exposing Graphs.jl functions to agents\n",
    "\n",
    "✓ **Understood the Model Context Protocol** as a standard for tool interoperability\n",
    "\n",
    "✓ **Analyzed safety considerations** for tool use and code execution\n",
    "\n",
    "✓ **Created agents that compute, not just converse** - executing real Julia code\n",
    "\n",
    "**Key Takeaways**:\n",
    "\n",
    "1. **Function calling bridges language and computation** - agents can DO things, not just describe them\n",
    "\n",
    "2. **JSON schemas are the interface language** - clear descriptions enable agents to use tools correctly\n",
    "\n",
    "3. **MCP provides standardization** - write tools once, use with any AI application\n",
    "\n",
    "4. **Safety is paramount** - unrestricted tool use is dangerous, design with security in mind\n",
    "\n",
    "5. **Multi-step reasoning emerges** - agents chain tool calls to solve complex problems\n",
    "\n",
    "6. **Domain expertise encoded as tools** - computational social science becomes accessible via natural language\n",
    "\n",
    "7. **Precision matters** - tool use gives verified results, not approximations\n",
    "\n",
    "**Next Lecture**: We'll explore structured output patterns and type safety with PydanticAI, learning how to build more robust and reliable agentic systems with strong validation and error handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-reading",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "**Function Calling and Tool Use**:\n",
    "- Schick et al. (2023) \"Toolformer: Language Models Can Teach Themselves to Use Tools\" [arXiv:2302.04761](https://arxiv.org/abs/2302.04761)\n",
    "- Qin et al. (2023) \"Tool Learning with Foundation Models\" [arXiv:2304.08354](https://arxiv.org/abs/2304.08354)\n",
    "- Patil et al. (2023) \"Gorilla: Large Language Model Connected with Massive APIs\" [arXiv:2305.15334](https://arxiv.org/abs/2305.15334)\n",
    "\n",
    "**Model Context Protocol**:\n",
    "- MCP Specification: [https://modelcontextprotocol.io/](https://modelcontextprotocol.io/)\n",
    "- MCP Announcement Blog Post: [https://www.anthropic.com/news/model-context-protocol](https://www.anthropic.com/news/model-context-protocol)\n",
    "- MCP Server Examples: [https://github.com/modelcontextprotocol/servers](https://github.com/modelcontextprotocol/servers)\n",
    "\n",
    "**API Documentation**:\n",
    "- OpenAI Function Calling: [https://platform.openai.com/docs/guides/function-calling](https://platform.openai.com/docs/guides/function-calling)\n",
    "- Anthropic Tool Use: [https://docs.anthropic.com/claude/docs/tool-use](https://docs.anthropic.com/claude/docs/tool-use)\n",
    "\n",
    "**Safety and Sandboxing**:\n",
    "- E2B Code Interpreter: [https://e2b.dev/](https://e2b.dev/)\n",
    "- Modal Sandboxed Execution: [https://modal.com/](https://modal.com/)\n",
    "- Kang et al. (2023) \"If LLM Is the Wizard, Then Code Is the Wand\" [arXiv:2401.00812](https://arxiv.org/abs/2401.00812)\n",
    "\n",
    "**Agentic Systems**:\n",
    "- Wang et al. (2024) \"A Survey on Large Language Model Based Autonomous Agents\" [arXiv:2308.11432](https://arxiv.org/abs/2308.11432)\n",
    "- Xi et al. (2023) \"The Rise and Potential of Large Language Model Based Agents\" [arXiv:2309.07864](https://arxiv.org/abs/2309.07864)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
