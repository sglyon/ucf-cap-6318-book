{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Reinforcement learning, I - the problem\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "- Linear Algebra\n",
    "- Statistics and Probability\n",
    "- Dynamic Programming\n",
    "\n",
    "**Outcomes**\n",
    "\n",
    "- Understand the core structure of the reinforcement learning project\n",
    "- See how \"Robot vaccums\" may be an example of RL techiniques\n",
    "- Know the multi-armed bandit problem and see apply the epsilon greedy algorithm to it\n",
    "\n",
    "**References**\n",
    "\n",
    "- Barto & Sutton book (online by authors [here](http://incompleteideas.net/book/the-book.html)) chapters 1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Introduction &#x2013; Meet Roomba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://www.youtube.com/embed/OljPRVMfXW4\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f69304b02e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"OljPRVMfXW4\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### My Roomba: first clean\n",
    "\n",
    "\n",
    "\n",
    "-   Notified me it would take extra long to create a map\n",
    "-   Spent about 4 hours moving a few feet, bumping into something, then\n",
    "    moving a few more feet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### One Year Later\n",
    "\n",
    "\n",
    "\n",
    "-   Now Roomba runs in about 2 1/2 hours\n",
    "-   Rarely bumps in to anything\n",
    "-   Cleans automatically on a schedule\n",
    "-   Can clean individual rooms on command\n",
    "-   Learns a new path when we re-arrange furniture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### How might Roomba work?\n",
    "\n",
    "\n",
    "\n",
    "-   Roomba first had to `explore` my house\n",
    "    -   To do this, it `acted` by moving to various locations\n",
    "    -   In response to each movement Roomba received a `signal` about its `state`\n",
    "        -   Is it near an object (via cameras)\n",
    "        -   Did it just bump into something (via sensors)\n",
    "    -   After receiving signal, Roomba chose to `act` again\n",
    "-   Then, Roomba can `exploit` the knowledge it gained to achieve it's `goal`\n",
    "    -   The `goal` for Roomba is to clean my house as effectively and\n",
    "        efficiently as possible\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## What is Reinforcement Learning?\n",
    "\n",
    "\n",
    "\n",
    "-   Reinforcement Learning (RL) is a branch of Computer Science (Machine Learning)\n",
    "    that aims to find algorithms that can learn by doing\n",
    "-   To understand RL, we need to understand:\n",
    "    1.  The RL problem/setting - today\n",
    "    2.  RL algorithms - another day\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### The Reinforcement Learning Problem\n",
    "\n",
    "-   Time is discrete and indexed by $t$\n",
    "-   At each time step (period) the RL agent observes the state of the\n",
    "    environment: $S_t \\in \\mathcal{S}$\n",
    "-   The agent must choose an action $A_t \\in \\mathcal{A}(S_t)$\n",
    "-   At the start of period $t+1$, the agent gets a reward $R_{t+1} \\in\n",
    "           \\mathbb{R}$\n",
    "    -   Reward depends, perhaps stochastically, on $S_t$ and $A_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Th RL Problem: Objective\n",
    "\n",
    "- The RL agent and its environment give rise to the following sequence of\n",
    "  events: $$S_0, A_0, R_1, S_1, A_1, R_2, S_2, A_2, R_3, \\dots$$\n",
    "- The *goal* of the RL agent is to learn to behave optimally by interacting\n",
    "  with its environment\n",
    "   - Observe $S$, choose $A$, observe $R$... repeat!\n",
    "   - Try to maximize all the $R_t$\n",
    "- More formally: $$\\max_{\\{A_t\\}_t} \\sum_{t=0}^{T} \\beta^t R_t$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### The RL Problem, Illustrated\n",
    "\n",
    "\n",
    "\n",
    "-   The setting for RL can be understood by diagram below (From Barto &\n",
    "    Sutton book)\n",
    "\n",
    "![./rl-setting.png](./rl-setting.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Roomba as RL Problem?\n",
    "\n",
    "- We can think of Roomba as an RL agent\n",
    "- Each moment in time it receives signals from its sensors ($S_t$)\n",
    "- It chooses whether to turn, slow down, speed up, etc. ($A_t$)\n",
    "- Reward $R_{t+1}$ might be:\n",
    "    - Collision status\n",
    "    - Percentage of job complete\n",
    "- Note: Roomba was almost certainly programmed more deliberately than this,\n",
    "    but it is fun to think about!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Challenges in RL\n",
    "\n",
    "\n",
    "\n",
    "-   Solutions to the RL problem share some common challenges and obstacles\n",
    "    -   Exploration vs exploitation: how to both gather information and behave\n",
    "        optimally?\n",
    "    -   Curse of dimensionality: $\\mathcal{S}$ and $\\mathcal{A}$ can be very\n",
    "        large (example: self driving cars)\n",
    "    -   Time delays: perhaps actions in $t$ don't impact rewards until $t+N$\n",
    "        (example: exercise)\n",
    "-   We'll explore the exploration/exploitation tradeoff today\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Multi-Armed Bandits\n",
    "\n",
    "\n",
    "\n",
    "![./slot-machines.jpg](./slot-machines.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### What is a Bandit?\n",
    "\n",
    "\n",
    "\n",
    "-   To build intuition for the properties of RL problems and algorithms, we\n",
    "    will study a classic problem called the Multi-armed bandit\n",
    "-   A bandit is like a slot machine at a Casino\n",
    "    -   You pull the arm and a non-deterministic reward is paid out\n",
    "-   A multi-armed bandit is like a row of slot machines\n",
    "    -   Each machine or \"bandit\" has a fixed, but distinct and unknown\n",
    "        distribution of payoffs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### K-Armed Bandit Problem\n",
    "\n",
    "\n",
    "\n",
    "-   The variation of the multi-armed bandit problem we will study is as follows\n",
    "-   There will be $k \\in [2, 10]$ bandits\n",
    "-   For each bandit $i = 1, \\dots, k$ we will draw $\\mu_i \\sim U[-3,3]$\n",
    "-   If in time step $t$ the agent selects bandit $i$, we have $R_{t+1}\\sim\n",
    "           N(\\mu_i, 1)$\n",
    "-   The agent is allowed to know this structure (returns are normally\n",
    "    distributed with an $i$ specific mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Values\n",
    "\n",
    "-   Let $a \\in \\mathcal{A}$ represent an arbitrary action\n",
    "-   Let $q_{*}: \\mathcal{A} \\Longrightarrow \\mathbb{R}$, such that\n",
    "    $q_{*}(a)$ represents the the value of an RL agent of choosing $a$\n",
    "-   It must be that $$q_{*}(a) \\equiv E[R_{t+1} | A_t = a]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "-   The agent does not know the value of this expectation, but can approximate it\n",
    "    -   Let $Q_t: \\mathcal{S} \\times \\mathcal{A} \\Longrightarrow \\mathbb{R}$ represent the\n",
    "        agent's approximation for the value function at time $t$: $$Q_t(S_t, a)\n",
    "                 \\equiv E_t[q_{*}(a)] = E_t[R_{t+1} + Q_{t+1}(S_{t+1}, A_{t+1})| A_t =\n",
    "                 a]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Policies\n",
    "\n",
    "\n",
    "\n",
    "-   In RL a policy is a rule that dictates behavior\n",
    "-   Mathematically, a policy is a function: $\\pi_t: \\mathcal{S} \\times\n",
    "           \\mathbb{R} \\Longrightarrow \\mathcal{A}$\n",
    "-   Policies can be **determinsitic**: for each $S, R$ they always map to the\n",
    "    same $A$\n",
    "-   Policies can be **stochastic**: for each $S, R$ they map to a probability\n",
    "    distribution over $\\mathcal{A}$\n",
    "-   Policies can be **greedy**: select the action that maximizes $E_t[R_{t+1} | S_t, A_t]$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### $\\epsilon$ -Greedy Policies\n",
    "\n",
    "\n",
    "\n",
    "-   When playing a greedy policy, the RL agent chooses to forgo `exploration`\n",
    "    of the environment and `exploit` knowledge previously obtained\n",
    "-   This can be optimal, but only when the agent knows the best action\n",
    "-   When there is uncertainty about payoffs, it pays to explore, sometimes\n",
    "-   One way to handle the explore-exploit tradeoff is to use an\n",
    "    $\\epsilon$ -greedy policy\n",
    "    -   With probability $1-\\epsilon$ select a random action, with equal weights\n",
    "    -   With probability $\\epsilon$ select the action you believe is best\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Application to Bandit Problem\n",
    "\n",
    "See interactive example [here](https://sglyon.github.io/bandits/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "cap-6318",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
